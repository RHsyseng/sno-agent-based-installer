-- Logs begin at Tue 2023-06-06 02:03:04 UTC, end at Tue 2023-06-06 02:14:29 UTC. --
Jun 06 02:03:04 localhost kernel: Linux version 5.14.0-284.13.1.el9_2.x86_64 (mockbuild@x86-vm-09.build.eng.bos.redhat.com) (gcc (GCC) 11.3.1 20221121 (Red Hat 11.3.1-4), GNU ld version 2.35.2-37.el9) #1 SMP PREEMPT_DYNAMIC Thu Apr 27 13:3>
Jun 06 02:03:04 localhost kernel: The list of certified hardware and cloud instances for Red Hat Enterprise Linux 9 can be viewed at the Red Hat Ecosystem Catalog, https://catalog.redhat.com.
Jun 06 02:03:04 localhost kernel: Command line: BOOT_IMAGE=/images/pxeboot/vmlinuz coreos.liveiso=rhcos-413.92.202305021736-0 ignition.firstboot ignition.platform.id=metal
Jun 06 02:03:04 localhost kernel: x86/split lock detection: #AC: crashing the kernel on kernel split_locks and warning on user-space split_locks
Jun 06 02:03:04 localhost kernel: x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'
Jun 06 02:03:04 localhost kernel: x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'
Jun 06 02:03:04 localhost kernel: x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'
Jun 06 02:03:04 localhost kernel: x86/fpu: Supporting XSAVE feature 0x020: 'AVX-512 opmask'
Jun 06 02:03:04 localhost kernel: x86/fpu: Supporting XSAVE feature 0x040: 'AVX-512 Hi256'
Jun 06 02:03:04 localhost kernel: x86/fpu: Supporting XSAVE feature 0x080: 'AVX-512 ZMM_Hi256'
Jun 06 02:03:04 localhost kernel: x86/fpu: Supporting XSAVE feature 0x200: 'Protection Keys User registers'
Jun 06 02:03:04 localhost kernel: x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256
Jun 06 02:03:04 localhost kernel: x86/fpu: xstate_offset[5]:  832, xstate_sizes[5]:   64
Jun 06 02:03:04 localhost kernel: x86/fpu: xstate_offset[6]:  896, xstate_sizes[6]:  512
Jun 06 02:03:04 localhost kernel: x86/fpu: xstate_offset[7]: 1408, xstate_sizes[7]: 1024
Jun 06 02:03:04 localhost kernel: x86/fpu: xstate_offset[9]: 2432, xstate_sizes[9]:    8
Jun 06 02:03:04 localhost kernel: x86/fpu: Enabled xstate features 0x2e7, context size is 2440 bytes, using 'compacted' format.
Jun 06 02:03:04 localhost kernel: signal: max sigframe size: 3632
Jun 06 02:03:04 localhost kernel: BIOS-provided physical RAM map:
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000000000000-0x000000000008ffff] usable
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000000090000-0x0000000000093fff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000000094000-0x000000000009efff] usable
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x000000000009f000-0x000000000009ffff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000000100000-0x0000000053c6bfff] usable
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000053c6c000-0x0000000053c9bfff] ACPI data
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000053c9c000-0x00000000558ebfff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x00000000558ec000-0x0000000058481fff] usable
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000058482000-0x00000000584fdfff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x00000000584fe000-0x00000000595fdfff] ACPI NVS
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x00000000595fe000-0x0000000059835fff] usable
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000059836000-0x00000000598b6fff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x00000000598b7000-0x000000006f7fffff] usable
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x000000006f800000-0x000000008fffffff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000098000000-0x0000000099c0ffff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x00000000fe000000-0x00000000fe00ffff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000100000000-0x000000207fffffff] usable
Jun 06 02:03:04 localhost kernel: NX (Execute Disable) protection: active
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x505e6018-0x505ee057] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x505e6018-0x505ee057] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x505da018-0x505e5257] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x505da018-0x505e5257] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x505a4018-0x505d9057] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x505a4018-0x505d9057] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x50570018-0x505a3657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x50570018-0x505a3657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x5053c018-0x5056f657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x5053c018-0x5056f657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x50508018-0x5053b657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x50508018-0x5053b657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x504d4018-0x50507657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x504d4018-0x50507657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x504a0018-0x504d3657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x504a0018-0x504d3657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x5046c018-0x5049f657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x5046c018-0x5049f657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec5b018-0x3ec8e657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec5b018-0x3ec8e657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec27018-0x3ec5a657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec27018-0x3ec5a657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec20018-0x3ec26657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec20018-0x3ec26657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec19018-0x3ec1f657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec19018-0x3ec1f657] usable ==> usable
Jun 06 02:03:04 localhost kernel: extended physical RAM map:
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000000000000-0x000000000008ffff] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000000090000-0x0000000000093fff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000000094000-0x000000000009efff] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000000009f000-0x000000000009ffff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000000f0000-0x00000000000fffff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000000100000-0x000000003ec19017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec19018-0x000000003ec1f657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec1f658-0x000000003ec20017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec20018-0x000000003ec26657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec26658-0x000000003ec27017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec27018-0x000000003ec5a657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec5a658-0x000000003ec5b017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec5b018-0x000000003ec8e657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec8e658-0x000000005046c017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000005046c018-0x000000005049f657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000005049f658-0x00000000504a0017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000504a0018-0x00000000504d3657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000504d3658-0x00000000504d4017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000504d4018-0x0000000050507657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000050507658-0x0000000050508017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000050508018-0x000000005053b657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000005053b658-0x000000005053c017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000005053c018-0x000000005056f657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000005056f658-0x0000000050570017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000050570018-0x00000000505a3657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000505a3658-0x00000000505a4017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000505a4018-0x00000000505d9057] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000505d9058-0x00000000505da017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000505da018-0x00000000505e5257] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000505e5258-0x00000000505e6017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000505e6018-0x00000000505ee057] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000505ee058-0x0000000053c6bfff] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000053c6c000-0x0000000053c9bfff] ACPI data
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000053c9c000-0x00000000558ebfff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000558ec000-0x0000000058481fff] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000058482000-0x00000000584fdfff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000584fe000-0x00000000595fdfff] ACPI NVS
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000595fe000-0x0000000059835fff] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000059836000-0x00000000598b6fff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000598b7000-0x000000006f7fffff] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000006f800000-0x000000008fffffff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000098000000-0x0000000099c0ffff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000fe000000-0x00000000fe00ffff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000100000000-0x000000207fffffff] usable
Jun 06 02:03:04 localhost kernel: efi: EFI v2.70 by HPE
Jun 06 02:03:04 localhost kernel: efi: SMBIOS=0x540a8000 SMBIOS 3.0=0x540a6000 ACPI=0x53c9b000 ACPI 2.0=0x53c9b014 TPMFinalLog=0x5856d000 MEMATTR=0x3ec8f018 MOKvar=0x540a5000 RNG=0x540bab18 TPMEventLog=0x505ef018 
Jun 06 02:03:04 localhost kernel: efi: seeding entropy pool
Jun 06 02:03:04 localhost kernel: secureboot: Secure boot disabled
Jun 06 02:03:04 localhost kernel: SMBIOS 3.4.0 present.
Jun 06 02:03:04 localhost kernel: DMI: HPE Edgeline e920t/Edgeline e920t, BIOS H10 08/16/2022
Jun 06 02:03:04 localhost kernel: tsc: Detected 2200.000 MHz processor
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x00000000-0x00000fff] usable ==> reserved
Jun 06 02:03:04 localhost kernel: e820: remove [mem 0x000a0000-0x000fffff] usable
Jun 06 02:03:04 localhost kernel: last_pfn = 0x2080000 max_arch_pfn = 0x10000000000
Jun 06 02:03:04 localhost kernel: x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT  
Jun 06 02:03:04 localhost kernel: total RAM covered: 260080M
Jun 06 02:03:04 localhost kernel: Found optimal setting for mtrr clean up
Jun 06 02:03:04 localhost kernel:  gran_size: 64K         chunk_size: 32M         num_reg: 8          lose cover RAM: 0G
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x7f000000-0xffffffff] usable ==> reserved
Jun 06 02:03:04 localhost kernel: x2apic: enabled by BIOS, switching to x2apic ops
Jun 06 02:03:04 localhost kernel: last_pfn = 0x6f800 max_arch_pfn = 0x10000000000
Jun 06 02:03:04 localhost kernel: Using GB pages for direct mapping
Jun 06 02:03:04 localhost kernel: secureboot: Secure boot disabled
Jun 06 02:03:04 localhost kernel: RAMDISK: [mem 0x2a93b000-0x30225fff]
Jun 06 02:03:04 localhost kernel: ACPI: Early table checksum verification disabled
Jun 06 02:03:04 localhost kernel: ACPI: RSDP 0x0000000053C9B014 000024 (v02 HPE   )
Jun 06 02:03:04 localhost kernel: ACPI: XSDT 0x0000000053C84188 000124 (v01 HPE    Server   00000001      01000013)
Jun 06 02:03:04 localhost kernel: ACPI: FACP 0x0000000053C8E000 00010C (v06 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: DSDT 0x0000000053C77000 008089 (v02 HPE    Server   00000002 HPE  00020000)
Jun 06 02:03:04 localhost kernel: ACPI: FACS 0x000000005856B000 000040
Jun 06 02:03:04 localhost kernel: ACPI: SSDT 0x0000000053C99000 000C0A (v02 HPE    ADDRXLAT 00000001 INTL 20181003)
Jun 06 02:03:04 localhost kernel: ACPI: ERST 0x0000000053C98000 000250 (v01 HPE    Server   00000001 INTL 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: MCEJ 0x0000000053C97000 000130 (v01 HPE    Server   00000001 INTL 0100000D)
Jun 06 02:03:04 localhost kernel: ACPI: BERT 0x0000000053C96000 000030 (v01 HPE    Server   00000001 INTL 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: PMTT 0x0000000053C94000 000908 (v02 HPE    Server   00000001 INTL 20091013)
Jun 06 02:03:04 localhost kernel: ACPI: SSDT 0x0000000053C93000 000562 (v01 HPE    SgxSsdt  00000001 INTL 20181003)
Jun 06 02:03:04 localhost kernel: ACPI: HEST 0x0000000053C92000 00017C (v01 HPE    Server   00000001 INTL 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: EINJ 0x0000000053C91000 000170 (v01 HPE    Server   00000001 INTL 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: SSDT 0x0000000053C90000 00061B (v02 HPE    Tpm2Tabl 00001000 INTL 20181003)
Jun 06 02:03:04 localhost kernel: ACPI: TPM2 0x0000000053C8F000 00004C (v04 HPE    Server   00000002      01000013)
Jun 06 02:03:04 localhost kernel: ACPI: SSDT 0x0000000053C95000 00003A (v02 HPE    PLATOPRG 00000001 INTL 20181003)
Jun 06 02:03:04 localhost kernel: ACPI: HPET 0x0000000053C8D000 000038 (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: WDDT 0x0000000053C8C000 000040 (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: APIC 0x0000000053C8B000 00074C (v05 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: MCFG 0x0000000053C8A000 00003C (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: SLIT 0x0000000053C89000 00002D (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: SRAT 0x0000000053C88000 000680 (v03 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: HMAT 0x0000000053C87000 0000A4 (v02 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: SPMI 0x0000000053C86000 000041 (v05 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: SPCR 0x0000000053C85000 000050 (v02 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: MSCT 0x0000000053C9A000 00004E (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: BDAT 0x0000000053C83000 000030 (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: WSMT 0x0000000053C82000 000028 (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: PCCT 0x0000000053C81000 000030 (v02 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: DMAR 0x0000000053C80000 000178 (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: SSDT 0x0000000053C72000 004470 (v02 HPE    PCISSDT  00000002 HPE  00020000)
Jun 06 02:03:04 localhost kernel: ACPI: SSDT 0x0000000053C71000 0001C9 (v02 HPE    TIMESSDT 00000002 HPE  00020000)
Jun 06 02:03:04 localhost kernel: ACPI: SSDT 0x0000000053C70000 000302 (v01 HPE    pmab     00000001 1590 20181003)
Jun 06 02:03:04 localhost kernel: ACPI: OEM1 0x0000000053C6F000 000AB7 (v02 HPE    CPU  CPC 00000002 HPE  00020000)
Jun 06 02:03:04 localhost kernel: ACPI: BGRT 0x0000000053C6E000 000038 (v01 HPE    Server   00000002 1590 01000013)
Jun 06 02:03:04 localhost kernel: ACPI: FPDT 0x0000000053C6D000 000034 (v01 HPE    Server   00000002      01000013)
Jun 06 02:03:04 localhost kernel: ACPI: Reserving FACP table memory at [mem 0x53c8e000-0x53c8e10b]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving DSDT table memory at [mem 0x53c77000-0x53c7f088]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving FACS table memory at [mem 0x5856b000-0x5856b03f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SSDT table memory at [mem 0x53c99000-0x53c99c09]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving ERST table memory at [mem 0x53c98000-0x53c9824f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving MCEJ table memory at [mem 0x53c97000-0x53c9712f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving BERT table memory at [mem 0x53c96000-0x53c9602f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving PMTT table memory at [mem 0x53c94000-0x53c94907]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SSDT table memory at [mem 0x53c93000-0x53c93561]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving HEST table memory at [mem 0x53c92000-0x53c9217b]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving EINJ table memory at [mem 0x53c91000-0x53c9116f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SSDT table memory at [mem 0x53c90000-0x53c9061a]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving TPM2 table memory at [mem 0x53c8f000-0x53c8f04b]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SSDT table memory at [mem 0x53c95000-0x53c95039]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving HPET table memory at [mem 0x53c8d000-0x53c8d037]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving WDDT table memory at [mem 0x53c8c000-0x53c8c03f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving APIC table memory at [mem 0x53c8b000-0x53c8b74b]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving MCFG table memory at [mem 0x53c8a000-0x53c8a03b]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SLIT table memory at [mem 0x53c89000-0x53c8902c]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SRAT table memory at [mem 0x53c88000-0x53c8867f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving HMAT table memory at [mem 0x53c87000-0x53c870a3]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SPMI table memory at [mem 0x53c86000-0x53c86040]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SPCR table memory at [mem 0x53c85000-0x53c8504f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving MSCT table memory at [mem 0x53c9a000-0x53c9a04d]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving BDAT table memory at [mem 0x53c83000-0x53c8302f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving WSMT table memory at [mem 0x53c82000-0x53c82027]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving PCCT table memory at [mem 0x53c81000-0x53c8102f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving DMAR table memory at [mem 0x53c80000-0x53c80177]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SSDT table memory at [mem 0x53c72000-0x53c7646f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SSDT table memory at [mem 0x53c71000-0x53c711c8]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SSDT table memory at [mem 0x53c70000-0x53c70301]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving OEM1 table memory at [mem 0x53c6f000-0x53c6fab6]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving BGRT table memory at [mem 0x53c6e000-0x53c6e037]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving FPDT table memory at [mem 0x53c6d000-0x53c6d033]
Jun 06 02:03:04 localhost kernel: Setting APIC routing to cluster x2apic.
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0000 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0002 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0004 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0006 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0008 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x000a -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x000c -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x000e -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0010 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0012 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0014 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0016 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0018 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x001a -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x001c -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x001e -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0020 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0022 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0024 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0026 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0028 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x002a -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x002c -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x002e -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0030 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0032 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0034 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0036 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0038 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x003a -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x003c -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x003e -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0001 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0003 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0005 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0007 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0009 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x000b -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x000d -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x000f -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0011 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0013 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0015 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0017 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0019 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x001b -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x001d -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x001f -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0021 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0023 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0025 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0027 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0029 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x002b -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x002d -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x002f -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0031 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0033 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0035 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0037 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0039 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x003b -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x003d -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x003f -> Node 0
Jun 06 02:03:04 localhost kernel: ACPI: SRAT: Node 0 PXM 0 [mem 0x00000000-0x7fffffff]
Jun 06 02:03:04 localhost kernel: ACPI: SRAT: Node 0 PXM 0 [mem 0x100000000-0x207fffffff]
Jun 06 02:03:04 localhost kernel: NUMA: Initialized distance table, cnt=1
Jun 06 02:03:04 localhost kernel: NUMA: Node 0 [mem 0x00000000-0x7fffffff] + [mem 0x100000000-0x207fffffff] -> [mem 0x00000000-0x207fffffff]
Jun 06 02:03:04 localhost kernel: NODE_DATA(0) allocated [mem 0x207ffd4000-0x207fffefff]
Jun 06 02:03:04 localhost kernel: Zone ranges:
Jun 06 02:03:04 localhost kernel:   DMA      [mem 0x0000000000001000-0x0000000000ffffff]
Jun 06 02:03:04 localhost kernel:   DMA32    [mem 0x0000000001000000-0x00000000ffffffff]
Jun 06 02:03:04 localhost kernel:   Normal   [mem 0x0000000100000000-0x000000207fffffff]
Jun 06 02:03:04 localhost kernel:   Device   empty
Jun 06 02:03:04 localhost kernel: Movable zone start for each node
Jun 06 02:03:04 localhost kernel: Early memory node ranges
Jun 06 02:03:04 localhost kernel:   node   0: [mem 0x0000000000001000-0x000000000008ffff]
Jun 06 02:03:04 localhost kernel:   node   0: [mem 0x0000000000094000-0x000000000009efff]
Jun 06 02:03:04 localhost kernel:   node   0: [mem 0x0000000000100000-0x0000000053c6bfff]
Jun 06 02:03:04 localhost kernel:   node   0: [mem 0x00000000558ec000-0x0000000058481fff]
Jun 06 02:03:04 localhost kernel:   node   0: [mem 0x00000000595fe000-0x0000000059835fff]
Jun 06 02:03:04 localhost kernel:   node   0: [mem 0x00000000598b7000-0x000000006f7fffff]
Jun 06 02:03:04 localhost kernel:   node   0: [mem 0x0000000100000000-0x000000207fffffff]
Jun 06 02:03:04 localhost kernel: Initmem setup node 0 [mem 0x0000000000001000-0x000000207fffffff]
Jun 06 02:03:04 localhost kernel: On node 0, zone DMA: 1 pages in unavailable ranges
Jun 06 02:03:04 localhost kernel: On node 0, zone DMA: 4 pages in unavailable ranges
Jun 06 02:03:04 localhost kernel: On node 0, zone DMA: 97 pages in unavailable ranges
Jun 06 02:03:04 localhost kernel: On node 0, zone DMA32: 7296 pages in unavailable ranges
Jun 06 02:03:04 localhost kernel: On node 0, zone DMA32: 4476 pages in unavailable ranges
Jun 06 02:03:04 localhost kernel: On node 0, zone DMA32: 129 pages in unavailable ranges
Jun 06 02:03:04 localhost kernel: On node 0, zone Normal: 2048 pages in unavailable ranges
Jun 06 02:03:04 localhost kernel: ACPI: PM-Timer IO Port: 0x508
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x00] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x01] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x02] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x03] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x04] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x05] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x06] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x07] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x08] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x09] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x0a] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x0b] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x0c] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x0d] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x0e] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x0f] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x10] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x11] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x12] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x13] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x14] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x15] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x16] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x17] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x18] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x19] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x1a] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x1b] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x1c] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x1d] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x1e] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x1f] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x20] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x21] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x22] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x23] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x24] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x25] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x26] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x27] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x28] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x29] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x2a] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x2b] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x2c] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x2d] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x2e] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x2f] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x30] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x31] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x32] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x33] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x34] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x35] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x36] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x37] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x38] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x39] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x3a] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x3b] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x3c] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x3d] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x3e] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x3f] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: IOAPIC[0]: apic_id 8, version 32, address 0xfec00000, GSI 0-119
Jun 06 02:03:04 localhost kernel: ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl)
Jun 06 02:03:04 localhost kernel: ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)
Jun 06 02:03:04 localhost kernel: ACPI: Using ACPI (MADT) for SMP configuration information
Jun 06 02:03:04 localhost kernel: ACPI: HPET id: 0x8086a701 base: 0xfed00000
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ecc5000-0x3ecf5fff] usable ==> reserved
Jun 06 02:03:04 localhost kernel: ACPI: SPCR: console: uart,mmio,0x0,115200
Jun 06 02:03:04 localhost kernel: TSC deadline timer available
Jun 06 02:03:04 localhost kernel: smpboot: Allowing 64 CPUs, 0 hotplug CPUs
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x00000000-0x00000fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x00090000-0x00093fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x0009f000-0x0009ffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x000a0000-0x000effff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x000f0000-0x000fffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec19000-0x3ec19fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec1f000-0x3ec1ffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec20000-0x3ec20fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec26000-0x3ec26fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec27000-0x3ec27fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec5a000-0x3ec5afff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec5b000-0x3ec5bfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec8e000-0x3ec8efff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ecc5000-0x3ecf5fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x5046c000-0x5046cfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x5049f000-0x5049ffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x504a0000-0x504a0fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x504d3000-0x504d3fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x504d4000-0x504d4fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x50507000-0x50507fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x50508000-0x50508fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x5053b000-0x5053bfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x5053c000-0x5053cfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x5056f000-0x5056ffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x50570000-0x50570fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x505a3000-0x505a3fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x505a4000-0x505a4fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x505d9000-0x505d9fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x505da000-0x505dafff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x505e5000-0x505e5fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x505e6000-0x505e6fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x505ee000-0x505eefff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x53c6c000-0x53c9bfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x53c9c000-0x558ebfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x58482000-0x584fdfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x584fe000-0x595fdfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x59836000-0x598b6fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x6f800000-0x8fffffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x90000000-0x97ffffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x98000000-0x99c0ffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x99c10000-0xfdffffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0xfe000000-0xfe00ffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0xfe010000-0xffffffff]
Jun 06 02:03:04 localhost kernel: [mem 0x99c10000-0xfdffffff] available for PCI devices
Jun 06 02:03:04 localhost kernel: Booting paravirtualized kernel on bare hardware
Jun 06 02:03:04 localhost kernel: clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns
Jun 06 02:03:04 localhost kernel: setup_percpu: NR_CPUS:8192 nr_cpumask_bits:64 nr_cpu_ids:64 nr_node_ids:1
Jun 06 02:03:04 localhost kernel: percpu: Embedded 55 pages/cpu s188416 r8192 d28672 u262144
Jun 06 02:03:04 localhost kernel: pcpu-alloc: s188416 r8192 d28672 u262144 alloc=1*2097152
Jun 06 02:03:04 localhost kernel: pcpu-alloc: [0] 00 01 02 03 04 05 06 07 [0] 08 09 10 11 12 13 14 15 
Jun 06 02:03:04 localhost kernel: pcpu-alloc: [0] 16 17 18 19 20 21 22 23 [0] 24 25 26 27 28 29 30 31 
Jun 06 02:03:04 localhost kernel: pcpu-alloc: [0] 32 33 34 35 36 37 38 39 [0] 40 41 42 43 44 45 46 47 
Jun 06 02:03:04 localhost kernel: pcpu-alloc: [0] 48 49 50 51 52 53 54 55 [0] 56 57 58 59 60 61 62 63 
Jun 06 02:03:04 localhost kernel: Fallback order for Node 0: 0 
Jun 06 02:03:04 localhost kernel: Built 1 zonelists, mobility grouping on.  Total pages: 32951644
Jun 06 02:03:04 localhost kernel: Policy zone: Normal
Jun 06 02:03:04 localhost kernel: Kernel command line: BOOT_IMAGE=/images/pxeboot/vmlinuz coreos.liveiso=rhcos-413.92.202305021736-0 ignition.firstboot ignition.platform.id=metal
Jun 06 02:03:04 localhost kernel: Unknown kernel command line parameters "BOOT_IMAGE=/images/pxeboot/vmlinuz", will be passed to user space.
Jun 06 02:03:04 localhost kernel: Dentry cache hash table entries: 8388608 (order: 14, 67108864 bytes, linear)
Jun 06 02:03:04 localhost kernel: Inode-cache hash table entries: 4194304 (order: 13, 33554432 bytes, linear)
Jun 06 02:03:04 localhost kernel: mem auto-init: stack:off, heap alloc:off, heap free:off
Jun 06 02:03:04 localhost kernel: software IO TLB: area num 64.
Jun 06 02:03:04 localhost kernel: Memory: 1333464K/133899380K available (14342K kernel code, 5536K rwdata, 10180K rodata, 2792K init, 7524K bss, 2834016K reserved, 0K cma-reserved)
Jun 06 02:03:04 localhost kernel: random: get_random_u64 called from kmem_cache_open+0x1e/0x210 with crng_init=0
Jun 06 02:03:04 localhost kernel: SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=64, Nodes=1
Jun 06 02:03:04 localhost kernel: ftrace: allocating 44805 entries in 176 pages
Jun 06 02:03:04 localhost kernel: ftrace: allocated 176 pages with 3 groups
Jun 06 02:03:04 localhost kernel: Dynamic Preempt: voluntary
Jun 06 02:03:04 localhost kernel: rcu: Preemptible hierarchical RCU implementation.
Jun 06 02:03:04 localhost kernel: rcu:         RCU restricting CPUs from NR_CPUS=8192 to nr_cpu_ids=64.
Jun 06 02:03:04 localhost kernel:         Trampoline variant of Tasks RCU enabled.
Jun 06 02:03:04 localhost kernel:         Rude variant of Tasks RCU enabled.
Jun 06 02:03:04 localhost kernel:         Tracing variant of Tasks RCU enabled.
Jun 06 02:03:04 localhost kernel: rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies.
Jun 06 02:03:04 localhost kernel: rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=64
Jun 06 02:03:04 localhost kernel: NR_IRQS: 524544, nr_irqs: 2568, preallocated irqs: 16
Jun 06 02:03:04 localhost kernel: rcu: srcu_init: Setting srcu_struct sizes based on contention.
Jun 06 02:03:04 localhost kernel: kfence: initialized - using 2097152 bytes for 255 objects at 0x(____ptrval____)-0x(____ptrval____)
Jun 06 02:03:04 localhost kernel: random: crng init done (trusting CPU's manufacturer)
Jun 06 02:03:04 localhost kernel: Console: colour dummy device 80x25
Jun 06 02:03:04 localhost kernel: printk: console [tty0] enabled
Jun 06 02:03:04 localhost kernel: ACPI: Core revision 20211217
Jun 06 02:03:04 localhost kernel: clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 79635855245 ns
Jun 06 02:03:04 localhost kernel: APIC: Switch to symmetric I/O mode setup
Jun 06 02:03:04 localhost kernel: DMAR: Host address width 46
Jun 06 02:03:04 localhost kernel: DMAR: DRHD base: 0x000000c17fc000 flags: 0x0
Jun 06 02:03:04 localhost kernel: DMAR: dmar0: reg_base_addr c17fc000 ver 4:0 cap 8ed008c40780466 ecap 60000f050df
Jun 06 02:03:04 localhost kernel: DMAR: DRHD base: 0x000000d4ffc000 flags: 0x0
Jun 06 02:03:04 localhost kernel: DMAR: dmar1: reg_base_addr d4ffc000 ver 4:0 cap 8ed008c40780466 ecap 60000f050df
Jun 06 02:03:04 localhost kernel: DMAR: DRHD base: 0x000000e87fc000 flags: 0x0
Jun 06 02:03:04 localhost kernel: DMAR: dmar2: reg_base_addr e87fc000 ver 4:0 cap 8ed008c40780466 ecap 60000f050df
Jun 06 02:03:04 localhost kernel: DMAR: DRHD base: 0x000000fb7fc000 flags: 0x0
Jun 06 02:03:04 localhost kernel: DMAR: dmar3: reg_base_addr fb7fc000 ver 4:0 cap 8ed008c40780466 ecap 60000f050df
Jun 06 02:03:04 localhost kernel: DMAR: DRHD base: 0x000000adffc000 flags: 0x1
Jun 06 02:03:04 localhost kernel: DMAR: dmar4: reg_base_addr adffc000 ver 4:0 cap 8ed008c40780466 ecap 60000f050df
Jun 06 02:03:04 localhost kernel: DMAR: RMRR base: 0x00000058483000 end: 0x00000058485fff
Jun 06 02:03:04 localhost kernel: DMAR: RMRR base: 0x000000584d3000 end: 0x000000584d3fff
Jun 06 02:03:04 localhost kernel: DMAR: ATSR flags: 0x0
Jun 06 02:03:04 localhost kernel: DMAR-IR: IOAPIC id 8 under DRHD base  0xadffc000 IOMMU 4
Jun 06 02:03:04 localhost kernel: DMAR-IR: HPET id 0 under DRHD base 0xadffc000
Jun 06 02:03:04 localhost kernel: DMAR-IR: Queued invalidation will be enabled to support x2apic and Intr-remapping.
Jun 06 02:03:04 localhost kernel: DMAR-IR: Enabled IRQ remapping in x2apic mode
Jun 06 02:03:04 localhost kernel: ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1
Jun 06 02:03:04 localhost kernel: clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1fb633008a4, max_idle_ns: 440795292230 ns
Jun 06 02:03:04 localhost kernel: Calibrating delay loop (skipped), value calculated using timer frequency.. 4400.00 BogoMIPS (lpj=2200000)
Jun 06 02:03:04 localhost kernel: pid_max: default: 65536 minimum: 512
Jun 06 02:03:04 localhost kernel: LSM: Security Framework initializing
Jun 06 02:03:04 localhost kernel: Yama: becoming mindful.
Jun 06 02:03:04 localhost kernel: SELinux:  Initializing.
Jun 06 02:03:04 localhost kernel: LSM support for eBPF active
Jun 06 02:03:04 localhost kernel: Mount-cache hash table entries: 131072 (order: 8, 1048576 bytes, linear)
Jun 06 02:03:04 localhost kernel: Mountpoint-cache hash table entries: 131072 (order: 8, 1048576 bytes, linear)
Jun 06 02:03:04 localhost kernel: x86/cpu: SGX disabled by BIOS.
Jun 06 02:03:04 localhost kernel: x86/tme: not enabled by BIOS
Jun 06 02:03:04 localhost kernel: CPU0: Thermal monitoring enabled (TM1)
Jun 06 02:03:04 localhost kernel: x86/cpu: User Mode Instruction Prevention (UMIP) activated
Jun 06 02:03:04 localhost kernel: process: using mwait in idle threads
Jun 06 02:03:04 localhost kernel: Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0
Jun 06 02:03:04 localhost kernel: Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0
Jun 06 02:03:04 localhost kernel: Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization
Jun 06 02:03:04 localhost kernel: Spectre V2 : Mitigation: Enhanced IBRS
Jun 06 02:03:04 localhost kernel: Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch
Jun 06 02:03:04 localhost kernel: Spectre V2 : Spectre v2 / PBRSB-eIBRS: Retire a single CALL on VMEXIT
Jun 06 02:03:04 localhost kernel: Spectre V2 : mitigation: Enabling conditional Indirect Branch Prediction Barrier
Jun 06 02:03:04 localhost kernel: Speculative Store Bypass: Mitigation: Speculative Store Bypass disabled via prctl
Jun 06 02:03:04 localhost kernel: MMIO Stale Data: Mitigation: Clear CPU buffers
Jun 06 02:03:04 localhost kernel: Freeing SMP alternatives memory: 36K
Jun 06 02:03:04 localhost kernel: smpboot: Estimated ratio of average max frequency by base frequency (times 1024): 1349
Jun 06 02:03:04 localhost kernel: smpboot: CPU0: Intel(R) Xeon(R) Gold 6338N CPU @ 2.20GHz (family: 0x6, model: 0x6a, stepping: 0x6)
Jun 06 02:03:04 localhost kernel: cblist_init_generic: Setting adjustable number of callback queues.
Jun 06 02:03:04 localhost kernel: cblist_init_generic: Setting shift to 6 and lim to 1.
Jun 06 02:03:04 localhost kernel: cblist_init_generic: Setting shift to 6 and lim to 1.
Jun 06 02:03:04 localhost kernel: cblist_init_generic: Setting shift to 6 and lim to 1.
Jun 06 02:03:04 localhost kernel: Performance Events: PEBS fmt4+-baseline,  AnyThread deprecated, Icelake events, 32-deep LBR, full-width counters, Intel PMU driver.
Jun 06 02:03:04 localhost kernel: ... version:                5
Jun 06 02:03:04 localhost kernel: ... bit width:              48
Jun 06 02:03:04 localhost kernel: ... generic registers:      8
Jun 06 02:03:04 localhost kernel: ... value mask:             0000ffffffffffff
Jun 06 02:03:04 localhost kernel: ... max period:             00007fffffffffff
Jun 06 02:03:04 localhost kernel: ... fixed-purpose events:   4
Jun 06 02:03:04 localhost kernel: ... event mask:             0001000f000000ff
Jun 06 02:03:04 localhost kernel: rcu: Hierarchical SRCU implementation.
Jun 06 02:03:04 localhost kernel: rcu:         Max phase no-delay instances is 400.
Jun 06 02:03:04 localhost kernel: NMI watchdog: Enabled. Permanently consumes one hw-PMU counter.
Jun 06 02:03:04 localhost kernel: smp: Bringing up secondary CPUs ...
Jun 06 02:03:04 localhost kernel: x86: Booting SMP configuration:
Jun 06 02:03:04 localhost kernel: .... node  #0, CPUs:        #1  #2  #3  #4  #5  #6  #7  #8  #9 #10 #11 #12 #13 #14 #15 #16 #17 #18 #19 #20 #21 #22 #23 #24 #25 #26 #27 #28 #29 #30 #31 #32
Jun 06 02:03:04 localhost kernel: MMIO Stale Data CPU bug present and SMT on, data leak possible. See https://www.kernel.org/doc/html/latest/admin-guide/hw-vuln/processor_mmio_stale_data.html for more details.
Jun 06 02:03:04 localhost kernel:  #33 #34 #35 #36 #37 #38 #39 #40 #41 #42 #43 #44 #45 #46 #47 #48 #49 #50 #51 #52 #53 #54 #55 #56 #57 #58 #59 #60 #61 #62 #63
Jun 06 02:03:04 localhost kernel: smp: Brought up 1 node, 64 CPUs
Jun 06 02:03:04 localhost kernel: smpboot: Max logical packages: 1
Jun 06 02:03:04 localhost kernel: smpboot: Total of 64 processors activated (281600.00 BogoMIPS)
Jun 06 02:03:04 localhost kernel: node 0 deferred pages initialised in 46ms
Jun 06 02:03:04 localhost kernel: devtmpfs: initialized
Jun 06 02:03:04 localhost kernel: x86/mm: Memory block size: 2048MB
Jun 06 02:03:04 localhost kernel: ACPI: PM: Registering ACPI NVS region [mem 0x584fe000-0x595fdfff] (17825792 bytes)
Jun 06 02:03:04 localhost kernel: clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns
Jun 06 02:03:04 localhost kernel: futex hash table entries: 16384 (order: 8, 1048576 bytes, linear)
Jun 06 02:03:04 localhost kernel: pinctrl core: initialized pinctrl subsystem
Jun 06 02:03:04 localhost kernel: NET: Registered PF_NETLINK/PF_ROUTE protocol family
Jun 06 02:03:04 localhost kernel: DMA: preallocated 4096 KiB GFP_KERNEL pool for atomic allocations
Jun 06 02:03:04 localhost kernel: DMA: preallocated 4096 KiB GFP_KERNEL|GFP_DMA pool for atomic allocations
Jun 06 02:03:04 localhost kernel: DMA: preallocated 4096 KiB GFP_KERNEL|GFP_DMA32 pool for atomic allocations
Jun 06 02:03:04 localhost kernel: audit: initializing netlink subsys (disabled)
Jun 06 02:03:04 localhost kernel: audit: type=2000 audit(1686016980.716:1): state=initialized audit_enabled=0 res=1
Jun 06 02:03:04 localhost kernel: thermal_sys: Registered thermal governor 'fair_share'
Jun 06 02:03:04 localhost kernel: thermal_sys: Registered thermal governor 'step_wise'
Jun 06 02:03:04 localhost kernel: thermal_sys: Registered thermal governor 'user_space'
Jun 06 02:03:04 localhost kernel: cpuidle: using governor menu
Jun 06 02:03:04 localhost kernel: Invalid PCCT: 0 PCC subspaces
Jun 06 02:03:04 localhost kernel: HugeTLB: can optimize 4095 vmemmap pages for hugepages-1048576kB
Jun 06 02:03:04 localhost kernel: ACPI FADT declares the system doesn't support PCIe ASPM, so disable it
Jun 06 02:03:04 localhost kernel: acpiphp: ACPI Hot Plug PCI Controller Driver version: 0.5
Jun 06 02:03:04 localhost kernel: PCI: MMCONFIG for domain 0000 [bus 00-ff] at [mem 0x80000000-0x8fffffff] (base 0x80000000)
Jun 06 02:03:04 localhost kernel: PCI: MMCONFIG at [mem 0x80000000-0x8fffffff] reserved in E820
Jun 06 02:03:04 localhost kernel: PCI: Using configuration type 1 for base access
Jun 06 02:03:04 localhost kernel: ENERGY_PERF_BIAS: Set to 'normal', was 'performance'
Jun 06 02:03:04 localhost kernel: kprobes: kprobe jump-optimization is enabled. All kprobes are optimized if possible.
Jun 06 02:03:04 localhost kernel: HugeTLB: can optimize 7 vmemmap pages for hugepages-2048kB
Jun 06 02:03:04 localhost kernel: HugeTLB registered 1.00 GiB page size, pre-allocated 0 pages
Jun 06 02:03:04 localhost kernel: HugeTLB registered 2.00 MiB page size, pre-allocated 0 pages
Jun 06 02:03:04 localhost kernel: cryptd: max_cpu_qlen set to 1000
Jun 06 02:03:04 localhost kernel: ACPI: Added _OSI(Module Device)
Jun 06 02:03:04 localhost kernel: ACPI: Added _OSI(Processor Device)
Jun 06 02:03:04 localhost kernel: ACPI: Added _OSI(3.0 _SCP Extensions)
Jun 06 02:03:04 localhost kernel: ACPI: Added _OSI(Processor Aggregator Device)
Jun 06 02:03:04 localhost kernel: ACPI: Added _OSI(Linux-Dell-Video)
Jun 06 02:03:04 localhost kernel: ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio)
Jun 06 02:03:04 localhost kernel: ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics)
Jun 06 02:03:04 localhost kernel: ACPI: 8 ACPI AML tables successfully acquired and loaded
Jun 06 02:03:04 localhost kernel: ACPI: Dynamic OEM Table Load:
Jun 06 02:03:04 localhost kernel: ACPI: Interpreter enabled
Jun 06 02:03:04 localhost kernel: ACPI: PM: (supports S0 S5)
Jun 06 02:03:04 localhost kernel: ACPI: Using IOAPIC for interrupt routing
Jun 06 02:03:04 localhost kernel: HEST: Table parsing has been initialized.
Jun 06 02:03:04 localhost kernel: PCI: Using host bridge windows from ACPI; if necessary, use "pci=nocrs" and report a bug
Jun 06 02:03:04 localhost kernel: PCI: Using E820 reservations for host bridge windows
Jun 06 02:03:04 localhost kernel: ACPI: Enabled 3 GPEs in block 00 to 7F
Jun 06 02:03:04 localhost kernel: ACPI: PCI Root Bridge [UNC0] (domain 0000 [bus fe])
Jun 06 02:03:04 localhost kernel: acpi PNP0A03:00: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI EDR HPX-Type3]
Jun 06 02:03:04 localhost kernel: PCI host bridge to bus 0000:fe
Jun 06 02:03:04 localhost kernel: pci_bus 0000:fe: root bus resource [bus fe]
Jun 06 02:03:04 localhost kernel: pci 0000:fe:00.0: [8086:3450] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:00.1: [8086:3451] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:00.2: [8086:3452] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:00.3: [8086:0998] type 00 class 0x060000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:00.5: [8086:3455] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:02.0: [8086:3440] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:02.1: [8086:3441] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:02.2: [8086:3442] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:03.0: [8086:3440] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:03.1: [8086:3441] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:03.2: [8086:3442] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:04.0: [8086:3440] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:04.1: [8086:3441] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:04.2: [8086:3442] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:04.3: [8086:3443] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:05.0: [8086:3445] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:05.1: [8086:3446] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:05.2: [8086:3447] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:06.0: [8086:3445] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:06.1: [8086:3446] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:06.2: [8086:3447] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:07.0: [8086:3445] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:07.1: [8086:3446] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:07.2: [8086:3447] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:0b.0: [8086:3448] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:0b.1: [8086:3448] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:0b.2: [8086:344b] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:0c.0: [8086:344a] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci 0000:fe:0d.0: [8086:344a] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci 0000:fe:0e.0: [8086:344a] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci 0000:fe:0f.0: [8086:344a] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci 0000:fe:1a.0: [8086:2880] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci 0000:fe:1b.0: [8086:2880] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci 0000:fe:1c.0: [8086:2880] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci 0000:fe:1d.0: [8086:2880] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci_bus 0000:fe: on NUMA node 0
Jun 06 02:03:04 localhost kernel: ACPI: PCI Root Bridge [UNC1] (domain 0000 [bus ff])
Jun 06 02:03:04 localhost kernel: acpi PNP0A03:01: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI EDR HPX-Type3]
Jun 06 02:03:04 localhost kernel: PCI host bridge to bus 0000:ff
Jun 06 02:03:04 localhost kernel: pci_bus 0000:ff: root bus resource [bus ff]
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.0: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.1: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.2: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.3: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.4: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.5: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.6: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.7: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.0: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.1: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.2: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.3: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.4: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.5: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.6: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.7: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.0: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.1: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.2: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.3: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.4: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.5: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.6: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.7: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.0: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.1: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.2: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.3: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.4: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.5: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.6: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.7: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.0: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.1: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.2: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.3: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.4: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.5: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.6: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.7: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.0: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.1: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.2: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.3: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.4: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.5: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.6: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.7: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.0: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.1: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.2: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.3: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.4: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.5: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.6: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.7: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.0: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.1: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.2: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.3: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.4: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.5: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.6: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.7: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.0: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.1: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.2: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.3: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.4: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.5: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.6: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.7: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.0: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.1: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.2: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.3: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.4: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.5: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.6: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.7: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1d.0: [8086:344f] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1d.1: [8086:3457] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.0: [8086:3458] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.1: [8086:3459] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.2: [8086:345a] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.3: [8086:345b] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.4: [8086:345c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.5: [8086:345d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.6: [8086:345e] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.7: [8086:345f] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci_bus 0000:ff: on NUMA node 0
Jun 06 02:03:04 localhost kernel: ACPI: PCI Root Bridge [PC00] (domain 0000 [bus 00-0e])
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:00: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI EDR HPX-Type3]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:00: _OSC: platform does not support [SHPCHotplug AER LTR DPC]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:00: _OSC: OS now controls [PCIeHotplug PME PCIeCapability]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:00: FADT indicates ASPM is unsupported, using BIOS configuration
Jun 06 02:03:04 localhost kernel: PCI host bridge to bus 0000:00
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [io  0x0000-0x03af window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [io  0x03e0-0x0cf7 window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [io  0x03b0-0x03bb window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [io  0x03c0-0x03df window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [io  0x1000-0x4fff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [mem 0x90000000-0xadffbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [mem 0x200000000000-0x20ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [bus 00-0e]
Jun 06 02:03:04 localhost kernel: pci 0000:00:00.0: [8086:09a2] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:00.1: [8086:09a4] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:00.2: [8086:09a3] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:00.4: [8086:0998] type 00 class 0x060000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.0: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.0: reg 0x10: [mem 0x20fffff40000-0x20fffff43fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.1: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.1: reg 0x10: [mem 0x20fffff3c000-0x20fffff3ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.2: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.2: reg 0x10: [mem 0x20fffff38000-0x20fffff3bfff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.3: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.3: reg 0x10: [mem 0x20fffff34000-0x20fffff37fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.4: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.4: reg 0x10: [mem 0x20fffff30000-0x20fffff33fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.5: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.5: reg 0x10: [mem 0x20fffff2c000-0x20fffff2ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.6: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.6: reg 0x10: [mem 0x20fffff28000-0x20fffff2bfff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.7: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.7: reg 0x10: [mem 0x20fffff24000-0x20fffff27fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.0: [8086:09a6] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.0: reg 0x10: [mem 0x9a194000-0x9a195fff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.1: [8086:09a7] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.1: reg 0x10: [mem 0x9a100000-0x9a17ffff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.1: reg 0x14: [mem 0x9a080000-0x9a0fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.4: [8086:3456] type 00 class 0x130000
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.4: reg 0x10: [mem 0x20ffffe00000-0x20ffffefffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.4: reg 0x18: [mem 0x20fffff20000-0x20fffff23fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.4: reg 0x20: [mem 0x20fffff00000-0x20fffff1ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:11.0: [8086:a1ec] type 00 class 0xff0000
Jun 06 02:03:04 localhost kernel: pci 0000:00:14.0: [8086:a1af] type 00 class 0x0c0330
Jun 06 02:03:04 localhost kernel: pci 0000:00:14.0: reg 0x10: [mem 0x9a180000-0x9a18ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:14.0: PME# supported from D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:00:14.2: [8086:a1b1] type 00 class 0x118000
Jun 06 02:03:04 localhost kernel: pci 0000:00:14.2: reg 0x10: [mem 0x20fffff47000-0x20fffff47fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.0: [8086:a190] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4: [8086:a194] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5: [8086:a195] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:00:1f.0: [8086:a1cb] type 00 class 0x060100
Jun 06 02:03:04 localhost kernel: pci 0000:00:1f.2: [8086:a1a1] type 00 class 0x058000
Jun 06 02:03:04 localhost kernel: pci 0000:00:1f.2: reg 0x10: [mem 0x9a190000-0x9a193fff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.0: PCI bridge to [bus 02]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.0: [103c:3306] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.0: reg 0x10: [io  0x1200-0x12ff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.0: reg 0x14: [mem 0x99b9e000-0x99b9e3ff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.0: reg 0x18: [io  0x1100-0x11ff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.0: reg 0x1c: [mem 0x94000000-0x97ffffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.0: reg 0x20: [mem 0x99800000-0x999fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: [102b:0538] type 00 class 0x030000
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: reg 0x10: [mem 0x98000000-0x98ffffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: reg 0x14: [mem 0x99b98000-0x99b9bfff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: reg 0x18: [mem 0x99000000-0x997fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: BAR 0: assigned to efifb
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: [103c:3307] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: reg 0x10: [io  0x1000-0x10ff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: reg 0x14: [mem 0x99b9d000-0x99b9d0ff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: reg 0x18: [mem 0x99a00000-0x99afffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: reg 0x1c: [mem 0x99b00000-0x99b7ffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: reg 0x20: [mem 0x99b90000-0x99b97fff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: reg 0x24: [mem 0x99b80000-0x99b8ffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: reg 0x30: [mem 0x00000000-0x0003ffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.4: [103c:22f6] type 00 class 0x0c0320
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.4: reg 0x10: [mem 0x99b9c000-0x99b9c0ff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4: PCI bridge to [bus 01]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4:   bridge window [io  0x1000-0x1fff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4:   bridge window [mem 0x90000000-0x99bfffff]
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: working around ROM BAR overlap defect
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: [8086:1537] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: reg 0x10: [mem 0x99d00000-0x99dfffff]
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: reg 0x18: [io  0x2000-0x201f]
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: reg 0x1c: [mem 0x99e00000-0x99e03fff]
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5: PCI bridge to [bus 03]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5:   bridge window [io  0x2000-0x2fff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5:   bridge window [mem 0x99d00000-0x99efffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: on NUMA node 0
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKA configured for IRQ 11
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKB configured for IRQ 10
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKC configured for IRQ 11
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKD configured for IRQ 11
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKE configured for IRQ 11
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKF configured for IRQ 11
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKG configured for IRQ 11
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKH configured for IRQ 11
Jun 06 02:03:04 localhost kernel: ACPI: PCI Root Bridge [PC01] (domain 0000 [bus 0f-49])
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:01: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI EDR HPX-Type3]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:01: _OSC: platform does not support [SHPCHotplug AER LTR DPC]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:01: _OSC: OS now controls [PCIeHotplug PME PCIeCapability]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:01: FADT indicates ASPM is unsupported, using BIOS configuration
Jun 06 02:03:04 localhost kernel: PCI host bridge to bus 0000:0f
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: root bus resource [io  0x5000-0x7fff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: root bus resource [mem 0xae000000-0xc17fbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: root bus resource [mem 0x210000000000-0x21ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: root bus resource [bus 0f-49]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:00.0: [8086:09a2] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:0f:00.1: [8086:09a4] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:0f:00.2: [8086:09a3] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:0f:00.4: [8086:0998] type 00 class 0x060000
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0: [8086:347a] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0: reg 0x10: [mem 0x21fffe520000-0x21fffe53ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0: [8086:347c] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0: reg 0x10: [mem 0x21fffe500000-0x21fffe51ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: reg 0x10: [mem 0x21ffee000000-0x21ffefffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: reg 0x1c: [mem 0x21fff2030000-0x21fff203ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: reg 0x184: [mem 0x21fff1800000-0x21fff181ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: VF(n) BAR0 space: [mem 0x21fff1800000-0x21fff1ffffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: reg 0x190: [mem 0x21fff2340000-0x21fff2343fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: VF(n) BAR3 space: [mem 0x21fff2340000-0x21fff243ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:02.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: reg 0x10: [mem 0x21ffec000000-0x21ffedffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: reg 0x1c: [mem 0x21fff2020000-0x21fff202ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: reg 0x184: [mem 0x21fff1000000-0x21fff101ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: VF(n) BAR0 space: [mem 0x21fff1000000-0x21fff17fffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: reg 0x190: [mem 0x21fff2240000-0x21fff2243fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: VF(n) BAR3 space: [mem 0x21fff2240000-0x21fff233ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: reg 0x10: [mem 0x21ffea000000-0x21ffebffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: reg 0x1c: [mem 0x21fff2010000-0x21fff201ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: reg 0x184: [mem 0x21fff0800000-0x21fff081ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: VF(n) BAR0 space: [mem 0x21fff0800000-0x21fff0ffffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: reg 0x190: [mem 0x21fff2140000-0x21fff2143fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: VF(n) BAR3 space: [mem 0x21fff2140000-0x21fff223ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: reg 0x10: [mem 0x21ffe8000000-0x21ffe9ffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: reg 0x1c: [mem 0x21fff2000000-0x21fff200ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: reg 0x184: [mem 0x21fff0000000-0x21fff001ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: VF(n) BAR0 space: [mem 0x21fff0000000-0x21fff07fffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: reg 0x190: [mem 0x21fff2040000-0x21fff2043fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: VF(n) BAR3 space: [mem 0x21fff2040000-0x21fff213ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0: PCI bridge to [bus 10-11]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0:   bridge window [mem 0x21ffe8000000-0x21fff24fffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: reg 0x10: [mem 0x21fffa000000-0x21fffbffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: reg 0x1c: [mem 0x21fffe030000-0x21fffe03ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: reg 0x184: [mem 0x21fffd800000-0x21fffd81ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: VF(n) BAR0 space: [mem 0x21fffd800000-0x21fffdffffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: reg 0x190: [mem 0x21fffe340000-0x21fffe343fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: VF(n) BAR3 space: [mem 0x21fffe340000-0x21fffe43ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:04.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: reg 0x10: [mem 0x21fff8000000-0x21fff9ffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: reg 0x1c: [mem 0x21fffe020000-0x21fffe02ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: reg 0x184: [mem 0x21fffd000000-0x21fffd01ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: VF(n) BAR0 space: [mem 0x21fffd000000-0x21fffd7fffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: reg 0x190: [mem 0x21fffe240000-0x21fffe243fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: VF(n) BAR3 space: [mem 0x21fffe240000-0x21fffe33ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: reg 0x10: [mem 0x21fff6000000-0x21fff7ffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: reg 0x1c: [mem 0x21fffe010000-0x21fffe01ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: reg 0x184: [mem 0x21fffc800000-0x21fffc81ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: VF(n) BAR0 space: [mem 0x21fffc800000-0x21fffcffffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: reg 0x190: [mem 0x21fffe140000-0x21fffe143fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: VF(n) BAR3 space: [mem 0x21fffe140000-0x21fffe23ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: reg 0x10: [mem 0x21fff4000000-0x21fff5ffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: reg 0x1c: [mem 0x21fffe000000-0x21fffe00ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: reg 0x184: [mem 0x21fffc000000-0x21fffc01ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: VF(n) BAR0 space: [mem 0x21fffc000000-0x21fffc7fffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: reg 0x190: [mem 0x21fffe040000-0x21fffe043fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: VF(n) BAR3 space: [mem 0x21fffe040000-0x21fffe13ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0: PCI bridge to [bus 12-13]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0:   bridge window [mem 0x21fff4000000-0x21fffe4fffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: on NUMA node 0
Jun 06 02:03:04 localhost kernel: ACPI: PCI Root Bridge [PC02] (domain 0000 [bus 4a-84])
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:02: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI EDR HPX-Type3]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:02: _OSC: platform does not support [SHPCHotplug AER LTR DPC]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:02: _OSC: OS now controls [PCIeHotplug PME PCIeCapability]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:02: FADT indicates ASPM is unsupported, using BIOS configuration
Jun 06 02:03:04 localhost kernel: PCI host bridge to bus 0000:4a
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: root bus resource [io  0x8000-0xafff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: root bus resource [mem 0xc1800000-0xd4ffbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: root bus resource [mem 0x220000000000-0x22ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: root bus resource [bus 4a-84]
Jun 06 02:03:04 localhost kernel: pci 0000:4a:00.0: [8086:09a2] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:4a:00.1: [8086:09a4] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:4a:00.2: [8086:09a3] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:4a:00.4: [8086:0998] type 00 class 0x060000
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0: [8086:347a] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0: reg 0x10: [mem 0x22fffff00000-0x22fffff1ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0: enabling Extended Tags
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:4b:00.0: [8086:0d5c] type 00 class 0x120001
Jun 06 02:03:04 localhost kernel: pci 0000:4b:00.0: reg 0x10: [mem 0xc2000000-0xc2ffffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:4b:00.0: PME# supported from D0 D3hot
Jun 06 02:03:04 localhost kernel: pci 0000:4b:00.0: reg 0x2c4: [mem 0xc3000000-0xc3000fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:4b:00.0: VF(n) BAR0 space: [mem 0xc3000000-0xc300ffff 64bit] (contains BAR0 for 16 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0: PCI bridge to [bus 4b-4d]
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0:   bridge window [mem 0xc2000000-0xc30fffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: on NUMA node 0
Jun 06 02:03:04 localhost kernel: ACPI: PCI Root Bridge [PC04] (domain 0000 [bus 85-bf])
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:03: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI EDR HPX-Type3]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:03: _OSC: platform does not support [SHPCHotplug AER LTR DPC]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:03: _OSC: OS now controls [PCIeHotplug PME PCIeCapability]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:03: FADT indicates ASPM is unsupported, using BIOS configuration
Jun 06 02:03:04 localhost kernel: PCI host bridge to bus 0000:85
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: root bus resource [io  0xb000-0xdfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: root bus resource [mem 0xd5000000-0xe87fbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: root bus resource [mem 0x230000000000-0x23ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: root bus resource [bus 85-bf]
Jun 06 02:03:04 localhost kernel: pci 0000:85:00.0: [8086:09a2] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:85:00.1: [8086:09a4] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:85:00.2: [8086:09a3] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:85:00.4: [8086:0998] type 00 class 0x060000
Jun 06 02:03:04 localhost kernel: pci 0000:85:02.0: [8086:347a] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:85:02.0: reg 0x10: [mem 0x23fffff00000-0x23fffff1ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:85:02.0: enabling Extended Tags
Jun 06 02:03:04 localhost kernel: pci 0000:85:02.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:85:02.0: PCI bridge to [bus 86]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: on NUMA node 0
Jun 06 02:03:04 localhost kernel: ACPI: PCI Root Bridge [PC05] (domain 0000 [bus c0-fa])
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:04: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI EDR HPX-Type3]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:04: _OSC: platform does not support [SHPCHotplug AER LTR DPC]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:04: _OSC: OS now controls [PCIeHotplug PME PCIeCapability]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:04: FADT indicates ASPM is unsupported, using BIOS configuration
Jun 06 02:03:04 localhost kernel: PCI host bridge to bus 0000:c0
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: root bus resource [io  0xe000-0xffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: root bus resource [mem 0xe8800000-0xfb7fbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: root bus resource [mem 0x240000000000-0x24ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: root bus resource [bus c0-fa]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:00.0: [8086:09a2] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:c0:00.1: [8086:09a4] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:c0:00.2: [8086:09a3] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:c0:00.4: [8086:0998] type 00 class 0x060000
Jun 06 02:03:04 localhost kernel: pci 0000:c0:02.0: [8086:347a] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:c0:02.0: reg 0x10: [mem 0x24fffff60000-0x24fffff7ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:02.0: enabling Extended Tags
Jun 06 02:03:04 localhost kernel: pci 0000:c0:02.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0: [8086:347b] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0: reg 0x10: [mem 0x24fffff40000-0x24fffff5ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0: enabling Extended Tags
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0: [8086:347c] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0: reg 0x10: [mem 0x24fffff20000-0x24fffff3ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0: enabling Extended Tags
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:c0:05.0: [8086:347d] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:c0:05.0: reg 0x10: [mem 0x24fffff00000-0x24fffff1ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:05.0: enabling Extended Tags
Jun 06 02:03:04 localhost kernel: pci 0000:c0:05.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:c0:02.0: PCI bridge to [bus c1]
Jun 06 02:03:04 localhost kernel: pci 0000:c2:00.0: [144d:a808] type 00 class 0x010802
Jun 06 02:03:04 localhost kernel: pci 0000:c2:00.0: reg 0x10: [mem 0xe8900000-0xe8903fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:c2:00.0: reg 0x30: [mem 0x00000000-0x0000ffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:c2:00.0: 15.752 Gb/s available PCIe bandwidth, limited by 8.0 GT/s PCIe x2 link at 0000:c0:03.0 (capable of 31.504 Gb/s with 8.0 GT/s PCIe x4 link)
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0: PCI bridge to [bus c2]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0:   bridge window [mem 0xe8900000-0xe89fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:c3:00.0: [144d:a808] type 00 class 0x010802
Jun 06 02:03:04 localhost kernel: pci 0000:c3:00.0: reg 0x10: [mem 0xe8800000-0xe8803fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:c3:00.0: reg 0x30: [mem 0x00000000-0x0000ffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:c3:00.0: 15.752 Gb/s available PCIe bandwidth, limited by 8.0 GT/s PCIe x2 link at 0000:c0:04.0 (capable of 31.504 Gb/s with 8.0 GT/s PCIe x4 link)
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0: PCI bridge to [bus c3]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0:   bridge window [mem 0xe8800000-0xe88fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:05.0: PCI bridge to [bus c4]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: on NUMA node 0
Jun 06 02:03:04 localhost kernel: iommu: Default domain type: Translated 
Jun 06 02:03:04 localhost kernel: iommu: DMA domain TLB invalidation policy: lazy mode 
Jun 06 02:03:04 localhost kernel: SCSI subsystem initialized
Jun 06 02:03:04 localhost kernel: ACPI: bus type USB registered
Jun 06 02:03:04 localhost kernel: usbcore: registered new interface driver usbfs
Jun 06 02:03:04 localhost kernel: usbcore: registered new interface driver hub
Jun 06 02:03:04 localhost kernel: usbcore: registered new device driver usb
Jun 06 02:03:04 localhost kernel: pps_core: LinuxPPS API ver. 1 registered
Jun 06 02:03:04 localhost kernel: pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it>
Jun 06 02:03:04 localhost kernel: PTP clock support registered
Jun 06 02:03:04 localhost kernel: EDAC MC: Ver: 3.0.0
Jun 06 02:03:04 localhost kernel: Registered efivars operations
Jun 06 02:03:04 localhost kernel: NetLabel: Initializing
Jun 06 02:03:04 localhost kernel: NetLabel:  domain hash size = 128
Jun 06 02:03:04 localhost kernel: NetLabel:  protocols = UNLABELED CIPSOv4 CALIPSO
Jun 06 02:03:04 localhost kernel: NetLabel:  unlabeled traffic allowed by default
Jun 06 02:03:04 localhost kernel: PCI: Using ACPI for IRQ routing
Jun 06 02:03:04 localhost kernel: PCI: pci_cache_line_size set to 64 bytes
Jun 06 02:03:04 localhost kernel: Expanded resource Reserved due to conflict with PCI Bus 0000:01
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x0009f000-0x0009ffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x3ec19018-0x3fffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x3ec20018-0x3fffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x3ec27018-0x3fffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x3ec5b018-0x3fffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x3ecc5000-0x3fffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x5046c018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x504a0018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x504d4018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x50508018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x5053c018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x50570018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x505a4018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x505da018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x505e6018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x53c6c000-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x58482000-0x5bffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x59836000-0x5bffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x6f800000-0x6fffffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: vgaarb: setting as boot VGA device
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: vgaarb: bridge control possible
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none
Jun 06 02:03:04 localhost kernel: vgaarb: loaded
Jun 06 02:03:04 localhost kernel: hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0, 0, 0, 0, 0, 0
Jun 06 02:03:04 localhost kernel: hpet0: 8 comparators, 64-bit 24.000000 MHz counter
Jun 06 02:03:04 localhost kernel: clocksource: Switched to clocksource tsc-early
Jun 06 02:03:04 localhost kernel: VFS: Disk quotas dquot_6.6.0
Jun 06 02:03:04 localhost kernel: VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)
Jun 06 02:03:04 localhost kernel: pnp: PnP ACPI init
Jun 06 02:03:04 localhost kernel: system 00:01: [io  0x0500-0x053f] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [io  0x0400-0x047f] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [io  0x0540-0x057f] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [io  0x0600-0x061f] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [io  0x0880-0x0883] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [io  0x0800-0x081f] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [mem 0xfed1c000-0xfed3ffff] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [mem 0xfed45000-0xfed8bfff] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [mem 0xff000000-0xffffffff] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [mem 0xfee00000-0xfeefffff] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [mem 0xfed12000-0xfed1200f] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [mem 0xfed12010-0xfed1201f] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [mem 0xfed1b000-0xfed1bfff] has been reserved
Jun 06 02:03:04 localhost kernel: pnp: PnP ACPI: found 3 devices
Jun 06 02:03:04 localhost kernel: clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns
Jun 06 02:03:04 localhost kernel: NET: Registered PF_INET protocol family
Jun 06 02:03:04 localhost kernel: IP idents hash table entries: 262144 (order: 9, 2097152 bytes, linear)
Jun 06 02:03:04 localhost kernel: tcp_listen_portaddr_hash hash table entries: 65536 (order: 8, 1048576 bytes, linear)
Jun 06 02:03:04 localhost kernel: Table-perturb hash table entries: 65536 (order: 6, 262144 bytes, linear)
Jun 06 02:03:04 localhost kernel: TCP established hash table entries: 524288 (order: 10, 4194304 bytes, linear)
Jun 06 02:03:04 localhost kernel: TCP bind hash table entries: 65536 (order: 8, 1048576 bytes, linear)
Jun 06 02:03:04 localhost kernel: TCP: Hash tables configured (established 524288 bind 65536)
Jun 06 02:03:04 localhost kernel: MPTCP token hash table entries: 65536 (order: 8, 1572864 bytes, linear)
Jun 06 02:03:04 localhost kernel: UDP hash table entries: 65536 (order: 9, 2097152 bytes, linear)
Jun 06 02:03:04 localhost kernel: UDP-Lite hash table entries: 65536 (order: 9, 2097152 bytes, linear)
Jun 06 02:03:04 localhost kernel: NET: Registered PF_UNIX/PF_LOCAL protocol family
Jun 06 02:03:04 localhost kernel: NET: Registered PF_XDP protocol family
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.0: PCI bridge to [bus 02]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: BAR 6: assigned [mem 0x90000000-0x9003ffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4: PCI bridge to [bus 01]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4:   bridge window [io  0x1000-0x1fff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4:   bridge window [mem 0x90000000-0x99bfffff]
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: BAR 6: no space for [mem size 0x00100000 pref]
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: BAR 6: failed to assign [mem size 0x00100000 pref]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5: PCI bridge to [bus 03]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5:   bridge window [io  0x2000-0x2fff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5:   bridge window [mem 0x99d00000-0x99efffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 4 [io  0x0000-0x03af window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 5 [io  0x03e0-0x0cf7 window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 6 [io  0x03b0-0x03bb window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 7 [io  0x03c0-0x03df window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 8 [mem 0x000a0000-0x000bffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 9 [io  0x1000-0x4fff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 10 [mem 0x90000000-0xadffbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 11 [mem 0x200000000000-0x20ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:01: resource 0 [io  0x1000-0x1fff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:01: resource 1 [mem 0x90000000-0x99bfffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:03: resource 0 [io  0x2000-0x2fff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:03: resource 1 [mem 0x99d00000-0x99efffff]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0: BAR 14: assigned [mem 0xae000000-0xae3fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0: BAR 14: assigned [mem 0xae400000-0xae7fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: BAR 6: assigned [mem 0xae000000-0xae0fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: BAR 6: assigned [mem 0xae100000-0xae1fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: BAR 6: assigned [mem 0xae200000-0xae2fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: BAR 6: assigned [mem 0xae300000-0xae3fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0: PCI bridge to [bus 10-11]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0:   bridge window [mem 0xae000000-0xae3fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0:   bridge window [mem 0x21ffe8000000-0x21fff24fffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: BAR 6: assigned [mem 0xae400000-0xae4fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: BAR 6: assigned [mem 0xae500000-0xae5fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: BAR 6: assigned [mem 0xae600000-0xae6fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: BAR 6: assigned [mem 0xae700000-0xae7fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0: PCI bridge to [bus 12-13]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0:   bridge window [mem 0xae400000-0xae7fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0:   bridge window [mem 0x21fff4000000-0x21fffe4fffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: resource 4 [io  0x5000-0x7fff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: resource 5 [mem 0xae000000-0xc17fbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: resource 6 [mem 0x210000000000-0x21ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:10: resource 1 [mem 0xae000000-0xae3fffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:10: resource 2 [mem 0x21ffe8000000-0x21fff24fffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:12: resource 1 [mem 0xae400000-0xae7fffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:12: resource 2 [mem 0x21fff4000000-0x21fffe4fffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0: PCI bridge to [bus 4b-4d]
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0:   bridge window [mem 0xc2000000-0xc30fffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: resource 4 [io  0x8000-0xafff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: resource 5 [mem 0xc1800000-0xd4ffbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: resource 6 [mem 0x220000000000-0x22ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4b: resource 1 [mem 0xc2000000-0xc30fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:85:02.0: PCI bridge to [bus 86]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: resource 4 [io  0xb000-0xdfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: resource 5 [mem 0xd5000000-0xe87fbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: resource 6 [mem 0x230000000000-0x23ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:02.0: PCI bridge to [bus c1]
Jun 06 02:03:04 localhost kernel: pci 0000:c2:00.0: BAR 6: assigned [mem 0xe8910000-0xe891ffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0: PCI bridge to [bus c2]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0:   bridge window [mem 0xe8900000-0xe89fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:c3:00.0: BAR 6: assigned [mem 0xe8810000-0xe881ffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0: PCI bridge to [bus c3]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0:   bridge window [mem 0xe8800000-0xe88fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:05.0: PCI bridge to [bus c4]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: resource 4 [io  0xe000-0xffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: resource 5 [mem 0xe8800000-0xfb7fbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: resource 6 [mem 0x240000000000-0x24ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c2: resource 1 [mem 0xe8900000-0xe89fffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c3: resource 1 [mem 0xe8800000-0xe88fffff]
Jun 06 02:03:04 localhost kernel: PCI: CLS 64 bytes, default 64
Jun 06 02:03:04 localhost kernel: Trying to unpack rootfs image as initramfs...
Jun 06 02:03:04 localhost kernel: PCI-DMA: Using software bounce buffering for IO (SWIOTLB)
Jun 06 02:03:04 localhost kernel: software IO TLB: mapped [mem 0x000000006b800000-0x000000006f800000] (64MB)
Jun 06 02:03:04 localhost kernel: ACPI: bus type thunderbolt registered
Jun 06 02:03:04 localhost kernel: Initialise system trusted keyrings
Jun 06 02:03:04 localhost kernel: Key type blacklist registered
Jun 06 02:03:04 localhost kernel: workingset: timestamp_bits=36 max_order=25 bucket_order=0
Jun 06 02:03:04 localhost kernel: zbud: loaded
Jun 06 02:03:04 localhost kernel: integrity: Platform Keyring initialized
Jun 06 02:03:04 localhost kernel: NET: Registered PF_ALG protocol family
Jun 06 02:03:04 localhost kernel: xor: automatically using best checksumming function   avx       
Jun 06 02:03:04 localhost kernel: Key type asymmetric registered
Jun 06 02:03:04 localhost kernel: Asymmetric key parser 'x509' registered
Jun 06 02:03:04 localhost kernel: Running certificate verification selftests
Jun 06 02:03:04 localhost kernel: Loaded X.509 cert 'Certificate verification self-testing key: f58703bb33ce1b73ee02eccdee5b8817518fe3db'
Jun 06 02:03:04 localhost kernel: Block layer SCSI generic (bsg) driver version 0.4 loaded (major 246)
Jun 06 02:03:04 localhost kernel: io scheduler mq-deadline registered
Jun 06 02:03:04 localhost kernel: io scheduler kyber registered
Jun 06 02:03:04 localhost kernel: io scheduler bfq registered
Jun 06 02:03:04 localhost kernel: atomic64_test: passed for x86-64 platform with CX8 and with SSE
Jun 06 02:03:04 localhost kernel: pcieport 0000:00:1c.0: PME: Signaling with IRQ 125
Jun 06 02:03:04 localhost kernel: pcieport 0000:00:1c.4: PME: Signaling with IRQ 126
Jun 06 02:03:04 localhost kernel: pcieport 0000:00:1c.5: PME: Signaling with IRQ 127
Jun 06 02:03:04 localhost kernel: pcieport 0000:0f:02.0: PME: Signaling with IRQ 128
Jun 06 02:03:04 localhost kernel: pcieport 0000:0f:04.0: PME: Signaling with IRQ 129
Jun 06 02:03:04 localhost kernel: pcieport 0000:4a:02.0: PME: Signaling with IRQ 130
Jun 06 02:03:04 localhost kernel: pcieport 0000:85:02.0: PME: Signaling with IRQ 131
Jun 06 02:03:04 localhost kernel: pcieport 0000:c0:02.0: PME: Signaling with IRQ 132
Jun 06 02:03:04 localhost kernel: pcieport 0000:c0:03.0: PME: Signaling with IRQ 133
Jun 06 02:03:04 localhost kernel: pcieport 0000:c0:04.0: PME: Signaling with IRQ 134
Jun 06 02:03:04 localhost kernel: pcieport 0000:c0:05.0: PME: Signaling with IRQ 135
Jun 06 02:03:04 localhost kernel: shpchp: Standard Hot Plug PCI Controller Driver version: 0.4
Jun 06 02:03:04 localhost kernel: Monitor-Mwait will be used to enter C-1 state
Jun 06 02:03:04 localhost kernel: Monitor-Mwait will be used to enter C-2 state
Jun 06 02:03:04 localhost kernel: ACPI: \_SB_.SCK0.C000: Found 2 idle states
Jun 06 02:03:04 localhost kernel: input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0
Jun 06 02:03:04 localhost kernel: ACPI: button: Power Button [PWRF]
Jun 06 02:03:04 localhost kernel: smpboot: Estimated ratio of average max frequency by base frequency (times 1024): 1349
Jun 06 02:03:04 localhost kernel: acpi/hmat: HMAT: Memory Flags:0001 Processor Domain:0 Memory Domain:0
Jun 06 02:03:04 localhost kernel: acpi/hmat: HMAT: Locality: Flags:00 Type:Access Latency Initiator Domains:1 Target Domains:1 Base:100
Jun 06 02:03:04 localhost kernel: acpi/hmat:   Initiator-Target[0-0]:0 nsec
Jun 06 02:03:04 localhost kernel: acpi/hmat: HMAT: Locality: Flags:00 Type:Access Bandwidth Initiator Domains:1 Target Domains:1 Base:10
Jun 06 02:03:04 localhost kernel: acpi/hmat:   Initiator-Target[0-0]:170560 MB/s
Jun 06 02:03:04 localhost kernel: ERST: Error Record Serialization Table (ERST) support is initialized.
Jun 06 02:03:04 localhost kernel: pstore: Registered erst as persistent store backend
Jun 06 02:03:04 localhost kernel: EDAC MC0: Giving out device to module ghes_edac.c controller ghes_edac: DEV ghes (INTERRUPT)
Jun 06 02:03:04 localhost kernel: GHES: APEI firmware first mode is enabled by APEI bit and WHEA _OSC.
Jun 06 02:03:04 localhost kernel: Serial: 8250/16550 driver, 4 ports, IRQ sharing enabled
Jun 06 02:03:04 localhost kernel: 00:02: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A
Jun 06 02:03:04 localhost kernel: Non-volatile memory driver v1.3
Jun 06 02:03:04 localhost kernel: tpm_tis STM7364:00: 2.0 TPM (device-id 0x0, rev-id 78)
Jun 06 02:03:04 localhost kernel: rdac: device handler registered
Jun 06 02:03:04 localhost kernel: hp_sw: device handler registered
Jun 06 02:03:04 localhost kernel: emc: device handler registered
Jun 06 02:03:04 localhost kernel: alua: device handler registered
Jun 06 02:03:04 localhost kernel: libphy: Fixed MDIO Bus: probed
Jun 06 02:03:04 localhost kernel: ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver
Jun 06 02:03:04 localhost kernel: ehci-pci: EHCI PCI platform driver
Jun 06 02:03:04 localhost kernel: ehci-pci 0000:01:00.4: EHCI Host Controller
Jun 06 02:03:04 localhost kernel: ehci-pci 0000:01:00.4: new USB bus registered, assigned bus number 1
Jun 06 02:03:04 localhost kernel: ehci-pci 0000:01:00.4: irq 136, io mem 0x99b9c000
Jun 06 02:03:04 localhost kernel: ehci-pci 0000:01:00.4: USB 2.0 started, EHCI 1.00
Jun 06 02:03:04 localhost kernel: usb usb1: New USB device found, idVendor=1d6b, idProduct=0002, bcdDevice= 5.14
Jun 06 02:03:04 localhost kernel: usb usb1: New USB device strings: Mfr=3, Product=2, SerialNumber=1
Jun 06 02:03:04 localhost kernel: usb usb1: Product: EHCI Host Controller
Jun 06 02:03:04 localhost kernel: usb usb1: Manufacturer: Linux 5.14.0-284.13.1.el9_2.x86_64 ehci_hcd
Jun 06 02:03:04 localhost kernel: usb usb1: SerialNumber: 0000:01:00.4
Jun 06 02:03:04 localhost kernel: hub 1-0:1.0: USB hub found
Jun 06 02:03:04 localhost kernel: hub 1-0:1.0: 8 ports detected
Jun 06 02:03:04 localhost kernel: ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver
Jun 06 02:03:04 localhost kernel: ohci-pci: OHCI PCI platform driver
Jun 06 02:03:04 localhost kernel: uhci_hcd: USB Universal Host Controller Interface driver
Jun 06 02:03:04 localhost kernel: xhci_hcd 0000:00:14.0: xHCI Host Controller
Jun 06 02:03:04 localhost kernel: xhci_hcd 0000:00:14.0: new USB bus registered, assigned bus number 2
Jun 06 02:03:04 localhost kernel: xhci_hcd 0000:00:14.0: hcc params 0x200077c1 hci version 0x100 quirks 0x0000000000009810
Jun 06 02:03:04 localhost kernel: xhci_hcd 0000:00:14.0: xHCI Host Controller
Jun 06 02:03:04 localhost kernel: xhci_hcd 0000:00:14.0: new USB bus registered, assigned bus number 3
Jun 06 02:03:04 localhost kernel: xhci_hcd 0000:00:14.0: Host supports USB 3.0 SuperSpeed
Jun 06 02:03:04 localhost kernel: usb usb2: New USB device found, idVendor=1d6b, idProduct=0002, bcdDevice= 5.14
Jun 06 02:03:04 localhost kernel: usb usb2: New USB device strings: Mfr=3, Product=2, SerialNumber=1
Jun 06 02:03:04 localhost kernel: usb usb2: Product: xHCI Host Controller
Jun 06 02:03:04 localhost kernel: usb usb2: Manufacturer: Linux 5.14.0-284.13.1.el9_2.x86_64 xhci-hcd
Jun 06 02:03:04 localhost kernel: usb usb2: SerialNumber: 0000:00:14.0
Jun 06 02:03:04 localhost kernel: hub 2-0:1.0: USB hub found
Jun 06 02:03:04 localhost kernel: hub 2-0:1.0: 16 ports detected
Jun 06 02:03:04 localhost kernel: usb usb3: New USB device found, idVendor=1d6b, idProduct=0003, bcdDevice= 5.14
Jun 06 02:03:04 localhost kernel: usb usb3: New USB device strings: Mfr=3, Product=2, SerialNumber=1
Jun 06 02:03:04 localhost kernel: usb usb3: Product: xHCI Host Controller
Jun 06 02:03:04 localhost kernel: usb usb3: Manufacturer: Linux 5.14.0-284.13.1.el9_2.x86_64 xhci-hcd
Jun 06 02:03:04 localhost kernel: usb usb3: SerialNumber: 0000:00:14.0
Jun 06 02:03:04 localhost kernel: hub 3-0:1.0: USB hub found
Jun 06 02:03:04 localhost kernel: hub 3-0:1.0: 10 ports detected
Jun 06 02:03:04 localhost kernel: usbcore: registered new interface driver usbserial_generic
Jun 06 02:03:04 localhost kernel: usbserial: USB Serial support registered for generic
Jun 06 02:03:04 localhost kernel: i8042: PNP: No PS/2 controller found.
Jun 06 02:03:04 localhost kernel: i8042: Probing ports directly.
Jun 06 02:03:04 localhost kernel: usb 2-3: new high-speed USB device number 2 using xhci_hcd
Jun 06 02:03:04 localhost kernel: usb 2-3: New USB device found, idVendor=0424, idProduct=2660, bcdDevice= 8.01
Jun 06 02:03:04 localhost kernel: usb 2-3: New USB device strings: Mfr=0, Product=0, SerialNumber=0
Jun 06 02:03:04 localhost kernel: hub 2-3:1.0: USB hub found
Jun 06 02:03:04 localhost kernel: hub 2-3:1.0: 2 ports detected
Jun 06 02:03:04 localhost kernel: i8042: Can't read CTR while initializing i8042
Jun 06 02:03:04 localhost kernel: i8042: probe of i8042 failed with error -5
Jun 06 02:03:04 localhost kernel: mousedev: PS/2 mouse device common for all mice
Jun 06 02:03:04 localhost kernel: rtc_cmos 00:00: RTC can wake from S4
Jun 06 02:03:04 localhost kernel: rtc_cmos 00:00: registered as rtc0
Jun 06 02:03:04 localhost kernel: rtc_cmos 00:00: setting system clock to 2023-06-06T02:03:02 UTC (1686016982)
Jun 06 02:03:04 localhost kernel: rtc_cmos 00:00: alarms up to one month, y3k, 114 bytes nvram, hpet irqs
Jun 06 02:03:04 localhost kernel: Freeing initrd memory: 91052K
Jun 06 02:03:04 localhost kernel: intel_pstate: HWP enabled by BIOS
Jun 06 02:03:04 localhost kernel: intel_pstate: Intel P-state driver initializing
Jun 06 02:03:04 localhost kernel: intel_pstate: HWP enabled
Jun 06 02:03:04 localhost kernel: efifb: probing for efifb
Jun 06 02:03:04 localhost kernel: efifb: framebuffer at 0x98000000, using 3072k, total 3072k
Jun 06 02:03:04 localhost kernel: efifb: mode is 1024x768x32, linelength=4096, pages=1
Jun 06 02:03:04 localhost kernel: efifb: scrolling: redraw
Jun 06 02:03:04 localhost kernel: efifb: Truecolor: size=8:8:8:8, shift=24:16:8:0
Jun 06 02:03:04 localhost kernel: Console: switching to colour frame buffer device 128x48
Jun 06 02:03:04 localhost kernel: fb0: EFI VGA frame buffer device
Jun 06 02:03:04 localhost kernel: EFI Variables Facility v0.08 2004-May-17
Jun 06 02:03:04 localhost kernel: hid: raw HID events driver (C) Jiri Kosina
Jun 06 02:03:04 localhost kernel: usbcore: registered new interface driver usbhid
Jun 06 02:03:04 localhost kernel: usbhid: USB HID core driver
Jun 06 02:03:04 localhost kernel: drop_monitor: Initializing network drop monitor service
Jun 06 02:03:04 localhost kernel: Initializing XFRM netlink socket
Jun 06 02:03:04 localhost kernel: NET: Registered PF_INET6 protocol family
Jun 06 02:03:04 localhost kernel: Segment Routing with IPv6
Jun 06 02:03:04 localhost kernel: NET: Registered PF_PACKET protocol family
Jun 06 02:03:04 localhost kernel: mpls_gso: MPLS GSO support
Jun 06 02:03:04 localhost kernel: microcode: sig=0x606a6, pf=0x1, revision=0xd000375
Jun 06 02:03:04 localhost kernel: microcode: Microcode Update Driver: v2.2.
Jun 06 02:03:04 localhost kernel: resctrl: L3 allocation detected
Jun 06 02:03:04 localhost kernel: resctrl: MB allocation detected
Jun 06 02:03:04 localhost kernel: resctrl: L3 monitoring detected
Jun 06 02:03:04 localhost kernel: IPI shorthand broadcast: enabled
Jun 06 02:03:04 localhost kernel: AVX2 version of gcm_enc/dec engaged.
Jun 06 02:03:04 localhost kernel: AES CTR mode by8 optimization enabled
Jun 06 02:03:04 localhost kernel: sched_clock: Marking stable (1755941349, 2949052)->(1966194808, -207304407)
Jun 06 02:03:04 localhost kernel: registered taskstats version 1
Jun 06 02:03:04 localhost kernel: Loading compiled-in X.509 certificates
Jun 06 02:03:04 localhost kernel: Loaded X.509 cert 'Red Hat Enterprise Linux kernel signing key: 00ecce0a8f5d0994e01ed9317bbe137eaf79c99b'
Jun 06 02:03:04 localhost kernel: Loaded X.509 cert 'Red Hat Enterprise Linux Driver Update Program (key 3): bf57f3e87362bc7229d9f465321773dfd1f77a80'
Jun 06 02:03:04 localhost kernel: Loaded X.509 cert 'Red Hat Enterprise Linux kpatch signing key: 4d38fd864ebe18c5f0b72e3852e2014c3a676fc8'
Jun 06 02:03:04 localhost kernel: zswap: loaded using pool lzo/zbud
Jun 06 02:03:04 localhost kernel: page_owner is disabled
Jun 06 02:03:04 localhost kernel: pstore: Using crash dump compression: deflate
Jun 06 02:03:04 localhost kernel: Key type big_key registered
Jun 06 02:03:04 localhost kernel: Key type trusted registered
Jun 06 02:03:04 localhost kernel: Key type encrypted registered
Jun 06 02:03:04 localhost kernel: integrity: Loading X.509 certificate: UEFI:db
Jun 06 02:03:04 localhost kernel: integrity: Loaded X.509 cert 'Hewlett Packard Enterprise Company: HPE UEFI Secure Boot 2016 DB Key: a068bfe686eec826df935e3bb1cd36f1c2772560'
Jun 06 02:03:04 localhost kernel: integrity: Loading X.509 certificate: UEFI:db
Jun 06 02:03:04 localhost kernel: integrity: Loaded X.509 cert 'Hewlett-Packard Company: HP UEFI Secure Boot 2013 DB key: 1d7cf2c2b92673f69c8ee1ec7063967ab9b62bec'
Jun 06 02:03:04 localhost kernel: integrity: Loading X.509 certificate: UEFI:db
Jun 06 02:03:04 localhost kernel: integrity: Loaded X.509 cert 'Microsoft Corporation UEFI CA 2011: 13adbf4309bd82709c8cd54f316ed522988a1bd4'
Jun 06 02:03:04 localhost kernel: integrity: Loading X.509 certificate: UEFI:db
Jun 06 02:03:04 localhost kernel: tsc: Refined TSC clocksource calibration: 2194.800 MHz
Jun 06 02:03:04 localhost kernel: usb 1-1: new high-speed USB device number 2 using ehci-pci
Jun 06 02:03:04 localhost kernel: integrity: Loaded X.509 cert 'Microsoft Windows Production PCA 2011: a92902398e16c49778cd90f99e4f9ae17c55af53'
Jun 06 02:03:04 localhost kernel: clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1fa302934c2, max_idle_ns: 440795231312 ns
Jun 06 02:03:04 localhost kernel: integrity: Loading X.509 certificate: UEFI:db
Jun 06 02:03:04 localhost kernel: clocksource: Switched to clocksource tsc
Jun 06 02:03:04 localhost kernel: integrity: Loaded X.509 cert 'VMware, Inc.: VMware Secure Boot Signing: 04597f3e1ffb240bba0ff0f05d5eb05f3e15f6d7'
Jun 06 02:03:04 localhost kernel: integrity: Loading X.509 certificate: UEFI:db
Jun 06 02:03:04 localhost kernel: alg: No test for pkcs1pad(rsa,sha1) (pkcs1pad(rsa-generic,sha1))
Jun 06 02:03:04 localhost kernel: integrity: Loaded X.509 cert 'Wind River Systems Inc: TiS: 00a774fa6f5e66ad03'
Jun 06 02:03:04 localhost kernel: integrity: Loading X.509 certificate: UEFI:MokListRT (MOKvar table)
Jun 06 02:03:04 localhost kernel: integrity: Loaded X.509 cert 'Red Hat Secure Boot CA 5: cc6fa5e72868ba494e939bbd680b9144769a9f8f'
Jun 06 02:03:04 localhost kernel: Loading compiled-in module X.509 certificates
Jun 06 02:03:04 localhost kernel: Loaded X.509 cert 'Red Hat Enterprise Linux kernel signing key: 00ecce0a8f5d0994e01ed9317bbe137eaf79c99b'
Jun 06 02:03:04 localhost kernel: ima: Allocated hash algorithm: sha256
Jun 06 02:03:04 localhost kernel: usb 1-1: New USB device found, idVendor=03f0, idProduct=7029, bcdDevice= 0.02
Jun 06 02:03:04 localhost kernel: usb 1-1: New USB device strings: Mfr=1, Product=2, SerialNumber=0
Jun 06 02:03:04 localhost kernel: usb 1-1: Product: Virtual Keyboard
Jun 06 02:03:04 localhost kernel: usb 1-1: Manufacturer: iLO
Jun 06 02:03:04 localhost kernel: ima: No architecture policies found
Jun 06 02:03:04 localhost kernel: input: iLO Virtual Keyboard as /devices/pci0000:00/0000:00:1c.4/0000:01:00.4/usb1/1-1/1-1:1.0/0003:03F0:7029.0001/input/input1
Jun 06 02:03:04 localhost kernel: evm: Initialising EVM extended attributes:
Jun 06 02:03:04 localhost kernel: evm: security.selinux
Jun 06 02:03:04 localhost kernel: evm: security.SMACK64 (disabled)
Jun 06 02:03:04 localhost kernel: evm: security.SMACK64EXEC (disabled)
Jun 06 02:03:04 localhost kernel: evm: security.SMACK64TRANSMUTE (disabled)
Jun 06 02:03:04 localhost kernel: evm: security.SMACK64MMAP (disabled)
Jun 06 02:03:04 localhost kernel: hid-generic 0003:03F0:7029.0001: input,hidraw0: USB HID v1.10 Keyboard [iLO Virtual Keyboard] on usb-0000:01:00.4-1/input0
Jun 06 02:03:04 localhost kernel: evm: security.apparmor (disabled)
Jun 06 02:03:04 localhost kernel: evm: security.ima
Jun 06 02:03:04 localhost kernel: evm: security.capability
Jun 06 02:03:04 localhost kernel: evm: HMAC attrs: 0x1
Jun 06 02:03:04 localhost kernel: input: iLO Virtual Keyboard as /devices/pci0000:00/0000:00:1c.4/0000:01:00.4/usb1/1-1/1-1:1.1/0003:03F0:7029.0002/input/input2
Jun 06 02:03:04 localhost kernel: hid-generic 0003:03F0:7029.0002: input,hidraw1: USB HID v1.10 Mouse [iLO Virtual Keyboard] on usb-0000:01:00.4-1/input1
Jun 06 02:03:04 localhost kernel: Freeing unused decrypted memory: 2036K
Jun 06 02:03:04 localhost kernel: Freeing unused kernel image (initmem) memory: 2792K
Jun 06 02:03:04 localhost kernel: Write protecting the kernel read-only data: 26624k
Jun 06 02:03:04 localhost kernel: Freeing unused kernel image (text/rodata gap) memory: 2040K
Jun 06 02:03:04 localhost kernel: usb 1-2: new high-speed USB device number 3 using ehci-pci
Jun 06 02:03:04 localhost kernel: Freeing unused kernel image (rodata/data gap) memory: 60K
Jun 06 02:03:04 localhost kernel: x86/mm: Checked W+X mappings: passed, no W+X pages found.
Jun 06 02:03:04 localhost kernel: Run /init as init process
Jun 06 02:03:04 localhost kernel:   with arguments:
Jun 06 02:03:04 localhost kernel:     /init
Jun 06 02:03:04 localhost kernel:   with environment:
Jun 06 02:03:04 localhost kernel:     HOME=/
Jun 06 02:03:04 localhost kernel:     TERM=linux
Jun 06 02:03:04 localhost kernel:     BOOT_IMAGE=/images/pxeboot/vmlinuz
Jun 06 02:03:04 localhost kernel: usb 1-2: New USB device found, idVendor=03f0, idProduct=2227, bcdDevice= 0.01
Jun 06 02:03:04 localhost kernel: usb 1-2: New USB device strings: Mfr=1, Product=2, SerialNumber=0
Jun 06 02:03:04 localhost kernel: usb 1-2: Product: Virtual CD-ROM
Jun 06 02:03:04 localhost kernel: usb 1-2: Manufacturer: iLO
Jun 06 02:03:04 localhost kernel: ERST: [Firmware Warn]: too many record IDs!
Jun 06 02:03:04 localhost systemd-journald[773]: Journal started
Jun 06 02:03:04 localhost systemd-journald[773]: Runtime Journal (/run/log/journal/de1e6fab70fa460f8917eab7ed136b20) is 8.0M, max 2.5G, 2.5G free.
Jun 06 02:03:04 localhost coreos-ignition-setup-user[766]: Copying /config.ign to /usr/lib/ignition/user.ign
Jun 06 02:03:04 localhost systemd-sysusers[775]: Creating group 'nobody' with GID 65534.
Jun 06 02:03:04 localhost systemd-modules-load[774]: Inserted module 'fuse'
Jun 06 02:03:04 localhost systemd-journald[773]: Missed 36 kernel messages
Jun 06 02:03:04 localhost kernel: fuse: init (API version 7.36)
Jun 06 02:03:04 localhost systemd-modules-load[774]: Module 'msr' is built in
Jun 06 02:03:04 localhost systemd[1]: Mounted /run/ephemeral_base.
Jun 06 02:03:04 localhost systemd[1]: Finished Afterburn Initrd Setup Network Kernel Arguments.
Jun 06 02:03:04 localhost systemd[1]: Finished CoreOS Ignition User Config Setup.
Jun 06 02:03:04 localhost systemd[1]: Finished CoreOS: Touch /run/agetty.reload.
Jun 06 02:03:04 localhost systemd[1]: Finished Create List of Static Device Nodes.
Jun 06 02:03:04 localhost systemd[1]: Finished Load Kernel Modules.
Jun 06 02:03:04 localhost systemd[1]: Finished Setup Virtual Console.
Jun 06 02:03:04 localhost systemd[1]: Starting dracut ask for additional cmdline parameters...
Jun 06 02:03:04 localhost systemd[1]: Starting Apply Kernel Variables...
Jun 06 02:03:04 localhost systemd[1]: Finished dracut ask for additional cmdline parameters.
Jun 06 02:03:04 localhost systemd[1]: Finished Apply Kernel Variables.
Jun 06 02:03:04 localhost systemd[1]: Starting dracut cmdline hook...
Jun 06 02:03:04 localhost dracut-cmdline[796]: dracut-413.92.202305021736-0 dracut-057-21.git20230214.el9
Jun 06 02:03:04 localhost dracut-cmdline[796]: Using kernel command line parameters:  ip=auto   BOOT_IMAGE=/images/pxeboot/vmlinuz coreos.liveiso=rhcos-413.92.202305021736-0 ignition.firstboot ignition.platform.id=metal
Jun 06 02:03:04 localhost systemd-sysusers[775]: Creating group 'sgx' with GID 999.
Jun 06 02:03:04 localhost systemd-sysusers[775]: Creating group 'users' with GID 100.
Jun 06 02:03:04 localhost systemd-sysusers[775]: Creating group 'root' with GID 998.
Jun 06 02:03:04 localhost systemd-sysusers[775]: Creating group 'dbus' with GID 81.
Jun 06 02:03:04 localhost systemd-sysusers[775]: Creating user 'dbus' (System Message Bus) with UID 81 and GID 81.
Jun 06 02:03:04 localhost systemd[1]: Finished Create System Users.
Jun 06 02:03:04 localhost systemd[1]: Starting Create Static Device Nodes in /dev...
Jun 06 02:03:05 localhost systemd[1]: Starting Create Volatile Files and Directories...
Jun 06 02:03:05 localhost systemd[1]: Finished dracut cmdline hook.
Jun 06 02:03:05 localhost systemd[1]: Finished Create Static Device Nodes in /dev.
Jun 06 02:03:05 localhost systemd[1]: Finished Create Volatile Files and Directories.
Jun 06 02:03:05 localhost systemd[1]: Starting dracut pre-udev hook...
Jun 06 02:03:05 localhost systemd[1]: Starting sysroot-xfs-ephemeral-mkfs.service...
Jun 06 02:03:05 localhost mkfs.xfs[933]: meta-data=/run/ephemeral_base/loopfs isize=512    agcount=4, agsize=4111879 blks
Jun 06 02:03:05 localhost mkfs.xfs[933]:          =                       sectsz=512   attr=2, projid32bit=1
Jun 06 02:03:05 localhost mkfs.xfs[933]:          =                       crc=1        finobt=1, sparse=1, rmapbt=0
Jun 06 02:03:05 localhost mkfs.xfs[933]:          =                       reflink=1    bigtime=1 inobtcount=1
Jun 06 02:03:05 localhost mkfs.xfs[933]: data     =                       bsize=4096   blocks=16447515, imaxpct=25
Jun 06 02:03:05 localhost mkfs.xfs[933]:          =                       sunit=0      swidth=0 blks
Jun 06 02:03:05 localhost mkfs.xfs[933]: naming   =version 2              bsize=4096   ascii-ci=0, ftype=1
Jun 06 02:03:05 localhost mkfs.xfs[933]: log      =internal log           bsize=4096   blocks=8031, version=2
Jun 06 02:03:05 localhost mkfs.xfs[933]:          =                       sectsz=512   sunit=0 blks, lazy-count=1
Jun 06 02:03:05 localhost mkfs.xfs[933]: realtime =none                   extsz=4096   blocks=0, rtextents=0
Jun 06 02:03:05 localhost systemd-journald[773]: Missed 31 kernel messages
Jun 06 02:03:05 localhost kernel: device-mapper: core: CONFIG_IMA_DISABLE_HTABLE is disabled. Duplicate IMA measurements will not be recorded in the IMA log.
Jun 06 02:03:05 localhost systemd-journald[773]: Missed 1 kernel messages
Jun 06 02:03:05 localhost kernel: device-mapper: uevent: version 1.0.3
Jun 06 02:03:05 localhost systemd-journald[773]: Missed 1 kernel messages
Jun 06 02:03:05 localhost kernel: device-mapper: ioctl: 4.47.0-ioctl (2022-07-28) initialised: dm-devel@redhat.com
Jun 06 02:03:05 localhost systemd[1]: Finished sysroot-xfs-ephemeral-mkfs.service.
Jun 06 02:03:05 localhost systemd[1]: Mounting /run/ephemeral...
Jun 06 02:03:05 localhost systemd-journald[773]: Missed 10 kernel messages
Jun 06 02:03:05 localhost kernel: loop: module loaded
Jun 06 02:03:05 localhost systemd[1]: Finished dracut pre-udev hook.
Jun 06 02:03:05 localhost kernel: loop0: detected capacity change from 0 to 131580120
Jun 06 02:03:05 localhost systemd[1]: Starting Rule-based Manager for Device Events and Files...
Jun 06 02:03:05 localhost systemd-udevd[958]: Using default interface naming scheme 'rhel-9.0'.
Jun 06 02:03:05 localhost systemd[1]: Started Rule-based Manager for Device Events and Files.
Jun 06 02:03:05 localhost systemd[1]: Starting dracut pre-trigger hook...
Jun 06 02:03:05 localhost dracut-pre-trigger[969]: rd.md=0: removing MD RAID activation
Jun 06 02:03:05 localhost systemd[1]: Finished dracut pre-trigger hook.
Jun 06 02:03:05 localhost systemd[1]: Starting Coldplug All udev Devices...
Jun 06 02:03:05 localhost systemd[1]: sys-module-fuse.device: Failed to enqueue SYSTEMD_WANTS= job, ignoring: Unit sys-fs-fuse-connections.mount not found.
Jun 06 02:03:05 localhost systemd[1]: Finished Coldplug All udev Devices.
Jun 06 02:03:05 localhost systemd[1]: Starting Wait for udev To Complete Device Initialization...
Jun 06 02:03:05 localhost udevadm[1101]: systemd-udev-settle.service is deprecated. Please fix multipathd-configure.service, run-media-iso.mount not to pull it in.
Jun 06 02:03:05 localhost systemd-journald[773]: Missed 12 kernel messages
Jun 06 02:03:05 localhost kernel: gnss: GNSS driver registered with major 240
Jun 06 02:03:05 localhost kernel: dca service started, version 1.12.1
Jun 06 02:03:05 localhost kernel: usb-storage 1-2:1.0: USB Mass Storage device detected
Jun 06 02:03:05 localhost kernel: scsi host0: usb-storage 1-2:1.0
Jun 06 02:03:05 localhost kernel: hpwdt 0000:01:00.0: HPE Watchdog Timer Driver: NMI decoding initialized
Jun 06 02:03:05 localhost kernel: usbcore: registered new interface driver usb-storage
Jun 06 02:03:05 localhost kernel: hpwdt 0000:01:00.0: HPE Watchdog Timer Driver: Version: 2.0.4
Jun 06 02:03:05 localhost kernel: hpwdt 0000:01:00.0: timeout: 30 seconds (nowayout=0)
Jun 06 02:03:05 localhost kernel: hpwdt 0000:01:00.0: pretimeout: on.
Jun 06 02:03:05 localhost kernel: hpwdt 0000:01:00.0: kdumptimeout: -1.
Jun 06 02:03:05 localhost kernel: SGI XFS with ACLs, security attributes, scrub, quota, no debug enabled
Jun 06 02:03:05 localhost kernel: XFS (loop0): Mounting V5 Filesystem
Jun 06 02:03:05 localhost systemd[1]: Mounted /run/ephemeral.
Jun 06 02:03:05 localhost kernel: XFS (loop0): Ending clean mount
Jun 06 02:03:05 localhost systemd-journald[773]: Missed 1 kernel messages
Jun 06 02:03:05 localhost kernel: igb: Intel(R) Gigabit Ethernet Network Driver
Jun 06 02:03:05 localhost kernel: igb: Copyright (c) 2007-2014 Intel Corporation.
Jun 06 02:03:05 localhost kernel: nvme nvme0: pci function 0000:c2:00.0
Jun 06 02:03:05 localhost kernel: nvme nvme1: pci function 0000:c3:00.0
Jun 06 02:03:05 localhost kernel: nvme nvme0: Shutdown timeout set to 8 seconds
Jun 06 02:03:05 localhost kernel: nvme nvme1: Shutdown timeout set to 8 seconds
Jun 06 02:03:05 localhost kernel: pps pps0: new PPS source ptp0
Jun 06 02:03:05 localhost kernel: igb 0000:03:00.0: added PHC on eth0
Jun 06 02:03:05 localhost kernel: nvme nvme0: 32/0/0 default/read/poll queues
Jun 06 02:03:05 localhost kernel: igb 0000:03:00.0: Intel(R) Gigabit Ethernet Network Connection
Jun 06 02:03:06 localhost kernel: nvme nvme1: 32/0/0 default/read/poll queues
Jun 06 02:03:06 localhost kernel: igb 0000:03:00.0: eth0: (PCIe:2.5Gb/s:Width x1) 5c:ba:2c:1f:6c:e5
Jun 06 02:03:06 localhost kernel: igb 0000:03:00.0: eth0: PBA No: 000300-000
Jun 06 02:03:06 localhost kernel: igb 0000:03:00.0: Using MSI-X interrupts. 4 rx queue(s), 4 tx queue(s)
Jun 06 02:03:06 localhost kernel: ice: Intel(R) Ethernet Connection E800 Series Linux Driver
Jun 06 02:03:06 localhost kernel: igb 0000:03:00.0 eno1: renamed from eth0
Jun 06 02:03:06 localhost kernel: ice: Copyright (c) 2018, Intel Corporation.
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.0: The DDP package was successfully loaded: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.0: PTP init successful
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.0: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.0: Configuring initial DCB values
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.0: Commit DCB Configuration to the hardware
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.0: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:02.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.1: DDP package already present on device: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:06 localhost kernel: scsi 0:0:0:0: CD-ROM            iLO      Virtual DVD-ROM       PQ: 0 ANSI: 0 CCS
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.1: PTP init successful
Jun 06 02:03:06 localhost kernel: scsi 0:0:0:0: Attached scsi generic sg0 type 5
Jun 06 02:03:06 localhost kernel: sr 0:0:0:0: [sr0] scsi3-mmc drive: 12x/12x cd/rw tray
Jun 06 02:03:06 localhost kernel: cdrom: Uniform CD-ROM driver Revision: 3.20
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.1: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.1: Configuring initial DCB values
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.1: Commit DCB Configuration to the hardware
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.1: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:02.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:06 localhost kernel: sr 0:0:0:0: Attached scsi CD-ROM sr0
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.2: DDP package already present on device: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.2: PTP init successful
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.2: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.2: Configuring initial DCB values
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.2: Commit DCB Configuration to the hardware
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.2: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:02.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.3: DDP package already present on device: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.3: PTP init successful
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.3: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.3: Configuring initial DCB values
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.3: Commit DCB Configuration to the hardware
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.3: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:02.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:07 localhost systemd[1]: Found device Virtual_DVD-ROM rhcos-413.92.202305021736-0.
Jun 06 02:03:07 localhost systemd-journald[773]: Missed 1 kernel messages
Jun 06 02:03:07 localhost kernel: ice 0000:12:00.0: The DDP package was successfully loaded: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.0: PTP init successful
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.0: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.0: Configuring initial DCB values
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.0: Commit DCB Configuration to the hardware
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.0: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:04.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.1: DDP package already present on device: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.1: PTP init successful
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.1: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.1: Configuring initial DCB values
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.1: Commit DCB Configuration to the hardware
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.1: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:04.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.2: DDP package already present on device: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.2: PTP init successful
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.2: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.2: Configuring initial DCB values
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.2: Commit DCB Configuration to the hardware
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.2: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:04.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.3: DDP package already present on device: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.3: PTP init successful
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.3: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.3: Configuring initial DCB values
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.3: Commit DCB Configuration to the hardware
Jun 06 02:03:09 localhost kernel: ice 0000:12:00.3: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:04.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:09 localhost kernel: ice 0000:10:00.3 ens1f3: renamed from eth3
Jun 06 02:03:09 localhost kernel: ice 0000:10:00.0 ens1f0: renamed from eth0
Jun 06 02:03:09 localhost kernel: ice 0000:10:00.2 ens1f2: renamed from eth2
Jun 06 02:03:09 localhost kernel: ice 0000:12:00.3 ens2f3: renamed from eth7
Jun 06 02:03:09 localhost kernel: ice 0000:12:00.2 ens2f2: renamed from eth6
Jun 06 02:03:09 localhost kernel: ice 0000:10:00.1 ens1f1: renamed from eth1
Jun 06 02:03:09 localhost kernel: ice 0000:12:00.1 ens2f1: renamed from eth5
Jun 06 02:03:09 localhost kernel: ice 0000:12:00.0 ens2f0: renamed from eth4
Jun 06 02:03:09 localhost kernel: i40e: Intel(R) Ethernet Connection XL710 Network Driver
Jun 06 02:03:09 localhost kernel: i40e: Copyright (c) 2013 - 2019 Intel Corporation.
Jun 06 02:03:09 localhost systemd[1]: Finished Wait for udev To Complete Device Initialization.
Jun 06 02:03:09 localhost systemd[1]: Created slice Slice /system/rdma-load-modules.
Jun 06 02:03:09 localhost systemd[1]: Device-Mapper Multipath Default Configuration was skipped because of an unmet condition check (ConditionKernelCommandLine=rd.multipath=default).
Jun 06 02:03:09 localhost systemd[1]: Starting Device-Mapper Multipath Device Controller...
Jun 06 02:03:10 localhost systemd[1]: Starting Load RDMA modules from /etc/rdma/modules/rdma.conf...
Jun 06 02:03:10 localhost multipathd[1266]: --------start up--------
Jun 06 02:03:10 localhost multipathd[1266]: read /etc/multipath.conf
Jun 06 02:03:10 localhost multipathd[1266]: /etc/multipath.conf does not exist, blacklisting all devices.
Jun 06 02:03:10 localhost multipathd[1266]: You can run "/sbin/mpathconf --enable" to create
Jun 06 02:03:10 localhost multipathd[1266]: /etc/multipath.conf. See man mpathconf(8) for more details
Jun 06 02:03:10 localhost multipathd[1266]: path checkers start up
Jun 06 02:03:10 localhost multipathd[1266]: /etc/multipath.conf does not exist, blacklisting all devices.
Jun 06 02:03:10 localhost multipathd[1266]: You can run "/sbin/mpathconf --enable" to create
Jun 06 02:03:10 localhost multipathd[1266]: /etc/multipath.conf. See man mpathconf(8) for more details
Jun 06 02:03:10 localhost systemd[1]: Started Device-Mapper Multipath Device Controller.
Jun 06 02:03:10 localhost systemd[1]: Reached target Preparation for Local File Systems.
Jun 06 02:03:10 localhost systemd[1]: Reached target Local File Systems.
Jun 06 02:03:10 localhost systemd-journald[773]: Missed 17 kernel messages
Jun 06 02:03:10 localhost kernel: Loading iSCSI transport class v2.0-870.
Jun 06 02:03:10 localhost kernel: iscsi: registered transport (iser)
Jun 06 02:03:10 localhost systemd-modules-load[1265]: Inserted module 'ib_iser'
Jun 06 02:03:10 localhost systemd-journald[773]: Missed 1 kernel messages
Jun 06 02:03:10 localhost kernel: Rounding down aligned max_sectors from 4294967295 to 4294967288
Jun 06 02:03:10 localhost kernel: db_root: cannot open: /etc/target
Jun 06 02:03:10 localhost systemd-modules-load[1265]: Inserted module 'ib_isert'
Jun 06 02:03:10 localhost systemd-modules-load[1265]: Inserted module 'ib_srpt'
Jun 06 02:03:10 localhost systemd-modules-load[1265]: Inserted module 'rdma_ucm'
Jun 06 02:03:10 localhost systemd-journald[773]: Missed 3 kernel messages
Jun 06 02:03:10 localhost kernel: RPC: Registered named UNIX socket transport module.
Jun 06 02:03:10 localhost kernel: RPC: Registered udp transport module.
Jun 06 02:03:10 localhost kernel: RPC: Registered tcp transport module.
Jun 06 02:03:10 localhost kernel: RPC: Registered tcp NFSv4.1 backchannel transport module.
Jun 06 02:03:10 localhost kernel: RPC: Registered rdma transport module.
Jun 06 02:03:10 localhost kernel: RPC: Registered rdma backchannel transport module.
Jun 06 02:03:10 localhost systemd-modules-load[1265]: Inserted module 'rpcrdma'
Jun 06 02:03:10 localhost systemd[1]: Finished Load RDMA modules from /etc/rdma/modules/rdma.conf.
Jun 06 02:03:10 localhost systemd[1]: Reached target Preparation for Network.
Jun 06 02:03:10 localhost systemd[1]: Reached target RDMA Hardware.
Jun 06 02:03:10 localhost systemd[1]: Reached target System Initialization.
Jun 06 02:03:10 localhost systemd[1]: Reached target Basic System.
Jun 06 02:03:10 localhost systemd[1]: Starting Ignition (fetch-offline)...
Jun 06 02:03:10 localhost ignition[1282]: Ignition 2.15.0
Jun 06 02:03:10 localhost ignition[1282]: Stage: fetch-offline
Jun 06 02:03:10 localhost ignition[1282]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:10 localhost ignition[1282]: parsing config with SHA512: ff6a5153be363997e4d5d3ea8cc4048373a457c48c4a5b134a08a30aacd167c1e0f099f0bdf1e24c99ad180628cd02b767b863b5fe3a8fce3fe1886847eb8e2e
Jun 06 02:03:10 localhost ignition[1282]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:10 localhost ignition[1282]: fetched base config from "system"
Jun 06 02:03:10 localhost ignition[1282]: parsed url from cmdline: ""
Jun 06 02:03:10 localhost ignition[1282]: fetched user config from "system"
Jun 06 02:03:10 localhost ignition[1282]: no config URL provided
Jun 06 02:03:10 localhost systemd[1]: Finished Ignition (fetch-offline).
Jun 06 02:03:10 localhost ignition[1282]: reading system config file "/usr/lib/ignition/user.ign"
Jun 06 02:03:10 localhost ignition[1282]: parsing config with SHA512: 09790f2f46eef6204b6be1d8cd2a28f3d2573f31b53ac7fc5fcd651c222252e4b2c420943864a5c756e2a5e093c616aec75eb2982a75e5ecb4a08e0f55850ba9
Jun 06 02:03:10 localhost ignition[1282]: fetch-offline: fetch-offline passed
Jun 06 02:03:10 localhost ignition[1282]: Ignition finished successfully
Jun 06 02:03:10 localhost systemd[1]: CoreOS Enable Network was skipped because no trigger condition checks were met.
Jun 06 02:03:10 localhost systemd[1]: Starting Copy CoreOS Firstboot Networking Config...
Jun 06 02:03:10 localhost coreos-copy-firstboot-network[1294]: info: no files to copy from /etc/coreos-firstboot-network; skipping
Jun 06 02:03:10 localhost systemd[1]: Finished Copy CoreOS Firstboot Networking Config.
Jun 06 02:03:10 localhost systemd[1]: nm-initrd.service was skipped because of an unmet condition check (ConditionPathExists=/run/NetworkManager/initrd/neednet).
Jun 06 02:03:10 localhost systemd[1]: Reached target Network.
Jun 06 02:03:10 localhost systemd[1]: Ignition (fetch) was skipped because of an unmet condition check (ConditionPathExists=!/run/ignition.json).
Jun 06 02:03:10 localhost systemd[1]: Starting Ignition (kargs)...
Jun 06 02:03:10 localhost systemd[1]: Ignition OSTree: Detect Partition Transposition was skipped because of an unmet condition check (ConditionKernelCommandLine=ostree).
Jun 06 02:03:10 localhost systemd[1]: Ignition OSTree: Save Partitions was skipped because of an unmet condition check (ConditionPathIsDirectory=/run/ignition-ostree-transposefs).
Jun 06 02:03:10 localhost ignition[1298]: Ignition 2.15.0
Jun 06 02:03:10 localhost systemd[1]: nm-wait-online-initrd.service was skipped because of an unmet condition check (ConditionPathExists=/run/NetworkManager/initrd/neednet).
Jun 06 02:03:10 localhost ignition[1298]: Stage: kargs
Jun 06 02:03:10 localhost systemd[1]: Starting dracut initqueue hook...
Jun 06 02:03:10 localhost ignition[1298]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:10 localhost ignition[1298]: parsing config with SHA512: ff6a5153be363997e4d5d3ea8cc4048373a457c48c4a5b134a08a30aacd167c1e0f099f0bdf1e24c99ad180628cd02b767b863b5fe3a8fce3fe1886847eb8e2e
Jun 06 02:03:10 localhost ignition[1298]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:10 localhost ignition[1298]: kargs: kargs passed
Jun 06 02:03:10 localhost ignition[1298]: Ignition finished successfully
Jun 06 02:03:11 localhost systemd[1]: Starting RHCOS Check For Legacy LUKS Configuration...
Jun 06 02:03:11 localhost systemd[1]: Finished Ignition (kargs).
Jun 06 02:03:11 localhost systemd[1]: Finished dracut initqueue hook.
Jun 06 02:03:11 localhost systemd[1]: Finished RHCOS Check For Legacy LUKS Configuration.
Jun 06 02:03:11 localhost systemd[1]: Reached target Preparation for Remote File Systems.
Jun 06 02:03:11 localhost systemd[1]: Reached target Remote Encrypted Volumes.
Jun 06 02:03:11 localhost systemd[1]: Reached target Remote File Systems.
Jun 06 02:03:11 localhost systemd[1]: CoreOS Kernel Arguments Reboot was skipped because of an unmet condition check (ConditionPathExists=/run/coreos-kargs-reboot).
Jun 06 02:03:11 localhost systemd[1]: Acquire Live PXE rootfs Image was skipped because of an unmet condition check (ConditionKernelCommandLine=!coreos.liveiso).
Jun 06 02:03:11 localhost systemd[1]: Persist Osmet Files (PXE) was skipped because of an unmet condition check (ConditionKernelCommandLine=!coreos.liveiso).
Jun 06 02:03:11 localhost systemd[1]: Starting dracut pre-mount hook...
Jun 06 02:03:11 localhost systemd[1]: Starting Ignition (disks)...
Jun 06 02:03:11 localhost ignition[1330]: Ignition 2.15.0
Jun 06 02:03:11 localhost ignition[1330]: Stage: disks
Jun 06 02:03:11 localhost ignition[1330]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:11 localhost ignition[1330]: parsing config with SHA512: ff6a5153be363997e4d5d3ea8cc4048373a457c48c4a5b134a08a30aacd167c1e0f099f0bdf1e24c99ad180628cd02b767b863b5fe3a8fce3fe1886847eb8e2e
Jun 06 02:03:11 localhost ignition[1330]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:11 localhost ignition[1330]: disks: disks passed
Jun 06 02:03:11 localhost ignition[1330]: Ignition finished successfully
Jun 06 02:03:11 localhost systemd[1]: Afterburn (Check In - from the initramfs) was skipped because of an unmet condition check (ConditionKernelCommandLine=ignition.platform.id=azure).
Jun 06 02:03:11 localhost systemd[1]: Finished dracut pre-mount hook.
Jun 06 02:03:11 localhost systemd[1]: Finished Ignition (disks).
Jun 06 02:03:11 localhost systemd[1]: Reached target Initrd Root Device.
Jun 06 02:03:11 localhost systemd[1]: Mounting /run/media/iso...
Jun 06 02:03:11 localhost systemd[1]: Ignition OSTree: Restore Partitions was skipped because of an unmet condition check (ConditionPathIsDirectory=/run/ignition-ostree-transposefs).
Jun 06 02:03:11 localhost systemd-journald[773]: Missed 60 kernel messages
Jun 06 02:03:11 localhost kernel: ISO 9660 Extensions: IEEE_P1282
Jun 06 02:03:11 localhost systemd[1]: Mounted /run/media/iso.
Jun 06 02:03:11 localhost systemd[1]: Mounting /sysroot...
Jun 06 02:03:11 localhost systemd-journald[773]: Missed 2 kernel messages
Jun 06 02:03:11 localhost kernel: loop1: detected capacity change from 0 to 1948353
Jun 06 02:03:11 localhost systemd[1]: Starting Persist Osmet Files (ISO)...
Jun 06 02:03:11 localhost systemd-journald[773]: Missed 1 kernel messages
Jun 06 02:03:11 localhost kernel: squashfs: version 4.0 (2009/01/31) Phillip Lougher
Jun 06 02:03:11 localhost bsdtar[1348]: bsdtar: Failed to set default locale
Jun 06 02:03:12 localhost systemd[1]: Mounted /sysroot.
Jun 06 02:03:12 localhost systemd[1]: Ignition OSTree: Grow Root Filesystem was skipped because of an unmet condition check (ConditionPathExists=!/run/ostree-live).
Jun 06 02:03:12 localhost systemd[1]: Starting OSTree Prepare OS/...
Jun 06 02:03:12 localhost ostree-prepare-root[1353]: preparing sysroot at /sysroot
Jun 06 02:03:12 localhost ostree-prepare-root[1353]: Resolved OSTree target to: /sysroot/ostree/deploy/rhcos/deploy/f069b5aca6a53934461a7361690bd20ad4aa3e223b6d12e77d54dc3ab4f48360.0
Jun 06 02:03:12 localhost ostree-prepare-root[1353]: filesystem at /sysroot currently writable: 0
Jun 06 02:03:12 localhost ostree-prepare-root[1353]: sysroot.readonly configuration value: 0
Jun 06 02:03:13 localhost systemd[1]: sysroot-ostree-deploy-rhcos-deploy-f069b5aca6a53934461a7361690bd20ad4aa3e223b6d12e77d54dc3ab4f48360.0.mount: Deactivated successfully.
Jun 06 02:03:13 localhost systemd[1]: sysroot.tmp-usr.mount: Deactivated successfully.
Jun 06 02:03:13 localhost systemd[1]: sysroot.tmp-boot.mount: Deactivated successfully.
Jun 06 02:03:13 localhost systemd[1]: sysroot.tmp.mount: Deactivated successfully.
Jun 06 02:03:13 localhost systemd[1]: proc-cmdline.mount: Deactivated successfully.
Jun 06 02:03:13 localhost systemd[1]: Finished OSTree Prepare OS/.
Jun 06 02:03:13 localhost systemd[1]: Ignition OSTree: Check Root Filesystem Size was skipped because of an unmet condition check (ConditionPathExists=!/run/ostree-live).
Jun 06 02:03:13 localhost systemd[1]: Starting sysroot-xfs-ephemeral-setup.service...
Jun 06 02:03:17 localhost systemd[1]: Finished Persist Osmet Files (ISO).
Jun 06 02:03:17 localhost systemd[1]: Finished sysroot-xfs-ephemeral-setup.service.
Jun 06 02:03:17 localhost systemd[1]: sysroot-etc.mount: Directory /sysroot/etc to mount over is not empty, mounting anyway.
Jun 06 02:03:17 localhost systemd[1]: Mounting /sysroot/etc...
Jun 06 02:03:17 localhost systemd[1]: Mounting /sysroot/var...
Jun 06 02:03:17 localhost systemd[1]: Mounted /sysroot/etc.
Jun 06 02:03:17 localhost systemd[1]: Mounted /sysroot/var.
Jun 06 02:03:17 localhost systemd[1]: Starting sysroot-relabel.service...
Jun 06 02:03:17 localhost systemd[1]: Finished sysroot-relabel.service.
Jun 06 02:03:17 localhost systemd[1]: Reached target Initrd Root File System.
Jun 06 02:03:17 localhost systemd[1]: Afterburn Hostname was skipped because no trigger condition checks were met.
Jun 06 02:03:17 localhost systemd[1]: Mount OSTree /var was skipped because of an unmet condition check (ConditionPathExists=!/run/ostree-live).
Jun 06 02:03:17 localhost systemd[1]: Starting Ignition (mount)...
Jun 06 02:03:17 localhost ignition[1368]: Ignition 2.15.0
Jun 06 02:03:17 localhost ignition[1368]: Stage: mount
Jun 06 02:03:17 localhost ignition[1368]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:17 localhost ignition[1368]: parsing config with SHA512: ff6a5153be363997e4d5d3ea8cc4048373a457c48c4a5b134a08a30aacd167c1e0f099f0bdf1e24c99ad180628cd02b767b863b5fe3a8fce3fe1886847eb8e2e
Jun 06 02:03:17 localhost ignition[1368]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:17 localhost ignition[1368]: mount: mount passed
Jun 06 02:03:17 localhost ignition[1368]: Ignition finished successfully
Jun 06 02:03:17 localhost systemd[1]: Finished Ignition (mount).
Jun 06 02:03:17 localhost systemd[1]: Clear SSSD NSS Cache in Persistent /var was skipped because of an unmet condition check (ConditionPathExists=/sysroot/var/lib/sss/mc).
Jun 06 02:03:17 localhost systemd[1]: Starting Populate OSTree /var...
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1382]: Relabeled /sysroot//var/lib from <no context> to system_u:object_r:var_lib_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1385]: Relabeled /sysroot//var/log from <no context> to system_u:object_r:var_log_t:s0
Jun 06 02:03:18 localhost systemd-tmpfiles[1386]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1386]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1388]: Relabeled /sysroot//var/home from <no context> to system_u:object_r:home_root_t:s0
Jun 06 02:03:18 localhost systemd-tmpfiles[1389]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1389]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome/.bash_logout from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome/.bash_profile from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome/.bashrc from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:18 localhost systemd-tmpfiles[1393]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1393]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1396]: Relabeled /sysroot//var/opt from <no context> to system_u:object_r:var_t:s0
Jun 06 02:03:18 localhost systemd-tmpfiles[1397]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1397]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1399]: Relabeled /sysroot//var/srv from <no context> to system_u:object_r:var_t:s0
Jun 06 02:03:18 localhost systemd-tmpfiles[1400]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1400]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/bin from <no context> to system_u:object_r:bin_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/etc from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/games from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/include from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/lib from <no context> to system_u:object_r:lib_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/man from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/sbin from <no context> to system_u:object_r:bin_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/share from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/src from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1405]: Relabeled /sysroot//var/mnt from <no context> to system_u:object_r:mnt_t:s0
Jun 06 02:03:18 localhost systemd-tmpfiles[1403]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1403]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1406]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1406]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd[1]: Finished Populate OSTree /var.
Jun 06 02:03:19 localhost systemd[1]: Starting Ignition (files)...
Jun 06 02:03:19 localhost ignition[1409]: Ignition 2.15.0
Jun 06 02:03:19 localhost ignition[1409]: Stage: files
Jun 06 02:03:19 localhost ignition[1409]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:19 localhost ignition[1409]: parsing config with SHA512: ff6a5153be363997e4d5d3ea8cc4048373a457c48c4a5b134a08a30aacd167c1e0f099f0bdf1e24c99ad180628cd02b767b863b5fe3a8fce3fe1886847eb8e2e
Jun 06 02:03:19 localhost ignition[1409]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:19 localhost ignition[1409]: files: ensureUsers: op(1): [started]  creating or modifying user "core"
Jun 06 02:03:19 localhost ignition[1409]: files: ensureUsers: op(1): executing: "useradd" "--root" "/sysroot" "--create-home" "--password" "$2a$10$86xgByocUSRwRniHSvMPBeTivQ6AoxOXF.lRnH9QHcXW0Jb/A.IjK" "--comment" "CoreOS Admin" "--groups">
Jun 06 02:03:22 localhost ignition[1409]: files: ensureUsers: op(1): [finished] creating or modifying user "core"
Jun 06 02:03:22 localhost ignition[1409]: files: ensureUsers: op(2): [started]  setting password for "core"
Jun 06 02:03:22 localhost ignition[1409]: files: ensureUsers: op(2): executing: "usermod" "--root" "/sysroot" "--password" "$2a$10$86xgByocUSRwRniHSvMPBeTivQ6AoxOXF.lRnH9QHcXW0Jb/A.IjK" "core"
Jun 06 02:03:22 localhost ignition[1409]: wrote ssh authorized keys file for user: core
Jun 06 02:03:22 localhost ignition[1409]: files: ensureUsers: op(2): [finished] setting password for "core"
Jun 06 02:03:22 localhost ignition[1409]: files: ensureUsers: op(3): [started]  adding ssh keys to user "core"
Jun 06 02:03:22 localhost ignition[1409]: files: ensureUsers: op(3): [finished] adding ssh keys to user "core"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(4): [started]  writing file "/sysroot/etc/issue"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(4): [finished] writing file "/sysroot/etc/issue"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(5): [started]  writing file "/sysroot/etc/multipath.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(5): [finished] writing file "/sysroot/etc/multipath.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(6): [started]  writing file "/sysroot/var/roothome/assisted.te"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(6): [finished] writing file "/sysroot/var/roothome/assisted.te"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(7): [started]  writing file "/sysroot/etc/assisted/agent-installer.env"
Jun 06 02:03:22 localhost systemd[1]: Finished Ignition (files).
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(7): [finished] writing file "/sysroot/etc/assisted/agent-installer.env"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(8): [started]  writing file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(8): [finished] writing file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(9): [started]  appending to file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(9): [finished] appending to file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(a): [started]  writing file "/sysroot/etc/motd.d/10-agent-installer"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(a): [finished] writing file "/sysroot/etc/motd.d/10-agent-installer"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(b): [started]  writing file "/sysroot/etc/containers/registries.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(b): [finished] writing file "/sysroot/etc/containers/registries.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(c): [started]  writing file "/sysroot/etc/assisted/extra-manifests/04-accelerated-container-startup-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(c): [finished] writing file "/sysroot/etc/assisted/extra-manifests/04-accelerated-container-startup-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(d): [started]  writing file "/sysroot/etc/systemd/system.conf.d/10-default-env.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(d): [finished] writing file "/sysroot/etc/systemd/system.conf.d/10-default-env.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(e): [started]  writing file "/sysroot/var/usrlocal/bin/common.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(e): [finished] writing file "/sysroot/var/usrlocal/bin/common.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(f): [started]  writing file "/sysroot/var/usrlocal/bin/extract-agent.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(f): [finished] writing file "/sysroot/var/usrlocal/bin/extract-agent.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(10): [started]  writing file "/sysroot/var/usrlocal/bin/get-container-images.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(10): [finished] writing file "/sysroot/var/usrlocal/bin/get-container-images.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(11): [started]  writing file "/sysroot/var/usrlocal/bin/install-status.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(11): [finished] writing file "/sysroot/var/usrlocal/bin/install-status.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(12): [started]  writing file "/sysroot/var/usrlocal/bin/issue_status.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(12): [finished] writing file "/sysroot/var/usrlocal/bin/issue_status.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(13): [started]  writing file "/sysroot/var/usrlocal/bin/set-hostname.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(13): [finished] writing file "/sysroot/var/usrlocal/bin/set-hostname.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(14): [started]  writing file "/sysroot/var/usrlocal/bin/set-node-zero.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(14): [finished] writing file "/sysroot/var/usrlocal/bin/set-node-zero.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(15): [started]  writing file "/sysroot/var/usrlocal/bin/start-agent.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(15): [finished] writing file "/sysroot/var/usrlocal/bin/start-agent.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(16): [started]  writing file "/sysroot/var/usrlocal/bin/start-cluster-installation.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(16): [finished] writing file "/sysroot/var/usrlocal/bin/start-cluster-installation.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(17): [started]  writing file "/sysroot/var/usrlocal/bin/wait-for-assisted-service.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(17): [finished] writing file "/sysroot/var/usrlocal/bin/wait-for-assisted-service.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(18): [started]  writing file "/sysroot/etc/assisted/extra-manifests/enable-crun-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(18): [finished] writing file "/sysroot/etc/assisted/extra-manifests/enable-crun-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(19): [started]  writing file "/sysroot/etc/assisted/extra-manifests/StorageSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(19): [finished] writing file "/sysroot/etc/assisted/extra-manifests/StorageSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1a): [started]  writing file "/sysroot/etc/assisted/extra-manifests/StorageOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1a): [finished] writing file "/sysroot/etc/assisted/extra-manifests/StorageOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1b): [started]  writing file "/sysroot/var/usrlocal/bin/bootstrap-service-record.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1b): [finished] writing file "/sysroot/var/usrlocal/bin/bootstrap-service-record.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1c): [started]  writing file "/sysroot/var/usrlocal/bin/release-image.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1c): [finished] writing file "/sysroot/var/usrlocal/bin/release-image.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1d): [started]  writing file "/sysroot/var/usrlocal/bin/release-image-download.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1d): [finished] writing file "/sysroot/var/usrlocal/bin/release-image-download.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1e): [started]  writing file "/sysroot/etc/assisted/manifests/agent-cluster-install.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1e): [finished] writing file "/sysroot/etc/assisted/manifests/agent-cluster-install.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1f): [started]  writing file "/sysroot/etc/assisted/manifests/cluster-deployment.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1f): [finished] writing file "/sysroot/etc/assisted/manifests/cluster-deployment.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(20): [started]  writing file "/sysroot/etc/assisted/manifests/cluster-image-set.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(20): [finished] writing file "/sysroot/etc/assisted/manifests/cluster-image-set.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(21): [started]  writing file "/sysroot/etc/assisted/manifests/infraenv.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(21): [finished] writing file "/sysroot/etc/assisted/manifests/infraenv.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(22): [started]  writing file "/sysroot/etc/assisted/manifests/nmstateconfig.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(22): [finished] writing file "/sysroot/etc/assisted/manifests/nmstateconfig.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(23): [started]  writing file "/sysroot/etc/assisted/manifests/pull-secret.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(23): [finished] writing file "/sysroot/etc/assisted/manifests/pull-secret.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(24): [started]  writing file "/sysroot/etc/assisted/manifests/agent-config.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(24): [finished] writing file "/sysroot/etc/assisted/manifests/agent-config.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(25): [started]  writing file "/sysroot/etc/assisted/hostnames/b4:96:91:d9:a4:64"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(25): [finished] writing file "/sysroot/etc/assisted/hostnames/b4:96:91:d9:a4:64"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(26): [started]  writing file "/sysroot/etc/assisted/extra-manifests/StorageNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(26): [finished] writing file "/sysroot/etc/assisted/extra-manifests/StorageNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(27): [started]  writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(27): [finished] writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(28): [started]  writing file "/sysroot/var/usrlocal/bin/pre-network-manager-config.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(28): [finished] writing file "/sysroot/var/usrlocal/bin/pre-network-manager-config.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(29): [started]  writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(29): [finished] writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2a): [started]  writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2a): [finished] writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2b): [started]  writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2b): [finished] writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2c): [started]  writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2c): [finished] writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2d): [started]  writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2d): [finished] writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2e): [started]  writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2e): [finished] writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2f): [started]  writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2f): [finished] writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(30): [started]  writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(30): [finished] writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(31): [started]  writing file "/sysroot/etc/assisted/extra-manifests/99-crio-disable-wipe-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(31): [finished] writing file "/sysroot/etc/assisted/extra-manifests/99-crio-disable-wipe-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(32): [started]  writing file "/sysroot/var/roothome/.docker/config.json"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(32): [finished] writing file "/sysroot/var/roothome/.docker/config.json"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(33): [started]  writing file "/sysroot/etc/assisted/extra-manifests/06-kdump-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(33): [finished] writing file "/sysroot/etc/assisted/extra-manifests/06-kdump-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(34): [started]  writing file "/sysroot/etc/assisted/extra-manifests/05-kdump-config-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(34): [finished] writing file "/sysroot/etc/assisted/extra-manifests/05-kdump-config-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(35): [started]  writing file "/sysroot/etc/assisted/extra-manifests/01-container-mount-ns-and-kubelet-conf-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(35): [finished] writing file "/sysroot/etc/assisted/extra-manifests/01-container-mount-ns-and-kubelet-conf-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(36): [started]  writing file "/sysroot/etc/assisted/extra-manifests/02-master-workload-partitioning-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(36): [finished] writing file "/sysroot/etc/assisted/extra-manifests/02-master-workload-partitioning-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(37): [started]  writing file "/sysroot/var/usrlocal/bin/agent-gather"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(37): [finished] writing file "/sysroot/var/usrlocal/bin/agent-gather"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(38): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(38): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(39): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(39): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3a): [started]  writing file "/sysroot/var/opt/agent/tls/kubeadmin-password.hash"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3a): [finished] writing file "/sysroot/var/opt/agent/tls/kubeadmin-password.hash"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3b): [started]  writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3b): [finished] writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3c): [started]  writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/root-device-hints.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3c): [finished] writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/root-device-hints.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3d): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3d): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3e): [started]  writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/mac_addresses"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3e): [finished] writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/mac_addresses"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3f): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3f): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(40): [started]  writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(40): [finished] writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(41): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(41): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(42): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(42): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(43): [started]  writing file "/sysroot/etc/assisted/network/host0/mac_interface.ini"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(43): [finished] writing file "/sysroot/etc/assisted/network/host0/mac_interface.ini"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(44): [started]  writing file "/sysroot/etc/assisted/network/host0/ens1f0.nmconnection"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(44): [finished] writing file "/sysroot/etc/assisted/network/host0/ens1f0.nmconnection"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(45): [started]  writing file "/sysroot/var/usrlocal/share/assisted-service/images.env"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(45): [finished] writing file "/sysroot/var/usrlocal/share/assisted-service/images.env"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(46): [started]  writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-service.env"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(46): [finished] writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-service.env"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(47): [started]  writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-db.env"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(47): [finished] writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-db.env"
Jun 06 02:03:22 localhost ignition[1409]: files: op(48): [started]  processing unit "agent-interactive-console.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(48): op(49): [started]  writing unit "agent-interactive-console.service" at "/sysroot/etc/systemd/system/agent-interactive-console.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(48): op(49): [finished] writing unit "agent-interactive-console.service" at "/sysroot/etc/systemd/system/agent-interactive-console.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(48): [finished] processing unit "agent-interactive-console.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4a): [started]  processing unit "agent.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4a): op(4b): [started]  writing unit "agent.service" at "/sysroot/etc/systemd/system/agent.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4a): op(4b): [finished] writing unit "agent.service" at "/sysroot/etc/systemd/system/agent.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4a): [finished] processing unit "agent.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4c): [started]  processing unit "apply-host-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4c): op(4d): [started]  writing unit "apply-host-config.service" at "/sysroot/etc/systemd/system/apply-host-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4c): op(4d): [finished] writing unit "apply-host-config.service" at "/sysroot/etc/systemd/system/apply-host-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4c): [finished] processing unit "apply-host-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4e): [started]  processing unit "assisted-service-db.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4e): op(4f): [started]  writing unit "assisted-service-db.service" at "/sysroot/etc/systemd/system/assisted-service-db.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4e): op(4f): [finished] writing unit "assisted-service-db.service" at "/sysroot/etc/systemd/system/assisted-service-db.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4e): [finished] processing unit "assisted-service-db.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(50): [started]  processing unit "assisted-service-pod.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(50): op(51): [started]  writing unit "assisted-service-pod.service" at "/sysroot/etc/systemd/system/assisted-service-pod.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(50): op(51): [finished] writing unit "assisted-service-pod.service" at "/sysroot/etc/systemd/system/assisted-service-pod.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(50): [finished] processing unit "assisted-service-pod.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(52): [started]  processing unit "assisted-service.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(52): op(53): [started]  writing unit "assisted-service.service" at "/sysroot/etc/systemd/system/assisted-service.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(52): op(53): [finished] writing unit "assisted-service.service" at "/sysroot/etc/systemd/system/assisted-service.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(52): [finished] processing unit "assisted-service.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(54): [started]  processing unit "create-cluster-and-infraenv.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(54): op(55): [started]  writing unit "create-cluster-and-infraenv.service" at "/sysroot/etc/systemd/system/create-cluster-and-infraenv.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(54): op(55): [finished] writing unit "create-cluster-and-infraenv.service" at "/sysroot/etc/systemd/system/create-cluster-and-infraenv.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(54): [finished] processing unit "create-cluster-and-infraenv.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(56): [started]  processing unit "install-status.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(56): op(57): [started]  writing unit "install-status.service" at "/sysroot/etc/systemd/system/install-status.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(56): op(57): [finished] writing unit "install-status.service" at "/sysroot/etc/systemd/system/install-status.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(56): [finished] processing unit "install-status.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(58): [started]  processing unit "node-zero.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(58): op(59): [started]  writing unit "node-zero.service" at "/sysroot/etc/systemd/system/node-zero.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(58): op(59): [finished] writing unit "node-zero.service" at "/sysroot/etc/systemd/system/node-zero.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(58): [finished] processing unit "node-zero.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5a): [started]  processing unit "pre-network-manager-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5a): op(5b): [started]  writing unit "pre-network-manager-config.service" at "/sysroot/etc/systemd/system/pre-network-manager-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5a): op(5b): [finished] writing unit "pre-network-manager-config.service" at "/sysroot/etc/systemd/system/pre-network-manager-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5a): [finished] processing unit "pre-network-manager-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5c): [started]  processing unit "selinux.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5c): op(5d): [started]  writing unit "selinux.service" at "/sysroot/etc/systemd/system/selinux.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5c): op(5d): [finished] writing unit "selinux.service" at "/sysroot/etc/systemd/system/selinux.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5c): [finished] processing unit "selinux.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5e): [started]  processing unit "set-hostname.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5e): op(5f): [started]  writing unit "set-hostname.service" at "/sysroot/etc/systemd/system/set-hostname.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5e): op(5f): [finished] writing unit "set-hostname.service" at "/sysroot/etc/systemd/system/set-hostname.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5e): [finished] processing unit "set-hostname.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(60): [started]  processing unit "start-cluster-installation.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(60): op(61): [started]  writing unit "start-cluster-installation.service" at "/sysroot/etc/systemd/system/start-cluster-installation.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(60): op(61): [finished] writing unit "start-cluster-installation.service" at "/sysroot/etc/systemd/system/start-cluster-installation.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(60): [finished] processing unit "start-cluster-installation.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(62): [started]  setting preset to enabled for "agent-interactive-console.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(62): [finished] setting preset to enabled for "agent-interactive-console.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(63): [started]  setting preset to enabled for "agent.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(63): [finished] setting preset to enabled for "agent.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(64): [started]  setting preset to enabled for "assisted-service-db.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(64): [finished] setting preset to enabled for "assisted-service-db.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(65): [started]  setting preset to enabled for "assisted-service-pod.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(65): [finished] setting preset to enabled for "assisted-service-pod.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(66): [started]  setting preset to enabled for "assisted-service.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(66): [finished] setting preset to enabled for "assisted-service.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(67): [started]  setting preset to enabled for "create-cluster-and-infraenv.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(67): [finished] setting preset to enabled for "create-cluster-and-infraenv.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(68): [started]  setting preset to enabled for "install-status.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(68): [finished] setting preset to enabled for "install-status.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(69): [started]  setting preset to enabled for "node-zero.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(69): [finished] setting preset to enabled for "node-zero.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6a): [started]  setting preset to enabled for "pre-network-manager-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6a): [finished] setting preset to enabled for "pre-network-manager-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6b): [started]  setting preset to enabled for "selinux.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6b): [finished] setting preset to enabled for "selinux.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6c): [started]  setting preset to enabled for "set-hostname.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6c): [finished] setting preset to enabled for "set-hostname.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6d): [started]  setting preset to enabled for "start-cluster-installation.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6d): [finished] setting preset to enabled for "start-cluster-installation.service"
Jun 06 02:03:22 localhost ignition[1409]: files: createResultFile: createFiles: op(6e): [started]  writing file "/sysroot/etc/.ignition-result.json"
Jun 06 02:03:22 localhost ignition[1409]: files: createResultFile: createFiles: op(6e): [finished] writing file "/sysroot/etc/.ignition-result.json"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6f): [started]  relabeling 97 patterns
Jun 06 02:03:22 localhost ignition[1409]: files: op(6f): executing: "setfiles" "-vF0" "-r" "/sysroot" "/sysroot/etc/selinux/targeted/contexts/files/file_contexts" "-f" "-"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6f): [finished] relabeling 97 patterns
Jun 06 02:03:22 localhost ignition[1409]: files: files passed
Jun 06 02:03:22 localhost ignition[1409]: Ignition finished successfully
Jun 06 02:03:27 localhost systemd[1]: Starting CoreOS Post Ignition Checks...
Jun 06 02:03:27 localhost systemd[1]: CoreOS Propagate Multipath Configuration was skipped because of an unmet condition check (ConditionKernelCommandLine=rd.multipath=default).
Jun 06 02:03:27 localhost systemd[1]: Starting Mountpoints Configured in the Real Root...
Jun 06 02:03:28 localhost systemd[1]: Finished CoreOS Post Ignition Checks.
Jun 06 02:03:28 localhost systemd[1]: Reached target Ignition Complete.
Jun 06 02:03:28 localhost multipathd[1266]: exit (signal)
Jun 06 02:03:28 localhost multipathd[1266]: --------shut down-------
Jun 06 02:03:28 localhost systemd[1]: Stopping Device-Mapper Multipath Device Controller...
Jun 06 02:03:28 localhost systemd[1]: multipathd.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped Device-Mapper Multipath Device Controller.
Jun 06 02:03:28 localhost systemd[1]: initrd-parse-etc.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Finished Mountpoints Configured in the Real Root.
Jun 06 02:03:28 localhost systemd[1]: Reached target Initrd File Systems.
Jun 06 02:03:28 localhost systemd[1]: Reached target Initrd Default Target.
Jun 06 02:03:28 localhost systemd[1]: Starting dracut mount hook...
Jun 06 02:03:28 localhost systemd[1]: Finished dracut mount hook.
Jun 06 02:03:28 localhost systemd[1]: Starting dracut pre-pivot and cleanup hook...
Jun 06 02:03:28 localhost dracut-pre-pivot[1553]: 27.335184 | /etc/multipath.conf does not exist, blacklisting all devices.
Jun 06 02:03:28 localhost dracut-pre-pivot[1553]: 27.335195 | You can run "/sbin/mpathconf --enable" to create
Jun 06 02:03:28 localhost dracut-pre-pivot[1553]: 27.335196 | /etc/multipath.conf. See man mpathconf(8) for more details
Jun 06 02:03:28 localhost systemd[1]: Finished dracut pre-pivot and cleanup hook.
Jun 06 02:03:28 localhost systemd[1]: Starting Cleaning Up and Shutting Down Daemons...
Jun 06 02:03:28 localhost systemd[1]: Stopped target Network.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Preparation for Network.
Jun 06 02:03:28 localhost systemd[1]: Stopped target RDMA Hardware.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Remote Encrypted Volumes.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Timer Units.
Jun 06 02:03:28 localhost systemd[1]: dbus.socket: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Closed D-Bus System Message Bus Socket.
Jun 06 02:03:28 localhost systemd[1]: coreos-liveiso-persist-osmet.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped Persist Osmet Files (ISO).
Jun 06 02:03:28 localhost systemd[1]: dracut-pre-pivot.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped dracut pre-pivot and cleanup hook.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Initrd Default Target.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Ignition Complete.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Initrd Root Device.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Initrd /usr File System.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Remote File Systems.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Preparation for Remote File Systems.
Jun 06 02:03:28 localhost systemd[1]: coreos-post-ignition-checks.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped CoreOS Post Ignition Checks.
Jun 06 02:03:28 localhost systemd[1]: coreos-touch-run-agetty.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped CoreOS: Touch /run/agetty.reload.
Jun 06 02:03:28 localhost systemd[1]: dracut-mount.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped dracut mount hook.
Jun 06 02:03:28 localhost systemd[1]: dracut-pre-mount.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped dracut pre-mount hook.
Jun 06 02:03:28 localhost systemd[1]: dracut-initqueue.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped dracut initqueue hook.
Jun 06 02:03:28 localhost systemd[1]: ignition-fetch-offline.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped Ignition (fetch-offline).
Jun 06 02:03:28 localhost systemd[1]: coreos-ignition-setup-user.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped CoreOS Ignition User Config Setup.
Jun 06 02:03:29 localhost systemd[1]: ignition-files.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Ignition (files).
Jun 06 02:03:29 localhost systemd[1]: ignition-ostree-populate-var.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Populate OSTree /var.
Jun 06 02:03:29 localhost systemd[1]: Stopping Ignition (mount)...
Jun 06 02:03:29 localhost ignition[1559]: Ignition 2.15.0
Jun 06 02:03:29 localhost ignition[1559]: Stage: umount
Jun 06 02:03:29 localhost ignition[1559]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:29 localhost ignition[1559]: parsing config with SHA512: ff6a5153be363997e4d5d3ea8cc4048373a457c48c4a5b134a08a30aacd167c1e0f099f0bdf1e24c99ad180628cd02b767b863b5fe3a8fce3fe1886847eb8e2e
Jun 06 02:03:29 localhost ignition[1559]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:29 localhost ignition[1559]: umount: umount passed
Jun 06 02:03:29 localhost ignition[1559]: Ignition finished successfully
Jun 06 02:03:29 localhost systemd[1]: ignition-mount.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Ignition (mount).
Jun 06 02:03:29 localhost systemd[1]: Unmount Live /var if Persistent /var Is Configured was skipped because no trigger condition checks were met.
Jun 06 02:03:29 localhost systemd[1]: Stopping CoreOS Tear Down Initramfs...
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: eno1
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1581]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f0
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1585]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f1
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1589]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f2
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1593]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f3
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1597]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f0
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1601]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f1
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1605]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f2
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1609]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f3
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1613]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: flushing all routing
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: no initramfs hostname information to propagate
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: no networking config is defined in the real root
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: skipping propagation of default networking configs
Jun 06 02:03:29 localhost systemd[1]: ignition-disks.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Ignition (disks).
Jun 06 02:03:29 localhost systemd[1]: ignition-kargs.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Ignition (kargs).
Jun 06 02:03:29 localhost systemd[1]: coreos-copy-firstboot-network.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Copy CoreOS Firstboot Networking Config.
Jun 06 02:03:29 localhost systemd[1]: rhcos-fail-boot-for-legacy-luks-config.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped RHCOS Check For Legacy LUKS Configuration.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Basic System.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Path Units.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Slice Units.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Socket Units.
Jun 06 02:03:29 localhost systemd[1]: Stopped target System Initialization.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Local Encrypted Volumes.
Jun 06 02:03:29 localhost systemd[1]: systemd-ask-password-console.path: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Dispatch Password Requests to Console Directory Watch.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Local Encrypted Volumes (Pre).
Jun 06 02:03:29 localhost systemd[1]: clevis-luks-askpass.path: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Forward Password Requests to Clevis Directory Watch.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Local File Systems.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Preparation for Local File Systems.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Swaps.
Jun 06 02:03:29 localhost systemd[1]: Acquire Live PXE rootfs Image was skipped because of an unmet condition check (ConditionKernelCommandLine=!coreos.liveiso).
Jun 06 02:03:29 localhost systemd[1]: rdma-load-modules@rdma.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Load RDMA modules from /etc/rdma/modules/rdma.conf.
Jun 06 02:03:29 localhost systemd[1]: systemd-sysctl.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Apply Kernel Variables.
Jun 06 02:03:30 localhost systemd[1]: systemd-modules-load.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Load Kernel Modules.
Jun 06 02:03:30 localhost systemd[1]: systemd-tmpfiles-setup.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Create Volatile Files and Directories.
Jun 06 02:03:30 localhost systemd[1]: systemd-udev-settle.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Wait for udev To Complete Device Initialization.
Jun 06 02:03:30 localhost systemd[1]: systemd-udev-trigger.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Coldplug All udev Devices.
Jun 06 02:03:30 localhost systemd[1]: dracut-pre-trigger.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped dracut pre-trigger hook.
Jun 06 02:03:30 localhost systemd[1]: Stopping Rule-based Manager for Device Events and Files...
Jun 06 02:03:30 localhost systemd[1]: run-credentials-systemd\x2dtmpfiles\x2dsetup.service.mount: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: run-credentials-systemd\x2dsysctl.service.mount: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: systemd-udevd.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Rule-based Manager for Device Events and Files.
Jun 06 02:03:30 localhost systemd[1]: systemd-udevd.service: Consumed 6.401s CPU time.
Jun 06 02:03:30 localhost systemd[1]: initrd-cleanup.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Finished Cleaning Up and Shutting Down Daemons.
Jun 06 02:03:30 localhost systemd[1]: coreos-teardown-initramfs.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped CoreOS Tear Down Initramfs.
Jun 06 02:03:30 localhost systemd[1]: systemd-udevd-control.socket: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Closed udev Control Socket.
Jun 06 02:03:30 localhost systemd[1]: systemd-udevd-kernel.socket: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Closed udev Kernel Socket.
Jun 06 02:03:30 localhost systemd[1]: dracut-pre-udev.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped dracut pre-udev hook.
Jun 06 02:03:30 localhost systemd[1]: dracut-cmdline.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped dracut cmdline hook.
Jun 06 02:03:30 localhost systemd[1]: afterburn-network-kargs.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Afterburn Initrd Setup Network Kernel Arguments.
Jun 06 02:03:30 localhost systemd[1]: CoreOS Enable Network was skipped because no trigger condition checks were met.
Jun 06 02:03:30 localhost systemd[1]: dracut-cmdline-ask.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped dracut ask for additional cmdline parameters.
Jun 06 02:03:30 localhost systemd[1]: Starting Cleanup udev Database...
Jun 06 02:03:30 localhost systemd[1]: systemd-tmpfiles-setup-dev.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Create Static Device Nodes in /dev.
Jun 06 02:03:30 localhost systemd[1]: kmod-static-nodes.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Create List of Static Device Nodes.
Jun 06 02:03:30 localhost systemd[1]: systemd-sysusers.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Create System Users.
Jun 06 02:03:30 localhost systemd[1]: systemd-vconsole-setup.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Setup Virtual Console.
Jun 06 02:03:30 localhost systemd[1]: run-credentials-systemd\x2dtmpfiles\x2dsetup\x2ddev.service.mount: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: run-credentials-systemd\x2dsysusers.service.mount: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: initrd-udevadm-cleanup-db.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Finished Cleanup udev Database.
Jun 06 02:03:30 localhost systemd[1]: Reached target Switch Root.
Jun 06 02:03:30 localhost systemd[1]: Starting Switch Root...
Jun 06 02:03:30 localhost systemd[1]: Switching root.
Jun 06 02:03:30 localhost systemd-journald[773]: Journal stopped
Jun 06 02:03:35 localhost bsdtar[1348]: bsdtar: Failed to set default locale
Jun 06 02:03:35 localhost systemd[1]: Mounted /sysroot.
Jun 06 02:03:35 localhost systemd[1]: Ignition OSTree: Grow Root Filesystem was skipped because of an unmet condition check (ConditionPathExists=!/run/ostree-live).
Jun 06 02:03:35 localhost systemd[1]: Starting OSTree Prepare OS/...
Jun 06 02:03:35 localhost ostree-prepare-root[1353]: preparing sysroot at /sysroot
Jun 06 02:03:35 localhost ostree-prepare-root[1353]: Resolved OSTree target to: /sysroot/ostree/deploy/rhcos/deploy/f069b5aca6a53934461a7361690bd20ad4aa3e223b6d12e77d54dc3ab4f48360.0
Jun 06 02:03:35 localhost ostree-prepare-root[1353]: filesystem at /sysroot currently writable: 0
Jun 06 02:03:35 localhost ostree-prepare-root[1353]: sysroot.readonly configuration value: 0
Jun 06 02:03:35 localhost systemd[1]: sysroot-ostree-deploy-rhcos-deploy-f069b5aca6a53934461a7361690bd20ad4aa3e223b6d12e77d54dc3ab4f48360.0.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: sysroot.tmp-usr.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: sysroot.tmp-boot.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: sysroot.tmp.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: proc-cmdline.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Finished OSTree Prepare OS/.
Jun 06 02:03:35 localhost systemd[1]: Ignition OSTree: Check Root Filesystem Size was skipped because of an unmet condition check (ConditionPathExists=!/run/ostree-live).
Jun 06 02:03:35 localhost systemd[1]: Starting sysroot-xfs-ephemeral-setup.service...
Jun 06 02:03:35 localhost systemd[1]: Finished Persist Osmet Files (ISO).
Jun 06 02:03:35 localhost systemd[1]: Finished sysroot-xfs-ephemeral-setup.service.
Jun 06 02:03:35 localhost systemd[1]: sysroot-etc.mount: Directory /sysroot/etc to mount over is not empty, mounting anyway.
Jun 06 02:03:35 localhost systemd[1]: Mounting /sysroot/etc...
Jun 06 02:03:35 localhost systemd[1]: Mounting /sysroot/var...
Jun 06 02:03:35 localhost systemd[1]: Mounted /sysroot/etc.
Jun 06 02:03:35 localhost systemd[1]: Mounted /sysroot/var.
Jun 06 02:03:35 localhost systemd[1]: Starting sysroot-relabel.service...
Jun 06 02:03:35 localhost systemd[1]: Finished sysroot-relabel.service.
Jun 06 02:03:35 localhost systemd[1]: Reached target Initrd Root File System.
Jun 06 02:03:35 localhost systemd[1]: Afterburn Hostname was skipped because no trigger condition checks were met.
Jun 06 02:03:35 localhost systemd[1]: Mount OSTree /var was skipped because of an unmet condition check (ConditionPathExists=!/run/ostree-live).
Jun 06 02:03:35 localhost systemd[1]: Starting Ignition (mount)...
Jun 06 02:03:35 localhost ignition[1368]: Ignition 2.15.0
Jun 06 02:03:35 localhost ignition[1368]: Stage: mount
Jun 06 02:03:35 localhost ignition[1368]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:35 localhost ignition[1368]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:35 localhost ignition[1368]: mount: mount passed
Jun 06 02:03:35 localhost ignition[1368]: Ignition finished successfully
Jun 06 02:03:35 localhost systemd[1]: Finished Ignition (mount).
Jun 06 02:03:35 localhost systemd[1]: Clear SSSD NSS Cache in Persistent /var was skipped because of an unmet condition check (ConditionPathExists=/sysroot/var/lib/sss/mc).
Jun 06 02:03:35 localhost systemd[1]: Starting Populate OSTree /var...
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1382]: Relabeled /sysroot//var/lib from <no context> to system_u:object_r:var_lib_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1385]: Relabeled /sysroot//var/log from <no context> to system_u:object_r:var_log_t:s0
Jun 06 02:03:35 localhost systemd-tmpfiles[1386]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1386]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1388]: Relabeled /sysroot//var/home from <no context> to system_u:object_r:home_root_t:s0
Jun 06 02:03:35 localhost systemd-tmpfiles[1389]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1389]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome/.bash_logout from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome/.bash_profile from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome/.bashrc from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:35 localhost systemd-tmpfiles[1393]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1393]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1396]: Relabeled /sysroot//var/opt from <no context> to system_u:object_r:var_t:s0
Jun 06 02:03:35 localhost systemd-tmpfiles[1397]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1397]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1399]: Relabeled /sysroot//var/srv from <no context> to system_u:object_r:var_t:s0
Jun 06 02:03:35 localhost systemd-tmpfiles[1400]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1400]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/bin from <no context> to system_u:object_r:bin_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/etc from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/games from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/include from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/lib from <no context> to system_u:object_r:lib_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/man from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/sbin from <no context> to system_u:object_r:bin_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/share from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/src from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1405]: Relabeled /sysroot//var/mnt from <no context> to system_u:object_r:mnt_t:s0
Jun 06 02:03:35 localhost systemd-tmpfiles[1403]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1403]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1406]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1406]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd[1]: Finished Populate OSTree /var.
Jun 06 02:03:35 localhost systemd[1]: Starting Ignition (files)...
Jun 06 02:03:35 localhost ignition[1409]: Ignition 2.15.0
Jun 06 02:03:35 localhost ignition[1409]: Stage: files
Jun 06 02:03:35 localhost ignition[1409]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:35 localhost ignition[1409]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:35 localhost ignition[1409]: files: ensureUsers: op(1): [started]  creating or modifying user "core"
Jun 06 02:03:35 localhost ignition[1409]: files: ensureUsers: op(1): [finished] creating or modifying user "core"
Jun 06 02:03:35 localhost ignition[1409]: files: ensureUsers: op(2): [started]  setting password for "core"
Jun 06 02:03:35 localhost ignition[1409]: wrote ssh authorized keys file for user: core
Jun 06 02:03:35 localhost ignition[1409]: files: ensureUsers: op(2): [finished] setting password for "core"
Jun 06 02:03:35 localhost ignition[1409]: files: ensureUsers: op(3): [started]  adding ssh keys to user "core"
Jun 06 02:03:35 localhost ignition[1409]: files: ensureUsers: op(3): [finished] adding ssh keys to user "core"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(4): [started]  writing file "/sysroot/etc/issue"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(4): [finished] writing file "/sysroot/etc/issue"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(5): [started]  writing file "/sysroot/etc/multipath.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(5): [finished] writing file "/sysroot/etc/multipath.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(6): [started]  writing file "/sysroot/var/roothome/assisted.te"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(6): [finished] writing file "/sysroot/var/roothome/assisted.te"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(7): [started]  writing file "/sysroot/etc/assisted/agent-installer.env"
Jun 06 02:03:35 localhost systemd[1]: Finished Ignition (files).
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(7): [finished] writing file "/sysroot/etc/assisted/agent-installer.env"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(8): [started]  writing file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(8): [finished] writing file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(9): [started]  appending to file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(9): [finished] appending to file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(a): [started]  writing file "/sysroot/etc/motd.d/10-agent-installer"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(a): [finished] writing file "/sysroot/etc/motd.d/10-agent-installer"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(b): [started]  writing file "/sysroot/etc/containers/registries.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(b): [finished] writing file "/sysroot/etc/containers/registries.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(c): [started]  writing file "/sysroot/etc/assisted/extra-manifests/04-accelerated-container-startup-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(c): [finished] writing file "/sysroot/etc/assisted/extra-manifests/04-accelerated-container-startup-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(d): [started]  writing file "/sysroot/etc/systemd/system.conf.d/10-default-env.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(d): [finished] writing file "/sysroot/etc/systemd/system.conf.d/10-default-env.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(e): [started]  writing file "/sysroot/var/usrlocal/bin/common.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(e): [finished] writing file "/sysroot/var/usrlocal/bin/common.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(f): [started]  writing file "/sysroot/var/usrlocal/bin/extract-agent.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(f): [finished] writing file "/sysroot/var/usrlocal/bin/extract-agent.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(10): [started]  writing file "/sysroot/var/usrlocal/bin/get-container-images.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(10): [finished] writing file "/sysroot/var/usrlocal/bin/get-container-images.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(11): [started]  writing file "/sysroot/var/usrlocal/bin/install-status.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(11): [finished] writing file "/sysroot/var/usrlocal/bin/install-status.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(12): [started]  writing file "/sysroot/var/usrlocal/bin/issue_status.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(12): [finished] writing file "/sysroot/var/usrlocal/bin/issue_status.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(13): [started]  writing file "/sysroot/var/usrlocal/bin/set-hostname.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(13): [finished] writing file "/sysroot/var/usrlocal/bin/set-hostname.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(14): [started]  writing file "/sysroot/var/usrlocal/bin/set-node-zero.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(14): [finished] writing file "/sysroot/var/usrlocal/bin/set-node-zero.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(15): [started]  writing file "/sysroot/var/usrlocal/bin/start-agent.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(15): [finished] writing file "/sysroot/var/usrlocal/bin/start-agent.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(16): [started]  writing file "/sysroot/var/usrlocal/bin/start-cluster-installation.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(16): [finished] writing file "/sysroot/var/usrlocal/bin/start-cluster-installation.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(17): [started]  writing file "/sysroot/var/usrlocal/bin/wait-for-assisted-service.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(17): [finished] writing file "/sysroot/var/usrlocal/bin/wait-for-assisted-service.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(18): [started]  writing file "/sysroot/etc/assisted/extra-manifests/enable-crun-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(18): [finished] writing file "/sysroot/etc/assisted/extra-manifests/enable-crun-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(19): [started]  writing file "/sysroot/etc/assisted/extra-manifests/StorageSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(19): [finished] writing file "/sysroot/etc/assisted/extra-manifests/StorageSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1a): [started]  writing file "/sysroot/etc/assisted/extra-manifests/StorageOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1a): [finished] writing file "/sysroot/etc/assisted/extra-manifests/StorageOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1b): [started]  writing file "/sysroot/var/usrlocal/bin/bootstrap-service-record.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1b): [finished] writing file "/sysroot/var/usrlocal/bin/bootstrap-service-record.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1c): [started]  writing file "/sysroot/var/usrlocal/bin/release-image.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1c): [finished] writing file "/sysroot/var/usrlocal/bin/release-image.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1d): [started]  writing file "/sysroot/var/usrlocal/bin/release-image-download.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1d): [finished] writing file "/sysroot/var/usrlocal/bin/release-image-download.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1e): [started]  writing file "/sysroot/etc/assisted/manifests/agent-cluster-install.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1e): [finished] writing file "/sysroot/etc/assisted/manifests/agent-cluster-install.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1f): [started]  writing file "/sysroot/etc/assisted/manifests/cluster-deployment.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1f): [finished] writing file "/sysroot/etc/assisted/manifests/cluster-deployment.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(20): [started]  writing file "/sysroot/etc/assisted/manifests/cluster-image-set.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(20): [finished] writing file "/sysroot/etc/assisted/manifests/cluster-image-set.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(21): [started]  writing file "/sysroot/etc/assisted/manifests/infraenv.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(21): [finished] writing file "/sysroot/etc/assisted/manifests/infraenv.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(22): [started]  writing file "/sysroot/etc/assisted/manifests/nmstateconfig.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(22): [finished] writing file "/sysroot/etc/assisted/manifests/nmstateconfig.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(23): [started]  writing file "/sysroot/etc/assisted/manifests/pull-secret.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(23): [finished] writing file "/sysroot/etc/assisted/manifests/pull-secret.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(24): [started]  writing file "/sysroot/etc/assisted/manifests/agent-config.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(24): [finished] writing file "/sysroot/etc/assisted/manifests/agent-config.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(25): [started]  writing file "/sysroot/etc/assisted/hostnames/b4:96:91:d9:a4:64"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(25): [finished] writing file "/sysroot/etc/assisted/hostnames/b4:96:91:d9:a4:64"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(26): [started]  writing file "/sysroot/etc/assisted/extra-manifests/StorageNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(26): [finished] writing file "/sysroot/etc/assisted/extra-manifests/StorageNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(27): [started]  writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(27): [finished] writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(28): [started]  writing file "/sysroot/var/usrlocal/bin/pre-network-manager-config.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(28): [finished] writing file "/sysroot/var/usrlocal/bin/pre-network-manager-config.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(29): [started]  writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(29): [finished] writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2a): [started]  writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2a): [finished] writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2b): [started]  writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2b): [finished] writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2c): [started]  writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2c): [finished] writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2d): [started]  writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2d): [finished] writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2e): [started]  writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2e): [finished] writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2f): [started]  writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2f): [finished] writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(30): [started]  writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(30): [finished] writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(31): [started]  writing file "/sysroot/etc/assisted/extra-manifests/99-crio-disable-wipe-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(31): [finished] writing file "/sysroot/etc/assisted/extra-manifests/99-crio-disable-wipe-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(32): [started]  writing file "/sysroot/var/roothome/.docker/config.json"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(32): [finished] writing file "/sysroot/var/roothome/.docker/config.json"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(33): [started]  writing file "/sysroot/etc/assisted/extra-manifests/06-kdump-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(33): [finished] writing file "/sysroot/etc/assisted/extra-manifests/06-kdump-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(34): [started]  writing file "/sysroot/etc/assisted/extra-manifests/05-kdump-config-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(34): [finished] writing file "/sysroot/etc/assisted/extra-manifests/05-kdump-config-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(35): [started]  writing file "/sysroot/etc/assisted/extra-manifests/01-container-mount-ns-and-kubelet-conf-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(35): [finished] writing file "/sysroot/etc/assisted/extra-manifests/01-container-mount-ns-and-kubelet-conf-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(36): [started]  writing file "/sysroot/etc/assisted/extra-manifests/02-master-workload-partitioning-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(36): [finished] writing file "/sysroot/etc/assisted/extra-manifests/02-master-workload-partitioning-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(37): [started]  writing file "/sysroot/var/usrlocal/bin/agent-gather"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(37): [finished] writing file "/sysroot/var/usrlocal/bin/agent-gather"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(38): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(38): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(39): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(39): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3a): [started]  writing file "/sysroot/var/opt/agent/tls/kubeadmin-password.hash"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3a): [finished] writing file "/sysroot/var/opt/agent/tls/kubeadmin-password.hash"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3b): [started]  writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3b): [finished] writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3c): [started]  writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/root-device-hints.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3c): [finished] writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/root-device-hints.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3d): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3d): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3e): [started]  writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/mac_addresses"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3e): [finished] writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/mac_addresses"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3f): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3f): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(40): [started]  writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(40): [finished] writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(41): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(41): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(42): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(42): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(43): [started]  writing file "/sysroot/etc/assisted/network/host0/mac_interface.ini"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(43): [finished] writing file "/sysroot/etc/assisted/network/host0/mac_interface.ini"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(44): [started]  writing file "/sysroot/etc/assisted/network/host0/ens1f0.nmconnection"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(44): [finished] writing file "/sysroot/etc/assisted/network/host0/ens1f0.nmconnection"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(45): [started]  writing file "/sysroot/var/usrlocal/share/assisted-service/images.env"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(45): [finished] writing file "/sysroot/var/usrlocal/share/assisted-service/images.env"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(46): [started]  writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-service.env"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(46): [finished] writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-service.env"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(47): [started]  writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-db.env"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(47): [finished] writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-db.env"
Jun 06 02:03:35 localhost ignition[1409]: files: op(48): [started]  processing unit "agent-interactive-console.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(48): op(49): [started]  writing unit "agent-interactive-console.service" at "/sysroot/etc/systemd/system/agent-interactive-console.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(48): op(49): [finished] writing unit "agent-interactive-console.service" at "/sysroot/etc/systemd/system/agent-interactive-console.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(48): [finished] processing unit "agent-interactive-console.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4a): [started]  processing unit "agent.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4a): op(4b): [started]  writing unit "agent.service" at "/sysroot/etc/systemd/system/agent.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4a): op(4b): [finished] writing unit "agent.service" at "/sysroot/etc/systemd/system/agent.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4a): [finished] processing unit "agent.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4c): [started]  processing unit "apply-host-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4c): op(4d): [started]  writing unit "apply-host-config.service" at "/sysroot/etc/systemd/system/apply-host-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4c): op(4d): [finished] writing unit "apply-host-config.service" at "/sysroot/etc/systemd/system/apply-host-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4c): [finished] processing unit "apply-host-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4e): [started]  processing unit "assisted-service-db.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4e): op(4f): [started]  writing unit "assisted-service-db.service" at "/sysroot/etc/systemd/system/assisted-service-db.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4e): op(4f): [finished] writing unit "assisted-service-db.service" at "/sysroot/etc/systemd/system/assisted-service-db.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4e): [finished] processing unit "assisted-service-db.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(50): [started]  processing unit "assisted-service-pod.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(50): op(51): [started]  writing unit "assisted-service-pod.service" at "/sysroot/etc/systemd/system/assisted-service-pod.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(50): op(51): [finished] writing unit "assisted-service-pod.service" at "/sysroot/etc/systemd/system/assisted-service-pod.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(50): [finished] processing unit "assisted-service-pod.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(52): [started]  processing unit "assisted-service.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(52): op(53): [started]  writing unit "assisted-service.service" at "/sysroot/etc/systemd/system/assisted-service.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(52): op(53): [finished] writing unit "assisted-service.service" at "/sysroot/etc/systemd/system/assisted-service.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(52): [finished] processing unit "assisted-service.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(54): [started]  processing unit "create-cluster-and-infraenv.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(54): op(55): [started]  writing unit "create-cluster-and-infraenv.service" at "/sysroot/etc/systemd/system/create-cluster-and-infraenv.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(54): op(55): [finished] writing unit "create-cluster-and-infraenv.service" at "/sysroot/etc/systemd/system/create-cluster-and-infraenv.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(54): [finished] processing unit "create-cluster-and-infraenv.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(56): [started]  processing unit "install-status.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(56): op(57): [started]  writing unit "install-status.service" at "/sysroot/etc/systemd/system/install-status.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(56): op(57): [finished] writing unit "install-status.service" at "/sysroot/etc/systemd/system/install-status.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(56): [finished] processing unit "install-status.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(58): [started]  processing unit "node-zero.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(58): op(59): [started]  writing unit "node-zero.service" at "/sysroot/etc/systemd/system/node-zero.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(58): op(59): [finished] writing unit "node-zero.service" at "/sysroot/etc/systemd/system/node-zero.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(58): [finished] processing unit "node-zero.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5a): [started]  processing unit "pre-network-manager-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5a): op(5b): [started]  writing unit "pre-network-manager-config.service" at "/sysroot/etc/systemd/system/pre-network-manager-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5a): op(5b): [finished] writing unit "pre-network-manager-config.service" at "/sysroot/etc/systemd/system/pre-network-manager-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5a): [finished] processing unit "pre-network-manager-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5c): [started]  processing unit "selinux.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5c): op(5d): [started]  writing unit "selinux.service" at "/sysroot/etc/systemd/system/selinux.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5c): op(5d): [finished] writing unit "selinux.service" at "/sysroot/etc/systemd/system/selinux.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5c): [finished] processing unit "selinux.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5e): [started]  processing unit "set-hostname.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5e): op(5f): [started]  writing unit "set-hostname.service" at "/sysroot/etc/systemd/system/set-hostname.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5e): op(5f): [finished] writing unit "set-hostname.service" at "/sysroot/etc/systemd/system/set-hostname.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5e): [finished] processing unit "set-hostname.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(60): [started]  processing unit "start-cluster-installation.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(60): op(61): [started]  writing unit "start-cluster-installation.service" at "/sysroot/etc/systemd/system/start-cluster-installation.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(60): op(61): [finished] writing unit "start-cluster-installation.service" at "/sysroot/etc/systemd/system/start-cluster-installation.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(60): [finished] processing unit "start-cluster-installation.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(62): [started]  setting preset to enabled for "agent-interactive-console.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(62): [finished] setting preset to enabled for "agent-interactive-console.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(63): [started]  setting preset to enabled for "agent.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(63): [finished] setting preset to enabled for "agent.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(64): [started]  setting preset to enabled for "assisted-service-db.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(64): [finished] setting preset to enabled for "assisted-service-db.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(65): [started]  setting preset to enabled for "assisted-service-pod.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(65): [finished] setting preset to enabled for "assisted-service-pod.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(66): [started]  setting preset to enabled for "assisted-service.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(66): [finished] setting preset to enabled for "assisted-service.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(67): [started]  setting preset to enabled for "create-cluster-and-infraenv.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(67): [finished] setting preset to enabled for "create-cluster-and-infraenv.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(68): [started]  setting preset to enabled for "install-status.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(68): [finished] setting preset to enabled for "install-status.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(69): [started]  setting preset to enabled for "node-zero.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(69): [finished] setting preset to enabled for "node-zero.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6a): [started]  setting preset to enabled for "pre-network-manager-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6a): [finished] setting preset to enabled for "pre-network-manager-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6b): [started]  setting preset to enabled for "selinux.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6b): [finished] setting preset to enabled for "selinux.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6c): [started]  setting preset to enabled for "set-hostname.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6c): [finished] setting preset to enabled for "set-hostname.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6d): [started]  setting preset to enabled for "start-cluster-installation.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6d): [finished] setting preset to enabled for "start-cluster-installation.service"
Jun 06 02:03:35 localhost ignition[1409]: files: createResultFile: createFiles: op(6e): [started]  writing file "/sysroot/etc/.ignition-result.json"
Jun 06 02:03:35 localhost ignition[1409]: files: createResultFile: createFiles: op(6e): [finished] writing file "/sysroot/etc/.ignition-result.json"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6f): [started]  relabeling 97 patterns
Jun 06 02:03:35 localhost ignition[1409]: files: op(6f): [finished] relabeling 97 patterns
Jun 06 02:03:35 localhost ignition[1409]: files: files passed
Jun 06 02:03:35 localhost ignition[1409]: Ignition finished successfully
Jun 06 02:03:35 localhost systemd[1]: Starting CoreOS Post Ignition Checks...
Jun 06 02:03:35 localhost systemd[1]: CoreOS Propagate Multipath Configuration was skipped because of an unmet condition check (ConditionKernelCommandLine=rd.multipath=default).
Jun 06 02:03:35 localhost systemd[1]: Starting Mountpoints Configured in the Real Root...
Jun 06 02:03:35 localhost systemd[1]: Finished CoreOS Post Ignition Checks.
Jun 06 02:03:35 localhost systemd[1]: Reached target Ignition Complete.
Jun 06 02:03:35 localhost multipathd[1266]: exit (signal)
Jun 06 02:03:35 localhost multipathd[1266]: --------shut down-------
Jun 06 02:03:35 localhost systemd[1]: Stopping Device-Mapper Multipath Device Controller...
Jun 06 02:03:35 localhost systemd[1]: multipathd.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Device-Mapper Multipath Device Controller.
Jun 06 02:03:35 localhost systemd[1]: initrd-parse-etc.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Finished Mountpoints Configured in the Real Root.
Jun 06 02:03:35 localhost systemd[1]: Reached target Initrd File Systems.
Jun 06 02:03:35 localhost systemd[1]: Reached target Initrd Default Target.
Jun 06 02:03:35 localhost systemd[1]: Starting dracut mount hook...
Jun 06 02:03:35 localhost systemd[1]: Finished dracut mount hook.
Jun 06 02:03:35 localhost systemd[1]: Starting dracut pre-pivot and cleanup hook...
Jun 06 02:03:35 localhost dracut-pre-pivot[1553]: 27.335184 | /etc/multipath.conf does not exist, blacklisting all devices.
Jun 06 02:03:35 localhost dracut-pre-pivot[1553]: 27.335195 | You can run "/sbin/mpathconf --enable" to create
Jun 06 02:03:35 localhost dracut-pre-pivot[1553]: 27.335196 | /etc/multipath.conf. See man mpathconf(8) for more details
Jun 06 02:03:35 localhost systemd[1]: Finished dracut pre-pivot and cleanup hook.
Jun 06 02:03:35 localhost systemd[1]: Starting Cleaning Up and Shutting Down Daemons...
Jun 06 02:03:35 localhost systemd[1]: Stopped target Network.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Preparation for Network.
Jun 06 02:03:35 localhost systemd[1]: Stopped target RDMA Hardware.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Remote Encrypted Volumes.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Timer Units.
Jun 06 02:03:35 localhost systemd[1]: dbus.socket: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Closed D-Bus System Message Bus Socket.
Jun 06 02:03:35 localhost systemd[1]: coreos-liveiso-persist-osmet.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Persist Osmet Files (ISO).
Jun 06 02:03:35 localhost systemd[1]: dracut-pre-pivot.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut pre-pivot and cleanup hook.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Initrd Default Target.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Ignition Complete.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Initrd Root Device.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Initrd /usr File System.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Remote File Systems.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Preparation for Remote File Systems.
Jun 06 02:03:35 localhost systemd[1]: coreos-post-ignition-checks.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped CoreOS Post Ignition Checks.
Jun 06 02:03:35 localhost systemd[1]: coreos-touch-run-agetty.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped CoreOS: Touch /run/agetty.reload.
Jun 06 02:03:35 localhost systemd[1]: dracut-mount.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut mount hook.
Jun 06 02:03:35 localhost systemd[1]: dracut-pre-mount.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut pre-mount hook.
Jun 06 02:03:35 localhost systemd[1]: dracut-initqueue.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut initqueue hook.
Jun 06 02:03:35 localhost systemd[1]: ignition-fetch-offline.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Ignition (fetch-offline).
Jun 06 02:03:35 localhost systemd[1]: coreos-ignition-setup-user.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped CoreOS Ignition User Config Setup.
Jun 06 02:03:35 localhost systemd[1]: ignition-files.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Ignition (files).
Jun 06 02:03:35 localhost systemd[1]: ignition-ostree-populate-var.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Populate OSTree /var.
Jun 06 02:03:35 localhost systemd[1]: Stopping Ignition (mount)...
Jun 06 02:03:35 localhost ignition[1559]: Ignition 2.15.0
Jun 06 02:03:35 localhost ignition[1559]: Stage: umount
Jun 06 02:03:35 localhost ignition[1559]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:35 localhost ignition[1559]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:35 localhost ignition[1559]: umount: umount passed
Jun 06 02:03:35 localhost ignition[1559]: Ignition finished successfully
Jun 06 02:03:35 localhost systemd[1]: ignition-mount.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Ignition (mount).
Jun 06 02:03:35 localhost systemd[1]: Unmount Live /var if Persistent /var Is Configured was skipped because no trigger condition checks were met.
Jun 06 02:03:35 localhost systemd[1]: Stopping CoreOS Tear Down Initramfs...
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: eno1
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1581]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f0
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1585]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f1
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1589]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f2
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1593]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f3
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1597]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f0
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1601]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f1
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1605]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f2
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1609]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f3
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1613]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: flushing all routing
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: no initramfs hostname information to propagate
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: no networking config is defined in the real root
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: skipping propagation of default networking configs
Jun 06 02:03:35 localhost systemd[1]: ignition-disks.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Ignition (disks).
Jun 06 02:03:35 localhost systemd[1]: ignition-kargs.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Ignition (kargs).
Jun 06 02:03:35 localhost systemd[1]: coreos-copy-firstboot-network.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Copy CoreOS Firstboot Networking Config.
Jun 06 02:03:35 localhost systemd[1]: rhcos-fail-boot-for-legacy-luks-config.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped RHCOS Check For Legacy LUKS Configuration.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Basic System.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Path Units.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Slice Units.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Socket Units.
Jun 06 02:03:35 localhost systemd[1]: Stopped target System Initialization.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Local Encrypted Volumes.
Jun 06 02:03:35 localhost systemd[1]: systemd-ask-password-console.path: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Dispatch Password Requests to Console Directory Watch.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Local Encrypted Volumes (Pre).
Jun 06 02:03:35 localhost systemd[1]: clevis-luks-askpass.path: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Forward Password Requests to Clevis Directory Watch.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Local File Systems.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Preparation for Local File Systems.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Swaps.
Jun 06 02:03:35 localhost systemd[1]: Acquire Live PXE rootfs Image was skipped because of an unmet condition check (ConditionKernelCommandLine=!coreos.liveiso).
Jun 06 02:03:35 localhost systemd[1]: rdma-load-modules@rdma.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Load RDMA modules from /etc/rdma/modules/rdma.conf.
Jun 06 02:03:35 localhost systemd[1]: systemd-sysctl.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Apply Kernel Variables.
Jun 06 02:03:35 localhost systemd[1]: systemd-modules-load.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Load Kernel Modules.
Jun 06 02:03:35 localhost systemd[1]: systemd-tmpfiles-setup.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Create Volatile Files and Directories.
Jun 06 02:03:35 localhost systemd[1]: systemd-udev-settle.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Wait for udev To Complete Device Initialization.
Jun 06 02:03:35 localhost systemd[1]: systemd-udev-trigger.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Coldplug All udev Devices.
Jun 06 02:03:35 localhost systemd[1]: dracut-pre-trigger.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut pre-trigger hook.
Jun 06 02:03:35 localhost systemd[1]: Stopping Rule-based Manager for Device Events and Files...
Jun 06 02:03:35 localhost systemd[1]: run-credentials-systemd\x2dtmpfiles\x2dsetup.service.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: run-credentials-systemd\x2dsysctl.service.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: systemd-udevd.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Rule-based Manager for Device Events and Files.
Jun 06 02:03:35 localhost systemd[1]: systemd-udevd.service: Consumed 6.401s CPU time.
Jun 06 02:03:35 localhost systemd[1]: initrd-cleanup.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Finished Cleaning Up and Shutting Down Daemons.
Jun 06 02:03:35 localhost systemd[1]: coreos-teardown-initramfs.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped CoreOS Tear Down Initramfs.
Jun 06 02:03:35 localhost systemd[1]: systemd-udevd-control.socket: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Closed udev Control Socket.
Jun 06 02:03:35 localhost systemd[1]: systemd-udevd-kernel.socket: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Closed udev Kernel Socket.
Jun 06 02:03:35 localhost systemd[1]: dracut-pre-udev.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut pre-udev hook.
Jun 06 02:03:35 localhost systemd[1]: dracut-cmdline.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut cmdline hook.
Jun 06 02:03:35 localhost systemd[1]: afterburn-network-kargs.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Afterburn Initrd Setup Network Kernel Arguments.
Jun 06 02:03:35 localhost systemd[1]: CoreOS Enable Network was skipped because no trigger condition checks were met.
Jun 06 02:03:35 localhost systemd[1]: dracut-cmdline-ask.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut ask for additional cmdline parameters.
Jun 06 02:03:35 localhost systemd[1]: Starting Cleanup udev Database...
Jun 06 02:03:35 localhost systemd[1]: systemd-tmpfiles-setup-dev.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Create Static Device Nodes in /dev.
Jun 06 02:03:35 localhost systemd[1]: kmod-static-nodes.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Create List of Static Device Nodes.
Jun 06 02:03:35 localhost systemd[1]: systemd-sysusers.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Create System Users.
Jun 06 02:03:35 localhost systemd[1]: systemd-vconsole-setup.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Setup Virtual Console.
Jun 06 02:03:35 localhost systemd[1]: run-credentials-systemd\x2dtmpfiles\x2dsetup\x2ddev.service.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: run-credentials-systemd\x2dsysusers.service.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: initrd-udevadm-cleanup-db.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Finished Cleanup udev Database.
Jun 06 02:03:35 localhost systemd[1]: Reached target Switch Root.
Jun 06 02:03:35 localhost systemd[1]: Starting Switch Root...
Jun 06 02:03:35 localhost systemd[1]: Switching root.
Jun 06 02:03:35 localhost systemd-journald[773]: Received SIGTERM from PID 1 (systemd).
Jun 06 02:03:35 localhost kernel: audit: type=1404 audit(1686017011.699:2): enforcing=1 old_enforcing=0 auid=4294967295 ses=4294967295 enabled=1 old-enabled=1 lsm=selinux res=1
Jun 06 02:03:35 localhost kernel: SELinux:  policy capability network_peer_controls=1
Jun 06 02:03:35 localhost kernel: SELinux:  policy capability open_perms=1
Jun 06 02:03:35 localhost kernel: SELinux:  policy capability extended_socket_class=1
Jun 06 02:03:35 localhost kernel: SELinux:  policy capability always_check_network=0
Jun 06 02:03:35 localhost kernel: SELinux:  policy capability cgroup_seclabel=1
Jun 06 02:03:35 localhost kernel: SELinux:  policy capability nnp_nosuid_transition=1
Jun 06 02:03:35 localhost kernel: SELinux:  policy capability genfs_seclabel_symlinks=1
Jun 06 02:03:35 localhost kernel: audit: type=1403 audit(1686017011.897:3): auid=4294967295 ses=4294967295 lsm=selinux res=1
Jun 06 02:03:35 localhost systemd[1]: Successfully loaded SELinux policy in 200.299ms.
Jun 06 02:03:35 localhost systemd[1]: Relabelled /dev, /dev/shm, /run, /sys/fs/cgroup in 23.577ms.
Jun 06 02:03:35 localhost systemd[1]: Configuration file /etc/systemd/system.conf.d/10-default-env.conf is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
Jun 06 02:03:35 localhost systemd[1]: systemd 252-14.el9.rhaos4.13 running in system mode (+PAM +AUDIT +SELINUX -APPARMOR +IMA +SMACK +SECCOMP +GCRYPT +GNUTLS +OPENSSL +ACL +BLKID +CURL +ELFUTILS -FIDO2 +IDN2 -IDN -IPTC +KMOD +LIBCRYPTSETU>
Jun 06 02:03:35 localhost systemd[1]: Detected architecture x86-64.
Jun 06 02:03:35 localhost systemd[1]: Detected first boot.
Jun 06 02:03:35 localhost systemd[1]: Initializing machine ID from random generator.
Jun 06 02:03:35 localhost systemd-rc-local-generator[1671]: /etc/rc.d/rc.local is not marked executable, skipping.
Jun 06 02:03:35 localhost systemd[1]: Populated /etc with preset unit settings.
Jun 06 02:03:35 localhost systemd[1]: initrd-switch-root.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Switch Root.
Jun 06 02:03:35 localhost systemd[1]: systemd-journald.service: Scheduled restart job, restart counter is at 1.
Jun 06 02:03:35 localhost systemd[1]: Created slice Slice /system/getty.
Jun 06 02:03:35 localhost systemd[1]: Created slice Slice /system/modprobe.
Jun 06 02:03:35 localhost systemd[1]: Created slice Slice /system/sshd-keygen.
Jun 06 02:03:35 localhost systemd[1]: Created slice User and Session Slice.
Jun 06 02:03:35 localhost systemd[1]: Started Forward Password Requests to Clevis Directory Watch.
Jun 06 02:03:35 localhost systemd[1]: Started Dispatch Password Requests to Console Directory Watch.
Jun 06 02:03:35 localhost systemd[1]: Started Forward Password Requests to Wall Directory Watch.
Jun 06 02:03:35 localhost systemd[1]: Set up automount Arbitrary Executable File Formats File System Automount Point.
Jun 06 02:03:35 localhost systemd[1]: Reached target Synchronize afterburn-sshkeys@.service template instances.
Jun 06 02:03:35 localhost systemd[1]: Reached target Local Encrypted Volumes (Pre).
Jun 06 02:03:35 localhost systemd[1]: Reached target Local Encrypted Volumes.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Switch Root.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Initrd File Systems.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Initrd Root File System.
Jun 06 02:03:35 localhost systemd[1]: Reached target Local Integrity Protected Volumes.
Jun 06 02:03:35 localhost systemd[1]: Reached target Path Units.
Jun 06 02:03:35 localhost systemd[1]: Reached target Slice Units.
Jun 06 02:03:35 localhost systemd[1]: Reached target Swaps.
Jun 06 02:03:35 localhost systemd[1]: Reached target Local Verity Protected Volumes.
Jun 06 02:03:35 localhost systemd[1]: Listening on Device-mapper event daemon FIFOs.
Jun 06 02:03:35 localhost systemd[1]: Listening on LVM2 poll daemon socket.
Jun 06 02:03:35 localhost systemd[1]: Listening on multipathd control socket.
Jun 06 02:03:35 localhost systemd[1]: Listening on Process Core Dump Socket.
Jun 06 02:03:35 localhost systemd[1]: Listening on initctl Compatibility Named Pipe.
Jun 06 02:03:35 localhost systemd[1]: Listening on udev Control Socket.
Jun 06 02:03:35 localhost systemd[1]: Listening on udev Kernel Socket.
Jun 06 02:03:35 localhost systemd[1]: Mounting Huge Pages File System...
Jun 06 02:03:35 localhost systemd[1]: Mounting POSIX Message Queue File System...
Jun 06 02:03:35 localhost systemd[1]: Mounting Kernel Debug File System...
Jun 06 02:03:35 localhost systemd[1]: Mounting Kernel Trace File System...
Jun 06 02:03:35 localhost systemd[1]: Mounting Temporary Directory /tmp...
Jun 06 02:03:35 localhost systemd[1]: Starting CoreOS: Set printk To Level 4 (warn)...
Jun 06 02:03:35 localhost systemd[1]: Ignition (delete config) was skipped because no trigger condition checks were met.
Jun 06 02:03:35 localhost systemd[1]: Starting Create List of Static Device Nodes...
Jun 06 02:03:35 localhost systemd[1]: Starting Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling...
Jun 06 02:03:35 localhost systemd[1]: Starting Load Kernel Module configfs...
Jun 06 02:03:35 localhost systemd[1]: Starting Load Kernel Module drm...
Jun 06 02:03:35 localhost systemd[1]: Starting Load Kernel Module efi_pstore...
Jun 06 02:03:35 localhost systemd[1]: Starting Load Kernel Module fuse...
Jun 06 02:03:35 localhost systemd[1]: ostree-prepare-root.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped OSTree Prepare OS/.
Jun 06 02:03:35 localhost systemd[1]: sysroot-relabel.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped sysroot-relabel.service.
Jun 06 02:03:35 localhost systemd[1]: sysroot-xfs-ephemeral-mkfs.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped sysroot-xfs-ephemeral-mkfs.service.
Jun 06 02:03:35 localhost systemd[1]: sysroot-xfs-ephemeral-setup.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped sysroot-xfs-ephemeral-setup.service.
Jun 06 02:03:35 localhost systemd[1]: Stopped Journal Service.
Jun 06 02:03:35 localhost systemd[1]: systemd-journald.service: Consumed 4.267s CPU time.
Jun 06 02:03:35 localhost systemd[1]: Starting Journal Service...
Jun 06 02:03:35 localhost systemd[1]: Starting Load Kernel Modules...
Jun 06 02:03:35 localhost systemd[1]: Starting Generate network units from Kernel command line...
Jun 06 02:03:35 localhost systemd[1]: Starting Remount Root and Kernel File Systems...
Jun 06 02:03:35 localhost systemd[1]: Repartition Root Disk was skipped because no trigger condition checks were met.
Jun 06 02:03:35 localhost systemd[1]: Starting Coldplug All udev Devices...
Jun 06 02:03:35 localhost systemd[1]: Mounted Huge Pages File System.
Jun 06 02:03:35 localhost systemd[1]: Mounted POSIX Message Queue File System.
Jun 06 02:03:35 localhost systemd[1]: Mounted Kernel Debug File System.
Jun 06 02:03:35 localhost systemd[1]: Mounted Kernel Trace File System.
Jun 06 02:03:35 localhost systemd[1]: Mounted Temporary Directory /tmp.
Jun 06 02:03:35 localhost systemd[1]: Finished CoreOS: Set printk To Level 4 (warn).
Jun 06 02:03:35 localhost systemd[1]: Finished Create List of Static Device Nodes.
Jun 06 02:03:35 localhost systemd[1]: Finished Generate network units from Kernel command line.
Jun 06 02:03:35 localhost systemd[1]: Finished Remount Root and Kernel File Systems.
Jun 06 02:03:35 localhost systemd[1]: Reached target Preparation for Network.
Jun 06 02:03:35 localhost systemd[1]: Special handling of early boot iSCSI sessions was skipped because of an unmet condition check (ConditionDirectoryNotEmpty=/sys/class/iscsi_session).
Jun 06 02:03:35 localhost systemd[1]: OSTree Remount OS/ Bind Mounts was skipped because of an unmet condition check (ConditionKernelCommandLine=ostree).
Jun 06 02:03:35 localhost systemd[1]: Starting Rebuild Hardware Database...
Jun 06 02:03:35 localhost systemd-journald[1708]: Journal started
Jun 06 02:03:35 localhost systemd-journald[1708]: Runtime Journal (/run/log/journal/a0c1be0936ce4e95ba9bfd63e3f4325c) is 8.0M, max 2.5G, 2.5G free.
Jun 06 02:03:34 localhost systemd[1]: Queued start job for default target Graphical Interface.
Jun 06 02:03:34 localhost systemd[1]: systemd-journald.service: Deactivated successfully.
Jun 06 02:03:34 localhost systemd[1]: systemd-journald.service: Consumed 4.267s CPU time.
Jun 06 02:03:35 localhost systemd-modules-load[1709]: Module 'msr' is built in
Jun 06 02:03:35 localhost systemd[1]: Starting Load/Save Random Seed...
Jun 06 02:03:35 localhost systemd[1]: Starting Create System Users...
Jun 06 02:03:35 localhost systemd[1]: Started Journal Service.
Jun 06 02:03:35 localhost systemd[1]: modprobe@configfs.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Finished Load Kernel Module configfs.
Jun 06 02:03:35 localhost systemd[1]: modprobe@efi_pstore.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Finished Load Kernel Module efi_pstore.
Jun 06 02:03:35 localhost systemd[1]: modprobe@fuse.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Finished Load Kernel Module fuse.
Jun 06 02:03:36 localhost systemd[1]: Finished Load Kernel Modules.
Jun 06 02:03:36 localhost systemd[1]: Finished Coldplug All udev Devices.
Jun 06 02:03:36 localhost systemd[1]: Mounting FUSE Control File System...
Jun 06 02:03:36 localhost systemd[1]: Mounting Kernel Configuration File System...
Jun 06 02:03:36 localhost systemd[1]: Starting Flush Journal to Persistent Storage...
Jun 06 02:03:36 localhost systemd[1]: Platform Persistent Storage Archival was skipped because of an unmet condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore).
Jun 06 02:03:36 localhost systemd[1]: Starting Apply Kernel Variables...
Jun 06 02:03:36 localhost systemd[1]: Starting Wait for udev To Complete Device Initialization...
Jun 06 02:03:36 localhost systemd[1]: Finished Load/Save Random Seed.
Jun 06 02:03:36 localhost systemd[1]: Mounted FUSE Control File System.
Jun 06 02:03:36 localhost systemd[1]: Mounted Kernel Configuration File System.
Jun 06 02:03:36 localhost udevadm[1724]: systemd-udev-settle.service is deprecated. Please fix multipathd.service not to pull it in.
Jun 06 02:03:36 localhost kernel: ACPI: bus type drm_connector registered
Jun 06 02:03:36 localhost systemd[1]: modprobe@drm.service: Deactivated successfully.
Jun 06 02:03:36 localhost systemd[1]: Finished Load Kernel Module drm.
Jun 06 02:03:36 localhost systemd-journald[1708]: Time spent on flushing to /var/log/journal/a0c1be0936ce4e95ba9bfd63e3f4325c is 17.930ms for 2680 entries.
Jun 06 02:03:36 localhost systemd-journald[1708]: System Journal (/var/log/journal/a0c1be0936ce4e95ba9bfd63e3f4325c) is 8.0M, max 4.0G, 3.9G free.
Jun 06 02:03:36 localhost systemd-journald[1708]: Received client request to flush runtime journal.
Jun 06 02:03:36 localhost systemd[1]: Finished Flush Journal to Persistent Storage.
Jun 06 02:03:36 localhost systemd-sysusers[1715]: Creating group 'sgx' with GID 991.
Jun 06 02:03:36 localhost systemd-sysusers[1715]: Creating group 'systemd-oom' with GID 990.
Jun 06 02:03:36 localhost systemd-sysusers[1715]: Creating user 'systemd-oom' (systemd Userspace OOM Killer) with UID 990 and GID 990.
Jun 06 02:03:36 localhost systemd[1]: Finished Create System Users.
Jun 06 02:03:36 localhost systemd[1]: Finished Apply Kernel Variables.
Jun 06 02:03:36 localhost systemd[1]: Starting Create Static Device Nodes in /dev...
Jun 06 02:03:36 localhost systemd[1]: Finished Create Static Device Nodes in /dev.
Jun 06 02:03:36 localhost systemd[1]: Finished Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling.
Jun 06 02:03:36 localhost systemd[1]: Finished Rebuild Hardware Database.
Jun 06 02:03:36 localhost systemd[1]: Starting Rule-based Manager for Device Events and Files...
Jun 06 02:03:36 localhost systemd-udevd[1730]: Using default interface naming scheme 'rhel-9.0'.
Jun 06 02:03:36 localhost systemd[1]: Started Rule-based Manager for Device Events and Files.
Jun 06 02:03:36 localhost systemd[1]: Starting Load Kernel Module configfs...
Jun 06 02:03:36 localhost systemd[1]: Starting Load Kernel Module fuse...
Jun 06 02:03:36 localhost systemd[1]: modprobe@configfs.service: Deactivated successfully.
Jun 06 02:03:36 localhost systemd[1]: Finished Load Kernel Module configfs.
Jun 06 02:03:36 localhost systemd[1]: modprobe@fuse.service: Deactivated successfully.
Jun 06 02:03:36 localhost systemd[1]: Finished Load Kernel Module fuse.
Jun 06 02:03:36 localhost kernel: power_meter ACPI000D:00: Found ACPI power meter.
Jun 06 02:03:36 localhost kernel: power_meter ACPI000D:00: Ignoring unsafe software power cap!
Jun 06 02:03:36 localhost kernel: power_meter ACPI000D:00: hwmon_device_register() is deprecated. Please convert the driver to use hwmon_device_register_with_info().
Jun 06 02:03:37 localhost kernel: acpi-tad ACPI000E:00: Unsupported capabilities
Jun 06 02:03:37 localhost kernel: input: PC Speaker as /devices/platform/pcspkr/input/input3
Jun 06 02:03:37 localhost kernel: IPMI message handler: version 39.2
Jun 06 02:03:37 localhost kernel: ipmi device interface
Jun 06 02:03:38 localhost kernel: ioatdma: Intel(R) QuickData Technology Driver 5.00
Jun 06 02:03:38 localhost systemd[1]: Starting Load RDMA modules from /etc/rdma/modules/rdma.conf...
Jun 06 02:03:38 localhost kernel: ipmi_si: IPMI System Interface driver
Jun 06 02:03:38 localhost kernel: ipmi_si dmi-ipmi-si.0: ipmi_platform: probing via SMBIOS
Jun 06 02:03:38 localhost kernel: ipmi_platform: ipmi_si: SMBIOS: io 0xca2 regsize 1 spacing 1 irq 0
Jun 06 02:03:38 localhost kernel: ipmi_si: Adding SMBIOS-specified kcs state machine
Jun 06 02:03:38 localhost kernel: ipmi_si IPI0001:00: ipmi_platform: probing via ACPI
Jun 06 02:03:38 localhost kernel: ipmi_si IPI0001:00: ipmi_platform: [io  0x0ca2-0x0ca3] regsize 1 spacing 1 irq 10
Jun 06 02:03:38 localhost systemd[1]: Starting RDMA Node Description Daemon...
Jun 06 02:03:38 localhost kernel: ipmi_si dmi-ipmi-si.0: Removing SMBIOS-specified kcs state machine in favor of ACPI
Jun 06 02:03:38 localhost kernel: ipmi_si: Adding ACPI-specified kcs state machine
Jun 06 02:03:38 localhost kernel: ipmi_si: Trying ACPI-specified kcs state machine at i/o address 0xca2, slave address 0x20, irq 10
Jun 06 02:03:38 localhost kernel: RAPL PMU: API unit is 2^-32 Joules, 2 fixed counters, 655360 ms ovfl timer
Jun 06 02:03:38 localhost kernel: RAPL PMU: hw unit of domain package 2^-14 Joules
Jun 06 02:03:38 localhost kernel: RAPL PMU: hw unit of domain dram 2^-16 Joules
Jun 06 02:03:38 localhost kernel: ipmi_si IPI0001:00: The BMC does not support clearing the recv irq bit, compensating, but the BMC needs to be fixed.
Jun 06 02:03:38 localhost kernel: ipmi_si IPI0001:00: Using irq 10
Jun 06 02:03:38 localhost kernel: ipmi_si IPI0001:00: IPMI message handler: Found new BMC (man_id: 0x00b85c, prod_id: 0x2100, dev_id: 0x13)
Jun 06 02:03:38 localhost kernel: ipmi_si IPI0001:00: IPMI kcs interface initialized
Jun 06 02:03:38 localhost systemd[1]: Started RDMA Node Description Daemon.
Jun 06 02:03:38 localhost kernel: ipmi_ssif: IPMI SSIF Interface driver
Jun 06 02:03:38 localhost kernel: Console: switching to colour dummy device 80x25
Jun 06 02:03:38 localhost kernel: mgag200 0000:01:00.1: vgaarb: deactivate vga console
Jun 06 02:03:38 localhost kernel: [drm] Initialized mgag200 1.0.0 20110418 for 0000:01:00.1 on minor 0
Jun 06 02:03:38 localhost kernel: fbcon: mgag200drmfb (fb0) is primary device
Jun 06 02:03:38 localhost kernel: Console: switching to colour frame buffer device 128x48
Jun 06 02:03:38 localhost kernel: mgag200 0000:01:00.1: [drm] fb0: mgag200drmfb frame buffer device
Jun 06 02:03:38 localhost systemd[1]: Finished Load RDMA modules from /etc/rdma/modules/rdma.conf.
Jun 06 02:03:38 localhost systemd[1]: Reached target RDMA Hardware.
Jun 06 02:03:39 localhost kernel: intel_rapl_common: Found RAPL domain package
Jun 06 02:03:39 localhost kernel: intel_rapl_common: Found RAPL domain dram
Jun 06 02:03:39 localhost kernel: intel_rapl_common: DRAM domain energy unit 15300pj
Jun 06 02:03:42 localhost systemd[1]: Finished Wait for udev To Complete Device Initialization.
Jun 06 02:03:42 localhost systemd[1]: Starting Device-Mapper Multipath Device Controller...
Jun 06 02:03:42 localhost multipathd[2071]: --------start up--------
Jun 06 02:03:42 localhost multipathd[2071]: read /etc/multipath.conf
Jun 06 02:03:42 localhost multipathd[2071]: path checkers start up
Jun 06 02:03:42 localhost systemd[1]: Started Device-Mapper Multipath Device Controller.
Jun 06 02:03:42 localhost systemd[1]: Reached target Preparation for Local File Systems.
Jun 06 02:03:42 localhost systemd[1]: Reached target Local File Systems.
Jun 06 02:03:42 localhost systemd[1]: Starting Run update-ca-trust...
Jun 06 02:03:42 localhost systemd[1]: Starting Rebuild Dynamic Linker Cache...
Jun 06 02:03:42 localhost systemd[1]: Mark the need to relabel after reboot was skipped because of an unmet condition check (ConditionSecurity=!selinux).
Jun 06 02:03:42 localhost systemd[1]: Set Up Additional Binary Formats was skipped because no trigger condition checks were met.
Jun 06 02:03:42 localhost systemd[1]: Store a System Token in an EFI Variable was skipped because of an unmet condition check (ConditionPathExists=/sys/firmware/efi/efivars/LoaderFeatures-4a67b082-0a4c-41cf-b6c7-440b29bb8c4f).
Jun 06 02:03:42 localhost systemd[1]: Starting Automatic Boot Loader Update...
Jun 06 02:03:42 localhost systemd[1]: Starting Create Volatile Files and Directories...
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: /usr/lib/tmpfiles.d/tmp.conf:12: Duplicate line for path "/var/tmp", ignoring.
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: /usr/lib/tmpfiles.d/var.conf:14: Duplicate line for path "/var/log", ignoring.
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: /usr/lib/tmpfiles.d/var.conf:19: Duplicate line for path "/var/cache", ignoring.
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: /usr/lib/tmpfiles.d/var.conf:21: Duplicate line for path "/var/lib", ignoring.
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: /usr/lib/tmpfiles.d/var.conf:23: Duplicate line for path "/var/spool", ignoring.
Jun 06 02:03:42 localhost bootctl[2082]: Couldn't find EFI system partition, skipping.
Jun 06 02:03:42 localhost systemd[1]: Finished Automatic Boot Loader Update.
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: "/home" already exists and is not a directory.
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: "/srv" already exists and is not a directory.
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: "/root" already exists and is not a directory.
Jun 06 02:03:42 localhost systemd[1]: Finished Create Volatile Files and Directories.
Jun 06 02:03:42 localhost systemd[1]: Starting Security Auditing Service...
Jun 06 02:03:42 localhost systemd[1]: Starting Prepare network manager config content...
Jun 06 02:03:42 localhost systemd[1]: Starting RHEL CoreOS Rebuild SELinux Policy If Necessary...
Jun 06 02:03:42 localhost systemd[1]: Starting RHCOS Fix SELinux Labeling For /usr/local/sbin...
Jun 06 02:03:42 localhost chcon[2091]: changing security context of '/usr/local/sbin'
Jun 06 02:03:42 localhost systemd[1]: Starting Rebuild Journal Catalog...
Jun 06 02:03:43 localhost rhcos-rebuild-selinux-policy[2089]: RHEL_VERSION=9.2Assuming we have new enough ostree
Jun 06 02:03:43 localhost systemd[1]: Finished RHEL CoreOS Rebuild SELinux Policy If Necessary.
Jun 06 02:03:43 localhost auditd[2101]: No plugins found, not dispatching events
Jun 06 02:03:43 localhost auditd[2101]: Init complete, auditd 3.0.7 listening for events (startup state enable)
Jun 06 02:03:43 localhost sh[2109]: changing security context of '/var/usrlocal/sbin'
Jun 06 02:03:43 localhost systemd[1]: Finished RHCOS Fix SELinux Labeling For /usr/local/sbin.
Jun 06 02:03:43 localhost pre-network-manager-config.sh[2149]: /usr/local/bin/pre-network-manager-config.sh: line 135: //: Is a directory
Jun 06 02:03:43 localhost systemd[1]: Finished Rebuild Journal Catalog.
Jun 06 02:03:43 localhost pre-network-manager-config.sh[2088]: Removing default connection files in '/etc/NetworkManager/system-connections'
Jun 06 02:03:43 localhost pre-network-manager-config.sh[2157]: mv: '/tmp/tmp.qaK71ppW23/ens1f0.nmconnection' and '/tmp/tmp.qaK71ppW23/ens1f0.nmconnection' are the same file
Jun 06 02:03:43 localhost systemd[1]: pre-network-manager-config.service: Deactivated successfully.
Jun 06 02:03:43 localhost systemd[1]: Finished Prepare network manager config content.
Jun 06 02:03:43 localhost augenrules[2168]: No rules
Jun 06 02:03:43 localhost augenrules[2168]: enabled 1
Jun 06 02:03:43 localhost augenrules[2168]: failure 1
Jun 06 02:03:43 localhost augenrules[2168]: pid 2101
Jun 06 02:03:43 localhost augenrules[2168]: rate_limit 0
Jun 06 02:03:43 localhost augenrules[2168]: backlog_limit 8192
Jun 06 02:03:43 localhost augenrules[2168]: lost 0
Jun 06 02:03:43 localhost augenrules[2168]: backlog 4
Jun 06 02:03:43 localhost augenrules[2168]: backlog_wait_time 60000
Jun 06 02:03:43 localhost augenrules[2168]: backlog_wait_time_actual 0
Jun 06 02:03:43 localhost augenrules[2168]: enabled 1
Jun 06 02:03:43 localhost augenrules[2168]: failure 1
Jun 06 02:03:43 localhost augenrules[2168]: pid 2101
Jun 06 02:03:43 localhost augenrules[2168]: rate_limit 0
Jun 06 02:03:43 localhost augenrules[2168]: backlog_limit 8192
Jun 06 02:03:43 localhost augenrules[2168]: lost 0
Jun 06 02:03:43 localhost augenrules[2168]: backlog 4
Jun 06 02:03:43 localhost augenrules[2168]: backlog_wait_time 60000
Jun 06 02:03:43 localhost augenrules[2168]: backlog_wait_time_actual 0
Jun 06 02:03:43 localhost augenrules[2168]: enabled 1
Jun 06 02:03:43 localhost augenrules[2168]: failure 1
Jun 06 02:03:43 localhost augenrules[2168]: pid 2101
Jun 06 02:03:43 localhost augenrules[2168]: rate_limit 0
Jun 06 02:03:43 localhost augenrules[2168]: backlog_limit 8192
Jun 06 02:03:43 localhost augenrules[2168]: lost 0
Jun 06 02:03:43 localhost augenrules[2168]: backlog 4
Jun 06 02:03:43 localhost augenrules[2168]: backlog_wait_time 60000
Jun 06 02:03:43 localhost augenrules[2168]: backlog_wait_time_actual 0
Jun 06 02:03:43 localhost systemd[1]: Started Security Auditing Service.
Jun 06 02:03:43 localhost systemd[1]: Starting Record System Boot/Shutdown in UTMP...
Jun 06 02:03:43 localhost systemd[1]: Finished Record System Boot/Shutdown in UTMP.
Jun 06 02:03:44 localhost systemd[1]: Finished Run update-ca-trust.
Jun 06 02:03:44 localhost systemd[1]: Reached target First Boot Complete.
Jun 06 02:03:44 localhost systemd[1]: Starting Commit a transient machine-id on disk...
Jun 06 02:03:44 localhost systemd[1]: etc-machine\x2did.mount: Deactivated successfully.
Jun 06 02:03:44 localhost systemd[1]: Finished Commit a transient machine-id on disk.
Jun 06 02:03:46 localhost systemd[1]: Finished Rebuild Dynamic Linker Cache.
Jun 06 02:03:46 localhost systemd[1]: Starting Update is Completed...
Jun 06 02:03:46 localhost systemd[1]: Finished Update is Completed.
Jun 06 02:03:46 localhost systemd[1]: Reached target System Initialization.
Jun 06 02:03:46 localhost systemd[1]: Started Daily rotation of log files.
Jun 06 02:03:46 localhost systemd[1]: Started Daily Cleanup of Temporary Directories.
Jun 06 02:03:46 localhost systemd[1]: Started daily update of the root trust anchor for DNSSEC.
Jun 06 02:03:46 localhost systemd[1]: Reached target Timer Units.
Jun 06 02:03:46 localhost systemd[1]: Listening on bootupd.socket.
Jun 06 02:03:46 localhost systemd[1]: Listening on D-Bus System Message Bus Socket.
Jun 06 02:03:46 localhost systemd[1]: Listening on Open-iSCSI iscsiuio Socket.
Jun 06 02:03:46 localhost systemd[1]: Reached target Socket Units.
Jun 06 02:03:46 localhost systemd[1]: TPM2 PCR Barrier (Initialization) was skipped because of an unmet condition check (ConditionPathExists=/sys/firmware/efi/efivars/StubPcrKernelImage-4a67b082-0a4c-41cf-b6c7-440b29bb8c4f).
Jun 06 02:03:46 localhost systemd[1]: Reached target Basic System.
Jun 06 02:03:46 localhost systemd[1]: Starting CoreOS Generate iSCSI Initiator Name...
Jun 06 02:03:46 localhost systemd[1]: CoreOS Delete Ignition Config From Hypervisor was skipped because no trigger condition checks were met.
Jun 06 02:03:46 localhost systemd[1]: CoreOS Mark Ignition Boot Complete was skipped because of an unmet condition check (ConditionPathExists=!/run/ostree-live).
Jun 06 02:03:46 localhost systemd[1]: Starting Create Ignition Status Issue Files...
Jun 06 02:03:46 localhost systemd[1]: CoreOS Configure Chrony Based On The Platform was skipped because no trigger condition checks were met.
Jun 06 02:03:46 localhost systemd[1]: Starting Network Manager...
Jun 06 02:03:46 localhost systemd[1]: Starting NTP client/server...
Jun 06 02:03:46 localhost systemd[1]: Starting Generation of shadow ID ranges for CRI-O...
Jun 06 02:03:46 localhost systemd[1]: Starting Restore /run/initramfs on shutdown...
Jun 06 02:03:46 localhost systemd[1]: Started irqbalance daemon.
Jun 06 02:03:46 localhost systemd[1]: Software RAID monitoring and management was skipped because of an unmet condition check (ConditionPathExists=/etc/mdadm.conf).
Jun 06 02:03:46 localhost systemd[1]: Starting Load CPU microcode update...
Jun 06 02:03:46 localhost systemd[1]: Auto-connect to subsystems on FC-NVME devices found during boot was skipped because of an unmet condition check (ConditionPathExists=/sys/class/fc/fc_udev_device/nvme_discovery).
Jun 06 02:03:46 localhost systemd[1]: Read-Only Sysroot Migration was skipped because of an unmet condition check (ConditionPathIsReadWrite=/sysroot).
Jun 06 02:03:46 localhost systemd[1]: Starting selinux.service...
Jun 06 02:03:46 localhost systemd[1]: Starting Agent-based installer hostname update service...
Jun 06 02:03:46 localhost systemd[1]: Starting OpenSSH ecdsa Server Key Generation...
Jun 06 02:03:46 localhost systemd[1]: Starting OpenSSH ed25519 Server Key Generation...
Jun 06 02:03:46 localhost systemd[1]: Starting OpenSSH rsa Server Key Generation...
Jun 06 02:03:46 localhost systemd[1]: System Security Services Daemon was skipped because no trigger condition checks were met.
Jun 06 02:03:46 localhost systemd[1]: Reached target User and Group Name Lookups.
Jun 06 02:03:46 localhost systemd[1]: Starting User Login Management...
Jun 06 02:03:46 localhost systemd[1]: VGAuth Service for open-vm-tools was skipped because of an unmet condition check (ConditionVirtualization=vmware).
Jun 06 02:03:46 localhost systemd[1]: Service for virtual machines hosted on VMware was skipped because of an unmet condition check (ConditionVirtualization=vmware).
Jun 06 02:03:46 localhost systemd[1]: Finished CoreOS Generate iSCSI Initiator Name.
Jun 06 02:03:46 localhost systemd[1]: Finished Restore /run/initramfs on shutdown.
Jun 06 02:03:47 localhost systemd-logind[2202]: New seat seat0.
Jun 06 02:03:47 localhost systemd-logind[2202]: Watching system buttons on /dev/input/event0 (Power Button)
Jun 06 02:03:47 localhost systemd-logind[2202]: Watching system buttons on /dev/input/event1 (iLO Virtual Keyboard)
Jun 06 02:03:47 localhost systemd[1]: Starting D-Bus System Message Bus...
Jun 06 02:03:47 localhost groupadd[2215]: group added to /etc/group: name=containers, GID=989
Jun 06 02:03:47 localhost groupadd[2215]: group added to /etc/gshadow: name=containers
Jun 06 02:03:47 localhost groupadd[2215]: new group: name=containers, GID=989
Jun 06 02:03:47 localhost dbus-broker-launch[2219]: Looking up NSS user entry for 'dbus'...
Jun 06 02:03:47 localhost set-hostname.sh[2198]: Host has matching MAC address: b4:96:91:d9:a4:64
Jun 06 02:03:47 localhost set-hostname.sh[2198]: Setting hostname to sno131.outbound.vz.bos2.lab
Jun 06 02:03:47 localhost dbus-broker-launch[2219]: NSS returned NAME 'dbus' and UID '81'
Jun 06 02:03:47 localhost systemd[1]: Finished Create Ignition Status Issue Files.
Jun 06 02:03:47 localhost useradd[2249]: new user: name=containers, UID=989, GID=989, home=/var/home/containers, shell=/sbin/nologin, from=none
Jun 06 02:03:48 localhost chronyd[2259]: chronyd version 4.3 starting (+CMDMON +NTP +REFCLOCK +RTC +PRIVDROP +SCFILTER +SIGND +ASYNCDNS +NTS +SECHASH +IPV6 +DEBUG)
Jun 06 02:03:48 localhost chronyd[2259]: Using right/UTC timezone to obtain leap second data
Jun 06 02:03:48 localhost chronyd[2259]: Loaded seccomp filter (level 2)
Jun 06 02:03:48 localhost systemd[1]: Started NTP client/server.
Jun 06 02:03:48 localhost dbus-broker-launch[2219]: Looking up NSS user entry for 'polkitd'...
Jun 06 02:03:48 localhost dbus-broker-launch[2219]: NSS returned NAME 'polkitd' and UID '999'
Jun 06 02:03:48 localhost systemd[1]: crio-subid.service: Deactivated successfully.
Jun 06 02:03:48 localhost systemd[1]: Finished Generation of shadow ID ranges for CRI-O.
Jun 06 02:03:48 localhost systemd[1]: sshd-keygen@ecdsa.service: Deactivated successfully.
Jun 06 02:03:48 localhost systemd[1]: Finished OpenSSH ecdsa Server Key Generation.
Jun 06 02:03:48 localhost systemd[1]: sshd-keygen@ed25519.service: Deactivated successfully.
Jun 06 02:03:48 localhost systemd[1]: Finished OpenSSH ed25519 Server Key Generation.
Jun 06 02:03:48 localhost systemd[1]: Started D-Bus System Message Bus.
Jun 06 02:03:48 localhost NetworkManager[2186]: <info>  [1686017028.3848] NetworkManager (version 1.42.2-1.el9) is starting... (boot:1c4de38f-9407-4ca6-8d60-1949f93a762e)
Jun 06 02:03:48 localhost NetworkManager[2186]: <info>  [1686017028.3849] Read config: /etc/NetworkManager/NetworkManager.conf (lib: 10-disable-default-plugins.conf, 20-client-id-from-mac.conf)
Jun 06 02:03:48 localhost dbus-broker-lau[2219]: Ready
Jun 06 02:03:48 localhost systemd[1]: Started User Login Management.
Jun 06 02:03:48 localhost NetworkManager[2186]: <info>  [1686017028.4028] bus-manager: acquired D-Bus service "org.freedesktop.NetworkManager"
Jun 06 02:03:48 localhost systemd[1]: Started Network Manager.
Jun 06 02:03:48 localhost systemd[1]: Starting Hostname Service...
Jun 06 02:03:48 localhost NetworkManager[2186]: <info>  [1686017028.4842] manager[0x55d1d91c0030]: monitoring kernel firmware directory '/lib/firmware'.
Jun 06 02:03:48 localhost systemd[1]: Started Hostname Service.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd-hostnamed[2285]: Hostname set to <sno131.outbound.vz.bos2.lab> (static)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.4907] hostname: hostname: using hostnamed
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.4907] hostname: static hostname changed from (none) to "sno131.outbound.vz.bos2.lab"
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Finished Agent-based installer hostname update service.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.5520] dns-mgr: init: dns=default,systemd-resolved rc-manager=symlink (auto)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.6732] manager[0x55d1d91c0030]: rfkill: Wi-Fi hardware radio set enabled
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.6733] manager[0x55d1d91c0030]: rfkill: WWAN hardware radio set enabled
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Listening on Load/Save RF Kill Switch Status /dev/rfkill Watch.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7428] Loaded device plugin: NMOvsFactory (/usr/lib64/NetworkManager/1.42.2-1.el9/libnm-device-plugin-ovs.so)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7597] Loaded device plugin: NMTeamFactory (/usr/lib64/NetworkManager/1.42.2-1.el9/libnm-device-plugin-team.so)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7598] manager: rfkill: Wi-Fi enabled by radio killswitch; enabled by state file
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7598] manager: rfkill: WWAN enabled by radio killswitch; enabled by state file
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7598] manager: Networking is enabled by state file
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7604] settings: Loaded settings plugin: keyfile (internal)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7622] settings: Loaded settings plugin: ifcfg-rh ("/usr/lib64/NetworkManager/1.42.2-1.el9/libnm-settings-plugin-ifcfg-rh.so")
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7637] dhcp: init: Using DHCP client 'internal'
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Starting Network Manager Script Dispatcher Service...
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7638] manager: (lo): new Loopback device (/org/freedesktop/NetworkManager/Devices/1)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7644] device (lo): state change: unmanaged -> unavailable (reason 'connection-assumed', sys-iface-state: 'external')
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7646] device (lo): state change: unavailable -> disconnected (reason 'connection-assumed', sys-iface-state: 'external')
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7650] device (lo): Activation: starting connection 'lo' (c6d35040-12f1-43ac-b8a1-de7d6ef67e37)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7654] manager: (eno1): new Ethernet device (/org/freedesktop/NetworkManager/Devices/2)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7659] settings: (eno1): created default wired connection 'Wired connection 1'
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7659] device (eno1): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab kernel: igb 0000:03:00.0 eno1: igb: eno1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX/TX
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab kernel: IPv6: ADDRCONF(NETDEV_CHANGE): eno1: link becomes ready
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7884] manager: (ens1f0): new Ethernet device (/org/freedesktop/NetworkManager/Devices/3)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7885] device (ens1f0): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab kernel: ice 0000:10:00.0 ens1f0: NIC Link is up 25 Gbps Full Duplex, Requested FEC: RS-FEC, Negotiated FEC: NONE, Autoneg Advertised: Off, Autoneg Negotiated: False, Flow Control: None
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.8546] manager: (ens1f1): new Ethernet device (/org/freedesktop/NetworkManager/Devices/4)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.8551] settings: (ens1f1): created default wired connection 'Wired connection 2'
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.8551] device (ens1f1): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: sshd-keygen@rsa.service: Deactivated successfully.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Finished OpenSSH rsa Server Key Generation.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Reached target sshd-keygen.target.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Starting Generate SSH keys snippet for display via console-login-helper-messages...
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.9295] manager: (ens1f2): new Ethernet device (/org/freedesktop/NetworkManager/Devices/5)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.9301] settings: (ens1f2): created default wired connection 'Wired connection 3'
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.9301] device (ens1f2): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: microcode.service: Deactivated successfully.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Finished Load CPU microcode update.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Started Network Manager Script Dispatcher Service.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Finished Generate SSH keys snippet for display via console-login-helper-messages.
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.0098] manager: (ens1f3): new Ethernet device (/org/freedesktop/NetworkManager/Devices/6)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.0104] settings: (ens1f3): created default wired connection 'Wired connection 4'
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.0104] device (ens1f3): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.0949] manager: (ens2f0): new Ethernet device (/org/freedesktop/NetworkManager/Devices/7)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.0954] settings: (ens2f0): created default wired connection 'Wired connection 5'
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.0954] device (ens2f0): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.1716] manager: (ens2f1): new Ethernet device (/org/freedesktop/NetworkManager/Devices/8)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.1721] settings: (ens2f1): created default wired connection 'Wired connection 6'
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.1721] device (ens2f1): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.2369] manager: (ens2f2): new Ethernet device (/org/freedesktop/NetworkManager/Devices/9)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.2374] settings: (ens2f2): created default wired connection 'Wired connection 7'
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.2374] device (ens2f2): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.3539] manager: (ens2f3): new Ethernet device (/org/freedesktop/NetworkManager/Devices/10)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.3545] settings: (ens2f3): created default wired connection 'Wired connection 8'
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.3545] device (ens2f3): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4364] ovsdb: disconnected from ovsdb
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4364] device (lo): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4365] device (lo): state change: prepare -> config (reason 'none', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4366] device (lo): state change: config -> ip-config (reason 'none', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4367] device (eno1): carrier: link connected
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4368] device (ens1f0): carrier: link connected
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4374] device (lo): state change: ip-config -> ip-check (reason 'none', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4377] device (eno1): state change: unavailable -> disconnected (reason 'carrier-changed', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4385] device (ens1f0): state change: unavailable -> disconnected (reason 'carrier-changed', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4387] policy: auto-activating connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4388] policy: auto-activating connection 'ens1f0' (3ad293c7-96cd-4e16-a03d-ea898589a158)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4389] device (lo): state change: ip-check -> secondaries (reason 'none', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4390] device (eno1): Activation: starting connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4392] device (ens1f0): Activation: starting connection 'ens1f0' (3ad293c7-96cd-4e16-a03d-ea898589a158)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4392] device (lo): state change: secondaries -> activated (reason 'none', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4394] device (lo): Activation: successful, device activated.
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4397] device (eno1): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4398] manager: NetworkManager state is now CONNECTING
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4399] device (eno1): state change: prepare -> config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4406] device (ens1f0): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4407] device (ens1f0): state change: prepare -> config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4409] device (eno1): state change: config -> ip-config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4417] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4418] device (ens1f0): state change: config -> ip-config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4421] policy: set 'ens1f0' (ens1f0) as default for IPv4 routing and DNS
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4434] device (ens1f0): state change: ip-config -> ip-check (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4446] device (ens1f0): state change: ip-check -> secondaries (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4448] device (ens1f0): state change: secondaries -> activated (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4449] manager: NetworkManager state is now CONNECTED_SITE
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4450] device (ens1f0): Activation: successful, device activated.
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4453] manager: NetworkManager state is now CONNECTED_GLOBAL
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  Converting 353 SID table entries...
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  policy capability network_peer_controls=1
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  policy capability open_perms=1
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  policy capability extended_socket_class=1
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  policy capability always_check_network=0
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  policy capability cgroup_seclabel=1
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  policy capability nnp_nosuid_transition=1
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  policy capability genfs_seclabel_symlinks=1
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab systemd[1]: selinux.service: Deactivated successfully.
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab systemd[1]: Finished selinux.service.
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab systemd[1]: selinux.service: Consumed 5.281s CPU time.
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab dbus-broker-launch[2279]: avc:  op=load_policy lsm=selinux seqno=2 res=1
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab systemd[1]: Starting Get interactive user configuration at boot...
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab systemd[1]: Received SIGRTMIN+21 from PID 2421 (n/a).
Jun 06 02:03:55 sno131.outbound.vz.bos2.lab chronyd[2259]: Selected source 129.250.35.250 (2.rhel.pool.ntp.org)
Jun 06 02:03:55 sno131.outbound.vz.bos2.lab chronyd[2259]: System clock TAI offset set to 37 seconds
Jun 06 02:03:56 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-opaque\x2dbug\x2dcheck3669819565-merged.mount: Deactivated successfully.
Jun 06 02:03:59 sno131.outbound.vz.bos2.lab systemd[1]: NetworkManager-dispatcher.service: Deactivated successfully.
Jun 06 02:03:59 sno131.outbound.vz.bos2.lab kernel: VFS: idmapped mount is not enabled.
Jun 06 02:04:01 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay.mount: Deactivated successfully.
Jun 06 02:04:17 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay.mount: Deactivated successfully.
Jun 06 02:04:18 sno131.outbound.vz.bos2.lab systemd[1]: systemd-hostnamed.service: Deactivated successfully.
Jun 06 02:04:21 sno131.outbound.vz.bos2.lab systemd[1]: Finished Get interactive user configuration at boot.
Jun 06 02:04:21 sno131.outbound.vz.bos2.lab systemd[1]: Received SIGRTMIN+20 from PID 2584 (n/a).
Jun 06 02:04:21 sno131.outbound.vz.bos2.lab systemd[1]: Reached target Network.
Jun 06 02:04:21 sno131.outbound.vz.bos2.lab systemd[1]: Starting Network Manager Wait Online...
Jun 06 02:04:21 sno131.outbound.vz.bos2.lab systemd[1]: Update GCP routes for forwarded IPs. was skipped because no trigger condition checks were met.
Jun 06 02:04:21 sno131.outbound.vz.bos2.lab systemd[1]: Starting OpenSSH server daemon...
Jun 06 02:04:22 sno131.outbound.vz.bos2.lab sshd[2586]: main: sshd: ssh-rsa algorithm is disabled
Jun 06 02:04:22 sno131.outbound.vz.bos2.lab sshd[2586]: Server listening on 0.0.0.0 port 22.
Jun 06 02:04:22 sno131.outbound.vz.bos2.lab sshd[2586]: Server listening on :: port 22.
Jun 06 02:04:22 sno131.outbound.vz.bos2.lab systemd[1]: Started OpenSSH server daemon.
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9165] device (eno1): state change: ip-config -> failed (reason 'ip-config-unavailable', sys-iface-state: 'managed')
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <warn>  [1686017074.9169] device (eno1): Activation: failed for connection 'Wired connection 1'
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9170] device (eno1): state change: failed -> disconnected (reason 'none', sys-iface-state: 'managed')
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9264] dhcp4 (eno1): canceled DHCP transaction
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9265] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9265] dhcp4 (eno1): state changed no lease
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9275] policy: auto-activating connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9278] device (eno1): Activation: starting connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9278] device (eno1): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'managed')
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9279] device (eno1): state change: prepare -> config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9286] device (eno1): state change: config -> ip-config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9293] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9169] device (eno1): state change: ip-config -> failed (reason 'ip-config-unavailable', sys-iface-state: 'managed')
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <warn>  [1686017119.9175] device (eno1): Activation: failed for connection 'Wired connection 1'
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9176] device (eno1): state change: failed -> disconnected (reason 'none', sys-iface-state: 'managed')
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9265] dhcp4 (eno1): canceled DHCP transaction
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9265] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9265] dhcp4 (eno1): state changed no lease
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9281] policy: auto-activating connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9283] device (eno1): Activation: starting connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9283] device (eno1): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'managed')
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9284] device (eno1): state change: prepare -> config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9290] device (eno1): state change: config -> ip-config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9298] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: NetworkManager-wait-online.service: Main process exited, code=exited, status=1/FAILURE
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: NetworkManager-wait-online.service: Failed with result 'exit-code'.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Failed to start Network Manager Wait Online.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Reached target Network is Online.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Starting Assisted Installer Agent...
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Login and scanning of iSCSI devices was skipped because of an unmet condition check (ConditionDirectoryNotEmpty=/var/lib/iscsi/nodes).
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Reached target Preparation for Remote File Systems.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Reached target Remote Encrypted Volumes.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Reached target Remote File Systems.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Starting Identify node zero to run OpenShift Assisted Installation Service on...
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: TPM2 PCR Barrier (User) was skipped because of an unmet condition check (ConditionPathExists=/sys/firmware/efi/efivars/StubPcrKernelImage-4a67b082-0a4c-41cf-b6c7-440b29bb8c4f).
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Starting Permit User Sessions...
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab set-node-zero.sh[2593]: NODE_ZERO_IP: 192.168.14.27
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab set-node-zero.sh[2593]: Node 0 IP 192.168.14.27 found on this host
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Finished Permit User Sessions.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: CoreOS Live ISO virtio success was skipped because of an unmet condition check (ConditionPathExists=/dev/virtio-ports/coreos.liveiso-success).
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Started Getty on tty1.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Reached target Login Prompts.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab set-node-zero.sh[2593]: MAC Address for Node 0: b4:96:91:d9:a4:64
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab set-node-zero.sh[2593]: Created file /etc/assisted/node0
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Finished Identify node zero to run OpenShift Assisted Installation Service on.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Starting Assisted Service pod...
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab extract-agent.sh[2592]: Pulling quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27...
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab extract-agent.sh[2636]: bd31af778e86d50ac082b75a2860143704fe333a4a07562202de6fc7593859a3
Jun 06 02:05:23 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-e46a38b586d2a70bae40d9105b989a35d8f6bcfd9f6d306ac5a58f84a87c30b5-merged.mount: Deactivated successfully.
Jun 06 02:05:23 sno131.outbound.vz.bos2.lab systemd[1]: Created slice Slice /machine.
Jun 06 02:05:23 sno131.outbound.vz.bos2.lab systemd[1]: Created slice cgroup machine-libpod_pod_e500a56affcd21e1cd47bfd5e25c79930fd9cedcab025e87808ea2db56157309.slice.
Jun 06 02:05:23 sno131.outbound.vz.bos2.lab podman[2611]: e500a56affcd21e1cd47bfd5e25c79930fd9cedcab025e87808ea2db56157309
Jun 06 02:05:23 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay.mount: Deactivated successfully.
Jun 06 02:05:23 sno131.outbound.vz.bos2.lab get-container-images.sh[2780]: Pulling quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27...
Jun 06 02:05:23 sno131.outbound.vz.bos2.lab get-container-images.sh[2822]: bd31af778e86d50ac082b75a2860143704fe333a4a07562202de6fc7593859a3
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container e07fb8cc2f05481df8254458a2bc60d55df0aeb1d9bd66fe05d1e3b4bb43b033.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container f1e341f2afbfb5d95ec598eca63ea04f5ee6ccd3be4d3726f2e40e3f0b0a4189.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: libpod-f1e341f2afbfb5d95ec598eca63ea04f5ee6ccd3be4d3726f2e40e3f0b0a4189.scope: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: libpod-e07fb8cc2f05481df8254458a2bc60d55df0aeb1d9bd66fe05d1e3b4bb43b033.scope: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[2591]: Using agent image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d to copy bin
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-e5551cb7c837c441c1a450ed98adf93cccbc3ba8fa94400bc55898decf1a68e7-merged.mount: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-e07fb8cc2f05481df8254458a2bc60d55df0aeb1d9bd66fe05d1e3b4bb43b033-userdata-shm.mount: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-c64328db2afe4879c43df924cc39b1217c968a4a64054253ae0a441139176155-merged.mount: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-f1e341f2afbfb5d95ec598eca63ea04f5ee6ccd3be4d3726f2e40e3f0b0a4189-userdata-shm.mount: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 71760a4938885f280e35cdc32f7b6d2cba75db9decf63a393a12817dcbba0c98.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Trying to pull quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d...
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: libpod-71760a4938885f280e35cdc32f7b6d2cba75db9decf63a393a12817dcbba0c98.scope: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-71760a4938885f280e35cdc32f7b6d2cba75db9decf63a393a12817dcbba0c98-userdata-shm.mount: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-4519fbfffc7dd0332b0a3a7ec7d962b1309ffe5f074bcf9f95c06d0685aed607-merged.mount: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay.mount: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 637f04e9e3397d61688f0871eaedbbb027c2c99a4cc3d7926eb4b3365cbb9188.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: libpod-637f04e9e3397d61688f0871eaedbbb027c2c99a4cc3d7926eb4b3365cbb9188.scope: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 4ea181c3746b66edd8edff91b2af65efb88f5c11e8fbfa778a1c1e41dcea5efc.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: libpod-4ea181c3746b66edd8edff91b2af65efb88f5c11e8fbfa778a1c1e41dcea5efc.scope: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Getting image source signatures
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Copying blob sha256:80c3686a5885b426af5147f41131b7c1bbc851599811ae921a08747f120593ee
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Copying blob sha256:d8190195889efb5333eeec18af9b6c82313edd4db62989bd3a357caca4f13f0e
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Copying blob sha256:97da74cc6d8fa5d1634eb1760fd1da5c6048619c264c23e62d75f3bf6b8ef5c4
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Copying blob sha256:df8999d603e3929dbee92d7be49011da4d311a163f6258489e52f972d5819eab
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Copying blob sha256:49382d220048678f7bb2c81d0bb67193dca1889debc1d93345fbb15363b0dfab
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: bridge: filtering via arp/ip/ip6tables is no longer available by default. Update your scripts to load br_netfilter if you need this.
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1322] manager: (cni-podman0): new Bridge device (/org/freedesktop/NetworkManager/Devices/11)
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1948] manager: (veth32502cb4): new Veth device (/org/freedesktop/NetworkManager/Devices/12)
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 1(veth32502cb4) entered blocking state
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 1(veth32502cb4) entered disabled state
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: device veth32502cb4 entered promiscuous mode
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1968] device (cni-podman0): state change: unmanaged -> unavailable (reason 'connection-assumed', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1971] device (cni-podman0): state change: unavailable -> disconnected (reason 'connection-assumed', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1974] device (cni-podman0): Activation: starting connection 'cni-podman0' (f19b4267-235e-436e-8238-3f90901453ec)
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1975] device (cni-podman0): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1976] device (cni-podman0): state change: prepare -> config (reason 'none', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1977] device (cni-podman0): state change: config -> ip-config (reason 'none', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1978] device (cni-podman0): state change: ip-config -> ip-check (reason 'none', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab systemd[1]: Starting Network Manager Script Dispatcher Service...
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab systemd[1]: Started Network Manager Script Dispatcher Service.
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.2072] device (cni-podman0): state change: ip-check -> secondaries (reason 'none', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.2074] device (cni-podman0): state change: secondaries -> activated (reason 'none', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.2077] device (cni-podman0): Activation: successful, device activated.
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab systemd[1]: iscsi.service: Unit cannot be reloaded because it is inactive.
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: IPv6: ADDRCONF(NETDEV_CHANGE): veth32502cb4: link becomes ready
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 1(veth32502cb4) entered blocking state
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 1(veth32502cb4) entered forwarding state
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.4934] device (veth32502cb4): carrier: link connected
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.4936] device (cni-podman0): carrier: link connected
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: Warning: Deprecated Driver is detected: nft_compat will not be maintained in a future major release and may be disabled
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 361d59273eefae6f5a76a2f69b781d5baa1e2a52ae0f3607ee7acf6de1e8e5f2.
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3286]: e500a56affcd21e1cd47bfd5e25c79930fd9cedcab025e87808ea2db56157309
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab systemd[1]: Started Assisted Service pod.
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab systemd[1]: Starting Assisted Service database...
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab systemd[1]: Starting Assisted Service container...
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3560]: Trying to pull quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f8e7aad960ddc3ce2e3857b613531b2b2211641496e964f0631f3bdd3916983a...
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3561]: Trying to pull quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f8e7aad960ddc3ce2e3857b613531b2b2211641496e964f0631f3bdd3916983a...
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3560]: Getting image source signatures
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3560]: Copying blob sha256:b54649f20f4c3693f373a46c9be1d47f7ffd67826ec57c12ec0429660966acae
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3560]: Copying blob sha256:d8190195889efb5333eeec18af9b6c82313edd4db62989bd3a357caca4f13f0e
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3560]: Copying blob sha256:97da74cc6d8fa5d1634eb1760fd1da5c6048619c264c23e62d75f3bf6b8ef5c4
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3560]: Copying blob sha256:df8999d603e3929dbee92d7be49011da4d311a163f6258489e52f972d5819eab
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3560]: Copying blob sha256:49382d220048678f7bb2c81d0bb67193dca1889debc1d93345fbb15363b0dfab
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3561]: Getting image source signatures
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3561]: Copying blob sha256:b54649f20f4c3693f373a46c9be1d47f7ffd67826ec57c12ec0429660966acae
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3561]: Copying blob sha256:d8190195889efb5333eeec18af9b6c82313edd4db62989bd3a357caca4f13f0e
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3561]: Copying blob sha256:97da74cc6d8fa5d1634eb1760fd1da5c6048619c264c23e62d75f3bf6b8ef5c4
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3561]: Copying blob sha256:df8999d603e3929dbee92d7be49011da4d311a163f6258489e52f972d5819eab
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3561]: Copying blob sha256:49382d220048678f7bb2c81d0bb67193dca1889debc1d93345fbb15363b0dfab
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Copying config sha256:fc010a8158201642d346b874174efe504792e21920adb879b2b95c55a736e5ec
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Writing manifest to image destination
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Storing signatures
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(veth8196f551) entered blocking state
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(veth8196f551) entered disabled state
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: device veth8196f551 entered promiscuous mode
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017132.7413] manager: (veth8196f551): new Veth device (/org/freedesktop/NetworkManager/Devices/13)
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017132.7462] device (veth8196f551): carrier: link connected
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: IPv6: ADDRCONF(NETDEV_CHANGE): veth8196f551: link becomes ready
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(veth8196f551) entered blocking state
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(veth8196f551) entered forwarding state
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 7c6891ca661099d78a610db79c96cd24dc13d994c2b9cbb67fee558892dbdd69.
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab systemd[1]: libpod-7c6891ca661099d78a610db79c96cd24dc13d994c2b9cbb67fee558892dbdd69.scope: Deactivated successfully.
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(veth8196f551) entered disabled state
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: device veth8196f551 left promiscuous mode
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(veth8196f551) entered disabled state
Jun 06 02:05:33 sno131.outbound.vz.bos2.lab systemd[1]: run-netns-netns\x2d81c61221\x2de3f4\x2d85cd\x2d0dcf\x2d08864e8317ae.mount: Deactivated successfully.
Jun 06 02:05:33 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-7c6891ca661099d78a610db79c96cd24dc13d994c2b9cbb67fee558892dbdd69-userdata-shm.mount: Deactivated successfully.
Jun 06 02:05:33 sno131.outbound.vz.bos2.lab systemd[1]: Started Assisted Installer Agent.
Jun 06 02:05:33 sno131.outbound.vz.bos2.lab start-agent.sh[3898]: Waiting for infra-env-id to be available
Jun 06 02:05:33 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-a18683a05ab24a67db1b238250f9e5a25774a0d03a4fd32a3ec7908084d7baca-merged.mount: Deactivated successfully.
Jun 06 02:05:35 sno131.outbound.vz.bos2.lab systemd[1]: NetworkManager-dispatcher.service: Deactivated successfully.
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3561]: Copying config sha256:4d83c30aa720e8b7398a2a16d5ca48a0643dc3d02553c5cb6505e542f3d60ec8
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3561]: Writing manifest to image destination
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3561]: Storing signatures
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3561]: 
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3560]: Copying config sha256:4d83c30aa720e8b7398a2a16d5ca48a0643dc3d02553c5cb6505e542f3d60ec8
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3560]: Writing manifest to image destination
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3560]: Storing signatures
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 1a132fbc13657ffe2402c713a27588f1043a0b105f0356cbf0f724e455bc491d.
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3560]: 
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3561]: 1a132fbc13657ffe2402c713a27588f1043a0b105f0356cbf0f724e455bc491d
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container e8d3d8160983a8de3617641b410b53150d8b90dd9ef5bc438defff9d19faeb52.
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab systemd[1]: Started Assisted Service container.
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab systemd[1]: Starting Service that creates initial cluster and infraenv...
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab wait-for-assisted-service.sh[3966]: Waiting for assisted-service to be ready
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: false
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:36Z" level=info msg="Setting log format: text" func=main.InitLogs file="/src/cmd/main.go:176"
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:36Z" level=info msg="Setting Log Level: info" func=main.InitLogs file="/src/cmd/main.go:182"
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:36Z" level=info msg="Starting assisted-service version: bcceba754250cad2c4247770656c88b96c8cbe5e" func=main.main file="/src/cmd/main.go:209"
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:36Z" level=info msg="Starting bm service" func=main.main file="/src/cmd/main.go:224"
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:36Z" level=info msg="Started service with OS images [{\"openshift_version\":\"4.13.2\",\"cpu_architecture\":\"x86_64\",\"url\":\"https://rhcos.mirror.openshi>
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:36Z" level=info msg="Connecting to DB" func=main.setupDB file="/src/cmd/main.go:675"
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab systemd[1]: Started Assisted Service database.
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:36Z" level=info msg="Failed to connect to DB, retrying" func=main.setupDB.func1 file="/src/cmd/main.go:682" error="failed to connect to `host=127.0.0.1 user=>
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3560]: e8d3d8160983a8de3617641b410b53150d8b90dd9ef5bc438defff9d19faeb52
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab assisted-db[3936]: waiting for server to start.... done
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab assisted-db[3936]: server started
[root@hub-helper ~]# 
[root@hub-helper ~]# 
[root@hub-helper ~]# journalctl --file system-sno131.journal > system-sno131.txt
[root@hub-helper ~]# cat system-sno131.txt 
-- Logs begin at Tue 2023-06-06 02:03:04 UTC, end at Tue 2023-06-06 02:14:29 UTC. --
Jun 06 02:03:04 localhost kernel: Linux version 5.14.0-284.13.1.el9_2.x86_64 (mockbuild@x86-vm-09.build.eng.bos.redhat.com) (gcc (GCC) 11.3.1 20221121 (Red Hat 11.3.1-4), GNU ld version 2.35.2-37.el9) #1 SMP PREEMPT_DYNAMIC Thu Apr 27 13:35:10 EDT 2023
Jun 06 02:03:04 localhost kernel: The list of certified hardware and cloud instances for Red Hat Enterprise Linux 9 can be viewed at the Red Hat Ecosystem Catalog, https://catalog.redhat.com.
Jun 06 02:03:04 localhost kernel: Command line: BOOT_IMAGE=/images/pxeboot/vmlinuz coreos.liveiso=rhcos-413.92.202305021736-0 ignition.firstboot ignition.platform.id=metal
Jun 06 02:03:04 localhost kernel: x86/split lock detection: #AC: crashing the kernel on kernel split_locks and warning on user-space split_locks
Jun 06 02:03:04 localhost kernel: x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'
Jun 06 02:03:04 localhost kernel: x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'
Jun 06 02:03:04 localhost kernel: x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'
Jun 06 02:03:04 localhost kernel: x86/fpu: Supporting XSAVE feature 0x020: 'AVX-512 opmask'
Jun 06 02:03:04 localhost kernel: x86/fpu: Supporting XSAVE feature 0x040: 'AVX-512 Hi256'
Jun 06 02:03:04 localhost kernel: x86/fpu: Supporting XSAVE feature 0x080: 'AVX-512 ZMM_Hi256'
Jun 06 02:03:04 localhost kernel: x86/fpu: Supporting XSAVE feature 0x200: 'Protection Keys User registers'
Jun 06 02:03:04 localhost kernel: x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256
Jun 06 02:03:04 localhost kernel: x86/fpu: xstate_offset[5]:  832, xstate_sizes[5]:   64
Jun 06 02:03:04 localhost kernel: x86/fpu: xstate_offset[6]:  896, xstate_sizes[6]:  512
Jun 06 02:03:04 localhost kernel: x86/fpu: xstate_offset[7]: 1408, xstate_sizes[7]: 1024
Jun 06 02:03:04 localhost kernel: x86/fpu: xstate_offset[9]: 2432, xstate_sizes[9]:    8
Jun 06 02:03:04 localhost kernel: x86/fpu: Enabled xstate features 0x2e7, context size is 2440 bytes, using 'compacted' format.
Jun 06 02:03:04 localhost kernel: signal: max sigframe size: 3632
Jun 06 02:03:04 localhost kernel: BIOS-provided physical RAM map:
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000000000000-0x000000000008ffff] usable
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000000090000-0x0000000000093fff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000000094000-0x000000000009efff] usable
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x000000000009f000-0x000000000009ffff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000000100000-0x0000000053c6bfff] usable
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000053c6c000-0x0000000053c9bfff] ACPI data
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000053c9c000-0x00000000558ebfff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x00000000558ec000-0x0000000058481fff] usable
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000058482000-0x00000000584fdfff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x00000000584fe000-0x00000000595fdfff] ACPI NVS
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x00000000595fe000-0x0000000059835fff] usable
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000059836000-0x00000000598b6fff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x00000000598b7000-0x000000006f7fffff] usable
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x000000006f800000-0x000000008fffffff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000098000000-0x0000000099c0ffff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x00000000fe000000-0x00000000fe00ffff] reserved
Jun 06 02:03:04 localhost kernel: BIOS-e820: [mem 0x0000000100000000-0x000000207fffffff] usable
Jun 06 02:03:04 localhost kernel: NX (Execute Disable) protection: active
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x505e6018-0x505ee057] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x505e6018-0x505ee057] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x505da018-0x505e5257] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x505da018-0x505e5257] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x505a4018-0x505d9057] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x505a4018-0x505d9057] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x50570018-0x505a3657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x50570018-0x505a3657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x5053c018-0x5056f657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x5053c018-0x5056f657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x50508018-0x5053b657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x50508018-0x5053b657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x504d4018-0x50507657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x504d4018-0x50507657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x504a0018-0x504d3657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x504a0018-0x504d3657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x5046c018-0x5049f657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x5046c018-0x5049f657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec5b018-0x3ec8e657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec5b018-0x3ec8e657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec27018-0x3ec5a657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec27018-0x3ec5a657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec20018-0x3ec26657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec20018-0x3ec26657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec19018-0x3ec1f657] usable ==> usable
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ec19018-0x3ec1f657] usable ==> usable
Jun 06 02:03:04 localhost kernel: extended physical RAM map:
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000000000000-0x000000000008ffff] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000000090000-0x0000000000093fff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000000094000-0x000000000009efff] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000000009f000-0x000000000009ffff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000000f0000-0x00000000000fffff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000000100000-0x000000003ec19017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec19018-0x000000003ec1f657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec1f658-0x000000003ec20017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec20018-0x000000003ec26657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec26658-0x000000003ec27017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec27018-0x000000003ec5a657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec5a658-0x000000003ec5b017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec5b018-0x000000003ec8e657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000003ec8e658-0x000000005046c017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000005046c018-0x000000005049f657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000005049f658-0x00000000504a0017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000504a0018-0x00000000504d3657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000504d3658-0x00000000504d4017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000504d4018-0x0000000050507657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000050507658-0x0000000050508017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000050508018-0x000000005053b657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000005053b658-0x000000005053c017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000005053c018-0x000000005056f657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000005056f658-0x0000000050570017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000050570018-0x00000000505a3657] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000505a3658-0x00000000505a4017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000505a4018-0x00000000505d9057] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000505d9058-0x00000000505da017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000505da018-0x00000000505e5257] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000505e5258-0x00000000505e6017] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000505e6018-0x00000000505ee057] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000505ee058-0x0000000053c6bfff] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000053c6c000-0x0000000053c9bfff] ACPI data
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000053c9c000-0x00000000558ebfff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000558ec000-0x0000000058481fff] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000058482000-0x00000000584fdfff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000584fe000-0x00000000595fdfff] ACPI NVS
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000595fe000-0x0000000059835fff] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000059836000-0x00000000598b6fff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000598b7000-0x000000006f7fffff] usable
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x000000006f800000-0x000000008fffffff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000098000000-0x0000000099c0ffff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x00000000fe000000-0x00000000fe00ffff] reserved
Jun 06 02:03:04 localhost kernel: reserve setup_data: [mem 0x0000000100000000-0x000000207fffffff] usable
Jun 06 02:03:04 localhost kernel: efi: EFI v2.70 by HPE
Jun 06 02:03:04 localhost kernel: efi: SMBIOS=0x540a8000 SMBIOS 3.0=0x540a6000 ACPI=0x53c9b000 ACPI 2.0=0x53c9b014 TPMFinalLog=0x5856d000 MEMATTR=0x3ec8f018 MOKvar=0x540a5000 RNG=0x540bab18 TPMEventLog=0x505ef018 
Jun 06 02:03:04 localhost kernel: efi: seeding entropy pool
Jun 06 02:03:04 localhost kernel: secureboot: Secure boot disabled
Jun 06 02:03:04 localhost kernel: SMBIOS 3.4.0 present.
Jun 06 02:03:04 localhost kernel: DMI: HPE Edgeline e920t/Edgeline e920t, BIOS H10 08/16/2022
Jun 06 02:03:04 localhost kernel: tsc: Detected 2200.000 MHz processor
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x00000000-0x00000fff] usable ==> reserved
Jun 06 02:03:04 localhost kernel: e820: remove [mem 0x000a0000-0x000fffff] usable
Jun 06 02:03:04 localhost kernel: last_pfn = 0x2080000 max_arch_pfn = 0x10000000000
Jun 06 02:03:04 localhost kernel: x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT  
Jun 06 02:03:04 localhost kernel: total RAM covered: 260080M
Jun 06 02:03:04 localhost kernel: Found optimal setting for mtrr clean up
Jun 06 02:03:04 localhost kernel:  gran_size: 64K         chunk_size: 32M         num_reg: 8          lose cover RAM: 0G
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x7f000000-0xffffffff] usable ==> reserved
Jun 06 02:03:04 localhost kernel: x2apic: enabled by BIOS, switching to x2apic ops
Jun 06 02:03:04 localhost kernel: last_pfn = 0x6f800 max_arch_pfn = 0x10000000000
Jun 06 02:03:04 localhost kernel: Using GB pages for direct mapping
Jun 06 02:03:04 localhost kernel: secureboot: Secure boot disabled
Jun 06 02:03:04 localhost kernel: RAMDISK: [mem 0x2a93b000-0x30225fff]
Jun 06 02:03:04 localhost kernel: ACPI: Early table checksum verification disabled
Jun 06 02:03:04 localhost kernel: ACPI: RSDP 0x0000000053C9B014 000024 (v02 HPE   )
Jun 06 02:03:04 localhost kernel: ACPI: XSDT 0x0000000053C84188 000124 (v01 HPE    Server   00000001      01000013)
Jun 06 02:03:04 localhost kernel: ACPI: FACP 0x0000000053C8E000 00010C (v06 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: DSDT 0x0000000053C77000 008089 (v02 HPE    Server   00000002 HPE  00020000)
Jun 06 02:03:04 localhost kernel: ACPI: FACS 0x000000005856B000 000040
Jun 06 02:03:04 localhost kernel: ACPI: SSDT 0x0000000053C99000 000C0A (v02 HPE    ADDRXLAT 00000001 INTL 20181003)
Jun 06 02:03:04 localhost kernel: ACPI: ERST 0x0000000053C98000 000250 (v01 HPE    Server   00000001 INTL 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: MCEJ 0x0000000053C97000 000130 (v01 HPE    Server   00000001 INTL 0100000D)
Jun 06 02:03:04 localhost kernel: ACPI: BERT 0x0000000053C96000 000030 (v01 HPE    Server   00000001 INTL 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: PMTT 0x0000000053C94000 000908 (v02 HPE    Server   00000001 INTL 20091013)
Jun 06 02:03:04 localhost kernel: ACPI: SSDT 0x0000000053C93000 000562 (v01 HPE    SgxSsdt  00000001 INTL 20181003)
Jun 06 02:03:04 localhost kernel: ACPI: HEST 0x0000000053C92000 00017C (v01 HPE    Server   00000001 INTL 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: EINJ 0x0000000053C91000 000170 (v01 HPE    Server   00000001 INTL 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: SSDT 0x0000000053C90000 00061B (v02 HPE    Tpm2Tabl 00001000 INTL 20181003)
Jun 06 02:03:04 localhost kernel: ACPI: TPM2 0x0000000053C8F000 00004C (v04 HPE    Server   00000002      01000013)
Jun 06 02:03:04 localhost kernel: ACPI: SSDT 0x0000000053C95000 00003A (v02 HPE    PLATOPRG 00000001 INTL 20181003)
Jun 06 02:03:04 localhost kernel: ACPI: HPET 0x0000000053C8D000 000038 (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: WDDT 0x0000000053C8C000 000040 (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: APIC 0x0000000053C8B000 00074C (v05 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: MCFG 0x0000000053C8A000 00003C (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: SLIT 0x0000000053C89000 00002D (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: SRAT 0x0000000053C88000 000680 (v03 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: HMAT 0x0000000053C87000 0000A4 (v02 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: SPMI 0x0000000053C86000 000041 (v05 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: SPCR 0x0000000053C85000 000050 (v02 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: MSCT 0x0000000053C9A000 00004E (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: BDAT 0x0000000053C83000 000030 (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: WSMT 0x0000000053C82000 000028 (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: PCCT 0x0000000053C81000 000030 (v02 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: DMAR 0x0000000053C80000 000178 (v01 HPE    Server   00000001 1590 00000001)
Jun 06 02:03:04 localhost kernel: ACPI: SSDT 0x0000000053C72000 004470 (v02 HPE    PCISSDT  00000002 HPE  00020000)
Jun 06 02:03:04 localhost kernel: ACPI: SSDT 0x0000000053C71000 0001C9 (v02 HPE    TIMESSDT 00000002 HPE  00020000)
Jun 06 02:03:04 localhost kernel: ACPI: SSDT 0x0000000053C70000 000302 (v01 HPE    pmab     00000001 1590 20181003)
Jun 06 02:03:04 localhost kernel: ACPI: OEM1 0x0000000053C6F000 000AB7 (v02 HPE    CPU  CPC 00000002 HPE  00020000)
Jun 06 02:03:04 localhost kernel: ACPI: BGRT 0x0000000053C6E000 000038 (v01 HPE    Server   00000002 1590 01000013)
Jun 06 02:03:04 localhost kernel: ACPI: FPDT 0x0000000053C6D000 000034 (v01 HPE    Server   00000002      01000013)
Jun 06 02:03:04 localhost kernel: ACPI: Reserving FACP table memory at [mem 0x53c8e000-0x53c8e10b]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving DSDT table memory at [mem 0x53c77000-0x53c7f088]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving FACS table memory at [mem 0x5856b000-0x5856b03f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SSDT table memory at [mem 0x53c99000-0x53c99c09]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving ERST table memory at [mem 0x53c98000-0x53c9824f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving MCEJ table memory at [mem 0x53c97000-0x53c9712f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving BERT table memory at [mem 0x53c96000-0x53c9602f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving PMTT table memory at [mem 0x53c94000-0x53c94907]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SSDT table memory at [mem 0x53c93000-0x53c93561]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving HEST table memory at [mem 0x53c92000-0x53c9217b]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving EINJ table memory at [mem 0x53c91000-0x53c9116f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SSDT table memory at [mem 0x53c90000-0x53c9061a]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving TPM2 table memory at [mem 0x53c8f000-0x53c8f04b]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SSDT table memory at [mem 0x53c95000-0x53c95039]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving HPET table memory at [mem 0x53c8d000-0x53c8d037]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving WDDT table memory at [mem 0x53c8c000-0x53c8c03f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving APIC table memory at [mem 0x53c8b000-0x53c8b74b]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving MCFG table memory at [mem 0x53c8a000-0x53c8a03b]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SLIT table memory at [mem 0x53c89000-0x53c8902c]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SRAT table memory at [mem 0x53c88000-0x53c8867f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving HMAT table memory at [mem 0x53c87000-0x53c870a3]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SPMI table memory at [mem 0x53c86000-0x53c86040]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SPCR table memory at [mem 0x53c85000-0x53c8504f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving MSCT table memory at [mem 0x53c9a000-0x53c9a04d]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving BDAT table memory at [mem 0x53c83000-0x53c8302f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving WSMT table memory at [mem 0x53c82000-0x53c82027]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving PCCT table memory at [mem 0x53c81000-0x53c8102f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving DMAR table memory at [mem 0x53c80000-0x53c80177]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SSDT table memory at [mem 0x53c72000-0x53c7646f]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SSDT table memory at [mem 0x53c71000-0x53c711c8]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving SSDT table memory at [mem 0x53c70000-0x53c70301]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving OEM1 table memory at [mem 0x53c6f000-0x53c6fab6]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving BGRT table memory at [mem 0x53c6e000-0x53c6e037]
Jun 06 02:03:04 localhost kernel: ACPI: Reserving FPDT table memory at [mem 0x53c6d000-0x53c6d033]
Jun 06 02:03:04 localhost kernel: Setting APIC routing to cluster x2apic.
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0000 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0002 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0004 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0006 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0008 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x000a -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x000c -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x000e -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0010 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0012 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0014 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0016 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0018 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x001a -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x001c -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x001e -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0020 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0022 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0024 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0026 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0028 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x002a -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x002c -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x002e -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0030 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0032 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0034 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0036 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0038 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x003a -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x003c -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x003e -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0001 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0003 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0005 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0007 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0009 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x000b -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x000d -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x000f -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0011 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0013 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0015 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0017 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0019 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x001b -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x001d -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x001f -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0021 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0023 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0025 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0027 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0029 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x002b -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x002d -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x002f -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0031 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0033 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0035 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0037 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x0039 -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x003b -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x003d -> Node 0
Jun 06 02:03:04 localhost kernel: SRAT: PXM 0 -> APIC 0x003f -> Node 0
Jun 06 02:03:04 localhost kernel: ACPI: SRAT: Node 0 PXM 0 [mem 0x00000000-0x7fffffff]
Jun 06 02:03:04 localhost kernel: ACPI: SRAT: Node 0 PXM 0 [mem 0x100000000-0x207fffffff]
Jun 06 02:03:04 localhost kernel: NUMA: Initialized distance table, cnt=1
Jun 06 02:03:04 localhost kernel: NUMA: Node 0 [mem 0x00000000-0x7fffffff] + [mem 0x100000000-0x207fffffff] -> [mem 0x00000000-0x207fffffff]
Jun 06 02:03:04 localhost kernel: NODE_DATA(0) allocated [mem 0x207ffd4000-0x207fffefff]
Jun 06 02:03:04 localhost kernel: Zone ranges:
Jun 06 02:03:04 localhost kernel:   DMA      [mem 0x0000000000001000-0x0000000000ffffff]
Jun 06 02:03:04 localhost kernel:   DMA32    [mem 0x0000000001000000-0x00000000ffffffff]
Jun 06 02:03:04 localhost kernel:   Normal   [mem 0x0000000100000000-0x000000207fffffff]
Jun 06 02:03:04 localhost kernel:   Device   empty
Jun 06 02:03:04 localhost kernel: Movable zone start for each node
Jun 06 02:03:04 localhost kernel: Early memory node ranges
Jun 06 02:03:04 localhost kernel:   node   0: [mem 0x0000000000001000-0x000000000008ffff]
Jun 06 02:03:04 localhost kernel:   node   0: [mem 0x0000000000094000-0x000000000009efff]
Jun 06 02:03:04 localhost kernel:   node   0: [mem 0x0000000000100000-0x0000000053c6bfff]
Jun 06 02:03:04 localhost kernel:   node   0: [mem 0x00000000558ec000-0x0000000058481fff]
Jun 06 02:03:04 localhost kernel:   node   0: [mem 0x00000000595fe000-0x0000000059835fff]
Jun 06 02:03:04 localhost kernel:   node   0: [mem 0x00000000598b7000-0x000000006f7fffff]
Jun 06 02:03:04 localhost kernel:   node   0: [mem 0x0000000100000000-0x000000207fffffff]
Jun 06 02:03:04 localhost kernel: Initmem setup node 0 [mem 0x0000000000001000-0x000000207fffffff]
Jun 06 02:03:04 localhost kernel: On node 0, zone DMA: 1 pages in unavailable ranges
Jun 06 02:03:04 localhost kernel: On node 0, zone DMA: 4 pages in unavailable ranges
Jun 06 02:03:04 localhost kernel: On node 0, zone DMA: 97 pages in unavailable ranges
Jun 06 02:03:04 localhost kernel: On node 0, zone DMA32: 7296 pages in unavailable ranges
Jun 06 02:03:04 localhost kernel: On node 0, zone DMA32: 4476 pages in unavailable ranges
Jun 06 02:03:04 localhost kernel: On node 0, zone DMA32: 129 pages in unavailable ranges
Jun 06 02:03:04 localhost kernel: On node 0, zone Normal: 2048 pages in unavailable ranges
Jun 06 02:03:04 localhost kernel: ACPI: PM-Timer IO Port: 0x508
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x00] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x01] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x02] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x03] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x04] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x05] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x06] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x07] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x08] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x09] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x0a] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x0b] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x0c] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x0d] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x0e] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x0f] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x10] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x11] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x12] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x13] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x14] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x15] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x16] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x17] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x18] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x19] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x1a] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x1b] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x1c] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x1d] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x1e] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x1f] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x20] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x21] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x22] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x23] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x24] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x25] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x26] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x27] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x28] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x29] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x2a] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x2b] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x2c] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x2d] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x2e] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x2f] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x30] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x31] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x32] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x33] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x34] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x35] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x36] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x37] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x38] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x39] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x3a] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x3b] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x3c] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x3d] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x3e] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: ACPI: X2APIC_NMI (uid[0x3f] high level lint[0x1])
Jun 06 02:03:04 localhost kernel: IOAPIC[0]: apic_id 8, version 32, address 0xfec00000, GSI 0-119
Jun 06 02:03:04 localhost kernel: ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl)
Jun 06 02:03:04 localhost kernel: ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)
Jun 06 02:03:04 localhost kernel: ACPI: Using ACPI (MADT) for SMP configuration information
Jun 06 02:03:04 localhost kernel: ACPI: HPET id: 0x8086a701 base: 0xfed00000
Jun 06 02:03:04 localhost kernel: e820: update [mem 0x3ecc5000-0x3ecf5fff] usable ==> reserved
Jun 06 02:03:04 localhost kernel: ACPI: SPCR: console: uart,mmio,0x0,115200
Jun 06 02:03:04 localhost kernel: TSC deadline timer available
Jun 06 02:03:04 localhost kernel: smpboot: Allowing 64 CPUs, 0 hotplug CPUs
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x00000000-0x00000fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x00090000-0x00093fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x0009f000-0x0009ffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x000a0000-0x000effff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x000f0000-0x000fffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec19000-0x3ec19fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec1f000-0x3ec1ffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec20000-0x3ec20fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec26000-0x3ec26fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec27000-0x3ec27fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec5a000-0x3ec5afff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec5b000-0x3ec5bfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ec8e000-0x3ec8efff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x3ecc5000-0x3ecf5fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x5046c000-0x5046cfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x5049f000-0x5049ffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x504a0000-0x504a0fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x504d3000-0x504d3fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x504d4000-0x504d4fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x50507000-0x50507fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x50508000-0x50508fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x5053b000-0x5053bfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x5053c000-0x5053cfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x5056f000-0x5056ffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x50570000-0x50570fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x505a3000-0x505a3fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x505a4000-0x505a4fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x505d9000-0x505d9fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x505da000-0x505dafff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x505e5000-0x505e5fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x505e6000-0x505e6fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x505ee000-0x505eefff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x53c6c000-0x53c9bfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x53c9c000-0x558ebfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x58482000-0x584fdfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x584fe000-0x595fdfff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x59836000-0x598b6fff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x6f800000-0x8fffffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x90000000-0x97ffffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x98000000-0x99c0ffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0x99c10000-0xfdffffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0xfe000000-0xfe00ffff]
Jun 06 02:03:04 localhost kernel: PM: hibernation: Registered nosave memory: [mem 0xfe010000-0xffffffff]
Jun 06 02:03:04 localhost kernel: [mem 0x99c10000-0xfdffffff] available for PCI devices
Jun 06 02:03:04 localhost kernel: Booting paravirtualized kernel on bare hardware
Jun 06 02:03:04 localhost kernel: clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns
Jun 06 02:03:04 localhost kernel: setup_percpu: NR_CPUS:8192 nr_cpumask_bits:64 nr_cpu_ids:64 nr_node_ids:1
Jun 06 02:03:04 localhost kernel: percpu: Embedded 55 pages/cpu s188416 r8192 d28672 u262144
Jun 06 02:03:04 localhost kernel: pcpu-alloc: s188416 r8192 d28672 u262144 alloc=1*2097152
Jun 06 02:03:04 localhost kernel: pcpu-alloc: [0] 00 01 02 03 04 05 06 07 [0] 08 09 10 11 12 13 14 15 
Jun 06 02:03:04 localhost kernel: pcpu-alloc: [0] 16 17 18 19 20 21 22 23 [0] 24 25 26 27 28 29 30 31 
Jun 06 02:03:04 localhost kernel: pcpu-alloc: [0] 32 33 34 35 36 37 38 39 [0] 40 41 42 43 44 45 46 47 
Jun 06 02:03:04 localhost kernel: pcpu-alloc: [0] 48 49 50 51 52 53 54 55 [0] 56 57 58 59 60 61 62 63 
Jun 06 02:03:04 localhost kernel: Fallback order for Node 0: 0 
Jun 06 02:03:04 localhost kernel: Built 1 zonelists, mobility grouping on.  Total pages: 32951644
Jun 06 02:03:04 localhost kernel: Policy zone: Normal
Jun 06 02:03:04 localhost kernel: Kernel command line: BOOT_IMAGE=/images/pxeboot/vmlinuz coreos.liveiso=rhcos-413.92.202305021736-0 ignition.firstboot ignition.platform.id=metal
Jun 06 02:03:04 localhost kernel: Unknown kernel command line parameters "BOOT_IMAGE=/images/pxeboot/vmlinuz", will be passed to user space.
Jun 06 02:03:04 localhost kernel: Dentry cache hash table entries: 8388608 (order: 14, 67108864 bytes, linear)
Jun 06 02:03:04 localhost kernel: Inode-cache hash table entries: 4194304 (order: 13, 33554432 bytes, linear)
Jun 06 02:03:04 localhost kernel: mem auto-init: stack:off, heap alloc:off, heap free:off
Jun 06 02:03:04 localhost kernel: software IO TLB: area num 64.
Jun 06 02:03:04 localhost kernel: Memory: 1333464K/133899380K available (14342K kernel code, 5536K rwdata, 10180K rodata, 2792K init, 7524K bss, 2834016K reserved, 0K cma-reserved)
Jun 06 02:03:04 localhost kernel: random: get_random_u64 called from kmem_cache_open+0x1e/0x210 with crng_init=0
Jun 06 02:03:04 localhost kernel: SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=64, Nodes=1
Jun 06 02:03:04 localhost kernel: ftrace: allocating 44805 entries in 176 pages
Jun 06 02:03:04 localhost kernel: ftrace: allocated 176 pages with 3 groups
Jun 06 02:03:04 localhost kernel: Dynamic Preempt: voluntary
Jun 06 02:03:04 localhost kernel: rcu: Preemptible hierarchical RCU implementation.
Jun 06 02:03:04 localhost kernel: rcu:         RCU restricting CPUs from NR_CPUS=8192 to nr_cpu_ids=64.
Jun 06 02:03:04 localhost kernel:         Trampoline variant of Tasks RCU enabled.
Jun 06 02:03:04 localhost kernel:         Rude variant of Tasks RCU enabled.
Jun 06 02:03:04 localhost kernel:         Tracing variant of Tasks RCU enabled.
Jun 06 02:03:04 localhost kernel: rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies.
Jun 06 02:03:04 localhost kernel: rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=64
Jun 06 02:03:04 localhost kernel: NR_IRQS: 524544, nr_irqs: 2568, preallocated irqs: 16
Jun 06 02:03:04 localhost kernel: rcu: srcu_init: Setting srcu_struct sizes based on contention.
Jun 06 02:03:04 localhost kernel: kfence: initialized - using 2097152 bytes for 255 objects at 0x(____ptrval____)-0x(____ptrval____)
Jun 06 02:03:04 localhost kernel: random: crng init done (trusting CPU's manufacturer)
Jun 06 02:03:04 localhost kernel: Console: colour dummy device 80x25
Jun 06 02:03:04 localhost kernel: printk: console [tty0] enabled
Jun 06 02:03:04 localhost kernel: ACPI: Core revision 20211217
Jun 06 02:03:04 localhost kernel: clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 79635855245 ns
Jun 06 02:03:04 localhost kernel: APIC: Switch to symmetric I/O mode setup
Jun 06 02:03:04 localhost kernel: DMAR: Host address width 46
Jun 06 02:03:04 localhost kernel: DMAR: DRHD base: 0x000000c17fc000 flags: 0x0
Jun 06 02:03:04 localhost kernel: DMAR: dmar0: reg_base_addr c17fc000 ver 4:0 cap 8ed008c40780466 ecap 60000f050df
Jun 06 02:03:04 localhost kernel: DMAR: DRHD base: 0x000000d4ffc000 flags: 0x0
Jun 06 02:03:04 localhost kernel: DMAR: dmar1: reg_base_addr d4ffc000 ver 4:0 cap 8ed008c40780466 ecap 60000f050df
Jun 06 02:03:04 localhost kernel: DMAR: DRHD base: 0x000000e87fc000 flags: 0x0
Jun 06 02:03:04 localhost kernel: DMAR: dmar2: reg_base_addr e87fc000 ver 4:0 cap 8ed008c40780466 ecap 60000f050df
Jun 06 02:03:04 localhost kernel: DMAR: DRHD base: 0x000000fb7fc000 flags: 0x0
Jun 06 02:03:04 localhost kernel: DMAR: dmar3: reg_base_addr fb7fc000 ver 4:0 cap 8ed008c40780466 ecap 60000f050df
Jun 06 02:03:04 localhost kernel: DMAR: DRHD base: 0x000000adffc000 flags: 0x1
Jun 06 02:03:04 localhost kernel: DMAR: dmar4: reg_base_addr adffc000 ver 4:0 cap 8ed008c40780466 ecap 60000f050df
Jun 06 02:03:04 localhost kernel: DMAR: RMRR base: 0x00000058483000 end: 0x00000058485fff
Jun 06 02:03:04 localhost kernel: DMAR: RMRR base: 0x000000584d3000 end: 0x000000584d3fff
Jun 06 02:03:04 localhost kernel: DMAR: ATSR flags: 0x0
Jun 06 02:03:04 localhost kernel: DMAR-IR: IOAPIC id 8 under DRHD base  0xadffc000 IOMMU 4
Jun 06 02:03:04 localhost kernel: DMAR-IR: HPET id 0 under DRHD base 0xadffc000
Jun 06 02:03:04 localhost kernel: DMAR-IR: Queued invalidation will be enabled to support x2apic and Intr-remapping.
Jun 06 02:03:04 localhost kernel: DMAR-IR: Enabled IRQ remapping in x2apic mode
Jun 06 02:03:04 localhost kernel: ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1
Jun 06 02:03:04 localhost kernel: clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1fb633008a4, max_idle_ns: 440795292230 ns
Jun 06 02:03:04 localhost kernel: Calibrating delay loop (skipped), value calculated using timer frequency.. 4400.00 BogoMIPS (lpj=2200000)
Jun 06 02:03:04 localhost kernel: pid_max: default: 65536 minimum: 512
Jun 06 02:03:04 localhost kernel: LSM: Security Framework initializing
Jun 06 02:03:04 localhost kernel: Yama: becoming mindful.
Jun 06 02:03:04 localhost kernel: SELinux:  Initializing.
Jun 06 02:03:04 localhost kernel: LSM support for eBPF active
Jun 06 02:03:04 localhost kernel: Mount-cache hash table entries: 131072 (order: 8, 1048576 bytes, linear)
Jun 06 02:03:04 localhost kernel: Mountpoint-cache hash table entries: 131072 (order: 8, 1048576 bytes, linear)
Jun 06 02:03:04 localhost kernel: x86/cpu: SGX disabled by BIOS.
Jun 06 02:03:04 localhost kernel: x86/tme: not enabled by BIOS
Jun 06 02:03:04 localhost kernel: CPU0: Thermal monitoring enabled (TM1)
Jun 06 02:03:04 localhost kernel: x86/cpu: User Mode Instruction Prevention (UMIP) activated
Jun 06 02:03:04 localhost kernel: process: using mwait in idle threads
Jun 06 02:03:04 localhost kernel: Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0
Jun 06 02:03:04 localhost kernel: Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0
Jun 06 02:03:04 localhost kernel: Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization
Jun 06 02:03:04 localhost kernel: Spectre V2 : Mitigation: Enhanced IBRS
Jun 06 02:03:04 localhost kernel: Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch
Jun 06 02:03:04 localhost kernel: Spectre V2 : Spectre v2 / PBRSB-eIBRS: Retire a single CALL on VMEXIT
Jun 06 02:03:04 localhost kernel: Spectre V2 : mitigation: Enabling conditional Indirect Branch Prediction Barrier
Jun 06 02:03:04 localhost kernel: Speculative Store Bypass: Mitigation: Speculative Store Bypass disabled via prctl
Jun 06 02:03:04 localhost kernel: MMIO Stale Data: Mitigation: Clear CPU buffers
Jun 06 02:03:04 localhost kernel: Freeing SMP alternatives memory: 36K
Jun 06 02:03:04 localhost kernel: smpboot: Estimated ratio of average max frequency by base frequency (times 1024): 1349
Jun 06 02:03:04 localhost kernel: smpboot: CPU0: Intel(R) Xeon(R) Gold 6338N CPU @ 2.20GHz (family: 0x6, model: 0x6a, stepping: 0x6)
Jun 06 02:03:04 localhost kernel: cblist_init_generic: Setting adjustable number of callback queues.
Jun 06 02:03:04 localhost kernel: cblist_init_generic: Setting shift to 6 and lim to 1.
Jun 06 02:03:04 localhost kernel: cblist_init_generic: Setting shift to 6 and lim to 1.
Jun 06 02:03:04 localhost kernel: cblist_init_generic: Setting shift to 6 and lim to 1.
Jun 06 02:03:04 localhost kernel: Performance Events: PEBS fmt4+-baseline,  AnyThread deprecated, Icelake events, 32-deep LBR, full-width counters, Intel PMU driver.
Jun 06 02:03:04 localhost kernel: ... version:                5
Jun 06 02:03:04 localhost kernel: ... bit width:              48
Jun 06 02:03:04 localhost kernel: ... generic registers:      8
Jun 06 02:03:04 localhost kernel: ... value mask:             0000ffffffffffff
Jun 06 02:03:04 localhost kernel: ... max period:             00007fffffffffff
Jun 06 02:03:04 localhost kernel: ... fixed-purpose events:   4
Jun 06 02:03:04 localhost kernel: ... event mask:             0001000f000000ff
Jun 06 02:03:04 localhost kernel: rcu: Hierarchical SRCU implementation.
Jun 06 02:03:04 localhost kernel: rcu:         Max phase no-delay instances is 400.
Jun 06 02:03:04 localhost kernel: NMI watchdog: Enabled. Permanently consumes one hw-PMU counter.
Jun 06 02:03:04 localhost kernel: smp: Bringing up secondary CPUs ...
Jun 06 02:03:04 localhost kernel: x86: Booting SMP configuration:
Jun 06 02:03:04 localhost kernel: .... node  #0, CPUs:        #1  #2  #3  #4  #5  #6  #7  #8  #9 #10 #11 #12 #13 #14 #15 #16 #17 #18 #19 #20 #21 #22 #23 #24 #25 #26 #27 #28 #29 #30 #31 #32
Jun 06 02:03:04 localhost kernel: MMIO Stale Data CPU bug present and SMT on, data leak possible. See https://www.kernel.org/doc/html/latest/admin-guide/hw-vuln/processor_mmio_stale_data.html for more details.
Jun 06 02:03:04 localhost kernel:  #33 #34 #35 #36 #37 #38 #39 #40 #41 #42 #43 #44 #45 #46 #47 #48 #49 #50 #51 #52 #53 #54 #55 #56 #57 #58 #59 #60 #61 #62 #63
Jun 06 02:03:04 localhost kernel: smp: Brought up 1 node, 64 CPUs
Jun 06 02:03:04 localhost kernel: smpboot: Max logical packages: 1
Jun 06 02:03:04 localhost kernel: smpboot: Total of 64 processors activated (281600.00 BogoMIPS)
Jun 06 02:03:04 localhost kernel: node 0 deferred pages initialised in 46ms
Jun 06 02:03:04 localhost kernel: devtmpfs: initialized
Jun 06 02:03:04 localhost kernel: x86/mm: Memory block size: 2048MB
Jun 06 02:03:04 localhost kernel: ACPI: PM: Registering ACPI NVS region [mem 0x584fe000-0x595fdfff] (17825792 bytes)
Jun 06 02:03:04 localhost kernel: clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns
Jun 06 02:03:04 localhost kernel: futex hash table entries: 16384 (order: 8, 1048576 bytes, linear)
Jun 06 02:03:04 localhost kernel: pinctrl core: initialized pinctrl subsystem
Jun 06 02:03:04 localhost kernel: NET: Registered PF_NETLINK/PF_ROUTE protocol family
Jun 06 02:03:04 localhost kernel: DMA: preallocated 4096 KiB GFP_KERNEL pool for atomic allocations
Jun 06 02:03:04 localhost kernel: DMA: preallocated 4096 KiB GFP_KERNEL|GFP_DMA pool for atomic allocations
Jun 06 02:03:04 localhost kernel: DMA: preallocated 4096 KiB GFP_KERNEL|GFP_DMA32 pool for atomic allocations
Jun 06 02:03:04 localhost kernel: audit: initializing netlink subsys (disabled)
Jun 06 02:03:04 localhost kernel: audit: type=2000 audit(1686016980.716:1): state=initialized audit_enabled=0 res=1
Jun 06 02:03:04 localhost kernel: thermal_sys: Registered thermal governor 'fair_share'
Jun 06 02:03:04 localhost kernel: thermal_sys: Registered thermal governor 'step_wise'
Jun 06 02:03:04 localhost kernel: thermal_sys: Registered thermal governor 'user_space'
Jun 06 02:03:04 localhost kernel: cpuidle: using governor menu
Jun 06 02:03:04 localhost kernel: Invalid PCCT: 0 PCC subspaces
Jun 06 02:03:04 localhost kernel: HugeTLB: can optimize 4095 vmemmap pages for hugepages-1048576kB
Jun 06 02:03:04 localhost kernel: ACPI FADT declares the system doesn't support PCIe ASPM, so disable it
Jun 06 02:03:04 localhost kernel: acpiphp: ACPI Hot Plug PCI Controller Driver version: 0.5
Jun 06 02:03:04 localhost kernel: PCI: MMCONFIG for domain 0000 [bus 00-ff] at [mem 0x80000000-0x8fffffff] (base 0x80000000)
Jun 06 02:03:04 localhost kernel: PCI: MMCONFIG at [mem 0x80000000-0x8fffffff] reserved in E820
Jun 06 02:03:04 localhost kernel: PCI: Using configuration type 1 for base access
Jun 06 02:03:04 localhost kernel: ENERGY_PERF_BIAS: Set to 'normal', was 'performance'
Jun 06 02:03:04 localhost kernel: kprobes: kprobe jump-optimization is enabled. All kprobes are optimized if possible.
Jun 06 02:03:04 localhost kernel: HugeTLB: can optimize 7 vmemmap pages for hugepages-2048kB
Jun 06 02:03:04 localhost kernel: HugeTLB registered 1.00 GiB page size, pre-allocated 0 pages
Jun 06 02:03:04 localhost kernel: HugeTLB registered 2.00 MiB page size, pre-allocated 0 pages
Jun 06 02:03:04 localhost kernel: cryptd: max_cpu_qlen set to 1000
Jun 06 02:03:04 localhost kernel: ACPI: Added _OSI(Module Device)
Jun 06 02:03:04 localhost kernel: ACPI: Added _OSI(Processor Device)
Jun 06 02:03:04 localhost kernel: ACPI: Added _OSI(3.0 _SCP Extensions)
Jun 06 02:03:04 localhost kernel: ACPI: Added _OSI(Processor Aggregator Device)
Jun 06 02:03:04 localhost kernel: ACPI: Added _OSI(Linux-Dell-Video)
Jun 06 02:03:04 localhost kernel: ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio)
Jun 06 02:03:04 localhost kernel: ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics)
Jun 06 02:03:04 localhost kernel: ACPI: 8 ACPI AML tables successfully acquired and loaded
Jun 06 02:03:04 localhost kernel: ACPI: Dynamic OEM Table Load:
Jun 06 02:03:04 localhost kernel: ACPI: Interpreter enabled
Jun 06 02:03:04 localhost kernel: ACPI: PM: (supports S0 S5)
Jun 06 02:03:04 localhost kernel: ACPI: Using IOAPIC for interrupt routing
Jun 06 02:03:04 localhost kernel: HEST: Table parsing has been initialized.
Jun 06 02:03:04 localhost kernel: PCI: Using host bridge windows from ACPI; if necessary, use "pci=nocrs" and report a bug
Jun 06 02:03:04 localhost kernel: PCI: Using E820 reservations for host bridge windows
Jun 06 02:03:04 localhost kernel: ACPI: Enabled 3 GPEs in block 00 to 7F
Jun 06 02:03:04 localhost kernel: ACPI: PCI Root Bridge [UNC0] (domain 0000 [bus fe])
Jun 06 02:03:04 localhost kernel: acpi PNP0A03:00: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI EDR HPX-Type3]
Jun 06 02:03:04 localhost kernel: PCI host bridge to bus 0000:fe
Jun 06 02:03:04 localhost kernel: pci_bus 0000:fe: root bus resource [bus fe]
Jun 06 02:03:04 localhost kernel: pci 0000:fe:00.0: [8086:3450] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:00.1: [8086:3451] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:00.2: [8086:3452] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:00.3: [8086:0998] type 00 class 0x060000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:00.5: [8086:3455] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:02.0: [8086:3440] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:02.1: [8086:3441] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:02.2: [8086:3442] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:03.0: [8086:3440] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:03.1: [8086:3441] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:03.2: [8086:3442] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:04.0: [8086:3440] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:04.1: [8086:3441] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:04.2: [8086:3442] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:04.3: [8086:3443] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:05.0: [8086:3445] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:05.1: [8086:3446] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:05.2: [8086:3447] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:06.0: [8086:3445] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:06.1: [8086:3446] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:06.2: [8086:3447] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:07.0: [8086:3445] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:07.1: [8086:3446] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:07.2: [8086:3447] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:0b.0: [8086:3448] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:0b.1: [8086:3448] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:0b.2: [8086:344b] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:fe:0c.0: [8086:344a] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci 0000:fe:0d.0: [8086:344a] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci 0000:fe:0e.0: [8086:344a] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci 0000:fe:0f.0: [8086:344a] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci 0000:fe:1a.0: [8086:2880] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci 0000:fe:1b.0: [8086:2880] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci 0000:fe:1c.0: [8086:2880] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci 0000:fe:1d.0: [8086:2880] type 00 class 0x110100
Jun 06 02:03:04 localhost kernel: pci_bus 0000:fe: on NUMA node 0
Jun 06 02:03:04 localhost kernel: ACPI: PCI Root Bridge [UNC1] (domain 0000 [bus ff])
Jun 06 02:03:04 localhost kernel: acpi PNP0A03:01: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI EDR HPX-Type3]
Jun 06 02:03:04 localhost kernel: PCI host bridge to bus 0000:ff
Jun 06 02:03:04 localhost kernel: pci_bus 0000:ff: root bus resource [bus ff]
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.0: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.1: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.2: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.3: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.4: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.5: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.6: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:00.7: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.0: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.1: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.2: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.3: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.4: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.5: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.6: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:01.7: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.0: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.1: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.2: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.3: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.4: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.5: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.6: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:02.7: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.0: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.1: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.2: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.3: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.4: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.5: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.6: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:03.7: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.0: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.1: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.2: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.3: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.4: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.5: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.6: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:04.7: [8086:344c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.0: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.1: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.2: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.3: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.4: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.5: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.6: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0a.7: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.0: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.1: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.2: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.3: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.4: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.5: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.6: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0b.7: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.0: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.1: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.2: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.3: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.4: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.5: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.6: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0c.7: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.0: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.1: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.2: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.3: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.4: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.5: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.6: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0d.7: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.0: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.1: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.2: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.3: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.4: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.5: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.6: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:0e.7: [8086:344d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1d.0: [8086:344f] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1d.1: [8086:3457] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.0: [8086:3458] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.1: [8086:3459] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.2: [8086:345a] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.3: [8086:345b] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.4: [8086:345c] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.5: [8086:345d] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.6: [8086:345e] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:ff:1e.7: [8086:345f] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci_bus 0000:ff: on NUMA node 0
Jun 06 02:03:04 localhost kernel: ACPI: PCI Root Bridge [PC00] (domain 0000 [bus 00-0e])
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:00: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI EDR HPX-Type3]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:00: _OSC: platform does not support [SHPCHotplug AER LTR DPC]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:00: _OSC: OS now controls [PCIeHotplug PME PCIeCapability]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:00: FADT indicates ASPM is unsupported, using BIOS configuration
Jun 06 02:03:04 localhost kernel: PCI host bridge to bus 0000:00
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [io  0x0000-0x03af window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [io  0x03e0-0x0cf7 window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [io  0x03b0-0x03bb window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [io  0x03c0-0x03df window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [io  0x1000-0x4fff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [mem 0x90000000-0xadffbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [mem 0x200000000000-0x20ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: root bus resource [bus 00-0e]
Jun 06 02:03:04 localhost kernel: pci 0000:00:00.0: [8086:09a2] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:00.1: [8086:09a4] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:00.2: [8086:09a3] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:00.4: [8086:0998] type 00 class 0x060000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.0: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.0: reg 0x10: [mem 0x20fffff40000-0x20fffff43fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.1: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.1: reg 0x10: [mem 0x20fffff3c000-0x20fffff3ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.2: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.2: reg 0x10: [mem 0x20fffff38000-0x20fffff3bfff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.3: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.3: reg 0x10: [mem 0x20fffff34000-0x20fffff37fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.4: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.4: reg 0x10: [mem 0x20fffff30000-0x20fffff33fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.5: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.5: reg 0x10: [mem 0x20fffff2c000-0x20fffff2ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.6: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.6: reg 0x10: [mem 0x20fffff28000-0x20fffff2bfff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.7: [8086:0b00] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:01.7: reg 0x10: [mem 0x20fffff24000-0x20fffff27fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.0: [8086:09a6] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.0: reg 0x10: [mem 0x9a194000-0x9a195fff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.1: [8086:09a7] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.1: reg 0x10: [mem 0x9a100000-0x9a17ffff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.1: reg 0x14: [mem 0x9a080000-0x9a0fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.4: [8086:3456] type 00 class 0x130000
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.4: reg 0x10: [mem 0x20ffffe00000-0x20ffffefffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.4: reg 0x18: [mem 0x20fffff20000-0x20fffff23fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:02.4: reg 0x20: [mem 0x20fffff00000-0x20fffff1ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:11.0: [8086:a1ec] type 00 class 0xff0000
Jun 06 02:03:04 localhost kernel: pci 0000:00:14.0: [8086:a1af] type 00 class 0x0c0330
Jun 06 02:03:04 localhost kernel: pci 0000:00:14.0: reg 0x10: [mem 0x9a180000-0x9a18ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:14.0: PME# supported from D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:00:14.2: [8086:a1b1] type 00 class 0x118000
Jun 06 02:03:04 localhost kernel: pci 0000:00:14.2: reg 0x10: [mem 0x20fffff47000-0x20fffff47fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.0: [8086:a190] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4: [8086:a194] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5: [8086:a195] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:00:1f.0: [8086:a1cb] type 00 class 0x060100
Jun 06 02:03:04 localhost kernel: pci 0000:00:1f.2: [8086:a1a1] type 00 class 0x058000
Jun 06 02:03:04 localhost kernel: pci 0000:00:1f.2: reg 0x10: [mem 0x9a190000-0x9a193fff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.0: PCI bridge to [bus 02]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.0: [103c:3306] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.0: reg 0x10: [io  0x1200-0x12ff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.0: reg 0x14: [mem 0x99b9e000-0x99b9e3ff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.0: reg 0x18: [io  0x1100-0x11ff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.0: reg 0x1c: [mem 0x94000000-0x97ffffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.0: reg 0x20: [mem 0x99800000-0x999fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: [102b:0538] type 00 class 0x030000
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: reg 0x10: [mem 0x98000000-0x98ffffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: reg 0x14: [mem 0x99b98000-0x99b9bfff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: reg 0x18: [mem 0x99000000-0x997fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: BAR 0: assigned to efifb
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: [103c:3307] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: reg 0x10: [io  0x1000-0x10ff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: reg 0x14: [mem 0x99b9d000-0x99b9d0ff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: reg 0x18: [mem 0x99a00000-0x99afffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: reg 0x1c: [mem 0x99b00000-0x99b7ffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: reg 0x20: [mem 0x99b90000-0x99b97fff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: reg 0x24: [mem 0x99b80000-0x99b8ffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: reg 0x30: [mem 0x00000000-0x0003ffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.4: [103c:22f6] type 00 class 0x0c0320
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.4: reg 0x10: [mem 0x99b9c000-0x99b9c0ff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4: PCI bridge to [bus 01]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4:   bridge window [io  0x1000-0x1fff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4:   bridge window [mem 0x90000000-0x99bfffff]
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: working around ROM BAR overlap defect
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: [8086:1537] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: reg 0x10: [mem 0x99d00000-0x99dfffff]
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: reg 0x18: [io  0x2000-0x201f]
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: reg 0x1c: [mem 0x99e00000-0x99e03fff]
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5: PCI bridge to [bus 03]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5:   bridge window [io  0x2000-0x2fff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5:   bridge window [mem 0x99d00000-0x99efffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: on NUMA node 0
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKA configured for IRQ 11
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKB configured for IRQ 10
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKC configured for IRQ 11
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKD configured for IRQ 11
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKE configured for IRQ 11
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKF configured for IRQ 11
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKG configured for IRQ 11
Jun 06 02:03:04 localhost kernel: ACPI: PCI: Interrupt link LNKH configured for IRQ 11
Jun 06 02:03:04 localhost kernel: ACPI: PCI Root Bridge [PC01] (domain 0000 [bus 0f-49])
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:01: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI EDR HPX-Type3]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:01: _OSC: platform does not support [SHPCHotplug AER LTR DPC]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:01: _OSC: OS now controls [PCIeHotplug PME PCIeCapability]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:01: FADT indicates ASPM is unsupported, using BIOS configuration
Jun 06 02:03:04 localhost kernel: PCI host bridge to bus 0000:0f
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: root bus resource [io  0x5000-0x7fff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: root bus resource [mem 0xae000000-0xc17fbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: root bus resource [mem 0x210000000000-0x21ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: root bus resource [bus 0f-49]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:00.0: [8086:09a2] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:0f:00.1: [8086:09a4] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:0f:00.2: [8086:09a3] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:0f:00.4: [8086:0998] type 00 class 0x060000
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0: [8086:347a] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0: reg 0x10: [mem 0x21fffe520000-0x21fffe53ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0: [8086:347c] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0: reg 0x10: [mem 0x21fffe500000-0x21fffe51ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: reg 0x10: [mem 0x21ffee000000-0x21ffefffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: reg 0x1c: [mem 0x21fff2030000-0x21fff203ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: reg 0x184: [mem 0x21fff1800000-0x21fff181ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: VF(n) BAR0 space: [mem 0x21fff1800000-0x21fff1ffffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: reg 0x190: [mem 0x21fff2340000-0x21fff2343fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: VF(n) BAR3 space: [mem 0x21fff2340000-0x21fff243ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:02.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: reg 0x10: [mem 0x21ffec000000-0x21ffedffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: reg 0x1c: [mem 0x21fff2020000-0x21fff202ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: reg 0x184: [mem 0x21fff1000000-0x21fff101ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: VF(n) BAR0 space: [mem 0x21fff1000000-0x21fff17fffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: reg 0x190: [mem 0x21fff2240000-0x21fff2243fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: VF(n) BAR3 space: [mem 0x21fff2240000-0x21fff233ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: reg 0x10: [mem 0x21ffea000000-0x21ffebffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: reg 0x1c: [mem 0x21fff2010000-0x21fff201ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: reg 0x184: [mem 0x21fff0800000-0x21fff081ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: VF(n) BAR0 space: [mem 0x21fff0800000-0x21fff0ffffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: reg 0x190: [mem 0x21fff2140000-0x21fff2143fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: VF(n) BAR3 space: [mem 0x21fff2140000-0x21fff223ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: reg 0x10: [mem 0x21ffe8000000-0x21ffe9ffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: reg 0x1c: [mem 0x21fff2000000-0x21fff200ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: reg 0x184: [mem 0x21fff0000000-0x21fff001ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: VF(n) BAR0 space: [mem 0x21fff0000000-0x21fff07fffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: reg 0x190: [mem 0x21fff2040000-0x21fff2043fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: VF(n) BAR3 space: [mem 0x21fff2040000-0x21fff213ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0: PCI bridge to [bus 10-11]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0:   bridge window [mem 0x21ffe8000000-0x21fff24fffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: reg 0x10: [mem 0x21fffa000000-0x21fffbffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: reg 0x1c: [mem 0x21fffe030000-0x21fffe03ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: reg 0x184: [mem 0x21fffd800000-0x21fffd81ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: VF(n) BAR0 space: [mem 0x21fffd800000-0x21fffdffffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: reg 0x190: [mem 0x21fffe340000-0x21fffe343fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: VF(n) BAR3 space: [mem 0x21fffe340000-0x21fffe43ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:04.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: reg 0x10: [mem 0x21fff8000000-0x21fff9ffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: reg 0x1c: [mem 0x21fffe020000-0x21fffe02ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: reg 0x184: [mem 0x21fffd000000-0x21fffd01ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: VF(n) BAR0 space: [mem 0x21fffd000000-0x21fffd7fffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: reg 0x190: [mem 0x21fffe240000-0x21fffe243fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: VF(n) BAR3 space: [mem 0x21fffe240000-0x21fffe33ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: reg 0x10: [mem 0x21fff6000000-0x21fff7ffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: reg 0x1c: [mem 0x21fffe010000-0x21fffe01ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: reg 0x184: [mem 0x21fffc800000-0x21fffc81ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: VF(n) BAR0 space: [mem 0x21fffc800000-0x21fffcffffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: reg 0x190: [mem 0x21fffe140000-0x21fffe143fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: VF(n) BAR3 space: [mem 0x21fffe140000-0x21fffe23ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: [8086:1593] type 00 class 0x020000
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: reg 0x10: [mem 0x21fff4000000-0x21fff5ffffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: reg 0x1c: [mem 0x21fffe000000-0x21fffe00ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: reg 0x30: [mem 0x00000000-0x000fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: reg 0x184: [mem 0x21fffc000000-0x21fffc01ffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: VF(n) BAR0 space: [mem 0x21fffc000000-0x21fffc7fffff 64bit pref] (contains BAR0 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: reg 0x190: [mem 0x21fffe040000-0x21fffe043fff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: VF(n) BAR3 space: [mem 0x21fffe040000-0x21fffe13ffff 64bit pref] (contains BAR3 for 64 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0: PCI bridge to [bus 12-13]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0:   bridge window [mem 0x21fff4000000-0x21fffe4fffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: on NUMA node 0
Jun 06 02:03:04 localhost kernel: ACPI: PCI Root Bridge [PC02] (domain 0000 [bus 4a-84])
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:02: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI EDR HPX-Type3]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:02: _OSC: platform does not support [SHPCHotplug AER LTR DPC]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:02: _OSC: OS now controls [PCIeHotplug PME PCIeCapability]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:02: FADT indicates ASPM is unsupported, using BIOS configuration
Jun 06 02:03:04 localhost kernel: PCI host bridge to bus 0000:4a
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: root bus resource [io  0x8000-0xafff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: root bus resource [mem 0xc1800000-0xd4ffbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: root bus resource [mem 0x220000000000-0x22ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: root bus resource [bus 4a-84]
Jun 06 02:03:04 localhost kernel: pci 0000:4a:00.0: [8086:09a2] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:4a:00.1: [8086:09a4] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:4a:00.2: [8086:09a3] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:4a:00.4: [8086:0998] type 00 class 0x060000
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0: [8086:347a] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0: reg 0x10: [mem 0x22fffff00000-0x22fffff1ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0: enabling Extended Tags
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:4b:00.0: [8086:0d5c] type 00 class 0x120001
Jun 06 02:03:04 localhost kernel: pci 0000:4b:00.0: reg 0x10: [mem 0xc2000000-0xc2ffffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:4b:00.0: PME# supported from D0 D3hot
Jun 06 02:03:04 localhost kernel: pci 0000:4b:00.0: reg 0x2c4: [mem 0xc3000000-0xc3000fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:4b:00.0: VF(n) BAR0 space: [mem 0xc3000000-0xc300ffff 64bit] (contains BAR0 for 16 VFs)
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0: PCI bridge to [bus 4b-4d]
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0:   bridge window [mem 0xc2000000-0xc30fffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: on NUMA node 0
Jun 06 02:03:04 localhost kernel: ACPI: PCI Root Bridge [PC04] (domain 0000 [bus 85-bf])
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:03: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI EDR HPX-Type3]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:03: _OSC: platform does not support [SHPCHotplug AER LTR DPC]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:03: _OSC: OS now controls [PCIeHotplug PME PCIeCapability]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:03: FADT indicates ASPM is unsupported, using BIOS configuration
Jun 06 02:03:04 localhost kernel: PCI host bridge to bus 0000:85
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: root bus resource [io  0xb000-0xdfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: root bus resource [mem 0xd5000000-0xe87fbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: root bus resource [mem 0x230000000000-0x23ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: root bus resource [bus 85-bf]
Jun 06 02:03:04 localhost kernel: pci 0000:85:00.0: [8086:09a2] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:85:00.1: [8086:09a4] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:85:00.2: [8086:09a3] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:85:00.4: [8086:0998] type 00 class 0x060000
Jun 06 02:03:04 localhost kernel: pci 0000:85:02.0: [8086:347a] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:85:02.0: reg 0x10: [mem 0x23fffff00000-0x23fffff1ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:85:02.0: enabling Extended Tags
Jun 06 02:03:04 localhost kernel: pci 0000:85:02.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:85:02.0: PCI bridge to [bus 86]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: on NUMA node 0
Jun 06 02:03:04 localhost kernel: ACPI: PCI Root Bridge [PC05] (domain 0000 [bus c0-fa])
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:04: _OSC: OS supports [ExtendedConfig ASPM ClockPM Segments MSI EDR HPX-Type3]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:04: _OSC: platform does not support [SHPCHotplug AER LTR DPC]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:04: _OSC: OS now controls [PCIeHotplug PME PCIeCapability]
Jun 06 02:03:04 localhost kernel: acpi PNP0A08:04: FADT indicates ASPM is unsupported, using BIOS configuration
Jun 06 02:03:04 localhost kernel: PCI host bridge to bus 0000:c0
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: root bus resource [io  0xe000-0xffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: root bus resource [mem 0xe8800000-0xfb7fbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: root bus resource [mem 0x240000000000-0x24ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: root bus resource [bus c0-fa]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:00.0: [8086:09a2] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:c0:00.1: [8086:09a4] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:c0:00.2: [8086:09a3] type 00 class 0x088000
Jun 06 02:03:04 localhost kernel: pci 0000:c0:00.4: [8086:0998] type 00 class 0x060000
Jun 06 02:03:04 localhost kernel: pci 0000:c0:02.0: [8086:347a] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:c0:02.0: reg 0x10: [mem 0x24fffff60000-0x24fffff7ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:02.0: enabling Extended Tags
Jun 06 02:03:04 localhost kernel: pci 0000:c0:02.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0: [8086:347b] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0: reg 0x10: [mem 0x24fffff40000-0x24fffff5ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0: enabling Extended Tags
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0: [8086:347c] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0: reg 0x10: [mem 0x24fffff20000-0x24fffff3ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0: enabling Extended Tags
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:c0:05.0: [8086:347d] type 01 class 0x060400
Jun 06 02:03:04 localhost kernel: pci 0000:c0:05.0: reg 0x10: [mem 0x24fffff00000-0x24fffff1ffff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:05.0: enabling Extended Tags
Jun 06 02:03:04 localhost kernel: pci 0000:c0:05.0: PME# supported from D0 D3hot D3cold
Jun 06 02:03:04 localhost kernel: pci 0000:c0:02.0: PCI bridge to [bus c1]
Jun 06 02:03:04 localhost kernel: pci 0000:c2:00.0: [144d:a808] type 00 class 0x010802
Jun 06 02:03:04 localhost kernel: pci 0000:c2:00.0: reg 0x10: [mem 0xe8900000-0xe8903fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:c2:00.0: reg 0x30: [mem 0x00000000-0x0000ffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:c2:00.0: 15.752 Gb/s available PCIe bandwidth, limited by 8.0 GT/s PCIe x2 link at 0000:c0:03.0 (capable of 31.504 Gb/s with 8.0 GT/s PCIe x4 link)
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0: PCI bridge to [bus c2]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0:   bridge window [mem 0xe8900000-0xe89fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:c3:00.0: [144d:a808] type 00 class 0x010802
Jun 06 02:03:04 localhost kernel: pci 0000:c3:00.0: reg 0x10: [mem 0xe8800000-0xe8803fff 64bit]
Jun 06 02:03:04 localhost kernel: pci 0000:c3:00.0: reg 0x30: [mem 0x00000000-0x0000ffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:c3:00.0: 15.752 Gb/s available PCIe bandwidth, limited by 8.0 GT/s PCIe x2 link at 0000:c0:04.0 (capable of 31.504 Gb/s with 8.0 GT/s PCIe x4 link)
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0: PCI bridge to [bus c3]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0:   bridge window [mem 0xe8800000-0xe88fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:05.0: PCI bridge to [bus c4]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: on NUMA node 0
Jun 06 02:03:04 localhost kernel: iommu: Default domain type: Translated 
Jun 06 02:03:04 localhost kernel: iommu: DMA domain TLB invalidation policy: lazy mode 
Jun 06 02:03:04 localhost kernel: SCSI subsystem initialized
Jun 06 02:03:04 localhost kernel: ACPI: bus type USB registered
Jun 06 02:03:04 localhost kernel: usbcore: registered new interface driver usbfs
Jun 06 02:03:04 localhost kernel: usbcore: registered new interface driver hub
Jun 06 02:03:04 localhost kernel: usbcore: registered new device driver usb
Jun 06 02:03:04 localhost kernel: pps_core: LinuxPPS API ver. 1 registered
Jun 06 02:03:04 localhost kernel: pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it>
Jun 06 02:03:04 localhost kernel: PTP clock support registered
Jun 06 02:03:04 localhost kernel: EDAC MC: Ver: 3.0.0
Jun 06 02:03:04 localhost kernel: Registered efivars operations
Jun 06 02:03:04 localhost kernel: NetLabel: Initializing
Jun 06 02:03:04 localhost kernel: NetLabel:  domain hash size = 128
Jun 06 02:03:04 localhost kernel: NetLabel:  protocols = UNLABELED CIPSOv4 CALIPSO
Jun 06 02:03:04 localhost kernel: NetLabel:  unlabeled traffic allowed by default
Jun 06 02:03:04 localhost kernel: PCI: Using ACPI for IRQ routing
Jun 06 02:03:04 localhost kernel: PCI: pci_cache_line_size set to 64 bytes
Jun 06 02:03:04 localhost kernel: Expanded resource Reserved due to conflict with PCI Bus 0000:01
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x0009f000-0x0009ffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x3ec19018-0x3fffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x3ec20018-0x3fffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x3ec27018-0x3fffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x3ec5b018-0x3fffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x3ecc5000-0x3fffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x5046c018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x504a0018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x504d4018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x50508018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x5053c018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x50570018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x505a4018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x505da018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x505e6018-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x53c6c000-0x53ffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x58482000-0x5bffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x59836000-0x5bffffff]
Jun 06 02:03:04 localhost kernel: e820: reserve RAM buffer [mem 0x6f800000-0x6fffffff]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: vgaarb: setting as boot VGA device
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: vgaarb: bridge control possible
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.1: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none
Jun 06 02:03:04 localhost kernel: vgaarb: loaded
Jun 06 02:03:04 localhost kernel: hpet0: at MMIO 0xfed00000, IRQs 2, 8, 0, 0, 0, 0, 0, 0
Jun 06 02:03:04 localhost kernel: hpet0: 8 comparators, 64-bit 24.000000 MHz counter
Jun 06 02:03:04 localhost kernel: clocksource: Switched to clocksource tsc-early
Jun 06 02:03:04 localhost kernel: VFS: Disk quotas dquot_6.6.0
Jun 06 02:03:04 localhost kernel: VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)
Jun 06 02:03:04 localhost kernel: pnp: PnP ACPI init
Jun 06 02:03:04 localhost kernel: system 00:01: [io  0x0500-0x053f] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [io  0x0400-0x047f] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [io  0x0540-0x057f] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [io  0x0600-0x061f] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [io  0x0880-0x0883] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [io  0x0800-0x081f] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [mem 0xfed1c000-0xfed3ffff] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [mem 0xfed45000-0xfed8bfff] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [mem 0xff000000-0xffffffff] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [mem 0xfee00000-0xfeefffff] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [mem 0xfed12000-0xfed1200f] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [mem 0xfed12010-0xfed1201f] has been reserved
Jun 06 02:03:04 localhost kernel: system 00:01: [mem 0xfed1b000-0xfed1bfff] has been reserved
Jun 06 02:03:04 localhost kernel: pnp: PnP ACPI: found 3 devices
Jun 06 02:03:04 localhost kernel: clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns
Jun 06 02:03:04 localhost kernel: NET: Registered PF_INET protocol family
Jun 06 02:03:04 localhost kernel: IP idents hash table entries: 262144 (order: 9, 2097152 bytes, linear)
Jun 06 02:03:04 localhost kernel: tcp_listen_portaddr_hash hash table entries: 65536 (order: 8, 1048576 bytes, linear)
Jun 06 02:03:04 localhost kernel: Table-perturb hash table entries: 65536 (order: 6, 262144 bytes, linear)
Jun 06 02:03:04 localhost kernel: TCP established hash table entries: 524288 (order: 10, 4194304 bytes, linear)
Jun 06 02:03:04 localhost kernel: TCP bind hash table entries: 65536 (order: 8, 1048576 bytes, linear)
Jun 06 02:03:04 localhost kernel: TCP: Hash tables configured (established 524288 bind 65536)
Jun 06 02:03:04 localhost kernel: MPTCP token hash table entries: 65536 (order: 8, 1572864 bytes, linear)
Jun 06 02:03:04 localhost kernel: UDP hash table entries: 65536 (order: 9, 2097152 bytes, linear)
Jun 06 02:03:04 localhost kernel: UDP-Lite hash table entries: 65536 (order: 9, 2097152 bytes, linear)
Jun 06 02:03:04 localhost kernel: NET: Registered PF_UNIX/PF_LOCAL protocol family
Jun 06 02:03:04 localhost kernel: NET: Registered PF_XDP protocol family
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.0: PCI bridge to [bus 02]
Jun 06 02:03:04 localhost kernel: pci 0000:01:00.2: BAR 6: assigned [mem 0x90000000-0x9003ffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4: PCI bridge to [bus 01]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4:   bridge window [io  0x1000-0x1fff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.4:   bridge window [mem 0x90000000-0x99bfffff]
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: BAR 6: no space for [mem size 0x00100000 pref]
Jun 06 02:03:04 localhost kernel: pci 0000:03:00.0: BAR 6: failed to assign [mem size 0x00100000 pref]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5: PCI bridge to [bus 03]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5:   bridge window [io  0x2000-0x2fff]
Jun 06 02:03:04 localhost kernel: pci 0000:00:1c.5:   bridge window [mem 0x99d00000-0x99efffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 4 [io  0x0000-0x03af window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 5 [io  0x03e0-0x0cf7 window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 6 [io  0x03b0-0x03bb window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 7 [io  0x03c0-0x03df window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 8 [mem 0x000a0000-0x000bffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 9 [io  0x1000-0x4fff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 10 [mem 0x90000000-0xadffbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:00: resource 11 [mem 0x200000000000-0x20ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:01: resource 0 [io  0x1000-0x1fff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:01: resource 1 [mem 0x90000000-0x99bfffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:03: resource 0 [io  0x2000-0x2fff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:03: resource 1 [mem 0x99d00000-0x99efffff]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0: BAR 14: assigned [mem 0xae000000-0xae3fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0: BAR 14: assigned [mem 0xae400000-0xae7fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.0: BAR 6: assigned [mem 0xae000000-0xae0fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.1: BAR 6: assigned [mem 0xae100000-0xae1fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.2: BAR 6: assigned [mem 0xae200000-0xae2fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:10:00.3: BAR 6: assigned [mem 0xae300000-0xae3fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0: PCI bridge to [bus 10-11]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0:   bridge window [mem 0xae000000-0xae3fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:02.0:   bridge window [mem 0x21ffe8000000-0x21fff24fffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.0: BAR 6: assigned [mem 0xae400000-0xae4fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.1: BAR 6: assigned [mem 0xae500000-0xae5fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.2: BAR 6: assigned [mem 0xae600000-0xae6fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:12:00.3: BAR 6: assigned [mem 0xae700000-0xae7fffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0: PCI bridge to [bus 12-13]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0:   bridge window [mem 0xae400000-0xae7fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:0f:04.0:   bridge window [mem 0x21fff4000000-0x21fffe4fffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: resource 4 [io  0x5000-0x7fff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: resource 5 [mem 0xae000000-0xc17fbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:0f: resource 6 [mem 0x210000000000-0x21ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:10: resource 1 [mem 0xae000000-0xae3fffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:10: resource 2 [mem 0x21ffe8000000-0x21fff24fffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:12: resource 1 [mem 0xae400000-0xae7fffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:12: resource 2 [mem 0x21fff4000000-0x21fffe4fffff 64bit pref]
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0: PCI bridge to [bus 4b-4d]
Jun 06 02:03:04 localhost kernel: pci 0000:4a:02.0:   bridge window [mem 0xc2000000-0xc30fffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: resource 4 [io  0x8000-0xafff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: resource 5 [mem 0xc1800000-0xd4ffbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4a: resource 6 [mem 0x220000000000-0x22ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:4b: resource 1 [mem 0xc2000000-0xc30fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:85:02.0: PCI bridge to [bus 86]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: resource 4 [io  0xb000-0xdfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: resource 5 [mem 0xd5000000-0xe87fbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:85: resource 6 [mem 0x230000000000-0x23ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:02.0: PCI bridge to [bus c1]
Jun 06 02:03:04 localhost kernel: pci 0000:c2:00.0: BAR 6: assigned [mem 0xe8910000-0xe891ffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0: PCI bridge to [bus c2]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:03.0:   bridge window [mem 0xe8900000-0xe89fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:c3:00.0: BAR 6: assigned [mem 0xe8810000-0xe881ffff pref]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0: PCI bridge to [bus c3]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:04.0:   bridge window [mem 0xe8800000-0xe88fffff]
Jun 06 02:03:04 localhost kernel: pci 0000:c0:05.0: PCI bridge to [bus c4]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: resource 4 [io  0xe000-0xffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: resource 5 [mem 0xe8800000-0xfb7fbfff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c0: resource 6 [mem 0x240000000000-0x24ffffffffff window]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c2: resource 1 [mem 0xe8900000-0xe89fffff]
Jun 06 02:03:04 localhost kernel: pci_bus 0000:c3: resource 1 [mem 0xe8800000-0xe88fffff]
Jun 06 02:03:04 localhost kernel: PCI: CLS 64 bytes, default 64
Jun 06 02:03:04 localhost kernel: Trying to unpack rootfs image as initramfs...
Jun 06 02:03:04 localhost kernel: PCI-DMA: Using software bounce buffering for IO (SWIOTLB)
Jun 06 02:03:04 localhost kernel: software IO TLB: mapped [mem 0x000000006b800000-0x000000006f800000] (64MB)
Jun 06 02:03:04 localhost kernel: ACPI: bus type thunderbolt registered
Jun 06 02:03:04 localhost kernel: Initialise system trusted keyrings
Jun 06 02:03:04 localhost kernel: Key type blacklist registered
Jun 06 02:03:04 localhost kernel: workingset: timestamp_bits=36 max_order=25 bucket_order=0
Jun 06 02:03:04 localhost kernel: zbud: loaded
Jun 06 02:03:04 localhost kernel: integrity: Platform Keyring initialized
Jun 06 02:03:04 localhost kernel: NET: Registered PF_ALG protocol family
Jun 06 02:03:04 localhost kernel: xor: automatically using best checksumming function   avx       
Jun 06 02:03:04 localhost kernel: Key type asymmetric registered
Jun 06 02:03:04 localhost kernel: Asymmetric key parser 'x509' registered
Jun 06 02:03:04 localhost kernel: Running certificate verification selftests
Jun 06 02:03:04 localhost kernel: Loaded X.509 cert 'Certificate verification self-testing key: f58703bb33ce1b73ee02eccdee5b8817518fe3db'
Jun 06 02:03:04 localhost kernel: Block layer SCSI generic (bsg) driver version 0.4 loaded (major 246)
Jun 06 02:03:04 localhost kernel: io scheduler mq-deadline registered
Jun 06 02:03:04 localhost kernel: io scheduler kyber registered
Jun 06 02:03:04 localhost kernel: io scheduler bfq registered
Jun 06 02:03:04 localhost kernel: atomic64_test: passed for x86-64 platform with CX8 and with SSE
Jun 06 02:03:04 localhost kernel: pcieport 0000:00:1c.0: PME: Signaling with IRQ 125
Jun 06 02:03:04 localhost kernel: pcieport 0000:00:1c.4: PME: Signaling with IRQ 126
Jun 06 02:03:04 localhost kernel: pcieport 0000:00:1c.5: PME: Signaling with IRQ 127
Jun 06 02:03:04 localhost kernel: pcieport 0000:0f:02.0: PME: Signaling with IRQ 128
Jun 06 02:03:04 localhost kernel: pcieport 0000:0f:04.0: PME: Signaling with IRQ 129
Jun 06 02:03:04 localhost kernel: pcieport 0000:4a:02.0: PME: Signaling with IRQ 130
Jun 06 02:03:04 localhost kernel: pcieport 0000:85:02.0: PME: Signaling with IRQ 131
Jun 06 02:03:04 localhost kernel: pcieport 0000:c0:02.0: PME: Signaling with IRQ 132
Jun 06 02:03:04 localhost kernel: pcieport 0000:c0:03.0: PME: Signaling with IRQ 133
Jun 06 02:03:04 localhost kernel: pcieport 0000:c0:04.0: PME: Signaling with IRQ 134
Jun 06 02:03:04 localhost kernel: pcieport 0000:c0:05.0: PME: Signaling with IRQ 135
Jun 06 02:03:04 localhost kernel: shpchp: Standard Hot Plug PCI Controller Driver version: 0.4
Jun 06 02:03:04 localhost kernel: Monitor-Mwait will be used to enter C-1 state
Jun 06 02:03:04 localhost kernel: Monitor-Mwait will be used to enter C-2 state
Jun 06 02:03:04 localhost kernel: ACPI: \_SB_.SCK0.C000: Found 2 idle states
Jun 06 02:03:04 localhost kernel: input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0
Jun 06 02:03:04 localhost kernel: ACPI: button: Power Button [PWRF]
Jun 06 02:03:04 localhost kernel: smpboot: Estimated ratio of average max frequency by base frequency (times 1024): 1349
Jun 06 02:03:04 localhost kernel: acpi/hmat: HMAT: Memory Flags:0001 Processor Domain:0 Memory Domain:0
Jun 06 02:03:04 localhost kernel: acpi/hmat: HMAT: Locality: Flags:00 Type:Access Latency Initiator Domains:1 Target Domains:1 Base:100
Jun 06 02:03:04 localhost kernel: acpi/hmat:   Initiator-Target[0-0]:0 nsec
Jun 06 02:03:04 localhost kernel: acpi/hmat: HMAT: Locality: Flags:00 Type:Access Bandwidth Initiator Domains:1 Target Domains:1 Base:10
Jun 06 02:03:04 localhost kernel: acpi/hmat:   Initiator-Target[0-0]:170560 MB/s
Jun 06 02:03:04 localhost kernel: ERST: Error Record Serialization Table (ERST) support is initialized.
Jun 06 02:03:04 localhost kernel: pstore: Registered erst as persistent store backend
Jun 06 02:03:04 localhost kernel: EDAC MC0: Giving out device to module ghes_edac.c controller ghes_edac: DEV ghes (INTERRUPT)
Jun 06 02:03:04 localhost kernel: GHES: APEI firmware first mode is enabled by APEI bit and WHEA _OSC.
Jun 06 02:03:04 localhost kernel: Serial: 8250/16550 driver, 4 ports, IRQ sharing enabled
Jun 06 02:03:04 localhost kernel: 00:02: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A
Jun 06 02:03:04 localhost kernel: Non-volatile memory driver v1.3
Jun 06 02:03:04 localhost kernel: tpm_tis STM7364:00: 2.0 TPM (device-id 0x0, rev-id 78)
Jun 06 02:03:04 localhost kernel: rdac: device handler registered
Jun 06 02:03:04 localhost kernel: hp_sw: device handler registered
Jun 06 02:03:04 localhost kernel: emc: device handler registered
Jun 06 02:03:04 localhost kernel: alua: device handler registered
Jun 06 02:03:04 localhost kernel: libphy: Fixed MDIO Bus: probed
Jun 06 02:03:04 localhost kernel: ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver
Jun 06 02:03:04 localhost kernel: ehci-pci: EHCI PCI platform driver
Jun 06 02:03:04 localhost kernel: ehci-pci 0000:01:00.4: EHCI Host Controller
Jun 06 02:03:04 localhost kernel: ehci-pci 0000:01:00.4: new USB bus registered, assigned bus number 1
Jun 06 02:03:04 localhost kernel: ehci-pci 0000:01:00.4: irq 136, io mem 0x99b9c000
Jun 06 02:03:04 localhost kernel: ehci-pci 0000:01:00.4: USB 2.0 started, EHCI 1.00
Jun 06 02:03:04 localhost kernel: usb usb1: New USB device found, idVendor=1d6b, idProduct=0002, bcdDevice= 5.14
Jun 06 02:03:04 localhost kernel: usb usb1: New USB device strings: Mfr=3, Product=2, SerialNumber=1
Jun 06 02:03:04 localhost kernel: usb usb1: Product: EHCI Host Controller
Jun 06 02:03:04 localhost kernel: usb usb1: Manufacturer: Linux 5.14.0-284.13.1.el9_2.x86_64 ehci_hcd
Jun 06 02:03:04 localhost kernel: usb usb1: SerialNumber: 0000:01:00.4
Jun 06 02:03:04 localhost kernel: hub 1-0:1.0: USB hub found
Jun 06 02:03:04 localhost kernel: hub 1-0:1.0: 8 ports detected
Jun 06 02:03:04 localhost kernel: ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver
Jun 06 02:03:04 localhost kernel: ohci-pci: OHCI PCI platform driver
Jun 06 02:03:04 localhost kernel: uhci_hcd: USB Universal Host Controller Interface driver
Jun 06 02:03:04 localhost kernel: xhci_hcd 0000:00:14.0: xHCI Host Controller
Jun 06 02:03:04 localhost kernel: xhci_hcd 0000:00:14.0: new USB bus registered, assigned bus number 2
Jun 06 02:03:04 localhost kernel: xhci_hcd 0000:00:14.0: hcc params 0x200077c1 hci version 0x100 quirks 0x0000000000009810
Jun 06 02:03:04 localhost kernel: xhci_hcd 0000:00:14.0: xHCI Host Controller
Jun 06 02:03:04 localhost kernel: xhci_hcd 0000:00:14.0: new USB bus registered, assigned bus number 3
Jun 06 02:03:04 localhost kernel: xhci_hcd 0000:00:14.0: Host supports USB 3.0 SuperSpeed
Jun 06 02:03:04 localhost kernel: usb usb2: New USB device found, idVendor=1d6b, idProduct=0002, bcdDevice= 5.14
Jun 06 02:03:04 localhost kernel: usb usb2: New USB device strings: Mfr=3, Product=2, SerialNumber=1
Jun 06 02:03:04 localhost kernel: usb usb2: Product: xHCI Host Controller
Jun 06 02:03:04 localhost kernel: usb usb2: Manufacturer: Linux 5.14.0-284.13.1.el9_2.x86_64 xhci-hcd
Jun 06 02:03:04 localhost kernel: usb usb2: SerialNumber: 0000:00:14.0
Jun 06 02:03:04 localhost kernel: hub 2-0:1.0: USB hub found
Jun 06 02:03:04 localhost kernel: hub 2-0:1.0: 16 ports detected
Jun 06 02:03:04 localhost kernel: usb usb3: New USB device found, idVendor=1d6b, idProduct=0003, bcdDevice= 5.14
Jun 06 02:03:04 localhost kernel: usb usb3: New USB device strings: Mfr=3, Product=2, SerialNumber=1
Jun 06 02:03:04 localhost kernel: usb usb3: Product: xHCI Host Controller
Jun 06 02:03:04 localhost kernel: usb usb3: Manufacturer: Linux 5.14.0-284.13.1.el9_2.x86_64 xhci-hcd
Jun 06 02:03:04 localhost kernel: usb usb3: SerialNumber: 0000:00:14.0
Jun 06 02:03:04 localhost kernel: hub 3-0:1.0: USB hub found
Jun 06 02:03:04 localhost kernel: hub 3-0:1.0: 10 ports detected
Jun 06 02:03:04 localhost kernel: usbcore: registered new interface driver usbserial_generic
Jun 06 02:03:04 localhost kernel: usbserial: USB Serial support registered for generic
Jun 06 02:03:04 localhost kernel: i8042: PNP: No PS/2 controller found.
Jun 06 02:03:04 localhost kernel: i8042: Probing ports directly.
Jun 06 02:03:04 localhost kernel: usb 2-3: new high-speed USB device number 2 using xhci_hcd
Jun 06 02:03:04 localhost kernel: usb 2-3: New USB device found, idVendor=0424, idProduct=2660, bcdDevice= 8.01
Jun 06 02:03:04 localhost kernel: usb 2-3: New USB device strings: Mfr=0, Product=0, SerialNumber=0
Jun 06 02:03:04 localhost kernel: hub 2-3:1.0: USB hub found
Jun 06 02:03:04 localhost kernel: hub 2-3:1.0: 2 ports detected
Jun 06 02:03:04 localhost kernel: i8042: Can't read CTR while initializing i8042
Jun 06 02:03:04 localhost kernel: i8042: probe of i8042 failed with error -5
Jun 06 02:03:04 localhost kernel: mousedev: PS/2 mouse device common for all mice
Jun 06 02:03:04 localhost kernel: rtc_cmos 00:00: RTC can wake from S4
Jun 06 02:03:04 localhost kernel: rtc_cmos 00:00: registered as rtc0
Jun 06 02:03:04 localhost kernel: rtc_cmos 00:00: setting system clock to 2023-06-06T02:03:02 UTC (1686016982)
Jun 06 02:03:04 localhost kernel: rtc_cmos 00:00: alarms up to one month, y3k, 114 bytes nvram, hpet irqs
Jun 06 02:03:04 localhost kernel: Freeing initrd memory: 91052K
Jun 06 02:03:04 localhost kernel: intel_pstate: HWP enabled by BIOS
Jun 06 02:03:04 localhost kernel: intel_pstate: Intel P-state driver initializing
Jun 06 02:03:04 localhost kernel: intel_pstate: HWP enabled
Jun 06 02:03:04 localhost kernel: efifb: probing for efifb
Jun 06 02:03:04 localhost kernel: efifb: framebuffer at 0x98000000, using 3072k, total 3072k
Jun 06 02:03:04 localhost kernel: efifb: mode is 1024x768x32, linelength=4096, pages=1
Jun 06 02:03:04 localhost kernel: efifb: scrolling: redraw
Jun 06 02:03:04 localhost kernel: efifb: Truecolor: size=8:8:8:8, shift=24:16:8:0
Jun 06 02:03:04 localhost kernel: Console: switching to colour frame buffer device 128x48
Jun 06 02:03:04 localhost kernel: fb0: EFI VGA frame buffer device
Jun 06 02:03:04 localhost kernel: EFI Variables Facility v0.08 2004-May-17
Jun 06 02:03:04 localhost kernel: hid: raw HID events driver (C) Jiri Kosina
Jun 06 02:03:04 localhost kernel: usbcore: registered new interface driver usbhid
Jun 06 02:03:04 localhost kernel: usbhid: USB HID core driver
Jun 06 02:03:04 localhost kernel: drop_monitor: Initializing network drop monitor service
Jun 06 02:03:04 localhost kernel: Initializing XFRM netlink socket
Jun 06 02:03:04 localhost kernel: NET: Registered PF_INET6 protocol family
Jun 06 02:03:04 localhost kernel: Segment Routing with IPv6
Jun 06 02:03:04 localhost kernel: NET: Registered PF_PACKET protocol family
Jun 06 02:03:04 localhost kernel: mpls_gso: MPLS GSO support
Jun 06 02:03:04 localhost kernel: microcode: sig=0x606a6, pf=0x1, revision=0xd000375
Jun 06 02:03:04 localhost kernel: microcode: Microcode Update Driver: v2.2.
Jun 06 02:03:04 localhost kernel: resctrl: L3 allocation detected
Jun 06 02:03:04 localhost kernel: resctrl: MB allocation detected
Jun 06 02:03:04 localhost kernel: resctrl: L3 monitoring detected
Jun 06 02:03:04 localhost kernel: IPI shorthand broadcast: enabled
Jun 06 02:03:04 localhost kernel: AVX2 version of gcm_enc/dec engaged.
Jun 06 02:03:04 localhost kernel: AES CTR mode by8 optimization enabled
Jun 06 02:03:04 localhost kernel: sched_clock: Marking stable (1755941349, 2949052)->(1966194808, -207304407)
Jun 06 02:03:04 localhost kernel: registered taskstats version 1
Jun 06 02:03:04 localhost kernel: Loading compiled-in X.509 certificates
Jun 06 02:03:04 localhost kernel: Loaded X.509 cert 'Red Hat Enterprise Linux kernel signing key: 00ecce0a8f5d0994e01ed9317bbe137eaf79c99b'
Jun 06 02:03:04 localhost kernel: Loaded X.509 cert 'Red Hat Enterprise Linux Driver Update Program (key 3): bf57f3e87362bc7229d9f465321773dfd1f77a80'
Jun 06 02:03:04 localhost kernel: Loaded X.509 cert 'Red Hat Enterprise Linux kpatch signing key: 4d38fd864ebe18c5f0b72e3852e2014c3a676fc8'
Jun 06 02:03:04 localhost kernel: zswap: loaded using pool lzo/zbud
Jun 06 02:03:04 localhost kernel: page_owner is disabled
Jun 06 02:03:04 localhost kernel: pstore: Using crash dump compression: deflate
Jun 06 02:03:04 localhost kernel: Key type big_key registered
Jun 06 02:03:04 localhost kernel: Key type trusted registered
Jun 06 02:03:04 localhost kernel: Key type encrypted registered
Jun 06 02:03:04 localhost kernel: integrity: Loading X.509 certificate: UEFI:db
Jun 06 02:03:04 localhost kernel: integrity: Loaded X.509 cert 'Hewlett Packard Enterprise Company: HPE UEFI Secure Boot 2016 DB Key: a068bfe686eec826df935e3bb1cd36f1c2772560'
Jun 06 02:03:04 localhost kernel: integrity: Loading X.509 certificate: UEFI:db
Jun 06 02:03:04 localhost kernel: integrity: Loaded X.509 cert 'Hewlett-Packard Company: HP UEFI Secure Boot 2013 DB key: 1d7cf2c2b92673f69c8ee1ec7063967ab9b62bec'
Jun 06 02:03:04 localhost kernel: integrity: Loading X.509 certificate: UEFI:db
Jun 06 02:03:04 localhost kernel: integrity: Loaded X.509 cert 'Microsoft Corporation UEFI CA 2011: 13adbf4309bd82709c8cd54f316ed522988a1bd4'
Jun 06 02:03:04 localhost kernel: integrity: Loading X.509 certificate: UEFI:db
Jun 06 02:03:04 localhost kernel: tsc: Refined TSC clocksource calibration: 2194.800 MHz
Jun 06 02:03:04 localhost kernel: usb 1-1: new high-speed USB device number 2 using ehci-pci
Jun 06 02:03:04 localhost kernel: integrity: Loaded X.509 cert 'Microsoft Windows Production PCA 2011: a92902398e16c49778cd90f99e4f9ae17c55af53'
Jun 06 02:03:04 localhost kernel: clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1fa302934c2, max_idle_ns: 440795231312 ns
Jun 06 02:03:04 localhost kernel: integrity: Loading X.509 certificate: UEFI:db
Jun 06 02:03:04 localhost kernel: clocksource: Switched to clocksource tsc
Jun 06 02:03:04 localhost kernel: integrity: Loaded X.509 cert 'VMware, Inc.: VMware Secure Boot Signing: 04597f3e1ffb240bba0ff0f05d5eb05f3e15f6d7'
Jun 06 02:03:04 localhost kernel: integrity: Loading X.509 certificate: UEFI:db
Jun 06 02:03:04 localhost kernel: alg: No test for pkcs1pad(rsa,sha1) (pkcs1pad(rsa-generic,sha1))
Jun 06 02:03:04 localhost kernel: integrity: Loaded X.509 cert 'Wind River Systems Inc: TiS: 00a774fa6f5e66ad03'
Jun 06 02:03:04 localhost kernel: integrity: Loading X.509 certificate: UEFI:MokListRT (MOKvar table)
Jun 06 02:03:04 localhost kernel: integrity: Loaded X.509 cert 'Red Hat Secure Boot CA 5: cc6fa5e72868ba494e939bbd680b9144769a9f8f'
Jun 06 02:03:04 localhost kernel: Loading compiled-in module X.509 certificates
Jun 06 02:03:04 localhost kernel: Loaded X.509 cert 'Red Hat Enterprise Linux kernel signing key: 00ecce0a8f5d0994e01ed9317bbe137eaf79c99b'
Jun 06 02:03:04 localhost kernel: ima: Allocated hash algorithm: sha256
Jun 06 02:03:04 localhost kernel: usb 1-1: New USB device found, idVendor=03f0, idProduct=7029, bcdDevice= 0.02
Jun 06 02:03:04 localhost kernel: usb 1-1: New USB device strings: Mfr=1, Product=2, SerialNumber=0
Jun 06 02:03:04 localhost kernel: usb 1-1: Product: Virtual Keyboard
Jun 06 02:03:04 localhost kernel: usb 1-1: Manufacturer: iLO
Jun 06 02:03:04 localhost kernel: ima: No architecture policies found
Jun 06 02:03:04 localhost kernel: input: iLO Virtual Keyboard as /devices/pci0000:00/0000:00:1c.4/0000:01:00.4/usb1/1-1/1-1:1.0/0003:03F0:7029.0001/input/input1
Jun 06 02:03:04 localhost kernel: evm: Initialising EVM extended attributes:
Jun 06 02:03:04 localhost kernel: evm: security.selinux
Jun 06 02:03:04 localhost kernel: evm: security.SMACK64 (disabled)
Jun 06 02:03:04 localhost kernel: evm: security.SMACK64EXEC (disabled)
Jun 06 02:03:04 localhost kernel: evm: security.SMACK64TRANSMUTE (disabled)
Jun 06 02:03:04 localhost kernel: evm: security.SMACK64MMAP (disabled)
Jun 06 02:03:04 localhost kernel: hid-generic 0003:03F0:7029.0001: input,hidraw0: USB HID v1.10 Keyboard [iLO Virtual Keyboard] on usb-0000:01:00.4-1/input0
Jun 06 02:03:04 localhost kernel: evm: security.apparmor (disabled)
Jun 06 02:03:04 localhost kernel: evm: security.ima
Jun 06 02:03:04 localhost kernel: evm: security.capability
Jun 06 02:03:04 localhost kernel: evm: HMAC attrs: 0x1
Jun 06 02:03:04 localhost kernel: input: iLO Virtual Keyboard as /devices/pci0000:00/0000:00:1c.4/0000:01:00.4/usb1/1-1/1-1:1.1/0003:03F0:7029.0002/input/input2
Jun 06 02:03:04 localhost kernel: hid-generic 0003:03F0:7029.0002: input,hidraw1: USB HID v1.10 Mouse [iLO Virtual Keyboard] on usb-0000:01:00.4-1/input1
Jun 06 02:03:04 localhost kernel: Freeing unused decrypted memory: 2036K
Jun 06 02:03:04 localhost kernel: Freeing unused kernel image (initmem) memory: 2792K
Jun 06 02:03:04 localhost kernel: Write protecting the kernel read-only data: 26624k
Jun 06 02:03:04 localhost kernel: Freeing unused kernel image (text/rodata gap) memory: 2040K
Jun 06 02:03:04 localhost kernel: usb 1-2: new high-speed USB device number 3 using ehci-pci
Jun 06 02:03:04 localhost kernel: Freeing unused kernel image (rodata/data gap) memory: 60K
Jun 06 02:03:04 localhost kernel: x86/mm: Checked W+X mappings: passed, no W+X pages found.
Jun 06 02:03:04 localhost kernel: Run /init as init process
Jun 06 02:03:04 localhost kernel:   with arguments:
Jun 06 02:03:04 localhost kernel:     /init
Jun 06 02:03:04 localhost kernel:   with environment:
Jun 06 02:03:04 localhost kernel:     HOME=/
Jun 06 02:03:04 localhost kernel:     TERM=linux
Jun 06 02:03:04 localhost kernel:     BOOT_IMAGE=/images/pxeboot/vmlinuz
Jun 06 02:03:04 localhost kernel: usb 1-2: New USB device found, idVendor=03f0, idProduct=2227, bcdDevice= 0.01
Jun 06 02:03:04 localhost kernel: usb 1-2: New USB device strings: Mfr=1, Product=2, SerialNumber=0
Jun 06 02:03:04 localhost kernel: usb 1-2: Product: Virtual CD-ROM
Jun 06 02:03:04 localhost kernel: usb 1-2: Manufacturer: iLO
Jun 06 02:03:04 localhost kernel: ERST: [Firmware Warn]: too many record IDs!
Jun 06 02:03:04 localhost systemd-journald[773]: Journal started
Jun 06 02:03:04 localhost systemd-journald[773]: Runtime Journal (/run/log/journal/de1e6fab70fa460f8917eab7ed136b20) is 8.0M, max 2.5G, 2.5G free.
Jun 06 02:03:04 localhost coreos-ignition-setup-user[766]: Copying /config.ign to /usr/lib/ignition/user.ign
Jun 06 02:03:04 localhost systemd-sysusers[775]: Creating group 'nobody' with GID 65534.
Jun 06 02:03:04 localhost systemd-modules-load[774]: Inserted module 'fuse'
Jun 06 02:03:04 localhost systemd-journald[773]: Missed 36 kernel messages
Jun 06 02:03:04 localhost kernel: fuse: init (API version 7.36)
Jun 06 02:03:04 localhost systemd-modules-load[774]: Module 'msr' is built in
Jun 06 02:03:04 localhost systemd[1]: Mounted /run/ephemeral_base.
Jun 06 02:03:04 localhost systemd[1]: Finished Afterburn Initrd Setup Network Kernel Arguments.
Jun 06 02:03:04 localhost systemd[1]: Finished CoreOS Ignition User Config Setup.
Jun 06 02:03:04 localhost systemd[1]: Finished CoreOS: Touch /run/agetty.reload.
Jun 06 02:03:04 localhost systemd[1]: Finished Create List of Static Device Nodes.
Jun 06 02:03:04 localhost systemd[1]: Finished Load Kernel Modules.
Jun 06 02:03:04 localhost systemd[1]: Finished Setup Virtual Console.
Jun 06 02:03:04 localhost systemd[1]: Starting dracut ask for additional cmdline parameters...
Jun 06 02:03:04 localhost systemd[1]: Starting Apply Kernel Variables...
Jun 06 02:03:04 localhost systemd[1]: Finished dracut ask for additional cmdline parameters.
Jun 06 02:03:04 localhost systemd[1]: Finished Apply Kernel Variables.
Jun 06 02:03:04 localhost systemd[1]: Starting dracut cmdline hook...
Jun 06 02:03:04 localhost dracut-cmdline[796]: dracut-413.92.202305021736-0 dracut-057-21.git20230214.el9
Jun 06 02:03:04 localhost dracut-cmdline[796]: Using kernel command line parameters:  ip=auto   BOOT_IMAGE=/images/pxeboot/vmlinuz coreos.liveiso=rhcos-413.92.202305021736-0 ignition.firstboot ignition.platform.id=metal
Jun 06 02:03:04 localhost systemd-sysusers[775]: Creating group 'sgx' with GID 999.
Jun 06 02:03:04 localhost systemd-sysusers[775]: Creating group 'users' with GID 100.
Jun 06 02:03:04 localhost systemd-sysusers[775]: Creating group 'root' with GID 998.
Jun 06 02:03:04 localhost systemd-sysusers[775]: Creating group 'dbus' with GID 81.
Jun 06 02:03:04 localhost systemd-sysusers[775]: Creating user 'dbus' (System Message Bus) with UID 81 and GID 81.
Jun 06 02:03:04 localhost systemd[1]: Finished Create System Users.
Jun 06 02:03:04 localhost systemd[1]: Starting Create Static Device Nodes in /dev...
Jun 06 02:03:05 localhost systemd[1]: Starting Create Volatile Files and Directories...
Jun 06 02:03:05 localhost systemd[1]: Finished dracut cmdline hook.
Jun 06 02:03:05 localhost systemd[1]: Finished Create Static Device Nodes in /dev.
Jun 06 02:03:05 localhost systemd[1]: Finished Create Volatile Files and Directories.
Jun 06 02:03:05 localhost systemd[1]: Starting dracut pre-udev hook...
Jun 06 02:03:05 localhost systemd[1]: Starting sysroot-xfs-ephemeral-mkfs.service...
Jun 06 02:03:05 localhost mkfs.xfs[933]: meta-data=/run/ephemeral_base/loopfs isize=512    agcount=4, agsize=4111879 blks
Jun 06 02:03:05 localhost mkfs.xfs[933]:          =                       sectsz=512   attr=2, projid32bit=1
Jun 06 02:03:05 localhost mkfs.xfs[933]:          =                       crc=1        finobt=1, sparse=1, rmapbt=0
Jun 06 02:03:05 localhost mkfs.xfs[933]:          =                       reflink=1    bigtime=1 inobtcount=1
Jun 06 02:03:05 localhost mkfs.xfs[933]: data     =                       bsize=4096   blocks=16447515, imaxpct=25
Jun 06 02:03:05 localhost mkfs.xfs[933]:          =                       sunit=0      swidth=0 blks
Jun 06 02:03:05 localhost mkfs.xfs[933]: naming   =version 2              bsize=4096   ascii-ci=0, ftype=1
Jun 06 02:03:05 localhost mkfs.xfs[933]: log      =internal log           bsize=4096   blocks=8031, version=2
Jun 06 02:03:05 localhost mkfs.xfs[933]:          =                       sectsz=512   sunit=0 blks, lazy-count=1
Jun 06 02:03:05 localhost mkfs.xfs[933]: realtime =none                   extsz=4096   blocks=0, rtextents=0
Jun 06 02:03:05 localhost systemd-journald[773]: Missed 31 kernel messages
Jun 06 02:03:05 localhost kernel: device-mapper: core: CONFIG_IMA_DISABLE_HTABLE is disabled. Duplicate IMA measurements will not be recorded in the IMA log.
Jun 06 02:03:05 localhost systemd-journald[773]: Missed 1 kernel messages
Jun 06 02:03:05 localhost kernel: device-mapper: uevent: version 1.0.3
Jun 06 02:03:05 localhost systemd-journald[773]: Missed 1 kernel messages
Jun 06 02:03:05 localhost kernel: device-mapper: ioctl: 4.47.0-ioctl (2022-07-28) initialised: dm-devel@redhat.com
Jun 06 02:03:05 localhost systemd[1]: Finished sysroot-xfs-ephemeral-mkfs.service.
Jun 06 02:03:05 localhost systemd[1]: Mounting /run/ephemeral...
Jun 06 02:03:05 localhost systemd-journald[773]: Missed 10 kernel messages
Jun 06 02:03:05 localhost kernel: loop: module loaded
Jun 06 02:03:05 localhost systemd[1]: Finished dracut pre-udev hook.
Jun 06 02:03:05 localhost kernel: loop0: detected capacity change from 0 to 131580120
Jun 06 02:03:05 localhost systemd[1]: Starting Rule-based Manager for Device Events and Files...
Jun 06 02:03:05 localhost systemd-udevd[958]: Using default interface naming scheme 'rhel-9.0'.
Jun 06 02:03:05 localhost systemd[1]: Started Rule-based Manager for Device Events and Files.
Jun 06 02:03:05 localhost systemd[1]: Starting dracut pre-trigger hook...
Jun 06 02:03:05 localhost dracut-pre-trigger[969]: rd.md=0: removing MD RAID activation
Jun 06 02:03:05 localhost systemd[1]: Finished dracut pre-trigger hook.
Jun 06 02:03:05 localhost systemd[1]: Starting Coldplug All udev Devices...
Jun 06 02:03:05 localhost systemd[1]: sys-module-fuse.device: Failed to enqueue SYSTEMD_WANTS= job, ignoring: Unit sys-fs-fuse-connections.mount not found.
Jun 06 02:03:05 localhost systemd[1]: Finished Coldplug All udev Devices.
Jun 06 02:03:05 localhost systemd[1]: Starting Wait for udev To Complete Device Initialization...
Jun 06 02:03:05 localhost udevadm[1101]: systemd-udev-settle.service is deprecated. Please fix multipathd-configure.service, run-media-iso.mount not to pull it in.
Jun 06 02:03:05 localhost systemd-journald[773]: Missed 12 kernel messages
Jun 06 02:03:05 localhost kernel: gnss: GNSS driver registered with major 240
Jun 06 02:03:05 localhost kernel: dca service started, version 1.12.1
Jun 06 02:03:05 localhost kernel: usb-storage 1-2:1.0: USB Mass Storage device detected
Jun 06 02:03:05 localhost kernel: scsi host0: usb-storage 1-2:1.0
Jun 06 02:03:05 localhost kernel: hpwdt 0000:01:00.0: HPE Watchdog Timer Driver: NMI decoding initialized
Jun 06 02:03:05 localhost kernel: usbcore: registered new interface driver usb-storage
Jun 06 02:03:05 localhost kernel: hpwdt 0000:01:00.0: HPE Watchdog Timer Driver: Version: 2.0.4
Jun 06 02:03:05 localhost kernel: hpwdt 0000:01:00.0: timeout: 30 seconds (nowayout=0)
Jun 06 02:03:05 localhost kernel: hpwdt 0000:01:00.0: pretimeout: on.
Jun 06 02:03:05 localhost kernel: hpwdt 0000:01:00.0: kdumptimeout: -1.
Jun 06 02:03:05 localhost kernel: SGI XFS with ACLs, security attributes, scrub, quota, no debug enabled
Jun 06 02:03:05 localhost kernel: XFS (loop0): Mounting V5 Filesystem
Jun 06 02:03:05 localhost systemd[1]: Mounted /run/ephemeral.
Jun 06 02:03:05 localhost kernel: XFS (loop0): Ending clean mount
Jun 06 02:03:05 localhost systemd-journald[773]: Missed 1 kernel messages
Jun 06 02:03:05 localhost kernel: igb: Intel(R) Gigabit Ethernet Network Driver
Jun 06 02:03:05 localhost kernel: igb: Copyright (c) 2007-2014 Intel Corporation.
Jun 06 02:03:05 localhost kernel: nvme nvme0: pci function 0000:c2:00.0
Jun 06 02:03:05 localhost kernel: nvme nvme1: pci function 0000:c3:00.0
Jun 06 02:03:05 localhost kernel: nvme nvme0: Shutdown timeout set to 8 seconds
Jun 06 02:03:05 localhost kernel: nvme nvme1: Shutdown timeout set to 8 seconds
Jun 06 02:03:05 localhost kernel: pps pps0: new PPS source ptp0
Jun 06 02:03:05 localhost kernel: igb 0000:03:00.0: added PHC on eth0
Jun 06 02:03:05 localhost kernel: nvme nvme0: 32/0/0 default/read/poll queues
Jun 06 02:03:05 localhost kernel: igb 0000:03:00.0: Intel(R) Gigabit Ethernet Network Connection
Jun 06 02:03:06 localhost kernel: nvme nvme1: 32/0/0 default/read/poll queues
Jun 06 02:03:06 localhost kernel: igb 0000:03:00.0: eth0: (PCIe:2.5Gb/s:Width x1) 5c:ba:2c:1f:6c:e5
Jun 06 02:03:06 localhost kernel: igb 0000:03:00.0: eth0: PBA No: 000300-000
Jun 06 02:03:06 localhost kernel: igb 0000:03:00.0: Using MSI-X interrupts. 4 rx queue(s), 4 tx queue(s)
Jun 06 02:03:06 localhost kernel: ice: Intel(R) Ethernet Connection E800 Series Linux Driver
Jun 06 02:03:06 localhost kernel: igb 0000:03:00.0 eno1: renamed from eth0
Jun 06 02:03:06 localhost kernel: ice: Copyright (c) 2018, Intel Corporation.
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.0: The DDP package was successfully loaded: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.0: PTP init successful
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.0: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.0: Configuring initial DCB values
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.0: Commit DCB Configuration to the hardware
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.0: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:02.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.1: DDP package already present on device: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:06 localhost kernel: scsi 0:0:0:0: CD-ROM            iLO      Virtual DVD-ROM       PQ: 0 ANSI: 0 CCS
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.1: PTP init successful
Jun 06 02:03:06 localhost kernel: scsi 0:0:0:0: Attached scsi generic sg0 type 5
Jun 06 02:03:06 localhost kernel: sr 0:0:0:0: [sr0] scsi3-mmc drive: 12x/12x cd/rw tray
Jun 06 02:03:06 localhost kernel: cdrom: Uniform CD-ROM driver Revision: 3.20
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.1: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.1: Configuring initial DCB values
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.1: Commit DCB Configuration to the hardware
Jun 06 02:03:06 localhost kernel: ice 0000:10:00.1: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:02.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:06 localhost kernel: sr 0:0:0:0: Attached scsi CD-ROM sr0
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.2: DDP package already present on device: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.2: PTP init successful
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.2: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.2: Configuring initial DCB values
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.2: Commit DCB Configuration to the hardware
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.2: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:02.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.3: DDP package already present on device: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.3: PTP init successful
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.3: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.3: Configuring initial DCB values
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.3: Commit DCB Configuration to the hardware
Jun 06 02:03:07 localhost kernel: ice 0000:10:00.3: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:02.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:07 localhost systemd[1]: Found device Virtual_DVD-ROM rhcos-413.92.202305021736-0.
Jun 06 02:03:07 localhost systemd-journald[773]: Missed 1 kernel messages
Jun 06 02:03:07 localhost kernel: ice 0000:12:00.0: The DDP package was successfully loaded: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.0: PTP init successful
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.0: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.0: Configuring initial DCB values
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.0: Commit DCB Configuration to the hardware
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.0: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:04.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.1: DDP package already present on device: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.1: PTP init successful
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.1: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.1: Configuring initial DCB values
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.1: Commit DCB Configuration to the hardware
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.1: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:04.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.2: DDP package already present on device: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.2: PTP init successful
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.2: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.2: Configuring initial DCB values
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.2: Commit DCB Configuration to the hardware
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.2: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:04.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.3: DDP package already present on device: ICE OS Default Package version 1.3.30.0
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.3: PTP init successful
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.3: DCB is enabled in the hardware, max number of TCs supported on this port are 8
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.3: Configuring initial DCB values
Jun 06 02:03:08 localhost kernel: ice 0000:12:00.3: Commit DCB Configuration to the hardware
Jun 06 02:03:09 localhost kernel: ice 0000:12:00.3: 126.024 Gb/s available PCIe bandwidth, limited by 16.0 GT/s PCIe x8 link at 0000:0f:04.0 (capable of 252.048 Gb/s with 16.0 GT/s PCIe x16 link)
Jun 06 02:03:09 localhost kernel: ice 0000:10:00.3 ens1f3: renamed from eth3
Jun 06 02:03:09 localhost kernel: ice 0000:10:00.0 ens1f0: renamed from eth0
Jun 06 02:03:09 localhost kernel: ice 0000:10:00.2 ens1f2: renamed from eth2
Jun 06 02:03:09 localhost kernel: ice 0000:12:00.3 ens2f3: renamed from eth7
Jun 06 02:03:09 localhost kernel: ice 0000:12:00.2 ens2f2: renamed from eth6
Jun 06 02:03:09 localhost kernel: ice 0000:10:00.1 ens1f1: renamed from eth1
Jun 06 02:03:09 localhost kernel: ice 0000:12:00.1 ens2f1: renamed from eth5
Jun 06 02:03:09 localhost kernel: ice 0000:12:00.0 ens2f0: renamed from eth4
Jun 06 02:03:09 localhost kernel: i40e: Intel(R) Ethernet Connection XL710 Network Driver
Jun 06 02:03:09 localhost kernel: i40e: Copyright (c) 2013 - 2019 Intel Corporation.
Jun 06 02:03:09 localhost systemd[1]: Finished Wait for udev To Complete Device Initialization.
Jun 06 02:03:09 localhost systemd[1]: Created slice Slice /system/rdma-load-modules.
Jun 06 02:03:09 localhost systemd[1]: Device-Mapper Multipath Default Configuration was skipped because of an unmet condition check (ConditionKernelCommandLine=rd.multipath=default).
Jun 06 02:03:09 localhost systemd[1]: Starting Device-Mapper Multipath Device Controller...
Jun 06 02:03:10 localhost systemd[1]: Starting Load RDMA modules from /etc/rdma/modules/rdma.conf...
Jun 06 02:03:10 localhost multipathd[1266]: --------start up--------
Jun 06 02:03:10 localhost multipathd[1266]: read /etc/multipath.conf
Jun 06 02:03:10 localhost multipathd[1266]: /etc/multipath.conf does not exist, blacklisting all devices.
Jun 06 02:03:10 localhost multipathd[1266]: You can run "/sbin/mpathconf --enable" to create
Jun 06 02:03:10 localhost multipathd[1266]: /etc/multipath.conf. See man mpathconf(8) for more details
Jun 06 02:03:10 localhost multipathd[1266]: path checkers start up
Jun 06 02:03:10 localhost multipathd[1266]: /etc/multipath.conf does not exist, blacklisting all devices.
Jun 06 02:03:10 localhost multipathd[1266]: You can run "/sbin/mpathconf --enable" to create
Jun 06 02:03:10 localhost multipathd[1266]: /etc/multipath.conf. See man mpathconf(8) for more details
Jun 06 02:03:10 localhost systemd[1]: Started Device-Mapper Multipath Device Controller.
Jun 06 02:03:10 localhost systemd[1]: Reached target Preparation for Local File Systems.
Jun 06 02:03:10 localhost systemd[1]: Reached target Local File Systems.
Jun 06 02:03:10 localhost systemd-journald[773]: Missed 17 kernel messages
Jun 06 02:03:10 localhost kernel: Loading iSCSI transport class v2.0-870.
Jun 06 02:03:10 localhost kernel: iscsi: registered transport (iser)
Jun 06 02:03:10 localhost systemd-modules-load[1265]: Inserted module 'ib_iser'
Jun 06 02:03:10 localhost systemd-journald[773]: Missed 1 kernel messages
Jun 06 02:03:10 localhost kernel: Rounding down aligned max_sectors from 4294967295 to 4294967288
Jun 06 02:03:10 localhost kernel: db_root: cannot open: /etc/target
Jun 06 02:03:10 localhost systemd-modules-load[1265]: Inserted module 'ib_isert'
Jun 06 02:03:10 localhost systemd-modules-load[1265]: Inserted module 'ib_srpt'
Jun 06 02:03:10 localhost systemd-modules-load[1265]: Inserted module 'rdma_ucm'
Jun 06 02:03:10 localhost systemd-journald[773]: Missed 3 kernel messages
Jun 06 02:03:10 localhost kernel: RPC: Registered named UNIX socket transport module.
Jun 06 02:03:10 localhost kernel: RPC: Registered udp transport module.
Jun 06 02:03:10 localhost kernel: RPC: Registered tcp transport module.
Jun 06 02:03:10 localhost kernel: RPC: Registered tcp NFSv4.1 backchannel transport module.
Jun 06 02:03:10 localhost kernel: RPC: Registered rdma transport module.
Jun 06 02:03:10 localhost kernel: RPC: Registered rdma backchannel transport module.
Jun 06 02:03:10 localhost systemd-modules-load[1265]: Inserted module 'rpcrdma'
Jun 06 02:03:10 localhost systemd[1]: Finished Load RDMA modules from /etc/rdma/modules/rdma.conf.
Jun 06 02:03:10 localhost systemd[1]: Reached target Preparation for Network.
Jun 06 02:03:10 localhost systemd[1]: Reached target RDMA Hardware.
Jun 06 02:03:10 localhost systemd[1]: Reached target System Initialization.
Jun 06 02:03:10 localhost systemd[1]: Reached target Basic System.
Jun 06 02:03:10 localhost systemd[1]: Starting Ignition (fetch-offline)...
Jun 06 02:03:10 localhost ignition[1282]: Ignition 2.15.0
Jun 06 02:03:10 localhost ignition[1282]: Stage: fetch-offline
Jun 06 02:03:10 localhost ignition[1282]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:10 localhost ignition[1282]: parsing config with SHA512: ff6a5153be363997e4d5d3ea8cc4048373a457c48c4a5b134a08a30aacd167c1e0f099f0bdf1e24c99ad180628cd02b767b863b5fe3a8fce3fe1886847eb8e2e
Jun 06 02:03:10 localhost ignition[1282]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:10 localhost ignition[1282]: fetched base config from "system"
Jun 06 02:03:10 localhost ignition[1282]: parsed url from cmdline: ""
Jun 06 02:03:10 localhost ignition[1282]: fetched user config from "system"
Jun 06 02:03:10 localhost ignition[1282]: no config URL provided
Jun 06 02:03:10 localhost systemd[1]: Finished Ignition (fetch-offline).
Jun 06 02:03:10 localhost ignition[1282]: reading system config file "/usr/lib/ignition/user.ign"
Jun 06 02:03:10 localhost ignition[1282]: parsing config with SHA512: 09790f2f46eef6204b6be1d8cd2a28f3d2573f31b53ac7fc5fcd651c222252e4b2c420943864a5c756e2a5e093c616aec75eb2982a75e5ecb4a08e0f55850ba9
Jun 06 02:03:10 localhost ignition[1282]: fetch-offline: fetch-offline passed
Jun 06 02:03:10 localhost ignition[1282]: Ignition finished successfully
Jun 06 02:03:10 localhost systemd[1]: CoreOS Enable Network was skipped because no trigger condition checks were met.
Jun 06 02:03:10 localhost systemd[1]: Starting Copy CoreOS Firstboot Networking Config...
Jun 06 02:03:10 localhost coreos-copy-firstboot-network[1294]: info: no files to copy from /etc/coreos-firstboot-network; skipping
Jun 06 02:03:10 localhost systemd[1]: Finished Copy CoreOS Firstboot Networking Config.
Jun 06 02:03:10 localhost systemd[1]: nm-initrd.service was skipped because of an unmet condition check (ConditionPathExists=/run/NetworkManager/initrd/neednet).
Jun 06 02:03:10 localhost systemd[1]: Reached target Network.
Jun 06 02:03:10 localhost systemd[1]: Ignition (fetch) was skipped because of an unmet condition check (ConditionPathExists=!/run/ignition.json).
Jun 06 02:03:10 localhost systemd[1]: Starting Ignition (kargs)...
Jun 06 02:03:10 localhost systemd[1]: Ignition OSTree: Detect Partition Transposition was skipped because of an unmet condition check (ConditionKernelCommandLine=ostree).
Jun 06 02:03:10 localhost systemd[1]: Ignition OSTree: Save Partitions was skipped because of an unmet condition check (ConditionPathIsDirectory=/run/ignition-ostree-transposefs).
Jun 06 02:03:10 localhost ignition[1298]: Ignition 2.15.0
Jun 06 02:03:10 localhost systemd[1]: nm-wait-online-initrd.service was skipped because of an unmet condition check (ConditionPathExists=/run/NetworkManager/initrd/neednet).
Jun 06 02:03:10 localhost ignition[1298]: Stage: kargs
Jun 06 02:03:10 localhost systemd[1]: Starting dracut initqueue hook...
Jun 06 02:03:10 localhost ignition[1298]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:10 localhost ignition[1298]: parsing config with SHA512: ff6a5153be363997e4d5d3ea8cc4048373a457c48c4a5b134a08a30aacd167c1e0f099f0bdf1e24c99ad180628cd02b767b863b5fe3a8fce3fe1886847eb8e2e
Jun 06 02:03:10 localhost ignition[1298]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:10 localhost ignition[1298]: kargs: kargs passed
Jun 06 02:03:10 localhost ignition[1298]: Ignition finished successfully
Jun 06 02:03:11 localhost systemd[1]: Starting RHCOS Check For Legacy LUKS Configuration...
Jun 06 02:03:11 localhost systemd[1]: Finished Ignition (kargs).
Jun 06 02:03:11 localhost systemd[1]: Finished dracut initqueue hook.
Jun 06 02:03:11 localhost systemd[1]: Finished RHCOS Check For Legacy LUKS Configuration.
Jun 06 02:03:11 localhost systemd[1]: Reached target Preparation for Remote File Systems.
Jun 06 02:03:11 localhost systemd[1]: Reached target Remote Encrypted Volumes.
Jun 06 02:03:11 localhost systemd[1]: Reached target Remote File Systems.
Jun 06 02:03:11 localhost systemd[1]: CoreOS Kernel Arguments Reboot was skipped because of an unmet condition check (ConditionPathExists=/run/coreos-kargs-reboot).
Jun 06 02:03:11 localhost systemd[1]: Acquire Live PXE rootfs Image was skipped because of an unmet condition check (ConditionKernelCommandLine=!coreos.liveiso).
Jun 06 02:03:11 localhost systemd[1]: Persist Osmet Files (PXE) was skipped because of an unmet condition check (ConditionKernelCommandLine=!coreos.liveiso).
Jun 06 02:03:11 localhost systemd[1]: Starting dracut pre-mount hook...
Jun 06 02:03:11 localhost systemd[1]: Starting Ignition (disks)...
Jun 06 02:03:11 localhost ignition[1330]: Ignition 2.15.0
Jun 06 02:03:11 localhost ignition[1330]: Stage: disks
Jun 06 02:03:11 localhost ignition[1330]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:11 localhost ignition[1330]: parsing config with SHA512: ff6a5153be363997e4d5d3ea8cc4048373a457c48c4a5b134a08a30aacd167c1e0f099f0bdf1e24c99ad180628cd02b767b863b5fe3a8fce3fe1886847eb8e2e
Jun 06 02:03:11 localhost ignition[1330]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:11 localhost ignition[1330]: disks: disks passed
Jun 06 02:03:11 localhost ignition[1330]: Ignition finished successfully
Jun 06 02:03:11 localhost systemd[1]: Afterburn (Check In - from the initramfs) was skipped because of an unmet condition check (ConditionKernelCommandLine=ignition.platform.id=azure).
Jun 06 02:03:11 localhost systemd[1]: Finished dracut pre-mount hook.
Jun 06 02:03:11 localhost systemd[1]: Finished Ignition (disks).
Jun 06 02:03:11 localhost systemd[1]: Reached target Initrd Root Device.
Jun 06 02:03:11 localhost systemd[1]: Mounting /run/media/iso...
Jun 06 02:03:11 localhost systemd[1]: Ignition OSTree: Restore Partitions was skipped because of an unmet condition check (ConditionPathIsDirectory=/run/ignition-ostree-transposefs).
Jun 06 02:03:11 localhost systemd-journald[773]: Missed 60 kernel messages
Jun 06 02:03:11 localhost kernel: ISO 9660 Extensions: IEEE_P1282
Jun 06 02:03:11 localhost systemd[1]: Mounted /run/media/iso.
Jun 06 02:03:11 localhost systemd[1]: Mounting /sysroot...
Jun 06 02:03:11 localhost systemd-journald[773]: Missed 2 kernel messages
Jun 06 02:03:11 localhost kernel: loop1: detected capacity change from 0 to 1948353
Jun 06 02:03:11 localhost systemd[1]: Starting Persist Osmet Files (ISO)...
Jun 06 02:03:11 localhost systemd-journald[773]: Missed 1 kernel messages
Jun 06 02:03:11 localhost kernel: squashfs: version 4.0 (2009/01/31) Phillip Lougher
Jun 06 02:03:11 localhost bsdtar[1348]: bsdtar: Failed to set default locale
Jun 06 02:03:12 localhost systemd[1]: Mounted /sysroot.
Jun 06 02:03:12 localhost systemd[1]: Ignition OSTree: Grow Root Filesystem was skipped because of an unmet condition check (ConditionPathExists=!/run/ostree-live).
Jun 06 02:03:12 localhost systemd[1]: Starting OSTree Prepare OS/...
Jun 06 02:03:12 localhost ostree-prepare-root[1353]: preparing sysroot at /sysroot
Jun 06 02:03:12 localhost ostree-prepare-root[1353]: Resolved OSTree target to: /sysroot/ostree/deploy/rhcos/deploy/f069b5aca6a53934461a7361690bd20ad4aa3e223b6d12e77d54dc3ab4f48360.0
Jun 06 02:03:12 localhost ostree-prepare-root[1353]: filesystem at /sysroot currently writable: 0
Jun 06 02:03:12 localhost ostree-prepare-root[1353]: sysroot.readonly configuration value: 0
Jun 06 02:03:13 localhost systemd[1]: sysroot-ostree-deploy-rhcos-deploy-f069b5aca6a53934461a7361690bd20ad4aa3e223b6d12e77d54dc3ab4f48360.0.mount: Deactivated successfully.
Jun 06 02:03:13 localhost systemd[1]: sysroot.tmp-usr.mount: Deactivated successfully.
Jun 06 02:03:13 localhost systemd[1]: sysroot.tmp-boot.mount: Deactivated successfully.
Jun 06 02:03:13 localhost systemd[1]: sysroot.tmp.mount: Deactivated successfully.
Jun 06 02:03:13 localhost systemd[1]: proc-cmdline.mount: Deactivated successfully.
Jun 06 02:03:13 localhost systemd[1]: Finished OSTree Prepare OS/.
Jun 06 02:03:13 localhost systemd[1]: Ignition OSTree: Check Root Filesystem Size was skipped because of an unmet condition check (ConditionPathExists=!/run/ostree-live).
Jun 06 02:03:13 localhost systemd[1]: Starting sysroot-xfs-ephemeral-setup.service...
Jun 06 02:03:17 localhost systemd[1]: Finished Persist Osmet Files (ISO).
Jun 06 02:03:17 localhost systemd[1]: Finished sysroot-xfs-ephemeral-setup.service.
Jun 06 02:03:17 localhost systemd[1]: sysroot-etc.mount: Directory /sysroot/etc to mount over is not empty, mounting anyway.
Jun 06 02:03:17 localhost systemd[1]: Mounting /sysroot/etc...
Jun 06 02:03:17 localhost systemd[1]: Mounting /sysroot/var...
Jun 06 02:03:17 localhost systemd[1]: Mounted /sysroot/etc.
Jun 06 02:03:17 localhost systemd[1]: Mounted /sysroot/var.
Jun 06 02:03:17 localhost systemd[1]: Starting sysroot-relabel.service...
Jun 06 02:03:17 localhost systemd[1]: Finished sysroot-relabel.service.
Jun 06 02:03:17 localhost systemd[1]: Reached target Initrd Root File System.
Jun 06 02:03:17 localhost systemd[1]: Afterburn Hostname was skipped because no trigger condition checks were met.
Jun 06 02:03:17 localhost systemd[1]: Mount OSTree /var was skipped because of an unmet condition check (ConditionPathExists=!/run/ostree-live).
Jun 06 02:03:17 localhost systemd[1]: Starting Ignition (mount)...
Jun 06 02:03:17 localhost ignition[1368]: Ignition 2.15.0
Jun 06 02:03:17 localhost ignition[1368]: Stage: mount
Jun 06 02:03:17 localhost ignition[1368]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:17 localhost ignition[1368]: parsing config with SHA512: ff6a5153be363997e4d5d3ea8cc4048373a457c48c4a5b134a08a30aacd167c1e0f099f0bdf1e24c99ad180628cd02b767b863b5fe3a8fce3fe1886847eb8e2e
Jun 06 02:03:17 localhost ignition[1368]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:17 localhost ignition[1368]: mount: mount passed
Jun 06 02:03:17 localhost ignition[1368]: Ignition finished successfully
Jun 06 02:03:17 localhost systemd[1]: Finished Ignition (mount).
Jun 06 02:03:17 localhost systemd[1]: Clear SSSD NSS Cache in Persistent /var was skipped because of an unmet condition check (ConditionPathExists=/sysroot/var/lib/sss/mc).
Jun 06 02:03:17 localhost systemd[1]: Starting Populate OSTree /var...
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1382]: Relabeled /sysroot//var/lib from <no context> to system_u:object_r:var_lib_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1385]: Relabeled /sysroot//var/log from <no context> to system_u:object_r:var_log_t:s0
Jun 06 02:03:18 localhost systemd-tmpfiles[1386]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1386]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1388]: Relabeled /sysroot//var/home from <no context> to system_u:object_r:home_root_t:s0
Jun 06 02:03:18 localhost systemd-tmpfiles[1389]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1389]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome/.bash_logout from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome/.bash_profile from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome/.bashrc from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:18 localhost systemd-tmpfiles[1393]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1393]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1396]: Relabeled /sysroot//var/opt from <no context> to system_u:object_r:var_t:s0
Jun 06 02:03:18 localhost systemd-tmpfiles[1397]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1397]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1399]: Relabeled /sysroot//var/srv from <no context> to system_u:object_r:var_t:s0
Jun 06 02:03:18 localhost systemd-tmpfiles[1400]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1400]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/bin from <no context> to system_u:object_r:bin_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/etc from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/games from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/include from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/lib from <no context> to system_u:object_r:lib_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/man from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/sbin from <no context> to system_u:object_r:bin_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/share from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/src from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:18 localhost ignition-ostree-populate-var[1405]: Relabeled /sysroot//var/mnt from <no context> to system_u:object_r:mnt_t:s0
Jun 06 02:03:18 localhost systemd-tmpfiles[1403]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1403]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1406]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd-tmpfiles[1406]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:18 localhost systemd[1]: Finished Populate OSTree /var.
Jun 06 02:03:19 localhost systemd[1]: Starting Ignition (files)...
Jun 06 02:03:19 localhost ignition[1409]: Ignition 2.15.0
Jun 06 02:03:19 localhost ignition[1409]: Stage: files
Jun 06 02:03:19 localhost ignition[1409]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:19 localhost ignition[1409]: parsing config with SHA512: ff6a5153be363997e4d5d3ea8cc4048373a457c48c4a5b134a08a30aacd167c1e0f099f0bdf1e24c99ad180628cd02b767b863b5fe3a8fce3fe1886847eb8e2e
Jun 06 02:03:19 localhost ignition[1409]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:19 localhost ignition[1409]: files: ensureUsers: op(1): [started]  creating or modifying user "core"
Jun 06 02:03:19 localhost ignition[1409]: files: ensureUsers: op(1): executing: "useradd" "--root" "/sysroot" "--create-home" "--password" "$2a$10$86xgByocUSRwRniHSvMPBeTivQ6AoxOXF.lRnH9QHcXW0Jb/A.IjK" "--comment" "CoreOS Admin" "--groups" "adm,sudo,systemd-journal,wheel" "core"
Jun 06 02:03:22 localhost ignition[1409]: files: ensureUsers: op(1): [finished] creating or modifying user "core"
Jun 06 02:03:22 localhost ignition[1409]: files: ensureUsers: op(2): [started]  setting password for "core"
Jun 06 02:03:22 localhost ignition[1409]: files: ensureUsers: op(2): executing: "usermod" "--root" "/sysroot" "--password" "$2a$10$86xgByocUSRwRniHSvMPBeTivQ6AoxOXF.lRnH9QHcXW0Jb/A.IjK" "core"
Jun 06 02:03:22 localhost ignition[1409]: wrote ssh authorized keys file for user: core
Jun 06 02:03:22 localhost ignition[1409]: files: ensureUsers: op(2): [finished] setting password for "core"
Jun 06 02:03:22 localhost ignition[1409]: files: ensureUsers: op(3): [started]  adding ssh keys to user "core"
Jun 06 02:03:22 localhost ignition[1409]: files: ensureUsers: op(3): [finished] adding ssh keys to user "core"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(4): [started]  writing file "/sysroot/etc/issue"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(4): [finished] writing file "/sysroot/etc/issue"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(5): [started]  writing file "/sysroot/etc/multipath.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(5): [finished] writing file "/sysroot/etc/multipath.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(6): [started]  writing file "/sysroot/var/roothome/assisted.te"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(6): [finished] writing file "/sysroot/var/roothome/assisted.te"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(7): [started]  writing file "/sysroot/etc/assisted/agent-installer.env"
Jun 06 02:03:22 localhost systemd[1]: Finished Ignition (files).
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(7): [finished] writing file "/sysroot/etc/assisted/agent-installer.env"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(8): [started]  writing file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(8): [finished] writing file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(9): [started]  appending to file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(9): [finished] appending to file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(a): [started]  writing file "/sysroot/etc/motd.d/10-agent-installer"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(a): [finished] writing file "/sysroot/etc/motd.d/10-agent-installer"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(b): [started]  writing file "/sysroot/etc/containers/registries.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(b): [finished] writing file "/sysroot/etc/containers/registries.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(c): [started]  writing file "/sysroot/etc/assisted/extra-manifests/04-accelerated-container-startup-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(c): [finished] writing file "/sysroot/etc/assisted/extra-manifests/04-accelerated-container-startup-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(d): [started]  writing file "/sysroot/etc/systemd/system.conf.d/10-default-env.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(d): [finished] writing file "/sysroot/etc/systemd/system.conf.d/10-default-env.conf"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(e): [started]  writing file "/sysroot/var/usrlocal/bin/common.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(e): [finished] writing file "/sysroot/var/usrlocal/bin/common.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(f): [started]  writing file "/sysroot/var/usrlocal/bin/extract-agent.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(f): [finished] writing file "/sysroot/var/usrlocal/bin/extract-agent.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(10): [started]  writing file "/sysroot/var/usrlocal/bin/get-container-images.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(10): [finished] writing file "/sysroot/var/usrlocal/bin/get-container-images.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(11): [started]  writing file "/sysroot/var/usrlocal/bin/install-status.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(11): [finished] writing file "/sysroot/var/usrlocal/bin/install-status.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(12): [started]  writing file "/sysroot/var/usrlocal/bin/issue_status.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(12): [finished] writing file "/sysroot/var/usrlocal/bin/issue_status.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(13): [started]  writing file "/sysroot/var/usrlocal/bin/set-hostname.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(13): [finished] writing file "/sysroot/var/usrlocal/bin/set-hostname.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(14): [started]  writing file "/sysroot/var/usrlocal/bin/set-node-zero.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(14): [finished] writing file "/sysroot/var/usrlocal/bin/set-node-zero.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(15): [started]  writing file "/sysroot/var/usrlocal/bin/start-agent.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(15): [finished] writing file "/sysroot/var/usrlocal/bin/start-agent.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(16): [started]  writing file "/sysroot/var/usrlocal/bin/start-cluster-installation.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(16): [finished] writing file "/sysroot/var/usrlocal/bin/start-cluster-installation.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(17): [started]  writing file "/sysroot/var/usrlocal/bin/wait-for-assisted-service.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(17): [finished] writing file "/sysroot/var/usrlocal/bin/wait-for-assisted-service.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(18): [started]  writing file "/sysroot/etc/assisted/extra-manifests/enable-crun-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(18): [finished] writing file "/sysroot/etc/assisted/extra-manifests/enable-crun-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(19): [started]  writing file "/sysroot/etc/assisted/extra-manifests/StorageSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(19): [finished] writing file "/sysroot/etc/assisted/extra-manifests/StorageSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1a): [started]  writing file "/sysroot/etc/assisted/extra-manifests/StorageOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1a): [finished] writing file "/sysroot/etc/assisted/extra-manifests/StorageOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1b): [started]  writing file "/sysroot/var/usrlocal/bin/bootstrap-service-record.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1b): [finished] writing file "/sysroot/var/usrlocal/bin/bootstrap-service-record.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1c): [started]  writing file "/sysroot/var/usrlocal/bin/release-image.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1c): [finished] writing file "/sysroot/var/usrlocal/bin/release-image.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1d): [started]  writing file "/sysroot/var/usrlocal/bin/release-image-download.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1d): [finished] writing file "/sysroot/var/usrlocal/bin/release-image-download.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1e): [started]  writing file "/sysroot/etc/assisted/manifests/agent-cluster-install.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1e): [finished] writing file "/sysroot/etc/assisted/manifests/agent-cluster-install.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1f): [started]  writing file "/sysroot/etc/assisted/manifests/cluster-deployment.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1f): [finished] writing file "/sysroot/etc/assisted/manifests/cluster-deployment.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(20): [started]  writing file "/sysroot/etc/assisted/manifests/cluster-image-set.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(20): [finished] writing file "/sysroot/etc/assisted/manifests/cluster-image-set.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(21): [started]  writing file "/sysroot/etc/assisted/manifests/infraenv.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(21): [finished] writing file "/sysroot/etc/assisted/manifests/infraenv.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(22): [started]  writing file "/sysroot/etc/assisted/manifests/nmstateconfig.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(22): [finished] writing file "/sysroot/etc/assisted/manifests/nmstateconfig.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(23): [started]  writing file "/sysroot/etc/assisted/manifests/pull-secret.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(23): [finished] writing file "/sysroot/etc/assisted/manifests/pull-secret.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(24): [started]  writing file "/sysroot/etc/assisted/manifests/agent-config.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(24): [finished] writing file "/sysroot/etc/assisted/manifests/agent-config.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(25): [started]  writing file "/sysroot/etc/assisted/hostnames/b4:96:91:d9:a4:64"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(25): [finished] writing file "/sysroot/etc/assisted/hostnames/b4:96:91:d9:a4:64"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(26): [started]  writing file "/sysroot/etc/assisted/extra-manifests/StorageNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(26): [finished] writing file "/sysroot/etc/assisted/extra-manifests/StorageNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(27): [started]  writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(27): [finished] writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(28): [started]  writing file "/sysroot/var/usrlocal/bin/pre-network-manager-config.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(28): [finished] writing file "/sysroot/var/usrlocal/bin/pre-network-manager-config.sh"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(29): [started]  writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(29): [finished] writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2a): [started]  writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2a): [finished] writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2b): [started]  writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2b): [finished] writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2c): [started]  writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2c): [finished] writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2d): [started]  writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2d): [finished] writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2e): [started]  writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2e): [finished] writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionOperGroup-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2f): [started]  writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2f): [finished] writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionNS-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(30): [started]  writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(30): [finished] writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscription-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(31): [started]  writing file "/sysroot/etc/assisted/extra-manifests/99-crio-disable-wipe-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(31): [finished] writing file "/sysroot/etc/assisted/extra-manifests/99-crio-disable-wipe-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(32): [started]  writing file "/sysroot/var/roothome/.docker/config.json"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(32): [finished] writing file "/sysroot/var/roothome/.docker/config.json"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(33): [started]  writing file "/sysroot/etc/assisted/extra-manifests/06-kdump-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(33): [finished] writing file "/sysroot/etc/assisted/extra-manifests/06-kdump-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(34): [started]  writing file "/sysroot/etc/assisted/extra-manifests/05-kdump-config-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(34): [finished] writing file "/sysroot/etc/assisted/extra-manifests/05-kdump-config-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(35): [started]  writing file "/sysroot/etc/assisted/extra-manifests/01-container-mount-ns-and-kubelet-conf-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(35): [finished] writing file "/sysroot/etc/assisted/extra-manifests/01-container-mount-ns-and-kubelet-conf-master-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(36): [started]  writing file "/sysroot/etc/assisted/extra-manifests/02-master-workload-partitioning-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(36): [finished] writing file "/sysroot/etc/assisted/extra-manifests/02-master-workload-partitioning-0.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(37): [started]  writing file "/sysroot/var/usrlocal/bin/agent-gather"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(37): [finished] writing file "/sysroot/var/usrlocal/bin/agent-gather"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(38): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(38): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(39): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(39): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3a): [started]  writing file "/sysroot/var/opt/agent/tls/kubeadmin-password.hash"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3a): [finished] writing file "/sysroot/var/opt/agent/tls/kubeadmin-password.hash"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3b): [started]  writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3b): [finished] writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3c): [started]  writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/root-device-hints.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3c): [finished] writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/root-device-hints.yaml"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3d): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3d): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3e): [started]  writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/mac_addresses"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3e): [finished] writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/mac_addresses"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3f): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3f): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(40): [started]  writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(40): [finished] writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(41): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(41): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.crt"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(42): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(42): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.key"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(43): [started]  writing file "/sysroot/etc/assisted/network/host0/mac_interface.ini"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(43): [finished] writing file "/sysroot/etc/assisted/network/host0/mac_interface.ini"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(44): [started]  writing file "/sysroot/etc/assisted/network/host0/ens1f0.nmconnection"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(44): [finished] writing file "/sysroot/etc/assisted/network/host0/ens1f0.nmconnection"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(45): [started]  writing file "/sysroot/var/usrlocal/share/assisted-service/images.env"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(45): [finished] writing file "/sysroot/var/usrlocal/share/assisted-service/images.env"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(46): [started]  writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-service.env"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(46): [finished] writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-service.env"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(47): [started]  writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-db.env"
Jun 06 02:03:22 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(47): [finished] writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-db.env"
Jun 06 02:03:22 localhost ignition[1409]: files: op(48): [started]  processing unit "agent-interactive-console.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(48): op(49): [started]  writing unit "agent-interactive-console.service" at "/sysroot/etc/systemd/system/agent-interactive-console.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(48): op(49): [finished] writing unit "agent-interactive-console.service" at "/sysroot/etc/systemd/system/agent-interactive-console.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(48): [finished] processing unit "agent-interactive-console.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4a): [started]  processing unit "agent.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4a): op(4b): [started]  writing unit "agent.service" at "/sysroot/etc/systemd/system/agent.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4a): op(4b): [finished] writing unit "agent.service" at "/sysroot/etc/systemd/system/agent.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4a): [finished] processing unit "agent.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4c): [started]  processing unit "apply-host-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4c): op(4d): [started]  writing unit "apply-host-config.service" at "/sysroot/etc/systemd/system/apply-host-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4c): op(4d): [finished] writing unit "apply-host-config.service" at "/sysroot/etc/systemd/system/apply-host-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4c): [finished] processing unit "apply-host-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4e): [started]  processing unit "assisted-service-db.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4e): op(4f): [started]  writing unit "assisted-service-db.service" at "/sysroot/etc/systemd/system/assisted-service-db.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4e): op(4f): [finished] writing unit "assisted-service-db.service" at "/sysroot/etc/systemd/system/assisted-service-db.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(4e): [finished] processing unit "assisted-service-db.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(50): [started]  processing unit "assisted-service-pod.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(50): op(51): [started]  writing unit "assisted-service-pod.service" at "/sysroot/etc/systemd/system/assisted-service-pod.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(50): op(51): [finished] writing unit "assisted-service-pod.service" at "/sysroot/etc/systemd/system/assisted-service-pod.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(50): [finished] processing unit "assisted-service-pod.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(52): [started]  processing unit "assisted-service.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(52): op(53): [started]  writing unit "assisted-service.service" at "/sysroot/etc/systemd/system/assisted-service.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(52): op(53): [finished] writing unit "assisted-service.service" at "/sysroot/etc/systemd/system/assisted-service.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(52): [finished] processing unit "assisted-service.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(54): [started]  processing unit "create-cluster-and-infraenv.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(54): op(55): [started]  writing unit "create-cluster-and-infraenv.service" at "/sysroot/etc/systemd/system/create-cluster-and-infraenv.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(54): op(55): [finished] writing unit "create-cluster-and-infraenv.service" at "/sysroot/etc/systemd/system/create-cluster-and-infraenv.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(54): [finished] processing unit "create-cluster-and-infraenv.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(56): [started]  processing unit "install-status.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(56): op(57): [started]  writing unit "install-status.service" at "/sysroot/etc/systemd/system/install-status.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(56): op(57): [finished] writing unit "install-status.service" at "/sysroot/etc/systemd/system/install-status.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(56): [finished] processing unit "install-status.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(58): [started]  processing unit "node-zero.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(58): op(59): [started]  writing unit "node-zero.service" at "/sysroot/etc/systemd/system/node-zero.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(58): op(59): [finished] writing unit "node-zero.service" at "/sysroot/etc/systemd/system/node-zero.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(58): [finished] processing unit "node-zero.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5a): [started]  processing unit "pre-network-manager-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5a): op(5b): [started]  writing unit "pre-network-manager-config.service" at "/sysroot/etc/systemd/system/pre-network-manager-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5a): op(5b): [finished] writing unit "pre-network-manager-config.service" at "/sysroot/etc/systemd/system/pre-network-manager-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5a): [finished] processing unit "pre-network-manager-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5c): [started]  processing unit "selinux.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5c): op(5d): [started]  writing unit "selinux.service" at "/sysroot/etc/systemd/system/selinux.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5c): op(5d): [finished] writing unit "selinux.service" at "/sysroot/etc/systemd/system/selinux.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5c): [finished] processing unit "selinux.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5e): [started]  processing unit "set-hostname.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5e): op(5f): [started]  writing unit "set-hostname.service" at "/sysroot/etc/systemd/system/set-hostname.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5e): op(5f): [finished] writing unit "set-hostname.service" at "/sysroot/etc/systemd/system/set-hostname.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(5e): [finished] processing unit "set-hostname.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(60): [started]  processing unit "start-cluster-installation.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(60): op(61): [started]  writing unit "start-cluster-installation.service" at "/sysroot/etc/systemd/system/start-cluster-installation.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(60): op(61): [finished] writing unit "start-cluster-installation.service" at "/sysroot/etc/systemd/system/start-cluster-installation.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(60): [finished] processing unit "start-cluster-installation.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(62): [started]  setting preset to enabled for "agent-interactive-console.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(62): [finished] setting preset to enabled for "agent-interactive-console.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(63): [started]  setting preset to enabled for "agent.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(63): [finished] setting preset to enabled for "agent.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(64): [started]  setting preset to enabled for "assisted-service-db.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(64): [finished] setting preset to enabled for "assisted-service-db.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(65): [started]  setting preset to enabled for "assisted-service-pod.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(65): [finished] setting preset to enabled for "assisted-service-pod.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(66): [started]  setting preset to enabled for "assisted-service.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(66): [finished] setting preset to enabled for "assisted-service.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(67): [started]  setting preset to enabled for "create-cluster-and-infraenv.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(67): [finished] setting preset to enabled for "create-cluster-and-infraenv.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(68): [started]  setting preset to enabled for "install-status.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(68): [finished] setting preset to enabled for "install-status.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(69): [started]  setting preset to enabled for "node-zero.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(69): [finished] setting preset to enabled for "node-zero.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6a): [started]  setting preset to enabled for "pre-network-manager-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6a): [finished] setting preset to enabled for "pre-network-manager-config.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6b): [started]  setting preset to enabled for "selinux.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6b): [finished] setting preset to enabled for "selinux.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6c): [started]  setting preset to enabled for "set-hostname.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6c): [finished] setting preset to enabled for "set-hostname.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6d): [started]  setting preset to enabled for "start-cluster-installation.service"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6d): [finished] setting preset to enabled for "start-cluster-installation.service"
Jun 06 02:03:22 localhost ignition[1409]: files: createResultFile: createFiles: op(6e): [started]  writing file "/sysroot/etc/.ignition-result.json"
Jun 06 02:03:22 localhost ignition[1409]: files: createResultFile: createFiles: op(6e): [finished] writing file "/sysroot/etc/.ignition-result.json"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6f): [started]  relabeling 97 patterns
Jun 06 02:03:22 localhost ignition[1409]: files: op(6f): executing: "setfiles" "-vF0" "-r" "/sysroot" "/sysroot/etc/selinux/targeted/contexts/files/file_contexts" "-f" "-"
Jun 06 02:03:22 localhost ignition[1409]: files: op(6f): [finished] relabeling 97 patterns
Jun 06 02:03:22 localhost ignition[1409]: files: files passed
Jun 06 02:03:22 localhost ignition[1409]: Ignition finished successfully
Jun 06 02:03:27 localhost systemd[1]: Starting CoreOS Post Ignition Checks...
Jun 06 02:03:27 localhost systemd[1]: CoreOS Propagate Multipath Configuration was skipped because of an unmet condition check (ConditionKernelCommandLine=rd.multipath=default).
Jun 06 02:03:27 localhost systemd[1]: Starting Mountpoints Configured in the Real Root...
Jun 06 02:03:28 localhost systemd[1]: Finished CoreOS Post Ignition Checks.
Jun 06 02:03:28 localhost systemd[1]: Reached target Ignition Complete.
Jun 06 02:03:28 localhost multipathd[1266]: exit (signal)
Jun 06 02:03:28 localhost multipathd[1266]: --------shut down-------
Jun 06 02:03:28 localhost systemd[1]: Stopping Device-Mapper Multipath Device Controller...
Jun 06 02:03:28 localhost systemd[1]: multipathd.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped Device-Mapper Multipath Device Controller.
Jun 06 02:03:28 localhost systemd[1]: initrd-parse-etc.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Finished Mountpoints Configured in the Real Root.
Jun 06 02:03:28 localhost systemd[1]: Reached target Initrd File Systems.
Jun 06 02:03:28 localhost systemd[1]: Reached target Initrd Default Target.
Jun 06 02:03:28 localhost systemd[1]: Starting dracut mount hook...
Jun 06 02:03:28 localhost systemd[1]: Finished dracut mount hook.
Jun 06 02:03:28 localhost systemd[1]: Starting dracut pre-pivot and cleanup hook...
Jun 06 02:03:28 localhost dracut-pre-pivot[1553]: 27.335184 | /etc/multipath.conf does not exist, blacklisting all devices.
Jun 06 02:03:28 localhost dracut-pre-pivot[1553]: 27.335195 | You can run "/sbin/mpathconf --enable" to create
Jun 06 02:03:28 localhost dracut-pre-pivot[1553]: 27.335196 | /etc/multipath.conf. See man mpathconf(8) for more details
Jun 06 02:03:28 localhost systemd[1]: Finished dracut pre-pivot and cleanup hook.
Jun 06 02:03:28 localhost systemd[1]: Starting Cleaning Up and Shutting Down Daemons...
Jun 06 02:03:28 localhost systemd[1]: Stopped target Network.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Preparation for Network.
Jun 06 02:03:28 localhost systemd[1]: Stopped target RDMA Hardware.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Remote Encrypted Volumes.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Timer Units.
Jun 06 02:03:28 localhost systemd[1]: dbus.socket: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Closed D-Bus System Message Bus Socket.
Jun 06 02:03:28 localhost systemd[1]: coreos-liveiso-persist-osmet.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped Persist Osmet Files (ISO).
Jun 06 02:03:28 localhost systemd[1]: dracut-pre-pivot.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped dracut pre-pivot and cleanup hook.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Initrd Default Target.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Ignition Complete.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Initrd Root Device.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Initrd /usr File System.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Remote File Systems.
Jun 06 02:03:28 localhost systemd[1]: Stopped target Preparation for Remote File Systems.
Jun 06 02:03:28 localhost systemd[1]: coreos-post-ignition-checks.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped CoreOS Post Ignition Checks.
Jun 06 02:03:28 localhost systemd[1]: coreos-touch-run-agetty.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped CoreOS: Touch /run/agetty.reload.
Jun 06 02:03:28 localhost systemd[1]: dracut-mount.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped dracut mount hook.
Jun 06 02:03:28 localhost systemd[1]: dracut-pre-mount.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped dracut pre-mount hook.
Jun 06 02:03:28 localhost systemd[1]: dracut-initqueue.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped dracut initqueue hook.
Jun 06 02:03:28 localhost systemd[1]: ignition-fetch-offline.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped Ignition (fetch-offline).
Jun 06 02:03:28 localhost systemd[1]: coreos-ignition-setup-user.service: Deactivated successfully.
Jun 06 02:03:28 localhost systemd[1]: Stopped CoreOS Ignition User Config Setup.
Jun 06 02:03:29 localhost systemd[1]: ignition-files.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Ignition (files).
Jun 06 02:03:29 localhost systemd[1]: ignition-ostree-populate-var.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Populate OSTree /var.
Jun 06 02:03:29 localhost systemd[1]: Stopping Ignition (mount)...
Jun 06 02:03:29 localhost ignition[1559]: Ignition 2.15.0
Jun 06 02:03:29 localhost ignition[1559]: Stage: umount
Jun 06 02:03:29 localhost ignition[1559]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:29 localhost ignition[1559]: parsing config with SHA512: ff6a5153be363997e4d5d3ea8cc4048373a457c48c4a5b134a08a30aacd167c1e0f099f0bdf1e24c99ad180628cd02b767b863b5fe3a8fce3fe1886847eb8e2e
Jun 06 02:03:29 localhost ignition[1559]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:29 localhost ignition[1559]: umount: umount passed
Jun 06 02:03:29 localhost ignition[1559]: Ignition finished successfully
Jun 06 02:03:29 localhost systemd[1]: ignition-mount.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Ignition (mount).
Jun 06 02:03:29 localhost systemd[1]: Unmount Live /var if Persistent /var Is Configured was skipped because no trigger condition checks were met.
Jun 06 02:03:29 localhost systemd[1]: Stopping CoreOS Tear Down Initramfs...
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: eno1
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1581]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f0
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1585]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f1
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1589]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f2
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1593]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f3
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1597]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f0
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1601]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f1
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1605]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f2
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1609]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f3
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1613]: RTNETLINK answers: Operation not supported
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: flushing all routing
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: no initramfs hostname information to propagate
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: no networking config is defined in the real root
Jun 06 02:03:29 localhost coreos-teardown-initramfs[1569]: info: skipping propagation of default networking configs
Jun 06 02:03:29 localhost systemd[1]: ignition-disks.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Ignition (disks).
Jun 06 02:03:29 localhost systemd[1]: ignition-kargs.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Ignition (kargs).
Jun 06 02:03:29 localhost systemd[1]: coreos-copy-firstboot-network.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Copy CoreOS Firstboot Networking Config.
Jun 06 02:03:29 localhost systemd[1]: rhcos-fail-boot-for-legacy-luks-config.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped RHCOS Check For Legacy LUKS Configuration.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Basic System.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Path Units.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Slice Units.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Socket Units.
Jun 06 02:03:29 localhost systemd[1]: Stopped target System Initialization.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Local Encrypted Volumes.
Jun 06 02:03:29 localhost systemd[1]: systemd-ask-password-console.path: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Dispatch Password Requests to Console Directory Watch.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Local Encrypted Volumes (Pre).
Jun 06 02:03:29 localhost systemd[1]: clevis-luks-askpass.path: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Forward Password Requests to Clevis Directory Watch.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Local File Systems.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Preparation for Local File Systems.
Jun 06 02:03:29 localhost systemd[1]: Stopped target Swaps.
Jun 06 02:03:29 localhost systemd[1]: Acquire Live PXE rootfs Image was skipped because of an unmet condition check (ConditionKernelCommandLine=!coreos.liveiso).
Jun 06 02:03:29 localhost systemd[1]: rdma-load-modules@rdma.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Load RDMA modules from /etc/rdma/modules/rdma.conf.
Jun 06 02:03:29 localhost systemd[1]: systemd-sysctl.service: Deactivated successfully.
Jun 06 02:03:29 localhost systemd[1]: Stopped Apply Kernel Variables.
Jun 06 02:03:30 localhost systemd[1]: systemd-modules-load.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Load Kernel Modules.
Jun 06 02:03:30 localhost systemd[1]: systemd-tmpfiles-setup.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Create Volatile Files and Directories.
Jun 06 02:03:30 localhost systemd[1]: systemd-udev-settle.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Wait for udev To Complete Device Initialization.
Jun 06 02:03:30 localhost systemd[1]: systemd-udev-trigger.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Coldplug All udev Devices.
Jun 06 02:03:30 localhost systemd[1]: dracut-pre-trigger.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped dracut pre-trigger hook.
Jun 06 02:03:30 localhost systemd[1]: Stopping Rule-based Manager for Device Events and Files...
Jun 06 02:03:30 localhost systemd[1]: run-credentials-systemd\x2dtmpfiles\x2dsetup.service.mount: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: run-credentials-systemd\x2dsysctl.service.mount: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: systemd-udevd.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Rule-based Manager for Device Events and Files.
Jun 06 02:03:30 localhost systemd[1]: systemd-udevd.service: Consumed 6.401s CPU time.
Jun 06 02:03:30 localhost systemd[1]: initrd-cleanup.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Finished Cleaning Up and Shutting Down Daemons.
Jun 06 02:03:30 localhost systemd[1]: coreos-teardown-initramfs.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped CoreOS Tear Down Initramfs.
Jun 06 02:03:30 localhost systemd[1]: systemd-udevd-control.socket: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Closed udev Control Socket.
Jun 06 02:03:30 localhost systemd[1]: systemd-udevd-kernel.socket: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Closed udev Kernel Socket.
Jun 06 02:03:30 localhost systemd[1]: dracut-pre-udev.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped dracut pre-udev hook.
Jun 06 02:03:30 localhost systemd[1]: dracut-cmdline.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped dracut cmdline hook.
Jun 06 02:03:30 localhost systemd[1]: afterburn-network-kargs.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Afterburn Initrd Setup Network Kernel Arguments.
Jun 06 02:03:30 localhost systemd[1]: CoreOS Enable Network was skipped because no trigger condition checks were met.
Jun 06 02:03:30 localhost systemd[1]: dracut-cmdline-ask.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped dracut ask for additional cmdline parameters.
Jun 06 02:03:30 localhost systemd[1]: Starting Cleanup udev Database...
Jun 06 02:03:30 localhost systemd[1]: systemd-tmpfiles-setup-dev.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Create Static Device Nodes in /dev.
Jun 06 02:03:30 localhost systemd[1]: kmod-static-nodes.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Create List of Static Device Nodes.
Jun 06 02:03:30 localhost systemd[1]: systemd-sysusers.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Create System Users.
Jun 06 02:03:30 localhost systemd[1]: systemd-vconsole-setup.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Stopped Setup Virtual Console.
Jun 06 02:03:30 localhost systemd[1]: run-credentials-systemd\x2dtmpfiles\x2dsetup\x2ddev.service.mount: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: run-credentials-systemd\x2dsysusers.service.mount: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: initrd-udevadm-cleanup-db.service: Deactivated successfully.
Jun 06 02:03:30 localhost systemd[1]: Finished Cleanup udev Database.
Jun 06 02:03:30 localhost systemd[1]: Reached target Switch Root.
Jun 06 02:03:30 localhost systemd[1]: Starting Switch Root...
Jun 06 02:03:30 localhost systemd[1]: Switching root.
Jun 06 02:03:30 localhost systemd-journald[773]: Journal stopped
Jun 06 02:03:35 localhost bsdtar[1348]: bsdtar: Failed to set default locale
Jun 06 02:03:35 localhost systemd[1]: Mounted /sysroot.
Jun 06 02:03:35 localhost systemd[1]: Ignition OSTree: Grow Root Filesystem was skipped because of an unmet condition check (ConditionPathExists=!/run/ostree-live).
Jun 06 02:03:35 localhost systemd[1]: Starting OSTree Prepare OS/...
Jun 06 02:03:35 localhost ostree-prepare-root[1353]: preparing sysroot at /sysroot
Jun 06 02:03:35 localhost ostree-prepare-root[1353]: Resolved OSTree target to: /sysroot/ostree/deploy/rhcos/deploy/f069b5aca6a53934461a7361690bd20ad4aa3e223b6d12e77d54dc3ab4f48360.0
Jun 06 02:03:35 localhost ostree-prepare-root[1353]: filesystem at /sysroot currently writable: 0
Jun 06 02:03:35 localhost ostree-prepare-root[1353]: sysroot.readonly configuration value: 0
Jun 06 02:03:35 localhost systemd[1]: sysroot-ostree-deploy-rhcos-deploy-f069b5aca6a53934461a7361690bd20ad4aa3e223b6d12e77d54dc3ab4f48360.0.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: sysroot.tmp-usr.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: sysroot.tmp-boot.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: sysroot.tmp.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: proc-cmdline.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Finished OSTree Prepare OS/.
Jun 06 02:03:35 localhost systemd[1]: Ignition OSTree: Check Root Filesystem Size was skipped because of an unmet condition check (ConditionPathExists=!/run/ostree-live).
Jun 06 02:03:35 localhost systemd[1]: Starting sysroot-xfs-ephemeral-setup.service...
Jun 06 02:03:35 localhost systemd[1]: Finished Persist Osmet Files (ISO).
Jun 06 02:03:35 localhost systemd[1]: Finished sysroot-xfs-ephemeral-setup.service.
Jun 06 02:03:35 localhost systemd[1]: sysroot-etc.mount: Directory /sysroot/etc to mount over is not empty, mounting anyway.
Jun 06 02:03:35 localhost systemd[1]: Mounting /sysroot/etc...
Jun 06 02:03:35 localhost systemd[1]: Mounting /sysroot/var...
Jun 06 02:03:35 localhost systemd[1]: Mounted /sysroot/etc.
Jun 06 02:03:35 localhost systemd[1]: Mounted /sysroot/var.
Jun 06 02:03:35 localhost systemd[1]: Starting sysroot-relabel.service...
Jun 06 02:03:35 localhost systemd[1]: Finished sysroot-relabel.service.
Jun 06 02:03:35 localhost systemd[1]: Reached target Initrd Root File System.
Jun 06 02:03:35 localhost systemd[1]: Afterburn Hostname was skipped because no trigger condition checks were met.
Jun 06 02:03:35 localhost systemd[1]: Mount OSTree /var was skipped because of an unmet condition check (ConditionPathExists=!/run/ostree-live).
Jun 06 02:03:35 localhost systemd[1]: Starting Ignition (mount)...
Jun 06 02:03:35 localhost ignition[1368]: Ignition 2.15.0
Jun 06 02:03:35 localhost ignition[1368]: Stage: mount
Jun 06 02:03:35 localhost ignition[1368]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:35 localhost ignition[1368]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:35 localhost ignition[1368]: mount: mount passed
Jun 06 02:03:35 localhost ignition[1368]: Ignition finished successfully
Jun 06 02:03:35 localhost systemd[1]: Finished Ignition (mount).
Jun 06 02:03:35 localhost systemd[1]: Clear SSSD NSS Cache in Persistent /var was skipped because of an unmet condition check (ConditionPathExists=/sysroot/var/lib/sss/mc).
Jun 06 02:03:35 localhost systemd[1]: Starting Populate OSTree /var...
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1382]: Relabeled /sysroot//var/lib from <no context> to system_u:object_r:var_lib_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1385]: Relabeled /sysroot//var/log from <no context> to system_u:object_r:var_log_t:s0
Jun 06 02:03:35 localhost systemd-tmpfiles[1386]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1386]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1388]: Relabeled /sysroot//var/home from <no context> to system_u:object_r:home_root_t:s0
Jun 06 02:03:35 localhost systemd-tmpfiles[1389]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1389]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome/.bash_logout from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome/.bash_profile from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1392]: Relabeled /sysroot//var/roothome/.bashrc from <no context> to system_u:object_r:admin_home_t:s0
Jun 06 02:03:35 localhost systemd-tmpfiles[1393]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1393]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1396]: Relabeled /sysroot//var/opt from <no context> to system_u:object_r:var_t:s0
Jun 06 02:03:35 localhost systemd-tmpfiles[1397]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1397]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1399]: Relabeled /sysroot//var/srv from <no context> to system_u:object_r:var_t:s0
Jun 06 02:03:35 localhost systemd-tmpfiles[1400]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1400]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/bin from <no context> to system_u:object_r:bin_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/etc from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/games from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/include from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/lib from <no context> to system_u:object_r:lib_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/man from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/sbin from <no context> to system_u:object_r:bin_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/share from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1402]: Relabeled /sysroot//var/usrlocal/src from <no context> to system_u:object_r:usr_t:s0
Jun 06 02:03:35 localhost ignition-ostree-populate-var[1405]: Relabeled /sysroot//var/mnt from <no context> to system_u:object_r:mnt_t:s0
Jun 06 02:03:35 localhost systemd-tmpfiles[1403]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1403]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1406]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd-tmpfiles[1406]: Failed to parse ACL "default:group:tss:rwx": No such file or directory. Ignoring
Jun 06 02:03:35 localhost systemd[1]: Finished Populate OSTree /var.
Jun 06 02:03:35 localhost systemd[1]: Starting Ignition (files)...
Jun 06 02:03:35 localhost ignition[1409]: Ignition 2.15.0
Jun 06 02:03:35 localhost ignition[1409]: Stage: files
Jun 06 02:03:35 localhost ignition[1409]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:35 localhost ignition[1409]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:35 localhost ignition[1409]: files: ensureUsers: op(1): [started]  creating or modifying user "core"
Jun 06 02:03:35 localhost ignition[1409]: files: ensureUsers: op(1): [finished] creating or modifying user "core"
Jun 06 02:03:35 localhost ignition[1409]: files: ensureUsers: op(2): [started]  setting password for "core"
Jun 06 02:03:35 localhost ignition[1409]: wrote ssh authorized keys file for user: core
Jun 06 02:03:35 localhost ignition[1409]: files: ensureUsers: op(2): [finished] setting password for "core"
Jun 06 02:03:35 localhost ignition[1409]: files: ensureUsers: op(3): [started]  adding ssh keys to user "core"
Jun 06 02:03:35 localhost ignition[1409]: files: ensureUsers: op(3): [finished] adding ssh keys to user "core"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(4): [started]  writing file "/sysroot/etc/issue"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(4): [finished] writing file "/sysroot/etc/issue"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(5): [started]  writing file "/sysroot/etc/multipath.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(5): [finished] writing file "/sysroot/etc/multipath.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(6): [started]  writing file "/sysroot/var/roothome/assisted.te"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(6): [finished] writing file "/sysroot/var/roothome/assisted.te"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(7): [started]  writing file "/sysroot/etc/assisted/agent-installer.env"
Jun 06 02:03:35 localhost systemd[1]: Finished Ignition (files).
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(7): [finished] writing file "/sysroot/etc/assisted/agent-installer.env"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(8): [started]  writing file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(8): [finished] writing file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(9): [started]  appending to file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(9): [finished] appending to file "/sysroot/etc/containers/containers.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(a): [started]  writing file "/sysroot/etc/motd.d/10-agent-installer"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(a): [finished] writing file "/sysroot/etc/motd.d/10-agent-installer"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(b): [started]  writing file "/sysroot/etc/containers/registries.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(b): [finished] writing file "/sysroot/etc/containers/registries.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(c): [started]  writing file "/sysroot/etc/assisted/extra-manifests/04-accelerated-container-startup-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(c): [finished] writing file "/sysroot/etc/assisted/extra-manifests/04-accelerated-container-startup-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(d): [started]  writing file "/sysroot/etc/systemd/system.conf.d/10-default-env.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(d): [finished] writing file "/sysroot/etc/systemd/system.conf.d/10-default-env.conf"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(e): [started]  writing file "/sysroot/var/usrlocal/bin/common.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(e): [finished] writing file "/sysroot/var/usrlocal/bin/common.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(f): [started]  writing file "/sysroot/var/usrlocal/bin/extract-agent.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(f): [finished] writing file "/sysroot/var/usrlocal/bin/extract-agent.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(10): [started]  writing file "/sysroot/var/usrlocal/bin/get-container-images.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(10): [finished] writing file "/sysroot/var/usrlocal/bin/get-container-images.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(11): [started]  writing file "/sysroot/var/usrlocal/bin/install-status.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(11): [finished] writing file "/sysroot/var/usrlocal/bin/install-status.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(12): [started]  writing file "/sysroot/var/usrlocal/bin/issue_status.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(12): [finished] writing file "/sysroot/var/usrlocal/bin/issue_status.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(13): [started]  writing file "/sysroot/var/usrlocal/bin/set-hostname.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(13): [finished] writing file "/sysroot/var/usrlocal/bin/set-hostname.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(14): [started]  writing file "/sysroot/var/usrlocal/bin/set-node-zero.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(14): [finished] writing file "/sysroot/var/usrlocal/bin/set-node-zero.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(15): [started]  writing file "/sysroot/var/usrlocal/bin/start-agent.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(15): [finished] writing file "/sysroot/var/usrlocal/bin/start-agent.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(16): [started]  writing file "/sysroot/var/usrlocal/bin/start-cluster-installation.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(16): [finished] writing file "/sysroot/var/usrlocal/bin/start-cluster-installation.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(17): [started]  writing file "/sysroot/var/usrlocal/bin/wait-for-assisted-service.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(17): [finished] writing file "/sysroot/var/usrlocal/bin/wait-for-assisted-service.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(18): [started]  writing file "/sysroot/etc/assisted/extra-manifests/enable-crun-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(18): [finished] writing file "/sysroot/etc/assisted/extra-manifests/enable-crun-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(19): [started]  writing file "/sysroot/etc/assisted/extra-manifests/StorageSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(19): [finished] writing file "/sysroot/etc/assisted/extra-manifests/StorageSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1a): [started]  writing file "/sysroot/etc/assisted/extra-manifests/StorageOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1a): [finished] writing file "/sysroot/etc/assisted/extra-manifests/StorageOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1b): [started]  writing file "/sysroot/var/usrlocal/bin/bootstrap-service-record.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1b): [finished] writing file "/sysroot/var/usrlocal/bin/bootstrap-service-record.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1c): [started]  writing file "/sysroot/var/usrlocal/bin/release-image.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1c): [finished] writing file "/sysroot/var/usrlocal/bin/release-image.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1d): [started]  writing file "/sysroot/var/usrlocal/bin/release-image-download.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1d): [finished] writing file "/sysroot/var/usrlocal/bin/release-image-download.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1e): [started]  writing file "/sysroot/etc/assisted/manifests/agent-cluster-install.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1e): [finished] writing file "/sysroot/etc/assisted/manifests/agent-cluster-install.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1f): [started]  writing file "/sysroot/etc/assisted/manifests/cluster-deployment.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(1f): [finished] writing file "/sysroot/etc/assisted/manifests/cluster-deployment.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(20): [started]  writing file "/sysroot/etc/assisted/manifests/cluster-image-set.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(20): [finished] writing file "/sysroot/etc/assisted/manifests/cluster-image-set.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(21): [started]  writing file "/sysroot/etc/assisted/manifests/infraenv.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(21): [finished] writing file "/sysroot/etc/assisted/manifests/infraenv.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(22): [started]  writing file "/sysroot/etc/assisted/manifests/nmstateconfig.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(22): [finished] writing file "/sysroot/etc/assisted/manifests/nmstateconfig.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(23): [started]  writing file "/sysroot/etc/assisted/manifests/pull-secret.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(23): [finished] writing file "/sysroot/etc/assisted/manifests/pull-secret.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(24): [started]  writing file "/sysroot/etc/assisted/manifests/agent-config.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(24): [finished] writing file "/sysroot/etc/assisted/manifests/agent-config.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(25): [started]  writing file "/sysroot/etc/assisted/hostnames/b4:96:91:d9:a4:64"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(25): [finished] writing file "/sysroot/etc/assisted/hostnames/b4:96:91:d9:a4:64"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(26): [started]  writing file "/sysroot/etc/assisted/extra-manifests/StorageNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(26): [finished] writing file "/sysroot/etc/assisted/extra-manifests/StorageNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(27): [started]  writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(27): [finished] writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(28): [started]  writing file "/sysroot/var/usrlocal/bin/pre-network-manager-config.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(28): [finished] writing file "/sysroot/var/usrlocal/bin/pre-network-manager-config.sh"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(29): [started]  writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(29): [finished] writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscriptionNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2a): [started]  writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2a): [finished] writing file "/sysroot/etc/assisted/extra-manifests/SriovSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2b): [started]  writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2b): [finished] writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2c): [started]  writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2c): [finished] writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscriptionNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2d): [started]  writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2d): [finished] writing file "/sysroot/etc/assisted/extra-manifests/PtpSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2e): [started]  writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2e): [finished] writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionOperGroup-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2f): [started]  writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(2f): [finished] writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscriptionNS-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(30): [started]  writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(30): [finished] writing file "/sysroot/etc/assisted/extra-manifests/AmqSubscription-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(31): [started]  writing file "/sysroot/etc/assisted/extra-manifests/99-crio-disable-wipe-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(31): [finished] writing file "/sysroot/etc/assisted/extra-manifests/99-crio-disable-wipe-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(32): [started]  writing file "/sysroot/var/roothome/.docker/config.json"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(32): [finished] writing file "/sysroot/var/roothome/.docker/config.json"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(33): [started]  writing file "/sysroot/etc/assisted/extra-manifests/06-kdump-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(33): [finished] writing file "/sysroot/etc/assisted/extra-manifests/06-kdump-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(34): [started]  writing file "/sysroot/etc/assisted/extra-manifests/05-kdump-config-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(34): [finished] writing file "/sysroot/etc/assisted/extra-manifests/05-kdump-config-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(35): [started]  writing file "/sysroot/etc/assisted/extra-manifests/01-container-mount-ns-and-kubelet-conf-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(35): [finished] writing file "/sysroot/etc/assisted/extra-manifests/01-container-mount-ns-and-kubelet-conf-master-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(36): [started]  writing file "/sysroot/etc/assisted/extra-manifests/02-master-workload-partitioning-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(36): [finished] writing file "/sysroot/etc/assisted/extra-manifests/02-master-workload-partitioning-0.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(37): [started]  writing file "/sysroot/var/usrlocal/bin/agent-gather"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(37): [finished] writing file "/sysroot/var/usrlocal/bin/agent-gather"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(38): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(38): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(39): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(39): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3a): [started]  writing file "/sysroot/var/opt/agent/tls/kubeadmin-password.hash"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3a): [finished] writing file "/sysroot/var/opt/agent/tls/kubeadmin-password.hash"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3b): [started]  writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3b): [finished] writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3c): [started]  writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/root-device-hints.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3c): [finished] writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/root-device-hints.yaml"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3d): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3d): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-service-network-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3e): [started]  writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/mac_addresses"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3e): [finished] writing file "/sysroot/etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab/mac_addresses"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3f): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(3f): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-localhost-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(40): [started]  writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(40): [finished] writing file "/sysroot/var/opt/agent/tls/admin-kubeconfig-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(41): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(41): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.crt"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(42): [started]  writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(42): [finished] writing file "/sysroot/var/opt/agent/tls/kube-apiserver-lb-signer.key"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(43): [started]  writing file "/sysroot/etc/assisted/network/host0/mac_interface.ini"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(43): [finished] writing file "/sysroot/etc/assisted/network/host0/mac_interface.ini"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(44): [started]  writing file "/sysroot/etc/assisted/network/host0/ens1f0.nmconnection"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(44): [finished] writing file "/sysroot/etc/assisted/network/host0/ens1f0.nmconnection"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(45): [started]  writing file "/sysroot/var/usrlocal/share/assisted-service/images.env"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(45): [finished] writing file "/sysroot/var/usrlocal/share/assisted-service/images.env"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(46): [started]  writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-service.env"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(46): [finished] writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-service.env"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(47): [started]  writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-db.env"
Jun 06 02:03:35 localhost ignition[1409]: files: createFilesystemsFiles: createFiles: op(47): [finished] writing file "/sysroot/var/usrlocal/share/assisted-service/assisted-db.env"
Jun 06 02:03:35 localhost ignition[1409]: files: op(48): [started]  processing unit "agent-interactive-console.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(48): op(49): [started]  writing unit "agent-interactive-console.service" at "/sysroot/etc/systemd/system/agent-interactive-console.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(48): op(49): [finished] writing unit "agent-interactive-console.service" at "/sysroot/etc/systemd/system/agent-interactive-console.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(48): [finished] processing unit "agent-interactive-console.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4a): [started]  processing unit "agent.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4a): op(4b): [started]  writing unit "agent.service" at "/sysroot/etc/systemd/system/agent.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4a): op(4b): [finished] writing unit "agent.service" at "/sysroot/etc/systemd/system/agent.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4a): [finished] processing unit "agent.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4c): [started]  processing unit "apply-host-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4c): op(4d): [started]  writing unit "apply-host-config.service" at "/sysroot/etc/systemd/system/apply-host-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4c): op(4d): [finished] writing unit "apply-host-config.service" at "/sysroot/etc/systemd/system/apply-host-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4c): [finished] processing unit "apply-host-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4e): [started]  processing unit "assisted-service-db.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4e): op(4f): [started]  writing unit "assisted-service-db.service" at "/sysroot/etc/systemd/system/assisted-service-db.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4e): op(4f): [finished] writing unit "assisted-service-db.service" at "/sysroot/etc/systemd/system/assisted-service-db.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(4e): [finished] processing unit "assisted-service-db.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(50): [started]  processing unit "assisted-service-pod.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(50): op(51): [started]  writing unit "assisted-service-pod.service" at "/sysroot/etc/systemd/system/assisted-service-pod.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(50): op(51): [finished] writing unit "assisted-service-pod.service" at "/sysroot/etc/systemd/system/assisted-service-pod.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(50): [finished] processing unit "assisted-service-pod.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(52): [started]  processing unit "assisted-service.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(52): op(53): [started]  writing unit "assisted-service.service" at "/sysroot/etc/systemd/system/assisted-service.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(52): op(53): [finished] writing unit "assisted-service.service" at "/sysroot/etc/systemd/system/assisted-service.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(52): [finished] processing unit "assisted-service.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(54): [started]  processing unit "create-cluster-and-infraenv.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(54): op(55): [started]  writing unit "create-cluster-and-infraenv.service" at "/sysroot/etc/systemd/system/create-cluster-and-infraenv.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(54): op(55): [finished] writing unit "create-cluster-and-infraenv.service" at "/sysroot/etc/systemd/system/create-cluster-and-infraenv.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(54): [finished] processing unit "create-cluster-and-infraenv.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(56): [started]  processing unit "install-status.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(56): op(57): [started]  writing unit "install-status.service" at "/sysroot/etc/systemd/system/install-status.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(56): op(57): [finished] writing unit "install-status.service" at "/sysroot/etc/systemd/system/install-status.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(56): [finished] processing unit "install-status.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(58): [started]  processing unit "node-zero.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(58): op(59): [started]  writing unit "node-zero.service" at "/sysroot/etc/systemd/system/node-zero.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(58): op(59): [finished] writing unit "node-zero.service" at "/sysroot/etc/systemd/system/node-zero.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(58): [finished] processing unit "node-zero.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5a): [started]  processing unit "pre-network-manager-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5a): op(5b): [started]  writing unit "pre-network-manager-config.service" at "/sysroot/etc/systemd/system/pre-network-manager-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5a): op(5b): [finished] writing unit "pre-network-manager-config.service" at "/sysroot/etc/systemd/system/pre-network-manager-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5a): [finished] processing unit "pre-network-manager-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5c): [started]  processing unit "selinux.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5c): op(5d): [started]  writing unit "selinux.service" at "/sysroot/etc/systemd/system/selinux.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5c): op(5d): [finished] writing unit "selinux.service" at "/sysroot/etc/systemd/system/selinux.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5c): [finished] processing unit "selinux.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5e): [started]  processing unit "set-hostname.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5e): op(5f): [started]  writing unit "set-hostname.service" at "/sysroot/etc/systemd/system/set-hostname.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5e): op(5f): [finished] writing unit "set-hostname.service" at "/sysroot/etc/systemd/system/set-hostname.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(5e): [finished] processing unit "set-hostname.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(60): [started]  processing unit "start-cluster-installation.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(60): op(61): [started]  writing unit "start-cluster-installation.service" at "/sysroot/etc/systemd/system/start-cluster-installation.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(60): op(61): [finished] writing unit "start-cluster-installation.service" at "/sysroot/etc/systemd/system/start-cluster-installation.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(60): [finished] processing unit "start-cluster-installation.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(62): [started]  setting preset to enabled for "agent-interactive-console.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(62): [finished] setting preset to enabled for "agent-interactive-console.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(63): [started]  setting preset to enabled for "agent.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(63): [finished] setting preset to enabled for "agent.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(64): [started]  setting preset to enabled for "assisted-service-db.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(64): [finished] setting preset to enabled for "assisted-service-db.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(65): [started]  setting preset to enabled for "assisted-service-pod.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(65): [finished] setting preset to enabled for "assisted-service-pod.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(66): [started]  setting preset to enabled for "assisted-service.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(66): [finished] setting preset to enabled for "assisted-service.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(67): [started]  setting preset to enabled for "create-cluster-and-infraenv.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(67): [finished] setting preset to enabled for "create-cluster-and-infraenv.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(68): [started]  setting preset to enabled for "install-status.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(68): [finished] setting preset to enabled for "install-status.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(69): [started]  setting preset to enabled for "node-zero.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(69): [finished] setting preset to enabled for "node-zero.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6a): [started]  setting preset to enabled for "pre-network-manager-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6a): [finished] setting preset to enabled for "pre-network-manager-config.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6b): [started]  setting preset to enabled for "selinux.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6b): [finished] setting preset to enabled for "selinux.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6c): [started]  setting preset to enabled for "set-hostname.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6c): [finished] setting preset to enabled for "set-hostname.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6d): [started]  setting preset to enabled for "start-cluster-installation.service"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6d): [finished] setting preset to enabled for "start-cluster-installation.service"
Jun 06 02:03:35 localhost ignition[1409]: files: createResultFile: createFiles: op(6e): [started]  writing file "/sysroot/etc/.ignition-result.json"
Jun 06 02:03:35 localhost ignition[1409]: files: createResultFile: createFiles: op(6e): [finished] writing file "/sysroot/etc/.ignition-result.json"
Jun 06 02:03:35 localhost ignition[1409]: files: op(6f): [started]  relabeling 97 patterns
Jun 06 02:03:35 localhost ignition[1409]: files: op(6f): [finished] relabeling 97 patterns
Jun 06 02:03:35 localhost ignition[1409]: files: files passed
Jun 06 02:03:35 localhost ignition[1409]: Ignition finished successfully
Jun 06 02:03:35 localhost systemd[1]: Starting CoreOS Post Ignition Checks...
Jun 06 02:03:35 localhost systemd[1]: CoreOS Propagate Multipath Configuration was skipped because of an unmet condition check (ConditionKernelCommandLine=rd.multipath=default).
Jun 06 02:03:35 localhost systemd[1]: Starting Mountpoints Configured in the Real Root...
Jun 06 02:03:35 localhost systemd[1]: Finished CoreOS Post Ignition Checks.
Jun 06 02:03:35 localhost systemd[1]: Reached target Ignition Complete.
Jun 06 02:03:35 localhost multipathd[1266]: exit (signal)
Jun 06 02:03:35 localhost multipathd[1266]: --------shut down-------
Jun 06 02:03:35 localhost systemd[1]: Stopping Device-Mapper Multipath Device Controller...
Jun 06 02:03:35 localhost systemd[1]: multipathd.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Device-Mapper Multipath Device Controller.
Jun 06 02:03:35 localhost systemd[1]: initrd-parse-etc.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Finished Mountpoints Configured in the Real Root.
Jun 06 02:03:35 localhost systemd[1]: Reached target Initrd File Systems.
Jun 06 02:03:35 localhost systemd[1]: Reached target Initrd Default Target.
Jun 06 02:03:35 localhost systemd[1]: Starting dracut mount hook...
Jun 06 02:03:35 localhost systemd[1]: Finished dracut mount hook.
Jun 06 02:03:35 localhost systemd[1]: Starting dracut pre-pivot and cleanup hook...
Jun 06 02:03:35 localhost dracut-pre-pivot[1553]: 27.335184 | /etc/multipath.conf does not exist, blacklisting all devices.
Jun 06 02:03:35 localhost dracut-pre-pivot[1553]: 27.335195 | You can run "/sbin/mpathconf --enable" to create
Jun 06 02:03:35 localhost dracut-pre-pivot[1553]: 27.335196 | /etc/multipath.conf. See man mpathconf(8) for more details
Jun 06 02:03:35 localhost systemd[1]: Finished dracut pre-pivot and cleanup hook.
Jun 06 02:03:35 localhost systemd[1]: Starting Cleaning Up and Shutting Down Daemons...
Jun 06 02:03:35 localhost systemd[1]: Stopped target Network.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Preparation for Network.
Jun 06 02:03:35 localhost systemd[1]: Stopped target RDMA Hardware.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Remote Encrypted Volumes.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Timer Units.
Jun 06 02:03:35 localhost systemd[1]: dbus.socket: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Closed D-Bus System Message Bus Socket.
Jun 06 02:03:35 localhost systemd[1]: coreos-liveiso-persist-osmet.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Persist Osmet Files (ISO).
Jun 06 02:03:35 localhost systemd[1]: dracut-pre-pivot.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut pre-pivot and cleanup hook.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Initrd Default Target.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Ignition Complete.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Initrd Root Device.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Initrd /usr File System.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Remote File Systems.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Preparation for Remote File Systems.
Jun 06 02:03:35 localhost systemd[1]: coreos-post-ignition-checks.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped CoreOS Post Ignition Checks.
Jun 06 02:03:35 localhost systemd[1]: coreos-touch-run-agetty.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped CoreOS: Touch /run/agetty.reload.
Jun 06 02:03:35 localhost systemd[1]: dracut-mount.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut mount hook.
Jun 06 02:03:35 localhost systemd[1]: dracut-pre-mount.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut pre-mount hook.
Jun 06 02:03:35 localhost systemd[1]: dracut-initqueue.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut initqueue hook.
Jun 06 02:03:35 localhost systemd[1]: ignition-fetch-offline.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Ignition (fetch-offline).
Jun 06 02:03:35 localhost systemd[1]: coreos-ignition-setup-user.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped CoreOS Ignition User Config Setup.
Jun 06 02:03:35 localhost systemd[1]: ignition-files.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Ignition (files).
Jun 06 02:03:35 localhost systemd[1]: ignition-ostree-populate-var.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Populate OSTree /var.
Jun 06 02:03:35 localhost systemd[1]: Stopping Ignition (mount)...
Jun 06 02:03:35 localhost ignition[1559]: Ignition 2.15.0
Jun 06 02:03:35 localhost ignition[1559]: Stage: umount
Jun 06 02:03:35 localhost ignition[1559]: reading system config file "/usr/lib/ignition/base.d/00-core.ign"
Jun 06 02:03:35 localhost ignition[1559]: no config dir at "/usr/lib/ignition/base.platform.d/metal"
Jun 06 02:03:35 localhost ignition[1559]: umount: umount passed
Jun 06 02:03:35 localhost ignition[1559]: Ignition finished successfully
Jun 06 02:03:35 localhost systemd[1]: ignition-mount.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Ignition (mount).
Jun 06 02:03:35 localhost systemd[1]: Unmount Live /var if Persistent /var Is Configured was skipped because no trigger condition checks were met.
Jun 06 02:03:35 localhost systemd[1]: Stopping CoreOS Tear Down Initramfs...
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: eno1
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1581]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f0
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1585]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f1
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1589]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f2
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1593]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens1f3
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1597]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f0
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1601]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f1
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1605]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f2
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1609]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: taking down network device: ens2f3
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1613]: RTNETLINK answers: Operation not supported
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: flushing all routing
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: no initramfs hostname information to propagate
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: no networking config is defined in the real root
Jun 06 02:03:35 localhost coreos-teardown-initramfs[1569]: info: skipping propagation of default networking configs
Jun 06 02:03:35 localhost systemd[1]: ignition-disks.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Ignition (disks).
Jun 06 02:03:35 localhost systemd[1]: ignition-kargs.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Ignition (kargs).
Jun 06 02:03:35 localhost systemd[1]: coreos-copy-firstboot-network.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Copy CoreOS Firstboot Networking Config.
Jun 06 02:03:35 localhost systemd[1]: rhcos-fail-boot-for-legacy-luks-config.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped RHCOS Check For Legacy LUKS Configuration.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Basic System.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Path Units.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Slice Units.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Socket Units.
Jun 06 02:03:35 localhost systemd[1]: Stopped target System Initialization.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Local Encrypted Volumes.
Jun 06 02:03:35 localhost systemd[1]: systemd-ask-password-console.path: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Dispatch Password Requests to Console Directory Watch.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Local Encrypted Volumes (Pre).
Jun 06 02:03:35 localhost systemd[1]: clevis-luks-askpass.path: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Forward Password Requests to Clevis Directory Watch.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Local File Systems.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Preparation for Local File Systems.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Swaps.
Jun 06 02:03:35 localhost systemd[1]: Acquire Live PXE rootfs Image was skipped because of an unmet condition check (ConditionKernelCommandLine=!coreos.liveiso).
Jun 06 02:03:35 localhost systemd[1]: rdma-load-modules@rdma.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Load RDMA modules from /etc/rdma/modules/rdma.conf.
Jun 06 02:03:35 localhost systemd[1]: systemd-sysctl.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Apply Kernel Variables.
Jun 06 02:03:35 localhost systemd[1]: systemd-modules-load.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Load Kernel Modules.
Jun 06 02:03:35 localhost systemd[1]: systemd-tmpfiles-setup.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Create Volatile Files and Directories.
Jun 06 02:03:35 localhost systemd[1]: systemd-udev-settle.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Wait for udev To Complete Device Initialization.
Jun 06 02:03:35 localhost systemd[1]: systemd-udev-trigger.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Coldplug All udev Devices.
Jun 06 02:03:35 localhost systemd[1]: dracut-pre-trigger.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut pre-trigger hook.
Jun 06 02:03:35 localhost systemd[1]: Stopping Rule-based Manager for Device Events and Files...
Jun 06 02:03:35 localhost systemd[1]: run-credentials-systemd\x2dtmpfiles\x2dsetup.service.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: run-credentials-systemd\x2dsysctl.service.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: systemd-udevd.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Rule-based Manager for Device Events and Files.
Jun 06 02:03:35 localhost systemd[1]: systemd-udevd.service: Consumed 6.401s CPU time.
Jun 06 02:03:35 localhost systemd[1]: initrd-cleanup.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Finished Cleaning Up and Shutting Down Daemons.
Jun 06 02:03:35 localhost systemd[1]: coreos-teardown-initramfs.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped CoreOS Tear Down Initramfs.
Jun 06 02:03:35 localhost systemd[1]: systemd-udevd-control.socket: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Closed udev Control Socket.
Jun 06 02:03:35 localhost systemd[1]: systemd-udevd-kernel.socket: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Closed udev Kernel Socket.
Jun 06 02:03:35 localhost systemd[1]: dracut-pre-udev.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut pre-udev hook.
Jun 06 02:03:35 localhost systemd[1]: dracut-cmdline.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut cmdline hook.
Jun 06 02:03:35 localhost systemd[1]: afterburn-network-kargs.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Afterburn Initrd Setup Network Kernel Arguments.
Jun 06 02:03:35 localhost systemd[1]: CoreOS Enable Network was skipped because no trigger condition checks were met.
Jun 06 02:03:35 localhost systemd[1]: dracut-cmdline-ask.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped dracut ask for additional cmdline parameters.
Jun 06 02:03:35 localhost systemd[1]: Starting Cleanup udev Database...
Jun 06 02:03:35 localhost systemd[1]: systemd-tmpfiles-setup-dev.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Create Static Device Nodes in /dev.
Jun 06 02:03:35 localhost systemd[1]: kmod-static-nodes.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Create List of Static Device Nodes.
Jun 06 02:03:35 localhost systemd[1]: systemd-sysusers.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Create System Users.
Jun 06 02:03:35 localhost systemd[1]: systemd-vconsole-setup.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Setup Virtual Console.
Jun 06 02:03:35 localhost systemd[1]: run-credentials-systemd\x2dtmpfiles\x2dsetup\x2ddev.service.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: run-credentials-systemd\x2dsysusers.service.mount: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: initrd-udevadm-cleanup-db.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Finished Cleanup udev Database.
Jun 06 02:03:35 localhost systemd[1]: Reached target Switch Root.
Jun 06 02:03:35 localhost systemd[1]: Starting Switch Root...
Jun 06 02:03:35 localhost systemd[1]: Switching root.
Jun 06 02:03:35 localhost systemd-journald[773]: Received SIGTERM from PID 1 (systemd).
Jun 06 02:03:35 localhost kernel: audit: type=1404 audit(1686017011.699:2): enforcing=1 old_enforcing=0 auid=4294967295 ses=4294967295 enabled=1 old-enabled=1 lsm=selinux res=1
Jun 06 02:03:35 localhost kernel: SELinux:  policy capability network_peer_controls=1
Jun 06 02:03:35 localhost kernel: SELinux:  policy capability open_perms=1
Jun 06 02:03:35 localhost kernel: SELinux:  policy capability extended_socket_class=1
Jun 06 02:03:35 localhost kernel: SELinux:  policy capability always_check_network=0
Jun 06 02:03:35 localhost kernel: SELinux:  policy capability cgroup_seclabel=1
Jun 06 02:03:35 localhost kernel: SELinux:  policy capability nnp_nosuid_transition=1
Jun 06 02:03:35 localhost kernel: SELinux:  policy capability genfs_seclabel_symlinks=1
Jun 06 02:03:35 localhost kernel: audit: type=1403 audit(1686017011.897:3): auid=4294967295 ses=4294967295 lsm=selinux res=1
Jun 06 02:03:35 localhost systemd[1]: Successfully loaded SELinux policy in 200.299ms.
Jun 06 02:03:35 localhost systemd[1]: Relabelled /dev, /dev/shm, /run, /sys/fs/cgroup in 23.577ms.
Jun 06 02:03:35 localhost systemd[1]: Configuration file /etc/systemd/system.conf.d/10-default-env.conf is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
Jun 06 02:03:35 localhost systemd[1]: systemd 252-14.el9.rhaos4.13 running in system mode (+PAM +AUDIT +SELINUX -APPARMOR +IMA +SMACK +SECCOMP +GCRYPT +GNUTLS +OPENSSL +ACL +BLKID +CURL +ELFUTILS -FIDO2 +IDN2 -IDN -IPTC +KMOD +LIBCRYPTSETUP +LIBFDISK +PCRE2 -PWQUALITY +P11KIT -QRENCODE +TPM2 +BZIP2 +LZ4 +XZ +ZLIB +ZSTD -BPF_FRAMEWORK +XKBCOMMON +UTMP +SYSVINIT default-hierarchy=unified)
Jun 06 02:03:35 localhost systemd[1]: Detected architecture x86-64.
Jun 06 02:03:35 localhost systemd[1]: Detected first boot.
Jun 06 02:03:35 localhost systemd[1]: Initializing machine ID from random generator.
Jun 06 02:03:35 localhost systemd-rc-local-generator[1671]: /etc/rc.d/rc.local is not marked executable, skipping.
Jun 06 02:03:35 localhost systemd[1]: Populated /etc with preset unit settings.
Jun 06 02:03:35 localhost systemd[1]: initrd-switch-root.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped Switch Root.
Jun 06 02:03:35 localhost systemd[1]: systemd-journald.service: Scheduled restart job, restart counter is at 1.
Jun 06 02:03:35 localhost systemd[1]: Created slice Slice /system/getty.
Jun 06 02:03:35 localhost systemd[1]: Created slice Slice /system/modprobe.
Jun 06 02:03:35 localhost systemd[1]: Created slice Slice /system/sshd-keygen.
Jun 06 02:03:35 localhost systemd[1]: Created slice User and Session Slice.
Jun 06 02:03:35 localhost systemd[1]: Started Forward Password Requests to Clevis Directory Watch.
Jun 06 02:03:35 localhost systemd[1]: Started Dispatch Password Requests to Console Directory Watch.
Jun 06 02:03:35 localhost systemd[1]: Started Forward Password Requests to Wall Directory Watch.
Jun 06 02:03:35 localhost systemd[1]: Set up automount Arbitrary Executable File Formats File System Automount Point.
Jun 06 02:03:35 localhost systemd[1]: Reached target Synchronize afterburn-sshkeys@.service template instances.
Jun 06 02:03:35 localhost systemd[1]: Reached target Local Encrypted Volumes (Pre).
Jun 06 02:03:35 localhost systemd[1]: Reached target Local Encrypted Volumes.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Switch Root.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Initrd File Systems.
Jun 06 02:03:35 localhost systemd[1]: Stopped target Initrd Root File System.
Jun 06 02:03:35 localhost systemd[1]: Reached target Local Integrity Protected Volumes.
Jun 06 02:03:35 localhost systemd[1]: Reached target Path Units.
Jun 06 02:03:35 localhost systemd[1]: Reached target Slice Units.
Jun 06 02:03:35 localhost systemd[1]: Reached target Swaps.
Jun 06 02:03:35 localhost systemd[1]: Reached target Local Verity Protected Volumes.
Jun 06 02:03:35 localhost systemd[1]: Listening on Device-mapper event daemon FIFOs.
Jun 06 02:03:35 localhost systemd[1]: Listening on LVM2 poll daemon socket.
Jun 06 02:03:35 localhost systemd[1]: Listening on multipathd control socket.
Jun 06 02:03:35 localhost systemd[1]: Listening on Process Core Dump Socket.
Jun 06 02:03:35 localhost systemd[1]: Listening on initctl Compatibility Named Pipe.
Jun 06 02:03:35 localhost systemd[1]: Listening on udev Control Socket.
Jun 06 02:03:35 localhost systemd[1]: Listening on udev Kernel Socket.
Jun 06 02:03:35 localhost systemd[1]: Mounting Huge Pages File System...
Jun 06 02:03:35 localhost systemd[1]: Mounting POSIX Message Queue File System...
Jun 06 02:03:35 localhost systemd[1]: Mounting Kernel Debug File System...
Jun 06 02:03:35 localhost systemd[1]: Mounting Kernel Trace File System...
Jun 06 02:03:35 localhost systemd[1]: Mounting Temporary Directory /tmp...
Jun 06 02:03:35 localhost systemd[1]: Starting CoreOS: Set printk To Level 4 (warn)...
Jun 06 02:03:35 localhost systemd[1]: Ignition (delete config) was skipped because no trigger condition checks were met.
Jun 06 02:03:35 localhost systemd[1]: Starting Create List of Static Device Nodes...
Jun 06 02:03:35 localhost systemd[1]: Starting Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling...
Jun 06 02:03:35 localhost systemd[1]: Starting Load Kernel Module configfs...
Jun 06 02:03:35 localhost systemd[1]: Starting Load Kernel Module drm...
Jun 06 02:03:35 localhost systemd[1]: Starting Load Kernel Module efi_pstore...
Jun 06 02:03:35 localhost systemd[1]: Starting Load Kernel Module fuse...
Jun 06 02:03:35 localhost systemd[1]: ostree-prepare-root.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped OSTree Prepare OS/.
Jun 06 02:03:35 localhost systemd[1]: sysroot-relabel.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped sysroot-relabel.service.
Jun 06 02:03:35 localhost systemd[1]: sysroot-xfs-ephemeral-mkfs.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped sysroot-xfs-ephemeral-mkfs.service.
Jun 06 02:03:35 localhost systemd[1]: sysroot-xfs-ephemeral-setup.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Stopped sysroot-xfs-ephemeral-setup.service.
Jun 06 02:03:35 localhost systemd[1]: Stopped Journal Service.
Jun 06 02:03:35 localhost systemd[1]: systemd-journald.service: Consumed 4.267s CPU time.
Jun 06 02:03:35 localhost systemd[1]: Starting Journal Service...
Jun 06 02:03:35 localhost systemd[1]: Starting Load Kernel Modules...
Jun 06 02:03:35 localhost systemd[1]: Starting Generate network units from Kernel command line...
Jun 06 02:03:35 localhost systemd[1]: Starting Remount Root and Kernel File Systems...
Jun 06 02:03:35 localhost systemd[1]: Repartition Root Disk was skipped because no trigger condition checks were met.
Jun 06 02:03:35 localhost systemd[1]: Starting Coldplug All udev Devices...
Jun 06 02:03:35 localhost systemd[1]: Mounted Huge Pages File System.
Jun 06 02:03:35 localhost systemd[1]: Mounted POSIX Message Queue File System.
Jun 06 02:03:35 localhost systemd[1]: Mounted Kernel Debug File System.
Jun 06 02:03:35 localhost systemd[1]: Mounted Kernel Trace File System.
Jun 06 02:03:35 localhost systemd[1]: Mounted Temporary Directory /tmp.
Jun 06 02:03:35 localhost systemd[1]: Finished CoreOS: Set printk To Level 4 (warn).
Jun 06 02:03:35 localhost systemd[1]: Finished Create List of Static Device Nodes.
Jun 06 02:03:35 localhost systemd[1]: Finished Generate network units from Kernel command line.
Jun 06 02:03:35 localhost systemd[1]: Finished Remount Root and Kernel File Systems.
Jun 06 02:03:35 localhost systemd[1]: Reached target Preparation for Network.
Jun 06 02:03:35 localhost systemd[1]: Special handling of early boot iSCSI sessions was skipped because of an unmet condition check (ConditionDirectoryNotEmpty=/sys/class/iscsi_session).
Jun 06 02:03:35 localhost systemd[1]: OSTree Remount OS/ Bind Mounts was skipped because of an unmet condition check (ConditionKernelCommandLine=ostree).
Jun 06 02:03:35 localhost systemd[1]: Starting Rebuild Hardware Database...
Jun 06 02:03:35 localhost systemd-journald[1708]: Journal started
Jun 06 02:03:35 localhost systemd-journald[1708]: Runtime Journal (/run/log/journal/a0c1be0936ce4e95ba9bfd63e3f4325c) is 8.0M, max 2.5G, 2.5G free.
Jun 06 02:03:34 localhost systemd[1]: Queued start job for default target Graphical Interface.
Jun 06 02:03:34 localhost systemd[1]: systemd-journald.service: Deactivated successfully.
Jun 06 02:03:34 localhost systemd[1]: systemd-journald.service: Consumed 4.267s CPU time.
Jun 06 02:03:35 localhost systemd-modules-load[1709]: Module 'msr' is built in
Jun 06 02:03:35 localhost systemd[1]: Starting Load/Save Random Seed...
Jun 06 02:03:35 localhost systemd[1]: Starting Create System Users...
Jun 06 02:03:35 localhost systemd[1]: Started Journal Service.
Jun 06 02:03:35 localhost systemd[1]: modprobe@configfs.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Finished Load Kernel Module configfs.
Jun 06 02:03:35 localhost systemd[1]: modprobe@efi_pstore.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Finished Load Kernel Module efi_pstore.
Jun 06 02:03:35 localhost systemd[1]: modprobe@fuse.service: Deactivated successfully.
Jun 06 02:03:35 localhost systemd[1]: Finished Load Kernel Module fuse.
Jun 06 02:03:36 localhost systemd[1]: Finished Load Kernel Modules.
Jun 06 02:03:36 localhost systemd[1]: Finished Coldplug All udev Devices.
Jun 06 02:03:36 localhost systemd[1]: Mounting FUSE Control File System...
Jun 06 02:03:36 localhost systemd[1]: Mounting Kernel Configuration File System...
Jun 06 02:03:36 localhost systemd[1]: Starting Flush Journal to Persistent Storage...
Jun 06 02:03:36 localhost systemd[1]: Platform Persistent Storage Archival was skipped because of an unmet condition check (ConditionDirectoryNotEmpty=/sys/fs/pstore).
Jun 06 02:03:36 localhost systemd[1]: Starting Apply Kernel Variables...
Jun 06 02:03:36 localhost systemd[1]: Starting Wait for udev To Complete Device Initialization...
Jun 06 02:03:36 localhost systemd[1]: Finished Load/Save Random Seed.
Jun 06 02:03:36 localhost systemd[1]: Mounted FUSE Control File System.
Jun 06 02:03:36 localhost systemd[1]: Mounted Kernel Configuration File System.
Jun 06 02:03:36 localhost udevadm[1724]: systemd-udev-settle.service is deprecated. Please fix multipathd.service not to pull it in.
Jun 06 02:03:36 localhost kernel: ACPI: bus type drm_connector registered
Jun 06 02:03:36 localhost systemd[1]: modprobe@drm.service: Deactivated successfully.
Jun 06 02:03:36 localhost systemd[1]: Finished Load Kernel Module drm.
Jun 06 02:03:36 localhost systemd-journald[1708]: Time spent on flushing to /var/log/journal/a0c1be0936ce4e95ba9bfd63e3f4325c is 17.930ms for 2680 entries.
Jun 06 02:03:36 localhost systemd-journald[1708]: System Journal (/var/log/journal/a0c1be0936ce4e95ba9bfd63e3f4325c) is 8.0M, max 4.0G, 3.9G free.
Jun 06 02:03:36 localhost systemd-journald[1708]: Received client request to flush runtime journal.
Jun 06 02:03:36 localhost systemd[1]: Finished Flush Journal to Persistent Storage.
Jun 06 02:03:36 localhost systemd-sysusers[1715]: Creating group 'sgx' with GID 991.
Jun 06 02:03:36 localhost systemd-sysusers[1715]: Creating group 'systemd-oom' with GID 990.
Jun 06 02:03:36 localhost systemd-sysusers[1715]: Creating user 'systemd-oom' (systemd Userspace OOM Killer) with UID 990 and GID 990.
Jun 06 02:03:36 localhost systemd[1]: Finished Create System Users.
Jun 06 02:03:36 localhost systemd[1]: Finished Apply Kernel Variables.
Jun 06 02:03:36 localhost systemd[1]: Starting Create Static Device Nodes in /dev...
Jun 06 02:03:36 localhost systemd[1]: Finished Create Static Device Nodes in /dev.
Jun 06 02:03:36 localhost systemd[1]: Finished Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling.
Jun 06 02:03:36 localhost systemd[1]: Finished Rebuild Hardware Database.
Jun 06 02:03:36 localhost systemd[1]: Starting Rule-based Manager for Device Events and Files...
Jun 06 02:03:36 localhost systemd-udevd[1730]: Using default interface naming scheme 'rhel-9.0'.
Jun 06 02:03:36 localhost systemd[1]: Started Rule-based Manager for Device Events and Files.
Jun 06 02:03:36 localhost systemd[1]: Starting Load Kernel Module configfs...
Jun 06 02:03:36 localhost systemd[1]: Starting Load Kernel Module fuse...
Jun 06 02:03:36 localhost systemd[1]: modprobe@configfs.service: Deactivated successfully.
Jun 06 02:03:36 localhost systemd[1]: Finished Load Kernel Module configfs.
Jun 06 02:03:36 localhost systemd[1]: modprobe@fuse.service: Deactivated successfully.
Jun 06 02:03:36 localhost systemd[1]: Finished Load Kernel Module fuse.
Jun 06 02:03:36 localhost kernel: power_meter ACPI000D:00: Found ACPI power meter.
Jun 06 02:03:36 localhost kernel: power_meter ACPI000D:00: Ignoring unsafe software power cap!
Jun 06 02:03:36 localhost kernel: power_meter ACPI000D:00: hwmon_device_register() is deprecated. Please convert the driver to use hwmon_device_register_with_info().
Jun 06 02:03:37 localhost kernel: acpi-tad ACPI000E:00: Unsupported capabilities
Jun 06 02:03:37 localhost kernel: input: PC Speaker as /devices/platform/pcspkr/input/input3
Jun 06 02:03:37 localhost kernel: IPMI message handler: version 39.2
Jun 06 02:03:37 localhost kernel: ipmi device interface
Jun 06 02:03:38 localhost kernel: ioatdma: Intel(R) QuickData Technology Driver 5.00
Jun 06 02:03:38 localhost systemd[1]: Starting Load RDMA modules from /etc/rdma/modules/rdma.conf...
Jun 06 02:03:38 localhost kernel: ipmi_si: IPMI System Interface driver
Jun 06 02:03:38 localhost kernel: ipmi_si dmi-ipmi-si.0: ipmi_platform: probing via SMBIOS
Jun 06 02:03:38 localhost kernel: ipmi_platform: ipmi_si: SMBIOS: io 0xca2 regsize 1 spacing 1 irq 0
Jun 06 02:03:38 localhost kernel: ipmi_si: Adding SMBIOS-specified kcs state machine
Jun 06 02:03:38 localhost kernel: ipmi_si IPI0001:00: ipmi_platform: probing via ACPI
Jun 06 02:03:38 localhost kernel: ipmi_si IPI0001:00: ipmi_platform: [io  0x0ca2-0x0ca3] regsize 1 spacing 1 irq 10
Jun 06 02:03:38 localhost systemd[1]: Starting RDMA Node Description Daemon...
Jun 06 02:03:38 localhost kernel: ipmi_si dmi-ipmi-si.0: Removing SMBIOS-specified kcs state machine in favor of ACPI
Jun 06 02:03:38 localhost kernel: ipmi_si: Adding ACPI-specified kcs state machine
Jun 06 02:03:38 localhost kernel: ipmi_si: Trying ACPI-specified kcs state machine at i/o address 0xca2, slave address 0x20, irq 10
Jun 06 02:03:38 localhost kernel: RAPL PMU: API unit is 2^-32 Joules, 2 fixed counters, 655360 ms ovfl timer
Jun 06 02:03:38 localhost kernel: RAPL PMU: hw unit of domain package 2^-14 Joules
Jun 06 02:03:38 localhost kernel: RAPL PMU: hw unit of domain dram 2^-16 Joules
Jun 06 02:03:38 localhost kernel: ipmi_si IPI0001:00: The BMC does not support clearing the recv irq bit, compensating, but the BMC needs to be fixed.
Jun 06 02:03:38 localhost kernel: ipmi_si IPI0001:00: Using irq 10
Jun 06 02:03:38 localhost kernel: ipmi_si IPI0001:00: IPMI message handler: Found new BMC (man_id: 0x00b85c, prod_id: 0x2100, dev_id: 0x13)
Jun 06 02:03:38 localhost kernel: ipmi_si IPI0001:00: IPMI kcs interface initialized
Jun 06 02:03:38 localhost systemd[1]: Started RDMA Node Description Daemon.
Jun 06 02:03:38 localhost kernel: ipmi_ssif: IPMI SSIF Interface driver
Jun 06 02:03:38 localhost kernel: Console: switching to colour dummy device 80x25
Jun 06 02:03:38 localhost kernel: mgag200 0000:01:00.1: vgaarb: deactivate vga console
Jun 06 02:03:38 localhost kernel: [drm] Initialized mgag200 1.0.0 20110418 for 0000:01:00.1 on minor 0
Jun 06 02:03:38 localhost kernel: fbcon: mgag200drmfb (fb0) is primary device
Jun 06 02:03:38 localhost kernel: Console: switching to colour frame buffer device 128x48
Jun 06 02:03:38 localhost kernel: mgag200 0000:01:00.1: [drm] fb0: mgag200drmfb frame buffer device
Jun 06 02:03:38 localhost systemd[1]: Finished Load RDMA modules from /etc/rdma/modules/rdma.conf.
Jun 06 02:03:38 localhost systemd[1]: Reached target RDMA Hardware.
Jun 06 02:03:39 localhost kernel: intel_rapl_common: Found RAPL domain package
Jun 06 02:03:39 localhost kernel: intel_rapl_common: Found RAPL domain dram
Jun 06 02:03:39 localhost kernel: intel_rapl_common: DRAM domain energy unit 15300pj
Jun 06 02:03:42 localhost systemd[1]: Finished Wait for udev To Complete Device Initialization.
Jun 06 02:03:42 localhost systemd[1]: Starting Device-Mapper Multipath Device Controller...
Jun 06 02:03:42 localhost multipathd[2071]: --------start up--------
Jun 06 02:03:42 localhost multipathd[2071]: read /etc/multipath.conf
Jun 06 02:03:42 localhost multipathd[2071]: path checkers start up
Jun 06 02:03:42 localhost systemd[1]: Started Device-Mapper Multipath Device Controller.
Jun 06 02:03:42 localhost systemd[1]: Reached target Preparation for Local File Systems.
Jun 06 02:03:42 localhost systemd[1]: Reached target Local File Systems.
Jun 06 02:03:42 localhost systemd[1]: Starting Run update-ca-trust...
Jun 06 02:03:42 localhost systemd[1]: Starting Rebuild Dynamic Linker Cache...
Jun 06 02:03:42 localhost systemd[1]: Mark the need to relabel after reboot was skipped because of an unmet condition check (ConditionSecurity=!selinux).
Jun 06 02:03:42 localhost systemd[1]: Set Up Additional Binary Formats was skipped because no trigger condition checks were met.
Jun 06 02:03:42 localhost systemd[1]: Store a System Token in an EFI Variable was skipped because of an unmet condition check (ConditionPathExists=/sys/firmware/efi/efivars/LoaderFeatures-4a67b082-0a4c-41cf-b6c7-440b29bb8c4f).
Jun 06 02:03:42 localhost systemd[1]: Starting Automatic Boot Loader Update...
Jun 06 02:03:42 localhost systemd[1]: Starting Create Volatile Files and Directories...
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: /usr/lib/tmpfiles.d/tmp.conf:12: Duplicate line for path "/var/tmp", ignoring.
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: /usr/lib/tmpfiles.d/var.conf:14: Duplicate line for path "/var/log", ignoring.
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: /usr/lib/tmpfiles.d/var.conf:19: Duplicate line for path "/var/cache", ignoring.
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: /usr/lib/tmpfiles.d/var.conf:21: Duplicate line for path "/var/lib", ignoring.
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: /usr/lib/tmpfiles.d/var.conf:23: Duplicate line for path "/var/spool", ignoring.
Jun 06 02:03:42 localhost bootctl[2082]: Couldn't find EFI system partition, skipping.
Jun 06 02:03:42 localhost systemd[1]: Finished Automatic Boot Loader Update.
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: "/home" already exists and is not a directory.
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: "/srv" already exists and is not a directory.
Jun 06 02:03:42 localhost systemd-tmpfiles[2083]: "/root" already exists and is not a directory.
Jun 06 02:03:42 localhost systemd[1]: Finished Create Volatile Files and Directories.
Jun 06 02:03:42 localhost systemd[1]: Starting Security Auditing Service...
Jun 06 02:03:42 localhost systemd[1]: Starting Prepare network manager config content...
Jun 06 02:03:42 localhost systemd[1]: Starting RHEL CoreOS Rebuild SELinux Policy If Necessary...
Jun 06 02:03:42 localhost systemd[1]: Starting RHCOS Fix SELinux Labeling For /usr/local/sbin...
Jun 06 02:03:42 localhost chcon[2091]: changing security context of '/usr/local/sbin'
Jun 06 02:03:42 localhost systemd[1]: Starting Rebuild Journal Catalog...
Jun 06 02:03:43 localhost rhcos-rebuild-selinux-policy[2089]: RHEL_VERSION=9.2Assuming we have new enough ostree
Jun 06 02:03:43 localhost systemd[1]: Finished RHEL CoreOS Rebuild SELinux Policy If Necessary.
Jun 06 02:03:43 localhost auditd[2101]: No plugins found, not dispatching events
Jun 06 02:03:43 localhost auditd[2101]: Init complete, auditd 3.0.7 listening for events (startup state enable)
Jun 06 02:03:43 localhost sh[2109]: changing security context of '/var/usrlocal/sbin'
Jun 06 02:03:43 localhost systemd[1]: Finished RHCOS Fix SELinux Labeling For /usr/local/sbin.
Jun 06 02:03:43 localhost pre-network-manager-config.sh[2149]: /usr/local/bin/pre-network-manager-config.sh: line 135: //: Is a directory
Jun 06 02:03:43 localhost systemd[1]: Finished Rebuild Journal Catalog.
Jun 06 02:03:43 localhost pre-network-manager-config.sh[2088]: Removing default connection files in '/etc/NetworkManager/system-connections'
Jun 06 02:03:43 localhost pre-network-manager-config.sh[2157]: mv: '/tmp/tmp.qaK71ppW23/ens1f0.nmconnection' and '/tmp/tmp.qaK71ppW23/ens1f0.nmconnection' are the same file
Jun 06 02:03:43 localhost systemd[1]: pre-network-manager-config.service: Deactivated successfully.
Jun 06 02:03:43 localhost systemd[1]: Finished Prepare network manager config content.
Jun 06 02:03:43 localhost augenrules[2168]: No rules
Jun 06 02:03:43 localhost augenrules[2168]: enabled 1
Jun 06 02:03:43 localhost augenrules[2168]: failure 1
Jun 06 02:03:43 localhost augenrules[2168]: pid 2101
Jun 06 02:03:43 localhost augenrules[2168]: rate_limit 0
Jun 06 02:03:43 localhost augenrules[2168]: backlog_limit 8192
Jun 06 02:03:43 localhost augenrules[2168]: lost 0
Jun 06 02:03:43 localhost augenrules[2168]: backlog 4
Jun 06 02:03:43 localhost augenrules[2168]: backlog_wait_time 60000
Jun 06 02:03:43 localhost augenrules[2168]: backlog_wait_time_actual 0
Jun 06 02:03:43 localhost augenrules[2168]: enabled 1
Jun 06 02:03:43 localhost augenrules[2168]: failure 1
Jun 06 02:03:43 localhost augenrules[2168]: pid 2101
Jun 06 02:03:43 localhost augenrules[2168]: rate_limit 0
Jun 06 02:03:43 localhost augenrules[2168]: backlog_limit 8192
Jun 06 02:03:43 localhost augenrules[2168]: lost 0
Jun 06 02:03:43 localhost augenrules[2168]: backlog 4
Jun 06 02:03:43 localhost augenrules[2168]: backlog_wait_time 60000
Jun 06 02:03:43 localhost augenrules[2168]: backlog_wait_time_actual 0
Jun 06 02:03:43 localhost augenrules[2168]: enabled 1
Jun 06 02:03:43 localhost augenrules[2168]: failure 1
Jun 06 02:03:43 localhost augenrules[2168]: pid 2101
Jun 06 02:03:43 localhost augenrules[2168]: rate_limit 0
Jun 06 02:03:43 localhost augenrules[2168]: backlog_limit 8192
Jun 06 02:03:43 localhost augenrules[2168]: lost 0
Jun 06 02:03:43 localhost augenrules[2168]: backlog 4
Jun 06 02:03:43 localhost augenrules[2168]: backlog_wait_time 60000
Jun 06 02:03:43 localhost augenrules[2168]: backlog_wait_time_actual 0
Jun 06 02:03:43 localhost systemd[1]: Started Security Auditing Service.
Jun 06 02:03:43 localhost systemd[1]: Starting Record System Boot/Shutdown in UTMP...
Jun 06 02:03:43 localhost systemd[1]: Finished Record System Boot/Shutdown in UTMP.
Jun 06 02:03:44 localhost systemd[1]: Finished Run update-ca-trust.
Jun 06 02:03:44 localhost systemd[1]: Reached target First Boot Complete.
Jun 06 02:03:44 localhost systemd[1]: Starting Commit a transient machine-id on disk...
Jun 06 02:03:44 localhost systemd[1]: etc-machine\x2did.mount: Deactivated successfully.
Jun 06 02:03:44 localhost systemd[1]: Finished Commit a transient machine-id on disk.
Jun 06 02:03:46 localhost systemd[1]: Finished Rebuild Dynamic Linker Cache.
Jun 06 02:03:46 localhost systemd[1]: Starting Update is Completed...
Jun 06 02:03:46 localhost systemd[1]: Finished Update is Completed.
Jun 06 02:03:46 localhost systemd[1]: Reached target System Initialization.
Jun 06 02:03:46 localhost systemd[1]: Started Daily rotation of log files.
Jun 06 02:03:46 localhost systemd[1]: Started Daily Cleanup of Temporary Directories.
Jun 06 02:03:46 localhost systemd[1]: Started daily update of the root trust anchor for DNSSEC.
Jun 06 02:03:46 localhost systemd[1]: Reached target Timer Units.
Jun 06 02:03:46 localhost systemd[1]: Listening on bootupd.socket.
Jun 06 02:03:46 localhost systemd[1]: Listening on D-Bus System Message Bus Socket.
Jun 06 02:03:46 localhost systemd[1]: Listening on Open-iSCSI iscsiuio Socket.
Jun 06 02:03:46 localhost systemd[1]: Reached target Socket Units.
Jun 06 02:03:46 localhost systemd[1]: TPM2 PCR Barrier (Initialization) was skipped because of an unmet condition check (ConditionPathExists=/sys/firmware/efi/efivars/StubPcrKernelImage-4a67b082-0a4c-41cf-b6c7-440b29bb8c4f).
Jun 06 02:03:46 localhost systemd[1]: Reached target Basic System.
Jun 06 02:03:46 localhost systemd[1]: Starting CoreOS Generate iSCSI Initiator Name...
Jun 06 02:03:46 localhost systemd[1]: CoreOS Delete Ignition Config From Hypervisor was skipped because no trigger condition checks were met.
Jun 06 02:03:46 localhost systemd[1]: CoreOS Mark Ignition Boot Complete was skipped because of an unmet condition check (ConditionPathExists=!/run/ostree-live).
Jun 06 02:03:46 localhost systemd[1]: Starting Create Ignition Status Issue Files...
Jun 06 02:03:46 localhost systemd[1]: CoreOS Configure Chrony Based On The Platform was skipped because no trigger condition checks were met.
Jun 06 02:03:46 localhost systemd[1]: Starting Network Manager...
Jun 06 02:03:46 localhost systemd[1]: Starting NTP client/server...
Jun 06 02:03:46 localhost systemd[1]: Starting Generation of shadow ID ranges for CRI-O...
Jun 06 02:03:46 localhost systemd[1]: Starting Restore /run/initramfs on shutdown...
Jun 06 02:03:46 localhost systemd[1]: Started irqbalance daemon.
Jun 06 02:03:46 localhost systemd[1]: Software RAID monitoring and management was skipped because of an unmet condition check (ConditionPathExists=/etc/mdadm.conf).
Jun 06 02:03:46 localhost systemd[1]: Starting Load CPU microcode update...
Jun 06 02:03:46 localhost systemd[1]: Auto-connect to subsystems on FC-NVME devices found during boot was skipped because of an unmet condition check (ConditionPathExists=/sys/class/fc/fc_udev_device/nvme_discovery).
Jun 06 02:03:46 localhost systemd[1]: Read-Only Sysroot Migration was skipped because of an unmet condition check (ConditionPathIsReadWrite=/sysroot).
Jun 06 02:03:46 localhost systemd[1]: Starting selinux.service...
Jun 06 02:03:46 localhost systemd[1]: Starting Agent-based installer hostname update service...
Jun 06 02:03:46 localhost systemd[1]: Starting OpenSSH ecdsa Server Key Generation...
Jun 06 02:03:46 localhost systemd[1]: Starting OpenSSH ed25519 Server Key Generation...
Jun 06 02:03:46 localhost systemd[1]: Starting OpenSSH rsa Server Key Generation...
Jun 06 02:03:46 localhost systemd[1]: System Security Services Daemon was skipped because no trigger condition checks were met.
Jun 06 02:03:46 localhost systemd[1]: Reached target User and Group Name Lookups.
Jun 06 02:03:46 localhost systemd[1]: Starting User Login Management...
Jun 06 02:03:46 localhost systemd[1]: VGAuth Service for open-vm-tools was skipped because of an unmet condition check (ConditionVirtualization=vmware).
Jun 06 02:03:46 localhost systemd[1]: Service for virtual machines hosted on VMware was skipped because of an unmet condition check (ConditionVirtualization=vmware).
Jun 06 02:03:46 localhost systemd[1]: Finished CoreOS Generate iSCSI Initiator Name.
Jun 06 02:03:46 localhost systemd[1]: Finished Restore /run/initramfs on shutdown.
Jun 06 02:03:47 localhost systemd-logind[2202]: New seat seat0.
Jun 06 02:03:47 localhost systemd-logind[2202]: Watching system buttons on /dev/input/event0 (Power Button)
Jun 06 02:03:47 localhost systemd-logind[2202]: Watching system buttons on /dev/input/event1 (iLO Virtual Keyboard)
Jun 06 02:03:47 localhost systemd[1]: Starting D-Bus System Message Bus...
Jun 06 02:03:47 localhost groupadd[2215]: group added to /etc/group: name=containers, GID=989
Jun 06 02:03:47 localhost groupadd[2215]: group added to /etc/gshadow: name=containers
Jun 06 02:03:47 localhost groupadd[2215]: new group: name=containers, GID=989
Jun 06 02:03:47 localhost dbus-broker-launch[2219]: Looking up NSS user entry for 'dbus'...
Jun 06 02:03:47 localhost set-hostname.sh[2198]: Host has matching MAC address: b4:96:91:d9:a4:64
Jun 06 02:03:47 localhost set-hostname.sh[2198]: Setting hostname to sno131.outbound.vz.bos2.lab
Jun 06 02:03:47 localhost dbus-broker-launch[2219]: NSS returned NAME 'dbus' and UID '81'
Jun 06 02:03:47 localhost systemd[1]: Finished Create Ignition Status Issue Files.
Jun 06 02:03:47 localhost useradd[2249]: new user: name=containers, UID=989, GID=989, home=/var/home/containers, shell=/sbin/nologin, from=none
Jun 06 02:03:48 localhost chronyd[2259]: chronyd version 4.3 starting (+CMDMON +NTP +REFCLOCK +RTC +PRIVDROP +SCFILTER +SIGND +ASYNCDNS +NTS +SECHASH +IPV6 +DEBUG)
Jun 06 02:03:48 localhost chronyd[2259]: Using right/UTC timezone to obtain leap second data
Jun 06 02:03:48 localhost chronyd[2259]: Loaded seccomp filter (level 2)
Jun 06 02:03:48 localhost systemd[1]: Started NTP client/server.
Jun 06 02:03:48 localhost dbus-broker-launch[2219]: Looking up NSS user entry for 'polkitd'...
Jun 06 02:03:48 localhost dbus-broker-launch[2219]: NSS returned NAME 'polkitd' and UID '999'
Jun 06 02:03:48 localhost systemd[1]: crio-subid.service: Deactivated successfully.
Jun 06 02:03:48 localhost systemd[1]: Finished Generation of shadow ID ranges for CRI-O.
Jun 06 02:03:48 localhost systemd[1]: sshd-keygen@ecdsa.service: Deactivated successfully.
Jun 06 02:03:48 localhost systemd[1]: Finished OpenSSH ecdsa Server Key Generation.
Jun 06 02:03:48 localhost systemd[1]: sshd-keygen@ed25519.service: Deactivated successfully.
Jun 06 02:03:48 localhost systemd[1]: Finished OpenSSH ed25519 Server Key Generation.
Jun 06 02:03:48 localhost systemd[1]: Started D-Bus System Message Bus.
Jun 06 02:03:48 localhost NetworkManager[2186]: <info>  [1686017028.3848] NetworkManager (version 1.42.2-1.el9) is starting... (boot:1c4de38f-9407-4ca6-8d60-1949f93a762e)
Jun 06 02:03:48 localhost NetworkManager[2186]: <info>  [1686017028.3849] Read config: /etc/NetworkManager/NetworkManager.conf (lib: 10-disable-default-plugins.conf, 20-client-id-from-mac.conf)
Jun 06 02:03:48 localhost dbus-broker-lau[2219]: Ready
Jun 06 02:03:48 localhost systemd[1]: Started User Login Management.
Jun 06 02:03:48 localhost NetworkManager[2186]: <info>  [1686017028.4028] bus-manager: acquired D-Bus service "org.freedesktop.NetworkManager"
Jun 06 02:03:48 localhost systemd[1]: Started Network Manager.
Jun 06 02:03:48 localhost systemd[1]: Starting Hostname Service...
Jun 06 02:03:48 localhost NetworkManager[2186]: <info>  [1686017028.4842] manager[0x55d1d91c0030]: monitoring kernel firmware directory '/lib/firmware'.
Jun 06 02:03:48 localhost systemd[1]: Started Hostname Service.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd-hostnamed[2285]: Hostname set to <sno131.outbound.vz.bos2.lab> (static)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.4907] hostname: hostname: using hostnamed
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.4907] hostname: static hostname changed from (none) to "sno131.outbound.vz.bos2.lab"
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Finished Agent-based installer hostname update service.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.5520] dns-mgr: init: dns=default,systemd-resolved rc-manager=symlink (auto)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.6732] manager[0x55d1d91c0030]: rfkill: Wi-Fi hardware radio set enabled
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.6733] manager[0x55d1d91c0030]: rfkill: WWAN hardware radio set enabled
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Listening on Load/Save RF Kill Switch Status /dev/rfkill Watch.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7428] Loaded device plugin: NMOvsFactory (/usr/lib64/NetworkManager/1.42.2-1.el9/libnm-device-plugin-ovs.so)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7597] Loaded device plugin: NMTeamFactory (/usr/lib64/NetworkManager/1.42.2-1.el9/libnm-device-plugin-team.so)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7598] manager: rfkill: Wi-Fi enabled by radio killswitch; enabled by state file
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7598] manager: rfkill: WWAN enabled by radio killswitch; enabled by state file
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7598] manager: Networking is enabled by state file
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7604] settings: Loaded settings plugin: keyfile (internal)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7622] settings: Loaded settings plugin: ifcfg-rh ("/usr/lib64/NetworkManager/1.42.2-1.el9/libnm-settings-plugin-ifcfg-rh.so")
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7637] dhcp: init: Using DHCP client 'internal'
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Starting Network Manager Script Dispatcher Service...
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7638] manager: (lo): new Loopback device (/org/freedesktop/NetworkManager/Devices/1)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7644] device (lo): state change: unmanaged -> unavailable (reason 'connection-assumed', sys-iface-state: 'external')
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7646] device (lo): state change: unavailable -> disconnected (reason 'connection-assumed', sys-iface-state: 'external')
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7650] device (lo): Activation: starting connection 'lo' (c6d35040-12f1-43ac-b8a1-de7d6ef67e37)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7654] manager: (eno1): new Ethernet device (/org/freedesktop/NetworkManager/Devices/2)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7659] settings: (eno1): created default wired connection 'Wired connection 1'
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7659] device (eno1): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab kernel: igb 0000:03:00.0 eno1: igb: eno1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX/TX
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab kernel: IPv6: ADDRCONF(NETDEV_CHANGE): eno1: link becomes ready
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7884] manager: (ens1f0): new Ethernet device (/org/freedesktop/NetworkManager/Devices/3)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.7885] device (ens1f0): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab kernel: ice 0000:10:00.0 ens1f0: NIC Link is up 25 Gbps Full Duplex, Requested FEC: RS-FEC, Negotiated FEC: NONE, Autoneg Advertised: Off, Autoneg Negotiated: False, Flow Control: None
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.8546] manager: (ens1f1): new Ethernet device (/org/freedesktop/NetworkManager/Devices/4)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.8551] settings: (ens1f1): created default wired connection 'Wired connection 2'
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.8551] device (ens1f1): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: sshd-keygen@rsa.service: Deactivated successfully.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Finished OpenSSH rsa Server Key Generation.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Reached target sshd-keygen.target.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Starting Generate SSH keys snippet for display via console-login-helper-messages...
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.9295] manager: (ens1f2): new Ethernet device (/org/freedesktop/NetworkManager/Devices/5)
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.9301] settings: (ens1f2): created default wired connection 'Wired connection 3'
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017028.9301] device (ens1f2): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: microcode.service: Deactivated successfully.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Finished Load CPU microcode update.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Started Network Manager Script Dispatcher Service.
Jun 06 02:03:48 sno131.outbound.vz.bos2.lab systemd[1]: Finished Generate SSH keys snippet for display via console-login-helper-messages.
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.0098] manager: (ens1f3): new Ethernet device (/org/freedesktop/NetworkManager/Devices/6)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.0104] settings: (ens1f3): created default wired connection 'Wired connection 4'
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.0104] device (ens1f3): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.0949] manager: (ens2f0): new Ethernet device (/org/freedesktop/NetworkManager/Devices/7)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.0954] settings: (ens2f0): created default wired connection 'Wired connection 5'
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.0954] device (ens2f0): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.1716] manager: (ens2f1): new Ethernet device (/org/freedesktop/NetworkManager/Devices/8)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.1721] settings: (ens2f1): created default wired connection 'Wired connection 6'
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.1721] device (ens2f1): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.2369] manager: (ens2f2): new Ethernet device (/org/freedesktop/NetworkManager/Devices/9)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.2374] settings: (ens2f2): created default wired connection 'Wired connection 7'
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.2374] device (ens2f2): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.3539] manager: (ens2f3): new Ethernet device (/org/freedesktop/NetworkManager/Devices/10)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.3545] settings: (ens2f3): created default wired connection 'Wired connection 8'
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.3545] device (ens2f3): state change: unmanaged -> unavailable (reason 'managed', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4364] ovsdb: disconnected from ovsdb
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4364] device (lo): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4365] device (lo): state change: prepare -> config (reason 'none', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4366] device (lo): state change: config -> ip-config (reason 'none', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4367] device (eno1): carrier: link connected
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4368] device (ens1f0): carrier: link connected
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4374] device (lo): state change: ip-config -> ip-check (reason 'none', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4377] device (eno1): state change: unavailable -> disconnected (reason 'carrier-changed', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4385] device (ens1f0): state change: unavailable -> disconnected (reason 'carrier-changed', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4387] policy: auto-activating connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4388] policy: auto-activating connection 'ens1f0' (3ad293c7-96cd-4e16-a03d-ea898589a158)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4389] device (lo): state change: ip-check -> secondaries (reason 'none', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4390] device (eno1): Activation: starting connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4392] device (ens1f0): Activation: starting connection 'ens1f0' (3ad293c7-96cd-4e16-a03d-ea898589a158)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4392] device (lo): state change: secondaries -> activated (reason 'none', sys-iface-state: 'external')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4394] device (lo): Activation: successful, device activated.
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4397] device (eno1): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4398] manager: NetworkManager state is now CONNECTING
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4399] device (eno1): state change: prepare -> config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4406] device (ens1f0): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4407] device (ens1f0): state change: prepare -> config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4409] device (eno1): state change: config -> ip-config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4417] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4418] device (ens1f0): state change: config -> ip-config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4421] policy: set 'ens1f0' (ens1f0) as default for IPv4 routing and DNS
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4434] device (ens1f0): state change: ip-config -> ip-check (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4446] device (ens1f0): state change: ip-check -> secondaries (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4448] device (ens1f0): state change: secondaries -> activated (reason 'none', sys-iface-state: 'managed')
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4449] manager: NetworkManager state is now CONNECTED_SITE
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4450] device (ens1f0): Activation: successful, device activated.
Jun 06 02:03:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017029.4453] manager: NetworkManager state is now CONNECTED_GLOBAL
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  Converting 353 SID table entries...
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  policy capability network_peer_controls=1
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  policy capability open_perms=1
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  policy capability extended_socket_class=1
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  policy capability always_check_network=0
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  policy capability cgroup_seclabel=1
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  policy capability nnp_nosuid_transition=1
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab kernel: SELinux:  policy capability genfs_seclabel_symlinks=1
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab systemd[1]: selinux.service: Deactivated successfully.
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab systemd[1]: Finished selinux.service.
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab systemd[1]: selinux.service: Consumed 5.281s CPU time.
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab dbus-broker-launch[2279]: avc:  op=load_policy lsm=selinux seqno=2 res=1
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab systemd[1]: Starting Get interactive user configuration at boot...
Jun 06 02:03:53 sno131.outbound.vz.bos2.lab systemd[1]: Received SIGRTMIN+21 from PID 2421 (n/a).
Jun 06 02:03:55 sno131.outbound.vz.bos2.lab chronyd[2259]: Selected source 129.250.35.250 (2.rhel.pool.ntp.org)
Jun 06 02:03:55 sno131.outbound.vz.bos2.lab chronyd[2259]: System clock TAI offset set to 37 seconds
Jun 06 02:03:56 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-opaque\x2dbug\x2dcheck3669819565-merged.mount: Deactivated successfully.
Jun 06 02:03:59 sno131.outbound.vz.bos2.lab systemd[1]: NetworkManager-dispatcher.service: Deactivated successfully.
Jun 06 02:03:59 sno131.outbound.vz.bos2.lab kernel: VFS: idmapped mount is not enabled.
Jun 06 02:04:01 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay.mount: Deactivated successfully.
Jun 06 02:04:17 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay.mount: Deactivated successfully.
Jun 06 02:04:18 sno131.outbound.vz.bos2.lab systemd[1]: systemd-hostnamed.service: Deactivated successfully.
Jun 06 02:04:21 sno131.outbound.vz.bos2.lab systemd[1]: Finished Get interactive user configuration at boot.
Jun 06 02:04:21 sno131.outbound.vz.bos2.lab systemd[1]: Received SIGRTMIN+20 from PID 2584 (n/a).
Jun 06 02:04:21 sno131.outbound.vz.bos2.lab systemd[1]: Reached target Network.
Jun 06 02:04:21 sno131.outbound.vz.bos2.lab systemd[1]: Starting Network Manager Wait Online...
Jun 06 02:04:21 sno131.outbound.vz.bos2.lab systemd[1]: Update GCP routes for forwarded IPs. was skipped because no trigger condition checks were met.
Jun 06 02:04:21 sno131.outbound.vz.bos2.lab systemd[1]: Starting OpenSSH server daemon...
Jun 06 02:04:22 sno131.outbound.vz.bos2.lab sshd[2586]: main: sshd: ssh-rsa algorithm is disabled
Jun 06 02:04:22 sno131.outbound.vz.bos2.lab sshd[2586]: Server listening on 0.0.0.0 port 22.
Jun 06 02:04:22 sno131.outbound.vz.bos2.lab sshd[2586]: Server listening on :: port 22.
Jun 06 02:04:22 sno131.outbound.vz.bos2.lab systemd[1]: Started OpenSSH server daemon.
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9165] device (eno1): state change: ip-config -> failed (reason 'ip-config-unavailable', sys-iface-state: 'managed')
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <warn>  [1686017074.9169] device (eno1): Activation: failed for connection 'Wired connection 1'
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9170] device (eno1): state change: failed -> disconnected (reason 'none', sys-iface-state: 'managed')
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9264] dhcp4 (eno1): canceled DHCP transaction
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9265] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9265] dhcp4 (eno1): state changed no lease
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9275] policy: auto-activating connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9278] device (eno1): Activation: starting connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9278] device (eno1): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'managed')
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9279] device (eno1): state change: prepare -> config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9286] device (eno1): state change: config -> ip-config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:04:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017074.9293] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9169] device (eno1): state change: ip-config -> failed (reason 'ip-config-unavailable', sys-iface-state: 'managed')
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <warn>  [1686017119.9175] device (eno1): Activation: failed for connection 'Wired connection 1'
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9176] device (eno1): state change: failed -> disconnected (reason 'none', sys-iface-state: 'managed')
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9265] dhcp4 (eno1): canceled DHCP transaction
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9265] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9265] dhcp4 (eno1): state changed no lease
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9281] policy: auto-activating connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9283] device (eno1): Activation: starting connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9283] device (eno1): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'managed')
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9284] device (eno1): state change: prepare -> config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9290] device (eno1): state change: config -> ip-config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:05:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017119.9298] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: NetworkManager-wait-online.service: Main process exited, code=exited, status=1/FAILURE
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: NetworkManager-wait-online.service: Failed with result 'exit-code'.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Failed to start Network Manager Wait Online.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Reached target Network is Online.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Starting Assisted Installer Agent...
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Login and scanning of iSCSI devices was skipped because of an unmet condition check (ConditionDirectoryNotEmpty=/var/lib/iscsi/nodes).
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Reached target Preparation for Remote File Systems.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Reached target Remote Encrypted Volumes.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Reached target Remote File Systems.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Starting Identify node zero to run OpenShift Assisted Installation Service on...
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: TPM2 PCR Barrier (User) was skipped because of an unmet condition check (ConditionPathExists=/sys/firmware/efi/efivars/StubPcrKernelImage-4a67b082-0a4c-41cf-b6c7-440b29bb8c4f).
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Starting Permit User Sessions...
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab set-node-zero.sh[2593]: NODE_ZERO_IP: 192.168.14.27
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab set-node-zero.sh[2593]: Node 0 IP 192.168.14.27 found on this host
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Finished Permit User Sessions.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: CoreOS Live ISO virtio success was skipped because of an unmet condition check (ConditionPathExists=/dev/virtio-ports/coreos.liveiso-success).
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Started Getty on tty1.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Reached target Login Prompts.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab set-node-zero.sh[2593]: MAC Address for Node 0: b4:96:91:d9:a4:64
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab set-node-zero.sh[2593]: Created file /etc/assisted/node0
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Finished Identify node zero to run OpenShift Assisted Installation Service on.
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab systemd[1]: Starting Assisted Service pod...
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab extract-agent.sh[2592]: Pulling quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27...
Jun 06 02:05:22 sno131.outbound.vz.bos2.lab extract-agent.sh[2636]: bd31af778e86d50ac082b75a2860143704fe333a4a07562202de6fc7593859a3
Jun 06 02:05:23 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-e46a38b586d2a70bae40d9105b989a35d8f6bcfd9f6d306ac5a58f84a87c30b5-merged.mount: Deactivated successfully.
Jun 06 02:05:23 sno131.outbound.vz.bos2.lab systemd[1]: Created slice Slice /machine.
Jun 06 02:05:23 sno131.outbound.vz.bos2.lab systemd[1]: Created slice cgroup machine-libpod_pod_e500a56affcd21e1cd47bfd5e25c79930fd9cedcab025e87808ea2db56157309.slice.
Jun 06 02:05:23 sno131.outbound.vz.bos2.lab podman[2611]: e500a56affcd21e1cd47bfd5e25c79930fd9cedcab025e87808ea2db56157309
Jun 06 02:05:23 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay.mount: Deactivated successfully.
Jun 06 02:05:23 sno131.outbound.vz.bos2.lab get-container-images.sh[2780]: Pulling quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27...
Jun 06 02:05:23 sno131.outbound.vz.bos2.lab get-container-images.sh[2822]: bd31af778e86d50ac082b75a2860143704fe333a4a07562202de6fc7593859a3
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container e07fb8cc2f05481df8254458a2bc60d55df0aeb1d9bd66fe05d1e3b4bb43b033.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container f1e341f2afbfb5d95ec598eca63ea04f5ee6ccd3be4d3726f2e40e3f0b0a4189.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: libpod-f1e341f2afbfb5d95ec598eca63ea04f5ee6ccd3be4d3726f2e40e3f0b0a4189.scope: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: libpod-e07fb8cc2f05481df8254458a2bc60d55df0aeb1d9bd66fe05d1e3b4bb43b033.scope: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[2591]: Using agent image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d to copy bin
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-e5551cb7c837c441c1a450ed98adf93cccbc3ba8fa94400bc55898decf1a68e7-merged.mount: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-e07fb8cc2f05481df8254458a2bc60d55df0aeb1d9bd66fe05d1e3b4bb43b033-userdata-shm.mount: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-c64328db2afe4879c43df924cc39b1217c968a4a64054253ae0a441139176155-merged.mount: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-f1e341f2afbfb5d95ec598eca63ea04f5ee6ccd3be4d3726f2e40e3f0b0a4189-userdata-shm.mount: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 71760a4938885f280e35cdc32f7b6d2cba75db9decf63a393a12817dcbba0c98.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Trying to pull quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d...
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: libpod-71760a4938885f280e35cdc32f7b6d2cba75db9decf63a393a12817dcbba0c98.scope: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-71760a4938885f280e35cdc32f7b6d2cba75db9decf63a393a12817dcbba0c98-userdata-shm.mount: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-4519fbfffc7dd0332b0a3a7ec7d962b1309ffe5f074bcf9f95c06d0685aed607-merged.mount: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay.mount: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 637f04e9e3397d61688f0871eaedbbb027c2c99a4cc3d7926eb4b3365cbb9188.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: libpod-637f04e9e3397d61688f0871eaedbbb027c2c99a4cc3d7926eb4b3365cbb9188.scope: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 4ea181c3746b66edd8edff91b2af65efb88f5c11e8fbfa778a1c1e41dcea5efc.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab systemd[1]: libpod-4ea181c3746b66edd8edff91b2af65efb88f5c11e8fbfa778a1c1e41dcea5efc.scope: Deactivated successfully.
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Getting image source signatures
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Copying blob sha256:80c3686a5885b426af5147f41131b7c1bbc851599811ae921a08747f120593ee
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Copying blob sha256:d8190195889efb5333eeec18af9b6c82313edd4db62989bd3a357caca4f13f0e
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Copying blob sha256:97da74cc6d8fa5d1634eb1760fd1da5c6048619c264c23e62d75f3bf6b8ef5c4
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Copying blob sha256:df8999d603e3929dbee92d7be49011da4d311a163f6258489e52f972d5819eab
Jun 06 02:05:24 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Copying blob sha256:49382d220048678f7bb2c81d0bb67193dca1889debc1d93345fbb15363b0dfab
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: bridge: filtering via arp/ip/ip6tables is no longer available by default. Update your scripts to load br_netfilter if you need this.
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1322] manager: (cni-podman0): new Bridge device (/org/freedesktop/NetworkManager/Devices/11)
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1948] manager: (veth32502cb4): new Veth device (/org/freedesktop/NetworkManager/Devices/12)
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 1(veth32502cb4) entered blocking state
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 1(veth32502cb4) entered disabled state
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: device veth32502cb4 entered promiscuous mode
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1968] device (cni-podman0): state change: unmanaged -> unavailable (reason 'connection-assumed', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1971] device (cni-podman0): state change: unavailable -> disconnected (reason 'connection-assumed', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1974] device (cni-podman0): Activation: starting connection 'cni-podman0' (f19b4267-235e-436e-8238-3f90901453ec)
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1975] device (cni-podman0): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1976] device (cni-podman0): state change: prepare -> config (reason 'none', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1977] device (cni-podman0): state change: config -> ip-config (reason 'none', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.1978] device (cni-podman0): state change: ip-config -> ip-check (reason 'none', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab systemd[1]: Starting Network Manager Script Dispatcher Service...
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab systemd[1]: Started Network Manager Script Dispatcher Service.
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.2072] device (cni-podman0): state change: ip-check -> secondaries (reason 'none', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.2074] device (cni-podman0): state change: secondaries -> activated (reason 'none', sys-iface-state: 'external')
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.2077] device (cni-podman0): Activation: successful, device activated.
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab systemd[1]: iscsi.service: Unit cannot be reloaded because it is inactive.
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: IPv6: ADDRCONF(NETDEV_CHANGE): veth32502cb4: link becomes ready
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 1(veth32502cb4) entered blocking state
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 1(veth32502cb4) entered forwarding state
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.4934] device (veth32502cb4): carrier: link connected
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017125.4936] device (cni-podman0): carrier: link connected
Jun 06 02:05:25 sno131.outbound.vz.bos2.lab kernel: Warning: Deprecated Driver is detected: nft_compat will not be maintained in a future major release and may be disabled
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 361d59273eefae6f5a76a2f69b781d5baa1e2a52ae0f3607ee7acf6de1e8e5f2.
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3286]: e500a56affcd21e1cd47bfd5e25c79930fd9cedcab025e87808ea2db56157309
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab systemd[1]: Started Assisted Service pod.
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab systemd[1]: Starting Assisted Service database...
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab systemd[1]: Starting Assisted Service container...
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3560]: Trying to pull quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f8e7aad960ddc3ce2e3857b613531b2b2211641496e964f0631f3bdd3916983a...
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3561]: Trying to pull quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f8e7aad960ddc3ce2e3857b613531b2b2211641496e964f0631f3bdd3916983a...
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3560]: Getting image source signatures
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3560]: Copying blob sha256:b54649f20f4c3693f373a46c9be1d47f7ffd67826ec57c12ec0429660966acae
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3560]: Copying blob sha256:d8190195889efb5333eeec18af9b6c82313edd4db62989bd3a357caca4f13f0e
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3560]: Copying blob sha256:97da74cc6d8fa5d1634eb1760fd1da5c6048619c264c23e62d75f3bf6b8ef5c4
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3560]: Copying blob sha256:df8999d603e3929dbee92d7be49011da4d311a163f6258489e52f972d5819eab
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3560]: Copying blob sha256:49382d220048678f7bb2c81d0bb67193dca1889debc1d93345fbb15363b0dfab
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3561]: Getting image source signatures
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3561]: Copying blob sha256:b54649f20f4c3693f373a46c9be1d47f7ffd67826ec57c12ec0429660966acae
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3561]: Copying blob sha256:d8190195889efb5333eeec18af9b6c82313edd4db62989bd3a357caca4f13f0e
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3561]: Copying blob sha256:97da74cc6d8fa5d1634eb1760fd1da5c6048619c264c23e62d75f3bf6b8ef5c4
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3561]: Copying blob sha256:df8999d603e3929dbee92d7be49011da4d311a163f6258489e52f972d5819eab
Jun 06 02:05:27 sno131.outbound.vz.bos2.lab podman[3561]: Copying blob sha256:49382d220048678f7bb2c81d0bb67193dca1889debc1d93345fbb15363b0dfab
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Copying config sha256:fc010a8158201642d346b874174efe504792e21920adb879b2b95c55a736e5ec
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Writing manifest to image destination
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab extract-agent.sh[3062]: Storing signatures
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(veth8196f551) entered blocking state
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(veth8196f551) entered disabled state
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: device veth8196f551 entered promiscuous mode
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017132.7413] manager: (veth8196f551): new Veth device (/org/freedesktop/NetworkManager/Devices/13)
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017132.7462] device (veth8196f551): carrier: link connected
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: IPv6: ADDRCONF(NETDEV_CHANGE): veth8196f551: link becomes ready
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(veth8196f551) entered blocking state
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(veth8196f551) entered forwarding state
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 7c6891ca661099d78a610db79c96cd24dc13d994c2b9cbb67fee558892dbdd69.
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab systemd[1]: libpod-7c6891ca661099d78a610db79c96cd24dc13d994c2b9cbb67fee558892dbdd69.scope: Deactivated successfully.
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(veth8196f551) entered disabled state
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: device veth8196f551 left promiscuous mode
Jun 06 02:05:32 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(veth8196f551) entered disabled state
Jun 06 02:05:33 sno131.outbound.vz.bos2.lab systemd[1]: run-netns-netns\x2d81c61221\x2de3f4\x2d85cd\x2d0dcf\x2d08864e8317ae.mount: Deactivated successfully.
Jun 06 02:05:33 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-7c6891ca661099d78a610db79c96cd24dc13d994c2b9cbb67fee558892dbdd69-userdata-shm.mount: Deactivated successfully.
Jun 06 02:05:33 sno131.outbound.vz.bos2.lab systemd[1]: Started Assisted Installer Agent.
Jun 06 02:05:33 sno131.outbound.vz.bos2.lab start-agent.sh[3898]: Waiting for infra-env-id to be available
Jun 06 02:05:33 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-a18683a05ab24a67db1b238250f9e5a25774a0d03a4fd32a3ec7908084d7baca-merged.mount: Deactivated successfully.
Jun 06 02:05:35 sno131.outbound.vz.bos2.lab systemd[1]: NetworkManager-dispatcher.service: Deactivated successfully.
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3561]: Copying config sha256:4d83c30aa720e8b7398a2a16d5ca48a0643dc3d02553c5cb6505e542f3d60ec8
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3561]: Writing manifest to image destination
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3561]: Storing signatures
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3561]: 
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3560]: Copying config sha256:4d83c30aa720e8b7398a2a16d5ca48a0643dc3d02553c5cb6505e542f3d60ec8
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3560]: Writing manifest to image destination
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3560]: Storing signatures
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 1a132fbc13657ffe2402c713a27588f1043a0b105f0356cbf0f724e455bc491d.
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3560]: 
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3561]: 1a132fbc13657ffe2402c713a27588f1043a0b105f0356cbf0f724e455bc491d
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container e8d3d8160983a8de3617641b410b53150d8b90dd9ef5bc438defff9d19faeb52.
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab systemd[1]: Started Assisted Service container.
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab systemd[1]: Starting Service that creates initial cluster and infraenv...
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab wait-for-assisted-service.sh[3966]: Waiting for assisted-service to be ready
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: false
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:36Z" level=info msg="Setting log format: text" func=main.InitLogs file="/src/cmd/main.go:176"
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:36Z" level=info msg="Setting Log Level: info" func=main.InitLogs file="/src/cmd/main.go:182"
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:36Z" level=info msg="Starting assisted-service version: bcceba754250cad2c4247770656c88b96c8cbe5e" func=main.main file="/src/cmd/main.go:209"
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:36Z" level=info msg="Starting bm service" func=main.main file="/src/cmd/main.go:224"
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:36Z" level=info msg="Started service with OS images [{\"openshift_version\":\"4.13.2\",\"cpu_architecture\":\"x86_64\",\"url\":\"https://rhcos.mirror.openshift.com/art/storage/prod/streams/4.13-9.2/builds/413.92.202305021736-0/x86_64/rhcos-413.92.202305021736-0-live.x86_64.iso\",\"version\":\"413.92.202305021736-0\"}], Release images [{\"openshift_version\":\"4.13.2\",\"cpu_architecture\":\"x86_64\",\"url\":\"quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27\",\"version\":\"4.13.2\"}]" func=main.main file="/src/cmd/main.go:248"
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:36Z" level=info msg="Connecting to DB" func=main.setupDB file="/src/cmd/main.go:675"
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab systemd[1]: Started Assisted Service database.
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:36Z" level=info msg="Failed to connect to DB, retrying" func=main.setupDB.func1 file="/src/cmd/main.go:682" error="failed to connect to `host=127.0.0.1 user=admin database=installer`: dial error (dial tcp 127.0.0.1:5432: connect: connection refused)"
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab podman[3560]: e8d3d8160983a8de3617641b410b53150d8b90dd9ef5bc438defff9d19faeb52
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab assisted-db[3936]: waiting for server to start.... done
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab assisted-db[3936]: server started
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab assisted-db[3936]: waiting for server to shut down.... done
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab assisted-db[3936]: server stopped
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab assisted-db[3936]: 2023-06-06 02:05:36.737 UTC [1] LOG:  listening on IPv6 address "::1", port 5432
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab assisted-db[3936]: 2023-06-06 02:05:36.737 UTC [1] LOG:  listening on IPv4 address "127.0.0.1", port 5432
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab assisted-db[3936]: 2023-06-06 02:05:36.737 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab assisted-db[3936]: 2023-06-06 02:05:36.737 UTC [1] LOG:  listening on Unix socket "/tmp/.s.PGSQL.5432"
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab assisted-db[3936]: 2023-06-06 02:05:36.741 UTC [1] LOG:  redirecting log output to logging collector process
Jun 06 02:05:36 sno131.outbound.vz.bos2.lab assisted-db[3936]: 2023-06-06 02:05:36.741 UTC [1] HINT:  Future log output will appear in directory "log".
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab start-agent.sh[3898]: Querying assisted-service for infra-env-id...
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab start-agent.sh[4006]: curl: (7) Failed to connect to 192.168.14.27 port 8090: Connection refused
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Connected to DB" func=main.setupDB file="/src/cmd/main.go:699"
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Created none authenticator" func=github.com/openshift/assisted-service/pkg/auth.NewAuthenticator file="/src/pkg/auth/authenticator.go:57" pkg=auth
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Configuring CNV Operator plugin" func=github.com/openshift/assisted-service/internal/operators/cnv.NewCNVOperator file="/src/internal/operators/cnv/cnv_operator.go:45" config="{map[10de:1db6:true 10de:1eb8:true] map[15b3:1013:true 15b3:1015:true 15b3:1017:true 15b3:101b:true 8086:158b:true] true true 50}"
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="DeployTarget: onprem" func=main.main file="/src/cmd/main.go:336"
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Starting manual pre migrations" func=main.autoMigrationWithLeader.func1 file="/src/cmd/main.go:755"
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Finished manual pre migrations" func=main.autoMigrationWithLeader.func1 file="/src/cmd/main.go:761"
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Start automigration" func=main.autoMigrationWithLeader.func1 file="/src/cmd/main.go:763"
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Finished automigration" func=main.autoMigrationWithLeader.func1 file="/src/cmd/main.go:769"
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Starting manual post migrations" func=main.autoMigrationWithLeader.func1 file="/src/cmd/main.go:771"
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Finished manual post migrations" func=main.autoMigrationWithLeader.func1 file="/src/cmd/main.go:777"
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Started Cluster State Monitor" func="github.com/openshift/assisted-service/pkg/thread.(*Thread).Start" file="/src/pkg/thread/thread.go:41" pkg=cluster-monitor
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Started Host State Monitor" func="github.com/openshift/assisted-service/pkg/thread.(*Thread).Start" file="/src/pkg/thread/thread.go:41" pkg=host-monitor
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Started Deregister Worker" func="github.com/openshift/assisted-service/pkg/thread.(*Thread).Start" file="/src/pkg/thread/thread.go:41" garbagecollector="Deregister Worker"
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Started Deletion Worker" func="github.com/openshift/assisted-service/pkg/thread.(*Thread).Start" file="/src/pkg/thread/thread.go:41" garbagecollector="Deletion Worker"
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Started Orphan Deletion Worker" func="github.com/openshift/assisted-service/pkg/thread.(*Thread).Start" file="/src/pkg/thread/thread.go:41" garbagecollector="Orphan Deletion Worker"
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Starting pprof... log level: info\n" func=main.main.func3 file="/src/cmd/main.go:517"
Jun 06 02:05:38 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:38Z" level=info msg="Starting http handler on :8090..."
Jun 06 02:05:41 sno131.outbound.vz.bos2.lab wait-for-assisted-service.sh[3966]: .
Jun 06 02:05:41 sno131.outbound.vz.bos2.lab podman[4015]: 
Jun 06 02:05:41 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 8e43e65348e2f62e06c335b49b333e7f4fbd99d14276d18e1f90031251a8ef26.
Jun 06 02:05:41 sno131.outbound.vz.bos2.lab create-cluster-and-infraenv[4042]: time="2023-06-06T02:05:41Z" level=info msg="SERVICE_BASE_URL: http://192.168.14.27:8090/"
Jun 06 02:05:41 sno131.outbound.vz.bos2.lab create-cluster-and-infraenv[4042]: time="2023-06-06T02:05:41Z" level=info msg="Registering cluster"
Jun 06 02:05:41 sno131.outbound.vz.bos2.lab podman[4015]: time="2023-06-06T02:05:41Z" level=info msg="SERVICE_BASE_URL: http://192.168.14.27:8090/"
Jun 06 02:05:41 sno131.outbound.vz.bos2.lab podman[4015]: time="2023-06-06T02:05:41Z" level=info msg="Registering cluster"
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab create-cluster-and-infraenv[4042]: time="2023-06-06T02:05:42Z" level=info msg="releaseImage: quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27"
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab create-cluster-and-infraenv[4042]: time="2023-06-06T02:05:42Z" level=info msg="releaseImage version 4.13.2 cpuarch x86_64"
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab podman[4015]: time="2023-06-06T02:05:42Z" level=info msg="releaseImage: quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27"
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab podman[4015]: time="2023-06-06T02:05:42Z" level=info msg="releaseImage version 4.13.2 cpuarch x86_64"
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:42Z" level=info msg="Register cluster: sno131 with id 348785c6-46bc-472b-80be-59bd077b9966 and params &{AdditionalNtpSource:<nil> APIVip: APIVips:[] BaseDNSDomain:outbound.vz.bos2.lab ClusterNetworkCidr:<nil> ClusterNetworkHostPrefix:0 ClusterNetworks:[0xc001494e40] CPUArchitecture:x86_64 DiskEncryption:<nil> HighAvailabilityMode:0xc001505920 HTTPProxy:<nil> HTTPSProxy:<nil> Hyperthreading:<nil> IgnitionEndpoint:<nil> IngressVip: IngressVips:[] MachineNetworks:[0xc00029d300] Name:0xc001505930 NetworkType:0xc001505940 NoProxy:<nil> OcpReleaseImage: OlmOperators:[] OpenshiftVersion:0xc001505950 Platform:0xc000e7e1d8 PullSecret:0xc001505970 SchedulableMasters:<nil> ServiceNetworkCidr:<nil> ServiceNetworks:[0xc00029dec0] SSHPublicKey:ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQD74lZFSOSfH8fWf9L419M6TwfJQfruuEKODlf9jdFzxWji+Y8qUQqe3rV6bbc7joADJtKnB/amvMcBr3kl7uC3AvHQB+m/BY4EJAgxiGhnhQaznrHUFQhDF7OGw2c+DuzO+jZAO0ColKOr1oN5E8nZGqVJBNYvYdP3/vAx69oLvTTA5MMilL9Ftjbv3uq0iKqJJ6xQdCNIEoxpOaKm8tAC2o4Sae4pn1JJYvPyXjRBdtg9GO+0BpqTHMBz74IyVg6qgUTctymEAIFWFO0joFq7BadsChJD7Be7FJhilYxAPvFFsYuRnOuVbj9ZVV2hH2Hhqi7LwWFv/Hmz84xbl4+woPIuI5OnQ0ys9Ec+ZXeh1ImzRl7kkmJ7dHALY8kb886v2+mWEcv1IKYCcMssO8lf2ZCbau1VV0Z7H6aRrRzQDv0mETf+gTnyzT8uwKORSu208oLuWf4Asz979kcW8LF+gtRBpRgIY0INtNRoIRJCr8SHXGRveyzvMEDr2JRNDOM= root@hub-helper Tags:<nil> UserManagedNetworking:0xc0003f506d VipDhcpAllocation:0xc0003f506e}" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).RegisterClusterInternal" file="/src/internal/bminventory/inventory.go:465" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=Inventory request_id=3993d28c-bb95-4e64-95e9-a8714fa5a944
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:42Z" level=info msg="Verifying cluster platform and user-managed-networking, got platform=none and userManagedNetworking=true" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).setDefaultRegisterClusterParams" file="/src/internal/bminventory/inventory.go:343" go-id=236 pkg=Inventory request_id=3993d28c-bb95-4e64-95e9-a8714fa5a944
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:42Z" level=info msg="Cluster high-availability-mode is set to None, setting platform type to none and user-managed-networking to true" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).setDefaultRegisterClusterParams" file="/src/internal/bminventory/inventory.go:352" go-id=236 pkg=Inventory request_id=3993d28c-bb95-4e64-95e9-a8714fa5a944
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:42Z" level=info msg="selected cluster release image: arch=x86_64, openshiftVersion=4.13.2, url=quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).RegisterClusterInternal" file="/src/internal/bminventory/inventory.go:521" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=Inventory request_id=3993d28c-bb95-4e64-95e9-a8714fa5a944
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:42Z" level=info msg="Successfully registered cluster sno131 with id 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).RegisterClusterInternal.func1" file="/src/internal/bminventory/inventory.go:472" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=Inventory request_id=3993d28c-bb95-4e64-95e9-a8714fa5a944
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab create-cluster-and-infraenv[4042]: time="2023-06-06T02:05:42Z" level=info msg="Registered cluster with id: 348785c6-46bc-472b-80be-59bd077b9966"
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab create-cluster-and-infraenv[4042]: time="2023-06-06T02:05:42Z" level=info msg="Registering infraenv"
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab podman[4015]: time="2023-06-06T02:05:42Z" level=info msg="Registered cluster with id: 348785c6-46bc-472b-80be-59bd077b9966"
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab podman[4015]: time="2023-06-06T02:05:42Z" level=info msg="Registering infraenv"
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab create-cluster-and-infraenv[4042]: time="2023-06-06T02:05:42Z" level=info msg="Added 1 nmstateconfigs"
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab podman[4015]: time="2023-06-06T02:05:42Z" level=info msg="Added 1 nmstateconfigs"
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:42Z" level=info msg="Register infraenv: sno131 with id 5f396111-46ed-4173-9648-bc0a9a818139" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).RegisterInfraEnvInternal" file="/src/internal/bminventory/inventory.go:4358" cluster_id=5f396111-46ed-4173-9648-bc0a9a818139 go-id=236 pkg=Inventory request_id=dff149fb-72f0-4ae6-a349-331ffd0c2d9c
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:42Z" level=info msg="Adding NMConnection file <ens1f0.nmconnection>" func="github.com/openshift/assisted-service/pkg/staticnetworkconfig.(*StaticNetworkConfigGenerator).createNMConnectionFiles" file="/src/pkg/staticnetworkconfig/generator.go:129" pkg=static_network_config
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:42Z" level=info msg="prepare image for infraEnv 5f396111-46ed-4173-9648-bc0a9a818139" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).GenerateInfraEnvISOInternal" file="/src/internal/bminventory/inventory.go:1076" go-id=236 pkg=Inventory request_id=dff149fb-72f0-4ae6-a349-331ffd0c2d9c
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:42Z" level=info msg="Auth type is none: image URL will remain as http://192.168.14.27:8888/images/5f396111-46ed-4173-9648-bc0a9a818139?arch=x86_64&type=full-iso&version=4.13.2" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).signURL" file="/src/internal/bminventory/inventory_v2_handlers.go:769" go-id=236 pkg=Inventory request_id=dff149fb-72f0-4ae6-a349-331ffd0c2d9c
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:42Z" level=info msg="Start configuring static network for 1 hosts" func="github.com/openshift/assisted-service/pkg/staticnetworkconfig.(*StaticNetworkConfigGenerator).GenerateStaticNetworkConfigData" file="/src/pkg/staticnetworkconfig/generator.go:54" pkg=static_network_config
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:42Z" level=info msg="Adding NMConnection file <ens1f0.nmconnection>" func="github.com/openshift/assisted-service/pkg/staticnetworkconfig.(*StaticNetworkConfigGenerator).createNMConnectionFiles" file="/src/pkg/staticnetworkconfig/generator.go:129" pkg=static_network_config
Jun 06 02:05:42 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:42Z" level=info msg="Fetching image from OCP release (oc adm release info --image-for=okd-rpms --insecure=false quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27)" func="github.com/openshift/assisted-service/internal/oc.(*release).getImageFromRelease" file="/src/internal/oc/release.go:287" pkg=ignition
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=warning msg="command 'oc adm release info --image-for=okd-rpms --insecure=false quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27 --registry-config=/tmp/registry-config3944410227' exited with non-zero exit code 1: \nerror: no image tag \"okd-rpms\" exists in the release image quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27\n" func=github.com/openshift/assisted-service/internal/oc.execute file="/src/internal/oc/release.go:400" pkg=ignition
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=error msg="failed to get okd-rpms image from release image quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27" func="github.com/openshift/assisted-service/internal/oc.(*release).getImageByName" file="/src/internal/oc/release.go:131" error="command 'oc adm release info --image-for=okd-rpms --insecure=false quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27 --registry-config=/tmp/registry-config3944410227' exited with non-zero exit code 1: \nerror: no image tag \"okd-rpms\" exists in the release image quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27\n" pkg=ignition
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Generated infra env <5f396111-46ed-4173-9648-bc0a9a818139> image with ignition config" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).getIgnitionConfigForLogging" file="/src/internal/bminventory/inventory.go:1118" pkg=Inventory
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully registered InfraEnv sno131 with id 5f396111-46ed-4173-9648-bc0a9a818139" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).RegisterInfraEnvInternal.func1" file="/src/internal/bminventory/inventory.go:4367" cluster_id=5f396111-46ed-4173-9648-bc0a9a818139 go-id=236 pkg=Inventory request_id=dff149fb-72f0-4ae6-a349-331ffd0c2d9c
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab create-cluster-and-infraenv[4042]: time="2023-06-06T02:05:43Z" level=info msg="Registered infraenv with id: 5f396111-46ed-4173-9648-bc0a9a818139"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab create-cluster-and-infraenv[4042]: time="2023-06-06T02:05:43Z" level=info msg="Registering extra manifests"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab podman[4015]: time="2023-06-06T02:05:43Z" level=info msg="Registered infraenv with id: 5f396111-46ed-4173-9648-bc0a9a818139"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab podman[4015]: time="2023-06-06T02:05:43Z" level=info msg="Registering extra manifests"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=22c990e5-2b09-4279-867d-0897abc3a0cf
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/01-container-mount-ns-and-kubelet-conf-master-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=22c990e5-2b09-4279-867d-0897abc3a0cf
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Filesystem '/data/' usage is 3.6%" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClientDecorator).conditionalLog" file="/src/pkg/s3wrapper/filesystem.go:309"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/01-container-mount-ns-and-kubelet-conf-master-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=22c990e5-2b09-4279-867d-0897abc3a0cf
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=478db0bc-3096-49dd-98e4-d484fb2bdab2
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/02-master-workload-partitioning-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=478db0bc-3096-49dd-98e4-d484fb2bdab2
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/02-master-workload-partitioning-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=478db0bc-3096-49dd-98e4-d484fb2bdab2
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=c8549a1c-2e5d-4e7a-a698-aae8b9299d96
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/04-accelerated-container-startup-master-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=c8549a1c-2e5d-4e7a-a698-aae8b9299d96
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/04-accelerated-container-startup-master-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=c8549a1c-2e5d-4e7a-a698-aae8b9299d96
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=c4b13ddb-1341-4568-b59f-099d5b5812c4
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/05-kdump-config-master-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=c4b13ddb-1341-4568-b59f-099d5b5812c4
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/05-kdump-config-master-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=c4b13ddb-1341-4568-b59f-099d5b5812c4
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=52320781-b676-4b0c-8c71-0dd07c5a4755
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/06-kdump-master-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=52320781-b676-4b0c-8c71-0dd07c5a4755
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/06-kdump-master-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=52320781-b676-4b0c-8c71-0dd07c5a4755
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=edfd4552-e171-4005-886f-089997e80cc1
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/99-crio-disable-wipe-master-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=edfd4552-e171-4005-886f-089997e80cc1
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/99-crio-disable-wipe-master-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=edfd4552-e171-4005-886f-089997e80cc1
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=1040fee4-a812-4f07-97a2-7d36d6294e66
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/AmqSubscription-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=1040fee4-a812-4f07-97a2-7d36d6294e66
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/AmqSubscription-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=1040fee4-a812-4f07-97a2-7d36d6294e66
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=1f06ef7b-1589-448e-9d34-2451628a2b40
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/AmqSubscriptionNS-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=1f06ef7b-1589-448e-9d34-2451628a2b40
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/AmqSubscriptionNS-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=1f06ef7b-1589-448e-9d34-2451628a2b40
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=afdbc7ab-c2b9-4c76-8d8b-aa07a3f34c5a
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/AmqSubscriptionOperGroup-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=afdbc7ab-c2b9-4c76-8d8b-aa07a3f34c5a
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/AmqSubscriptionOperGroup-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=afdbc7ab-c2b9-4c76-8d8b-aa07a3f34c5a
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=82db5ec5-62a8-42be-9286-f1954f102589
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/PtpSubscription-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=82db5ec5-62a8-42be-9286-f1954f102589
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/PtpSubscription-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=82db5ec5-62a8-42be-9286-f1954f102589
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=bbbc2d55-23ec-4f5f-b25e-29caa0e0c1c2
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/PtpSubscriptionNS-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=bbbc2d55-23ec-4f5f-b25e-29caa0e0c1c2
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/PtpSubscriptionNS-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=bbbc2d55-23ec-4f5f-b25e-29caa0e0c1c2
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=7f87d606-9a93-4dbe-ac25-31705610e154
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/PtpSubscriptionOperGroup-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=7f87d606-9a93-4dbe-ac25-31705610e154
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/PtpSubscriptionOperGroup-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=7f87d606-9a93-4dbe-ac25-31705610e154
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=f12ccebd-8855-46be-843a-11983ab6a755
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/SriovSubscription-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=f12ccebd-8855-46be-843a-11983ab6a755
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/SriovSubscription-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=f12ccebd-8855-46be-843a-11983ab6a755
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=3e3d2d1a-4ad7-4e9f-8c75-7aad1d725c09
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/SriovSubscriptionNS-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=3e3d2d1a-4ad7-4e9f-8c75-7aad1d725c09
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/SriovSubscriptionNS-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=3e3d2d1a-4ad7-4e9f-8c75-7aad1d725c09
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=f7293a6c-3fbb-415c-aa5e-45e9edb8b687
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/SriovSubscriptionOperGroup-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=f7293a6c-3fbb-415c-aa5e-45e9edb8b687
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/SriovSubscriptionOperGroup-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=f7293a6c-3fbb-415c-aa5e-45e9edb8b687
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=b244fe77-0acc-4686-87fe-83ae5c77cef7
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/StorageNS-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=b244fe77-0acc-4686-87fe-83ae5c77cef7
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/StorageNS-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=b244fe77-0acc-4686-87fe-83ae5c77cef7
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=084b649e-98c1-4180-bfc6-7e8c7399eb56
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/StorageOperGroup-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=084b649e-98c1-4180-bfc6-7e8c7399eb56
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/StorageOperGroup-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=084b649e-98c1-4180-bfc6-7e8c7399eb56
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab start-agent.sh[3898]: Querying assisted-service for infra-env-id...
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=ea4b2324-4db1-465c-a6a6-d3d8a3487ec5
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/StorageSubscription-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=ea4b2324-4db1-465c-a6a6-d3d8a3487ec5
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/StorageSubscription-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=ea4b2324-4db1-465c-a6a6-d3d8a3487ec5
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=ef0d6e9e-2198-429f-af6b-3e29ebde2475
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/enable-crun-master-0.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 request_id=ef0d6e9e-2198-429f-af6b-3e29ebde2475
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Done creating manifest openshift/enable-crun-master-0.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=236 pkg=manifests request_id=ef0d6e9e-2198-429f-af6b-3e29ebde2475
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab systemd[1]: libpod-8e43e65348e2f62e06c335b49b333e7f4fbd99d14276d18e1f90031251a8ef26.scope: Deactivated successfully.
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab start-agent.sh[3898]: Fetched infra-env-id and found: 5f396111-46ed-4173-9648-bc0a9a818139
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-7d09dd6efff9ffe9482079cb8b5425672b7d8ad9bfe26d2553ef29e0a127ebcc-merged.mount: Deactivated successfully.
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab systemd[1]: Finished Service that creates initial cluster and infraenv.
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab systemd[1]: Starting Service that applies host-specific configuration...
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab systemd[1]: Started Service that monitors host-specific configuration status.
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab wait-for-assisted-service.sh[4176]: Waiting for assisted-service to be ready
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 896a74935820643cacc21c8c0aae9efe20e223c678183344f02d9ffcddc4d3fc.
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab podman[4181]: 
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container f6fecb4ca43da3a7ef16682e62a49014f7df4bc4a20ef8088c315644c69ae22e.
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab systemd[1]: libpod-896a74935820643cacc21c8c0aae9efe20e223c678183344f02d9ffcddc4d3fc.scope: Deactivated successfully.
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab start-agent.sh[3898]: Using agent image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d to start agent
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:43Z" level=info msg="SERVICE_BASE_URL: http://192.168.14.27:8090/"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:43Z" level=info msg="Loading host configurations from disk in /etc/assisted/hostconfig"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:43Z" level=info msg="Reading directory /etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:43Z" level=info msg="No agent found matching config at /etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab (b4:96:91:d9:a4:64)"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:43Z" level=info msg="Not all hosts present yet"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:43Z" level=info msg="Sleeping for 1s"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:43Z" level=info msg="SERVICE_BASE_URL: http://192.168.14.27:8090/"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:43Z" level=info msg="Loading host configurations from disk in /etc/assisted/hostconfig"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:43Z" level=info msg="Reading directory /etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:43Z" level=info msg="No agent found matching config at /etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab (b4:96:91:d9:a4:64)"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:43Z" level=info msg="Not all hosts present yet"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:43Z" level=info msg="Sleeping for 1s"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab start-agent.sh[3898]: time="2023-06-06T02:05:43Z" level=warning msg="Agent Authentication Token not set"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab agent[3898]: time="06-06-2023 02:05:43" level=warning msg="Certificate verification is turned off. This is not recommended in production environments" file="inventory_session.go:126"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab agent[3898]: time="06-06-2023 02:05:43" level=info msg="Motherboard serial number is PZBVLZZLMG10H2" file="machine_uuid_scanner.go:102"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Register host: {HTTPRequest:0xc0019ddb00 DiscoveryAgentVersion:0xc000e58d90 InfraEnvID:5f396111-46ed-4173-9648-bc0a9a818139 NewHostParams:0xc000b88a68}" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2RegisterHost" file="/src/internal/bminventory/inventory.go:5012" go-id=317 infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=71f18ba8-c9f2-47cf-9e36-425c0fe0b03c
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Register new host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra env 5f396111-46ed-4173-9648-bc0a9a818139" func="github.com/openshift/assisted-service/internal/host.(*transitionHandler).PostRegisterHost" file="/src/internal/host/transition.go:125" go-id=317 infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=host-state request_id=71f18ba8-c9f2-47cf-9e36-425c0fe0b03c
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab agent[3898]: time="06-06-2023 02:05:43" level=info msg="Validating next step runner with args [{\"agent_version\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d\",\"host_id\":\"1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f\",\"infra_env_id\":\"5f396111-46ed-4173-9648-bc0a9a818139\"}]" file="action.go:29"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab agent[3898]: time="06-06-2023 02:05:43" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- podman rm -i next-step-runner]" file="execute.go:39"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab agent[3898]: time="06-06-2023 02:05:43" level=info msg="Running next step runner. Command: podman, Args: [run --rm -ti --privileged --pid=host --net=host --pids-limit=0 -v /dev:/dev:rw -v /opt:/opt:rw -v /run/systemd/journal/socket:/run/systemd/journal/socket -v /var/log:/var/log:rw -v /run/media:/run/media:rw -v /etc/pki:/etc/pki --env PULL_SECRET_TOKEN --env CONTAINERS_CONF --env CONTAINERS_STORAGE_CONF --env HTTP_PROXY --env HTTPS_PROXY --env NO_PROXY --env http_proxy --env https_proxy --env no_proxy --name next-step-runner quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d next_step_runner --url http://192.168.14.27:8090/ --infra-env-id 5f396111-46ed-4173-9648-bc0a9a818139 --host-id 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f --agent-version quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d --insecure=true]" file="agent.go:57"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab agent[3898]: time="06-06-2023 02:05:43" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- podman rm -i next-step-runner]" file="execute.go:39"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab agent[3898]: time="06-06-2023 02:05:43" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- podman run --rm -ti --privileged --pid=host --net=host --pids-limit=0 -v /dev:/dev:rw -v /opt:/opt:rw -v /run/systemd/journal/socket:/run/systemd/journal/socket -v /var/log:/var/log:rw -v /run/media:/run/media:rw -v /etc/pki:/etc/pki --env PULL_SECRET_TOKEN --env CONTAINERS_CONF --env CONTAINERS_STORAGE_CONF --env HTTP_PROXY --env HTTPS_PROXY --env NO_PROXY --env http_proxy --env https_proxy --env no_proxy --name next-step-runner quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d next_step_runner --url http://192.168.14.27:8090/ --infra-env-id 5f396111-46ed-4173-9648-bc0a9a818139 --host-id 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f --agent-version quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d --insecure=true]" file="execute.go:39"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 960e231b14850e73ea3702ecb0d9222bf5d681df20c9d96af44776c3f8027026.
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:05:43" level=warning msg="Certificate verification is turned off. This is not recommended in production environments" file="inventory_session.go:126"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:05:43" level=info msg="Query for next steps" file="step_processor.go:233" request_id=32bffe29-a336-4071-a958-f01d5e7c8d2c
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="GetNextSteps infra_env: <5f396111-46ed-4173-9648-bc0a9a818139>, host: <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>, host status: <discovering>" func="github.com/openshift/assisted-service/internal/host/hostcommands.(*InstructionManager).GetNextSteps" file="/src/internal/host/hostcommands/instruction_manager.go:160" go-id=300 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=32bffe29-a336-4071-a958-f01d5e7c8d2c
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:43Z" level=info msg="Submitting step <inventory> id <inventory-3a4efced> to infra_env <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>  Arguments: <[1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f]>" func=github.com/openshift/assisted-service/internal/host/hostcommands.logSteps file="/src/internal/host/hostcommands/instruction_manager.go:287" go-id=300 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=32bffe29-a336-4071-a958-f01d5e7c8d2c
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:05:43" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- findmnt --raw --noheadings --output SOURCE,TARGET --target /run/media/iso]" file="execute.go:39"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:05:43" level=info msg="Creating execution step for inventory inventory-3a4efced args <[1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f]>" file="step_processor.go:123" request_id=32bffe29-a336-4071-a958-f01d5e7c8d2c
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:05:43" level=info msg="Validating inventory with args [1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f]" file="action.go:29"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:05:43" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- sh -c cp /etc/mtab /root/mtab-1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f && podman run --privileged --pid=host --net=host --rm --quiet -v /var/log:/var/log -v /run/udev:/run/udev -v /dev/disk:/dev/disk -v /run/systemd/journal/socket:/run/systemd/journal/socket -v /var/log:/host/var/log:ro -v /proc/meminfo:/host/proc/meminfo:ro -v /sys/kernel/mm/hugepages:/host/sys/kernel/mm/hugepages:ro -v /proc/cpuinfo:/host/proc/cpuinfo:ro -v /root/mtab-1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f:/host/etc/mtab:ro -v /sys/block:/host/sys/block:ro -v /sys/devices:/host/sys/devices:ro -v /sys/bus:/host/sys/bus:ro -v /sys/class:/host/sys/class:ro -v /run/udev:/host/run/udev:ro -v /dev/disk:/host/dev/disk:ro quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d inventory]" file="execute.go:39"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab systemd[1]: Started libpod-conmon-e6511a205c22aefaeffc22c4c6033b1e747600032bc653d5199e11d7fefc66f7.scope.
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container e6511a205c22aefaeffc22c4c6033b1e747600032bc653d5199e11d7fefc66f7.
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:43" level=info msg="Executing ipmitool [lan print 1]" file="execute.go:39"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:43" level=info msg="Executing ipmitool [lan6 print 1 enables]" file="execute.go:39"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:43" level=info msg="Executing ipmitool [lan6 print 1 dynamic_addr]" file="execute.go:39"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:43" level=info msg="Executing lscpu [-J]" file="execute.go:39"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:43" level=info msg="Executing file [-s /dev/nvme0n1]" file="execute.go:39"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:43" level=info msg="Executing sg_inq [-p 0x83 /dev/nvme0n1]" file="execute.go:39"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:43" level=info msg="Executing file [-s /dev/nvme1n1]" file="execute.go:39"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:43" level=info msg="Executing sg_inq [-p 0x83 /dev/nvme1n1]" file="execute.go:39"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:43" level=info msg="Disk (name sr0 drive type ODD bus path pci-0000:01:00.4-usb-0:2:1.0-scsi-0:0:0:0 vendor iLO model Virtual_DVD-ROM partitions []) was found to be ineligible for installation for the following reasons: Disk is removable" file="disks.go:326"
Jun 06 02:05:43 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:43" level=info msg="Executing file [-s /dev/sr0]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing sg_inq [-p 0x83 /dev/sr0]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-33d5f518fbf60cab3278166647445dc146240d49bbd979499cbf78ae9d238f74-merged.mount: Deactivated successfully.
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-896a74935820643cacc21c8c0aae9efe20e223c678183344f02d9ffcddc4d3fc-userdata-shm.mount: Deactivated successfully.
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="hasUUID is false for path /dev/sr0: exit code 97, stdout: \n, stderr: invalid VPD response; probably a STANDARD INQUIRY response\n    inquiry: Malformed SCSI command\nsg_inq failed: Malformed SCSI command\n" file="disks.go:136"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:44Z" level=info msg="Checking configuration for host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:44Z" level=info msg="Inventory information not yet available"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:44Z" level=info msg="Checking configuration for host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:44Z" level=info msg="Inventory information not yet available"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:44Z" level=info msg="No agent found matching config at /etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab (b4:96:91:d9:a4:64)"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:44Z" level=info msg="Not all hosts present yet"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:44Z" level=info msg="Sleeping for 2s"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:44Z" level=info msg="No agent found matching config at /etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab (b4:96:91:d9:a4:64)"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:44Z" level=info msg="Not all hosts present yet"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:44Z" level=info msg="Sleeping for 2s"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing biosdevname [-i lo]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=warning msg="Could not read lo speed" file="network_interface.go:90" error="read /sys/class/net/lo/speed: invalid argument"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing biosdevname [-i eno1]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing biosdevname [-i ens1f0]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing biosdevname [-i ens1f1]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing biosdevname [-i ens1f2]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing biosdevname [-i ens1f3]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing biosdevname [-i ens2f0]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing biosdevname [-i ens2f1]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing biosdevname [-i ens2f2]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing biosdevname [-i ens2f3]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing biosdevname [-i cni-podman0]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing biosdevname [-i veth32502cb4]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing dmidecode [-t 17]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing systemd-detect-virt [--vm]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=warning msg="Error running systemd-detect-virt: exit status 1" file="system_vendor.go:37"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab inventory[4451]: time="06-06-2023 02:05:44" level=info msg="Executing cat [/sys/class/tpm/tpm0/tpm_version_major]" file="execute.go:39"
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab systemd[1]: libpod-e6511a205c22aefaeffc22c4c6033b1e747600032bc653d5199e11d7fefc66f7.scope: Deactivated successfully.
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-e6511a205c22aefaeffc22c4c6033b1e747600032bc653d5199e11d7fefc66f7-userdata-shm.mount: Deactivated successfully.
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-71452ae1f01a881462432aa9073ea81c7864e2aa0935a0a3a493a67efb7b4163-merged.mount: Deactivated successfully.
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab systemd[1]: libpod-conmon-e6511a205c22aefaeffc22c4c6033b1e747600032bc653d5199e11d7fefc66f7.scope: Deactivated successfully.
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:05:44" level=info msg="Sending step <inventory-3a4efced> reply output <{\"bmc_address\":\"192.168.14.131\",\"bmc_v6address\":\"fe80::5eba:2cff:fe1f:6ce4\",\"boot\":{\"current_boot_mode\":\"uefi\"},\"cpu\":{\"architecture\":\"x86_64\",\"count\":64,\"flags\":[\"fpu\",\"vme\",\"de\",\"pse\",\"tsc\",\"msr\",\"pae\",\"mce\",\"cx8\",\"apic\",\"sep\",\"mtrr\",\"pge\",\"mca\",\"cmov\",\"pat\",\"pse36\",\"clflush\",\"dts\",\"acpi\",\"mmx\",\"fxsr\",\"sse\",\"sse2\",\"ss\",\"ht\",\"tm\",\"pbe\",\"syscall\",\"nx\",\"pdpe1gb\",\"rdtscp\",\"lm\",\"constant_tsc\",\"art\",\"arch_perfmon\",\"pebs\",\"bts\",\"rep_good\",\"nopl\",\"xtopology\",\"nonstop_tsc\",\"cpuid\",\"aperfmperf\",\"pni\",\"pclmulqdq\",\"dtes64\",\"monitor\",\"ds_cpl\",\"vmx\",\"smx\",\"est\",\"tm2\",\"ssse3\",\"sdbg\",\"fma\",\"cx16\",\"xtpr\",\"pdcm\",\"pcid\",\"dca\",\"sse4_1\",\"sse4_2\",\"x2apic\",\"movbe\",\"popcnt\",\"tsc_deadline_timer\",\"aes\",\"xsave\",\"avx\",\"f16c\",\"rdrand\",\"lahf_lm\",\"abm\",\"3dnowprefetch\",\"cpuid_fault\",\"epb\",\"cat_l3\",\"invpcid_single\",\"ssbd\",\"mba\",\"ibrs\",\"ibpb\",\"stibp\",\"ibrs_enhanced\",\"tpr_shadow\",\"vnmi\",\"flexpriority\",\"ept\",\"vpid\",\"ept_ad\",\"fsgsbase\",\"tsc_adjust\",\"bmi1\",\"avx2\",\"smep\",\"bmi2\",\"erms\",\"invpcid\",\"cqm\",\"rdt_a\",\"avx512f\",\"avx512dq\",\"rdseed\",\"adx\",\"smap\",\"avx512ifma\",\"clflushopt\",\"clwb\",\"intel_pt\",\"avx512cd\",\"sha_ni\",\"avx512bw\",\"avx512vl\",\"xsaveopt\",\"xsavec\",\"xgetbv1\",\"xsaves\",\"cqm_llc\",\"cqm_occup_llc\",\"cqm_mbm_total\",\"cqm_mbm_local\",\"split_lock_detect\",\"wbnoinvd\",\"dtherm\",\"ida\",\"arat\",\"pln\",\"pts\",\"hwp\",\"hwp_act_window\",\"hwp_pkg_req\",\"avx512vbmi\",\"umip\",\"pku\",\"ospke\",\"avx512_vbmi2\",\"gfni\",\"vaes\",\"vpclmulqdq\",\"avx512_vnni\",\"avx512_bitalg\",\"tme\",\"avx512_vpopcntdq\",\"la57\",\"rdpid\",\"fsrm\",\"md_clear\",\"pconfig\",\"flush_l1d\",\"arch_capabilities\"],\"frequency\":3500,\"model_name\":\"Intel(R) Xeon(R) Gold 6338N CPU @ 2.20GHz\"},\"disks\":[{\"by_id\":\"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\",\"by_path\":\"/dev/disk/by-path/pci-0000:c2:00.0-nvme-1\",\"drive_type\":\"SSD\",\"has_uuid\":true,\"id\":\"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\",\"installation_eligibility\":{\"eligible\":true,\"not_eligible_reasons\":null},\"model\":\"SAMSUNG MZ1LB1T9HALS-00007\",\"name\":\"nvme0n1\",\"path\":\"/dev/nvme0n1\",\"serial\":\"S436NA0R757305\",\"size_bytes\":1920383410176,\"wwn\":\"eui.34333630527573050025384100000001\"},{\"by_id\":\"/dev/disk/by-id/nvme-eui.34333630527572890025384100000001\",\"by_path\":\"/dev/disk/by-path/pci-0000:c3:00.0-nvme-1\",\"drive_type\":\"SSD\",\"has_uuid\":true,\"id\":\"/dev/disk/by-id/nvme-eui.34333630527572890025384100000001\",\"installation_eligibility\":{\"eligible\":true,\"not_eligible_reasons\":null},\"model\":\"SAMSUNG MZ1LB1T9HALS-00007\",\"name\":\"nvme1n1\",\"path\":\"/dev/nvme1n1\",\"serial\":\"S436NA0R757289\",\"size_bytes\":1920383410176,\"wwn\":\"eui.34333630527572890025384100000001\"},{\"by_path\":\"/dev/disk/by-path/pci-0000:01:00.4-usb-0:2:1.0-scsi-0:0:0:0\",\"drive_type\":\"ODD\",\"hctl\":\"0:0:0:0\",\"id\":\"/dev/disk/by-path/pci-0000:01:00.4-usb-0:2:1.0-scsi-0:0:0:0\",\"installation_eligibility\":{\"not_eligible_reasons\":[\"Disk is removable\"]},\"is_installation_media\":true,\"model\":\"Virtual_DVD-ROM\",\"name\":\"sr0\",\"path\":\"/dev/sr0\",\"removable\":true,\"serial\":\"iLO_Virtual_DVD-ROM-0:0\",\"size_bytes\":1108533248,\"vendor\":\"iLO\"}],\"gpus\":[{\"address\":\"0000:01:00.1\"}],\"hostname\":\"sno131.outbound.vz.bos2.lab\",\"interfaces\":[{\"flags\":[\"up\",\"loopback\"],\"has_carrier\":true,\"ipv4_addresses\":[\"127.0.0.1/8\"],\"ipv6_addresses\":[\"::1/128\"],\"mtu\":65536,\"name\":\"lo\",\"type\":\"device\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"has_carrier\":true,\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"5c:ba:2c:1f:6c:e5\",\"mtu\":1500,\"name\":\"eno1\",\"product\":\"0x1537\",\"speed_mbps\":1000,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"has_carrier\":true,\"ipv4_addresses\":[\"192.168.14.27/27\"],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:d9:a4:64\",\"mtu\":1500,\"name\":\"ens1f0\",\"product\":\"0x1593\",\"speed_mbps\":25000,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:d9:a4:65\",\"mtu\":1500,\"name\":\"ens1f1\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:d9:a4:66\",\"mtu\":1500,\"name\":\"ens1f2\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:d9:a4:67\",\"mtu\":1500,\"name\":\"ens1f3\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:da:5a:c4\",\"mtu\":1500,\"name\":\"ens2f0\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:da:5a:c5\",\"mtu\":1500,\"name\":\"ens2f1\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:da:5a:c6\",\"mtu\":1500,\"name\":\"ens2f2\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:da:5a:c7\",\"mtu\":1500,\"name\":\"ens2f3\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"has_carrier\":true,\"ipv4_addresses\":[\"10.88.0.1/16\"],\"ipv6_addresses\":[],\"mac_address\":\"32:0b:12:25:7a:9e\",\"mtu\":1500,\"name\":\"cni-podman0\",\"speed_mbps\":10000,\"type\":\"bridge\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"has_carrier\":true,\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"e6:34:33:49:48:95\",\"mtu\":1500,\"name\":\"veth32502cb4\",\"speed_mbps\":10000,\"type\":\"veth\"}],\"memory\":{\"physical_bytes\":137438953472,\"physical_bytes_method\":\"dmidecode\",\"usable_bytes\":134738038784},\"routes\":[{\"destination\":\"0.0.0.0\",\"family\":2,\"gateway\":\"192.168.14.1\",\"interface\":\"ens1f0\",\"metric\":101},{\"destination\":\"10.88.0.0\",\"family\":2,\"interface\":\"cni-podman0\"},{\"destination\":\"192.168.14.0\",\"family\":2,\"interface\":\"ens1f0\",\"metric\":101},{\"destination\":\"::1\",\"family\":10,\"interface\":\"lo\",\"metric\":256},{\"destination\":\"fe80::\",\"family\":10,\"interface\":\"cni-podman0\",\"metric\":256},{\"destination\":\"fe80::\",\"family\":10,\"interface\":\"veth32502cb4\",\"metric\":256},{\"destination\":\"fe80::\",\"family\":10,\"interface\":\"eno1\",\"metric\":1024}],\"system_vendor\":{\"manufacturer\":\"HPE\",\"product_name\":\"Edgeline e920t\",\"serial_number\":\"MXQ2140KJL\"},\"tpm_version\":\"2.0\"}> error <> exit-code <0>" file="step_processor.go:76" request_id=32bffe29-a336-4071-a958-f01d5e7c8d2c
Jun 06 02:05:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:44Z" level=info msg="Received step reply <inventory-3a4efced> from infra-env <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f> exit-code <0> stderr <> stdout <{\"bmc_address\":\"192.168.14.131\",\"bmc_v6address\":\"fe80::5eba:2cff:fe1f:6ce4\",\"boot\":{\"current_boot_mode\":\"uefi\"},\"cpu\":{\"architecture\":\"x86_64\",\"count\":64,\"flags\":[\"fpu\",\"vme\",\"de\",\"pse\",\"tsc\",\"msr\",\"pae\",\"mce\",\"cx8\",\"apic\",\"sep\",\"mtrr\",\"pge\",\"mca\",\"cmov\",\"pat\",\"pse36\",\"clflush\",\"dts\",\"acpi\",\"mmx\",\"fxsr\",\"sse\",\"sse2\",\"ss\",\"ht\",\"tm\",\"pbe\",\"syscall\",\"nx\",\"pdpe1gb\",\"rdtscp\",\"lm\",\"constant_tsc\",\"art\",\"arch_perfmon\",\"pebs\",\"bts\",\"rep_good\",\"nopl\",\"xtopology\",\"nonstop_tsc\",\"cpuid\",\"aperfmperf\",\"pni\",\"pclmulqdq\",\"dtes64\",\"monitor\",\"ds_cpl\",\"vmx\",\"smx\",\"est\",\"tm2\",\"ssse3\",\"sdbg\",\"fma\",\"cx16\",\"xtpr\",\"pdcm\",\"pcid\",\"dca\",\"sse4_1\",\"sse4_2\",\"x2apic\",\"movbe\",\"popcnt\",\"tsc_deadline_timer\",\"aes\",\"xsave\",\"avx\",\"f16c\",\"rdrand\",\"lahf_lm\",\"abm\",\"3dnowprefetch\",\"cpuid_fault\",\"epb\",\"cat_l3\",\"invpcid_single\",\"ssbd\",\"mba\",\"ibrs\",\"ibpb\",\"stibp\",\"ibrs_enhanced\",\"tpr_shadow\",\"vnmi\",\"flexpriority\",\"ept\",\"vpid\",\"ept_ad\",\"fsgsbase\",\"tsc_adjust\",\"bmi1\",\"avx2\",\"smep\",\"bmi2\",\"erms\",\"invpcid\",\"cqm\",\"rdt_a\",\"avx512f\",\"avx512dq\",\"rdseed\",\"adx\",\"smap\",\"avx512ifma\",\"clflushopt\",\"clwb\",\"intel_pt\",\"avx512cd\",\"sha_ni\",\"avx512bw\",\"avx512vl\",\"xsaveopt\",\"xsavec\",\"xgetbv1\",\"xsaves\",\"cqm_llc\",\"cqm_occup_llc\",\"cqm_mbm_total\",\"cqm_mbm_local\",\"split_lock_detect\",\"wbnoinvd\",\"dtherm\",\"ida\",\"arat\",\"pln\",\"pts\",\"hwp\",\"hwp_act_window\",\"hwp_pkg_req\",\"avx512vbmi\",\"umip\",\"pku\",\"ospke\",\"avx512_vbmi2\",\"gfni\",\"vaes\",\"vpclmulqdq\",\"avx512_vnni\",\"avx512_bitalg\",\"tme\",\"avx512_vpopcntdq\",\"la57\",\"rdpid\",\"fsrm\",\"md_clear\",\"pconfig\",\"flush_l1d\",\"arch_capabilities\"],\"frequency\":3500,\"model_name\":\"Intel(R) Xeon(R) Gold 6338N CPU @ 2.20GHz\"},\"disks\":[{\"by_id\":\"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\",\"by_path\":\"/dev/disk/by-path/pci-0000:c2:00.0-nvme-1\",\"drive_type\":\"SSD\",\"has_uuid\":true,\"id\":\"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\",\"installation_eligibility\":{\"eligible\":true,\"not_eligible_reasons\":null},\"model\":\"SAMSUNG MZ1LB1T9HALS-00007\",\"name\":\"nvme0n1\",\"path\":\"/dev/nvme0n1\",\"serial\":\"S436NA0R757305\",\"size_bytes\":1920383410176,\"wwn\":\"eui.34333630527573050025384100000001\"},{\"by_id\":\"/dev/disk/by-id/nvme-eui.34333630527572890025384100000001\",\"by_path\":\"/dev/disk/by-path/pci-0000:c3:00.0-nvme-1\",\"drive_type\":\"SSD\",\"has_uuid\":true,\"id\":\"/dev/disk/by-id/nvme-eui.34333630527572890025384100000001\",\"installation_eligibility\":{\"eligible\":true,\"not_eligible_reasons\":null},\"model\":\"SAMSUNG MZ1LB1T9HALS-00007\",\"name\":\"nvme1n1\",\"path\":\"/dev/nvme1n1\",\"serial\":\"S436NA0R757289\",\"size_bytes\":1920383410176,\"wwn\":\"eui.34333630527572890025384100000001\"},{\"by_path\":\"/dev/disk/by-path/pci-0000:01:00.4-usb-0:2:1.0-scsi-0:0:0:0\",\"drive_type\":\"ODD\",\"hctl\":\"0:0:0:0\",\"id\":\"/dev/disk/by-path/pci-0000:01:00.4-usb-0:2:1.0-scsi-0:0:0:0\",\"installation_eligibility\":{\"not_eligible_reasons\":[\"Disk is removable\"]},\"is_installation_media\":true,\"model\":\"Virtual_DVD-ROM\",\"name\":\"sr0\",\"path\":\"/dev/sr0\",\"removable\":true,\"serial\":\"iLO_Virtual_DVD-ROM-0:0\",\"size_bytes\":1108533248,\"vendor\":\"iLO\"}],\"gpus\":[{\"address\":\"0000:01:00.1\"}],\"hostname\":\"sno131.outbound.vz.bos2.lab\",\"interfaces\":[{\"flags\":[\"up\",\"loopback\"],\"has_carrier\":true,\"ipv4_addresses\":[\"127.0.0.1/8\"],\"ipv6_addresses\":[\"::1/128\"],\"mtu\":65536,\"name\":\"lo\",\"type\":\"device\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"has_carrier\":true,\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"5c:ba:2c:1f:6c:e5\",\"mtu\":1500,\"name\":\"eno1\",\"product\":\"0x1537\",\"speed_mbps\":1000,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"has_carrier\":true,\"ipv4_addresses\":[\"192.168.14.27/27\"],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:d9:a4:64\",\"mtu\":1500,\"name\":\"ens1f0\",\"product\":\"0x1593\",\"speed_mbps\":25000,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:d9:a4:65\",\"mtu\":1500,\"name\":\"ens1f1\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:d9:a4:66\",\"mtu\":1500,\"name\":\"ens1f2\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:d9:a4:67\",\"mtu\":1500,\"name\":\"ens1f3\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:da:5a:c4\",\"mtu\":1500,\"name\":\"ens2f0\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:da:5a:c5\",\"mtu\":1500,\"name\":\"ens2f1\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:da:5a:c6\",\"mtu\":1500,\"name\":\"ens2f2\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:da:5a:c7\",\"mtu\":1500,\"name\":\"ens2f3\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"has_carrier\":true,\"ipv4_addresses\":[\"10.88.0.1/16\"],\"ipv6_addresses\":[],\"mac_address\":\"32:0b:12:25:7a:9e\",\"mtu\":1500,\"name\":\"cni-podman0\",\"speed_mbps\":10000,\"type\":\"bridge\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"has_carrier\":true,\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"e6:34:33:49:48:95\",\"mtu\":1500,\"name\":\"veth32502cb4\",\"speed_mbps\":10000,\"type\":\"veth\"}],\"memory\":{\"physical_bytes\":137438953472,\"physical_bytes_method\":\"dmidecode\",\"usable_bytes\":134738038784},\"routes\":[{\"destination\":\"0.0.0.0\",\"family\":2,\"gateway\":\"192.168.14.1\",\"interface\":\"ens1f0\",\"metric\":101},{\"destination\":\"10.88.0.0\",\"family\":2,\"interface\":\"cni-podman0\"},{\"destination\":\"192.168.14.0\",\"family\":2,\"interface\":\"ens1f0\",\"metric\":101},{\"destination\":\"::1\",\"family\":10,\"interface\":\"lo\",\"metric\":256},{\"destination\":\"fe80::\",\"family\":10,\"interface\":\"cni-podman0\",\"metric\":256},{\"destination\":\"fe80::\",\"family\":10,\"interface\":\"veth32502cb4\",\"metric\":256},{\"destination\":\"fe80::\",\"family\":10,\"interface\":\"eno1\",\"metric\":1024}],\"system_vendor\":{\"manufacturer\":\"HPE\",\"product_name\":\"Edgeline e920t\",\"serial_number\":\"MXQ2140KJL\"},\"tpm_version\":\"2.0\"}>" func=github.com/openshift/assisted-service/internal/bminventory.logReplyReceived file="/src/internal/bminventory/inventory.go:3423" go-id=300 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=32bffe29-a336-4071-a958-f01d5e7c8d2c
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:05:46Z" level=info msg="host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f from infra env 5f396111-46ed-4173-9648-bc0a9a818139 has been updated with the following updates [status insufficient status_info Host cannot be installed due to following failing validation(s): Host couldn't synchronize with any NTP server status_updated_at 2023-06-06T02:05:46.352Z trigger_monitor_timestamp 2023-06-06 02:05:46.352462336 +0000 UTC m=+10.102728949]" func=github.com/openshift/assisted-service/internal/host/hostutil.UpdateHostStatus file="/src/internal/host/hostutil/update_host.go:77" go-id=199 pkg=host-state request_id=ecccf1fd-51de-43bf-a50b-3d08170eba85
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:46Z" level=info msg="Checking configuration for host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:46Z" level=info msg="Searching for config for host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:46Z" level=info msg="Checking configuration for host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:46Z" level=info msg="Found host config in /etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:46Z" level=info msg="Searching for config for host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:46Z" level=info msg="Found host config in /etc/assisted/hostconfig/sno131.outbound.vz.bos2.lab"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:46Z" level=info msg="Read root device hints file"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:46Z" level=info msg="Selected disk /dev/disk/by-id/nvme-eui.34333630527573050025384100000001 already matches root device hints"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:46Z" level=info msg="No role file found for host"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:46Z" level=info msg="No role configured"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:46Z" level=info msg="No configuration changes needed"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:46Z" level=info msg="All expected hosts found"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab podman[4181]: time="2023-06-06T02:05:46Z" level=info msg="Configured all hosts"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:46Z" level=info msg="Read root device hints file"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:46Z" level=info msg="Selected disk /dev/disk/by-id/nvme-eui.34333630527573050025384100000001 already matches root device hints"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:46Z" level=info msg="No role file found for host"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:46Z" level=info msg="No role configured"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:46Z" level=info msg="No configuration changes needed"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:46Z" level=info msg="All expected hosts found"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab apply-host-config[4255]: time="2023-06-06T02:05:46Z" level=info msg="Configured all hosts"
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab systemd[1]: libpod-f6fecb4ca43da3a7ef16682e62a49014f7df4bc4a20ef8088c315644c69ae22e.scope: Deactivated successfully.
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-fbe430e3fcd835bafe1d195bc488d1116d5c829210429b7100d97164fa8a2eaa-merged.mount: Deactivated successfully.
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab systemd[1]: Finished Service that applies host-specific configuration.
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab systemd[1]: Starting Service that starts cluster installation...
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Waiting for assisted-service to be ready
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Infra env id is 5f396111-46ed-4173-9648-bc0a9a818139
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Number of required master nodes: 1
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Number of required worker nodes: 0
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Total number of required nodes: 1
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4525]: Hosts known and ready for cluster installation (0/1)
Jun 06 02:05:46 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Waiting for hosts to become ready for cluster installation...
Jun 06 02:05:56 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4571]: Hosts known and ready for cluster installation (0/1)
Jun 06 02:05:56 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Waiting for hosts to become ready for cluster installation...
Jun 06 02:06:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017164.9166] device (eno1): state change: ip-config -> failed (reason 'ip-config-unavailable', sys-iface-state: 'managed')
Jun 06 02:06:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <warn>  [1686017164.9173] device (eno1): Activation: failed for connection 'Wired connection 1'
Jun 06 02:06:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017164.9174] device (eno1): state change: failed -> disconnected (reason 'none', sys-iface-state: 'managed')
Jun 06 02:06:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017164.9188] dhcp4 (eno1): canceled DHCP transaction
Jun 06 02:06:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017164.9188] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:06:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017164.9188] dhcp4 (eno1): state changed no lease
Jun 06 02:06:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017164.9194] policy: auto-activating connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:06:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017164.9196] device (eno1): Activation: starting connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:06:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017164.9197] device (eno1): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'managed')
Jun 06 02:06:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017164.9198] device (eno1): state change: prepare -> config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:06:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017164.9204] device (eno1): state change: config -> ip-config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:06:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017164.9211] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:06:06 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4615]: Hosts known and ready for cluster installation (0/1)
Jun 06 02:06:06 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Waiting for hosts to become ready for cluster installation...
Jun 06 02:06:16 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4659]: Hosts known and ready for cluster installation (0/1)
Jun 06 02:06:16 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Waiting for hosts to become ready for cluster installation...
Jun 06 02:06:26 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4703]: Hosts known and ready for cluster installation (0/1)
Jun 06 02:06:26 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Waiting for hosts to become ready for cluster installation...
Jun 06 02:06:36 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4748]: Hosts known and ready for cluster installation (0/1)
Jun 06 02:06:36 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Waiting for hosts to become ready for cluster installation...
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=warning msg="Certificate verification is turned off. This is not recommended in production environments" file="inventory_session.go:126"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Query for next steps" file="step_processor.go:233" request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:06:43Z" level=info msg="GetNextSteps infra_env: <5f396111-46ed-4173-9648-bc0a9a818139>, host: <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>, host status: <insufficient>" func="github.com/openshift/assisted-service/internal/host/hostcommands.(*InstructionManager).GetNextSteps" file="/src/internal/host/hostcommands/instruction_manager.go:160" go-id=549 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:06:43Z" level=info msg="Submitting step <inventory> id <inventory-c0d838c8> to infra_env <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>  Arguments: <[1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f]>" func=github.com/openshift/assisted-service/internal/host/hostcommands.logSteps file="/src/internal/host/hostcommands/instruction_manager.go:287" go-id=549 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:06:43Z" level=info msg="Submitting step <free-network-addresses> id <free-network-addresses-e0b29b86> to infra_env <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>  Arguments: <[[\"192.168.14.0/27\"]]>" func=github.com/openshift/assisted-service/internal/host/hostcommands.logSteps file="/src/internal/host/hostcommands/instruction_manager.go:287" go-id=549 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:06:43Z" level=info msg="Submitting step <ntp-synchronizer> id <ntp-synchronizer-fa7ed173> to infra_env <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>  Arguments: <[{\"ntp_source\":\"\"}]>" func=github.com/openshift/assisted-service/internal/host/hostcommands.logSteps file="/src/internal/host/hostcommands/instruction_manager.go:287" go-id=549 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:06:43Z" level=info msg="Submitting step <domain-resolution> id <domain-resolution-2f89d92a> to infra_env <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>  Arguments: <[{\"domains\":[{\"domain_name\":\"api.sno131.outbound.vz.bos2.lab\"},{\"domain_name\":\"api-int.sno131.outbound.vz.bos2.lab\"},{\"domain_name\":\"console-openshift-console.apps.sno131.outbound.vz.bos2.lab\"},{\"domain_name\":\"validateNoWildcardDNS.sno131.outbound.vz.bos2.lab\"}]}]>" func=github.com/openshift/assisted-service/internal/host/hostcommands.logSteps file="/src/internal/host/hostcommands/instruction_manager.go:287" go-id=549 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- findmnt --raw --noheadings --output SOURCE,TARGET --target /run/media/iso]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- findmnt --raw --noheadings --output SOURCE,TARGET --target /run/media/iso]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- findmnt --raw --noheadings --output SOURCE,TARGET --target /run/media/iso]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- findmnt --raw --noheadings --output SOURCE,TARGET --target /run/media/iso]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Creating execution step for domain-resolution domain-resolution-2f89d92a args <[{\"domains\":[{\"domain_name\":\"api.sno131.outbound.vz.bos2.lab\"},{\"domain_name\":\"api-int.sno131.outbound.vz.bos2.lab\"},{\"domain_name\":\"console-openshift-console.apps.sno131.outbound.vz.bos2.lab\"},{\"domain_name\":\"validateNoWildcardDNS.sno131.outbound.vz.bos2.lab\"}]}]>" file="step_processor.go:123" request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Validating domain resolution with args [{\"domains\":[{\"domain_name\":\"api.sno131.outbound.vz.bos2.lab\"},{\"domain_name\":\"api-int.sno131.outbound.vz.bos2.lab\"},{\"domain_name\":\"console-openshift-console.apps.sno131.outbound.vz.bos2.lab\"},{\"domain_name\":\"validateNoWildcardDNS.sno131.outbound.vz.bos2.lab\"}]}]" file="action.go:29"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Creating execution step for free-network-addresses free-network-addresses-e0b29b86 args <[[\"192.168.14.0/27\"]]>" file="step_processor.go:123" request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Validating free addresses with args [[\"192.168.14.0/27\"]]" file="action.go:29"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- sh -c podman ps --format '{{.Names}}' | grep -q '^free_addresses_scanner$' || podman run --privileged --net=host --rm --quiet --name free_addresses_scanner -v /var/log:/var/log -v /run/systemd/journal/socket:/run/systemd/journal/socket quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d free_addresses '[\"192.168.14.0/27\"]']" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Sending step <domain-resolution-2f89d92a> reply output <{\"resolutions\":[{\"domain_name\":\"api.sno131.outbound.vz.bos2.lab\",\"ipv4_addresses\":[\"192.168.14.27\"],\"ipv6_addresses\":[]},{\"domain_name\":\"api-int.sno131.outbound.vz.bos2.lab\",\"ipv4_addresses\":[\"192.168.14.27\"],\"ipv6_addresses\":[]},{\"domain_name\":\"console-openshift-console.apps.sno131.outbound.vz.bos2.lab\",\"ipv4_addresses\":[\"192.168.14.27\"],\"ipv6_addresses\":[]},{\"domain_name\":\"validateNoWildcardDNS.sno131.outbound.vz.bos2.lab\",\"ipv4_addresses\":[],\"ipv6_addresses\":[]}]}> error <> exit-code <0>" file="step_processor.go:76" request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:06:43Z" level=info msg="Received step reply <domain-resolution-2f89d92a> from infra-env <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f> exit-code <0> stderr <> stdout <{\"resolutions\":[{\"domain_name\":\"api.sno131.outbound.vz.bos2.lab\",\"ipv4_addresses\":[\"192.168.14.27\"],\"ipv6_addresses\":[]},{\"domain_name\":\"api-int.sno131.outbound.vz.bos2.lab\",\"ipv4_addresses\":[\"192.168.14.27\"],\"ipv6_addresses\":[]},{\"domain_name\":\"console-openshift-console.apps.sno131.outbound.vz.bos2.lab\",\"ipv4_addresses\":[\"192.168.14.27\"],\"ipv6_addresses\":[]},{\"domain_name\":\"validateNoWildcardDNS.sno131.outbound.vz.bos2.lab\",\"ipv4_addresses\":[],\"ipv6_addresses\":[]}]}>" func=github.com/openshift/assisted-service/internal/bminventory.logReplyReceived file="/src/internal/bminventory/inventory.go:3423" go-id=549 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Creating execution step for inventory inventory-c0d838c8 args <[1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f]>" file="step_processor.go:123" request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Validating inventory with args [1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f]" file="action.go:29"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- sh -c cp /etc/mtab /root/mtab-1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f && podman run --privileged --pid=host --net=host --rm --quiet -v /var/log:/var/log -v /run/udev:/run/udev -v /dev/disk:/dev/disk -v /run/systemd/journal/socket:/run/systemd/journal/socket -v /var/log:/host/var/log:ro -v /proc/meminfo:/host/proc/meminfo:ro -v /sys/kernel/mm/hugepages:/host/sys/kernel/mm/hugepages:ro -v /proc/cpuinfo:/host/proc/cpuinfo:ro -v /root/mtab-1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f:/host/etc/mtab:ro -v /sys/block:/host/sys/block:ro -v /sys/devices:/host/sys/devices:ro -v /sys/bus:/host/sys/bus:ro -v /sys/class:/host/sys/class:ro -v /run/udev:/host/run/udev:ro -v /dev/disk:/host/dev/disk:ro quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d inventory]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Creating execution step for ntp-synchronizer ntp-synchronizer-fa7ed173 args <[{\"ntp_source\":\"\"}]>" file="step_processor.go:123" request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Validating ntp synchronizer with args [{\"ntp_source\":\"\"}]" file="action.go:29"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- timeout 30 chronyc -n sources]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:43" level=info msg="Sending step <ntp-synchronizer-fa7ed173> reply output <{\"ntp_sources\":[{\"source_name\":\"x.ns.gin.ntt.net\",\"source_state\":\"synced\"},{\"source_name\":\"65-100-46-166.dia.static.qwest.net\",\"source_state\":\"combined\"},{\"source_name\":\"c-73-61-36-59.hsd1.nh.comcast.net\",\"source_state\":\"combined\"},{\"source_name\":\"pi3.rellim.com\",\"source_state\":\"not_combined\"}]}> error <> exit-code <0>" file="step_processor.go:76" request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:06:43Z" level=info msg="Received step reply <ntp-synchronizer-fa7ed173> from infra-env <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f> exit-code <0> stderr <> stdout <{\"ntp_sources\":[{\"source_name\":\"x.ns.gin.ntt.net\",\"source_state\":\"synced\"},{\"source_name\":\"65-100-46-166.dia.static.qwest.net\",\"source_state\":\"combined\"},{\"source_name\":\"c-73-61-36-59.hsd1.nh.comcast.net\",\"source_state\":\"combined\"},{\"source_name\":\"pi3.rellim.com\",\"source_state\":\"not_combined\"}]}>" func=github.com/openshift/assisted-service/internal/bminventory.logReplyReceived file="/src/internal/bminventory/inventory.go:3423" go-id=549 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:06:43Z" level=info msg="Updating ntp source of host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f to [{\"source_name\":\"x.ns.gin.ntt.net\",\"source_state\":\"synced\"},{\"source_name\":\"65-100-46-166.dia.static.qwest.net\",\"source_state\":\"combined\"},{\"source_name\":\"c-73-61-36-59.hsd1.nh.comcast.net\",\"source_state\":\"combined\"},{\"source_name\":\"pi3.rellim.com\",\"source_state\":\"not_combined\"}]" func="github.com/openshift/assisted-service/internal/host.(*Manager).UpdateNTP" file="/src/internal/host/host.go:847" pkg=host-state
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab systemd[1]: Started libpod-conmon-e7fbdddf1d43e3aa4b957a3422442844251f3c204b440bdfb1b150e4603bc86b.scope.
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab systemd[1]: Started libpod-conmon-bb91a0f623708b9ba646514dcd9909eb76fc532751716abfcea41b334eb9df22.scope.
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container e7fbdddf1d43e3aa4b957a3422442844251f3c204b440bdfb1b150e4603bc86b.
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container bb91a0f623708b9ba646514dcd9909eb76fc532751716abfcea41b334eb9df22.
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab free_addresses[4882]: time="06-06-2023 02:06:43" level=info msg="Executing nmap [-sn -PR -n -oX - 192.168.14.0/27]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:43" level=info msg="Executing ipmitool [lan print 1]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:43" level=info msg="Executing ipmitool [lan6 print 1 enables]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:43" level=info msg="Executing ipmitool [lan6 print 1 dynamic_addr]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:43" level=info msg="Executing lscpu [-J]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:43" level=info msg="Executing file [-s /dev/nvme0n1]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:43" level=info msg="Executing sg_inq [-p 0x83 /dev/nvme0n1]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:43" level=info msg="Executing file [-s /dev/nvme1n1]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:43" level=info msg="Executing sg_inq [-p 0x83 /dev/nvme1n1]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:43" level=info msg="Disk (name sr0 drive type ODD bus path pci-0000:01:00.4-usb-0:2:1.0-scsi-0:0:0:0 vendor iLO model Virtual_DVD-ROM partitions []) was found to be ineligible for installation for the following reasons: Disk is removable" file="disks.go:326"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:43" level=info msg="Executing file [-s /dev/sr0]" file="execute.go:39"
Jun 06 02:06:43 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:43" level=info msg="Executing sg_inq [-p 0x83 /dev/sr0]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="hasUUID is false for path /dev/sr0: exit code 97, stdout: \n, stderr: invalid VPD response; probably a STANDARD INQUIRY response\n    inquiry: Malformed SCSI command\nsg_inq failed: Malformed SCSI command\n" file="disks.go:136"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="Executing biosdevname [-i lo]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=warning msg="Could not read lo speed" file="network_interface.go:90" error="read /sys/class/net/lo/speed: invalid argument"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="Executing biosdevname [-i eno1]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="Executing biosdevname [-i ens1f0]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="Executing biosdevname [-i ens1f1]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="Executing biosdevname [-i ens1f2]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="Executing biosdevname [-i ens1f3]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="Executing biosdevname [-i ens2f0]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="Executing biosdevname [-i ens2f1]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="Executing biosdevname [-i ens2f2]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="Executing biosdevname [-i ens2f3]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="Executing biosdevname [-i cni-podman0]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="Executing biosdevname [-i veth32502cb4]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="Executing dmidecode [-t 17]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="Executing systemd-detect-virt [--vm]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=warning msg="Error running systemd-detect-virt: exit status 1" file="system_vendor.go:37"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab inventory[4891]: time="06-06-2023 02:06:44" level=info msg="Executing cat [/sys/class/tpm/tpm0/tpm_version_major]" file="execute.go:39"
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab systemd[1]: libpod-bb91a0f623708b9ba646514dcd9909eb76fc532751716abfcea41b334eb9df22.scope: Deactivated successfully.
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab systemd[1]: libpod-conmon-bb91a0f623708b9ba646514dcd9909eb76fc532751716abfcea41b334eb9df22.scope: Deactivated successfully.
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:44" level=info msg="Result for inventory already exists in assisted service" file="step_processor.go:64" request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab systemd[1]: libpod-e7fbdddf1d43e3aa4b957a3422442844251f3c204b440bdfb1b150e4603bc86b.scope: Deactivated successfully.
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab systemd[1]: libpod-conmon-e7fbdddf1d43e3aa4b957a3422442844251f3c204b440bdfb1b150e4603bc86b.scope: Deactivated successfully.
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:06:44" level=info msg="Sending step <free-network-addresses-e0b29b86> reply error <> exit-code <0>" file="step_processor.go:74" request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:06:44Z" level=info msg="Received step reply <free-network-addresses-e0b29b86> from infra-env <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f> exit-code <0> stderr <>" func=github.com/openshift/assisted-service/internal/bminventory.logReplyReceived file="/src/internal/bminventory/inventory.go:3421" go-id=549 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=3e8d803e-7283-4de0-8fc3-c8f6846eee57
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-1a16662105537ab0a483b1dd2ad58e3316adc85b3f8356300bde427011a19f76-merged.mount: Deactivated successfully.
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-bb91a0f623708b9ba646514dcd9909eb76fc532751716abfcea41b334eb9df22-userdata-shm.mount: Deactivated successfully.
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-0841bca45bc5ec2cd3d92d8365d325d48b578e1f7dfc7d5e37bdb25ef930dcde-merged.mount: Deactivated successfully.
Jun 06 02:06:44 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-e7fbdddf1d43e3aa4b957a3422442844251f3c204b440bdfb1b150e4603bc86b-userdata-shm.mount: Deactivated successfully.
Jun 06 02:06:47 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4974]: Hosts known and ready for cluster installation (0/1)
Jun 06 02:06:47 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Waiting for hosts to become ready for cluster installation...
Jun 06 02:06:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017209.9091] device (eno1): state change: ip-config -> failed (reason 'ip-config-unavailable', sys-iface-state: 'managed')
Jun 06 02:06:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <warn>  [1686017209.9094] device (eno1): Activation: failed for connection 'Wired connection 1'
Jun 06 02:06:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017209.9095] device (eno1): state change: failed -> disconnected (reason 'none', sys-iface-state: 'managed')
Jun 06 02:06:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017209.9109] dhcp4 (eno1): canceled DHCP transaction
Jun 06 02:06:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017209.9109] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:06:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017209.9109] dhcp4 (eno1): state changed no lease
Jun 06 02:06:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017209.9115] manager: startup complete
Jun 06 02:06:50 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:06:50Z" level=info msg="Host sno131.outbound.vz.bos2.lab: validation 'ntp-synced' is now fixed" func="github.com/openshift/assisted-service/internal/host.(*Manager).reportValidationStatusChanged" file="/src/internal/host/host.go:1146" go-id=199 pkg=host-state request_id=f0efb923-ff85-4ff7-ac5b-9f83ab85f1f0
Jun 06 02:06:50 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:06:50Z" level=info msg="Host sno131.outbound.vz.bos2.lab: validation 'dns-wildcard-not-configured' status changed from pending to success" func="github.com/openshift/assisted-service/internal/host.(*Manager).reportValidationStatusChanged" file="/src/internal/host/host.go:1151" go-id=199 pkg=host-state request_id=f0efb923-ff85-4ff7-ac5b-9f83ab85f1f0
Jun 06 02:06:50 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:06:50Z" level=info msg="host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f from infra env 5f396111-46ed-4173-9648-bc0a9a818139 has been updated with the following updates [status known status_info Host is ready to be installed status_updated_at 2023-06-06T02:06:50.350Z trigger_monitor_timestamp 2023-06-06 02:06:50.350280819 +0000 UTC m=+74.100547433]" func=github.com/openshift/assisted-service/internal/host/hostutil.UpdateHostStatus file="/src/internal/host/hostutil/update_host.go:77" go-id=199 pkg=host-state request_id=f0efb923-ff85-4ff7-ac5b-9f83ab85f1f0
Jun 06 02:06:57 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[5018]: Hosts known and ready for cluster installation (1/1)
Jun 06 02:06:57 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: All 1 hosts are ready.
Jun 06 02:06:58 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:06:58Z" level=info msg="cluster 348785c6-46bc-472b-80be-59bd077b9966 has been updated with the following updates [status ready status_info Cluster ready to be installed status_updated_at 2023-06-06T02:06:58.350Z trigger_monitor_timestamp 2023-06-06 02:06:58.350890962 +0000 UTC m=+82.101157577]" func=github.com/openshift/assisted-service/internal/cluster.updateClusterStatus file="/src/internal/cluster/common.go:75" go-id=198 pkg=cluster-state request_id=6860aec0-7a9f-430e-93f3-2c0c9c99de54
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: ready
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Starting cluster installation...
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="preparing for cluster 348785c6-46bc-472b-80be-59bd077b9966 installation" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).InstallClusterInternal" file="/src/internal/bminventory/inventory.go:1206" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=Inventory request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="cluster 348785c6-46bc-472b-80be-59bd077b9966 has been updated with the following updates [status preparing-for-installation status_info Preparing cluster for installation install_started_at 2023-06-06T02:07:02.068Z installation_preparation_completion_status  logs_info  controller_logs_started_at 0001-01-01T00:00:00.000Z controller_logs_collected_at 0001-01-01T00:00:00.000Z status_updated_at 2023-06-06T02:07:02.068Z trigger_monitor_timestamp 2023-06-06 02:07:02.068630896 +0000 UTC m=+85.818897509]" func=github.com/openshift/assisted-service/internal/cluster.updateClusterStatus file="/src/internal/cluster/common.go:75" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=cluster-state request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Bootstrap ID is 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).setBootstrapHost" file="/src/internal/bminventory/inventory.go:1473" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=Inventory request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=manifests request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/50-masters-chrony-configuration.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Done creating manifest openshift/50-masters-chrony-configuration.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=manifests request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=manifests request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/50-workers-chrony-configuration.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Done creating manifest openshift/50-workers-chrony-configuration.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=manifests request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Creating dnsmasq manifest with values: cluster name: \"sno131\", domain - \"outbound.vz.bos2.lab\", host ip - \"192.168.14.27\"" func=github.com/openshift/assisted-service/internal/network.createDnsmasqForSingleNode file="/src/internal/network/manifests_generator.go:382" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=cluster-state request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=manifests request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/dnsmasq-bootstrap-in-place.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Done creating manifest openshift/dnsmasq-bootstrap-in-place.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=manifests request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=manifests request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/cluster-scheduler-02-config.yml.patch_ai_set_masters_schedulable" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Done creating manifest openshift/cluster-scheduler-02-config.yml.patch_ai_set_masters_schedulable for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=manifests request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Adding node add ip hint manifests" func="github.com/openshift/assisted-service/internal/network.(*ManifestsGenerator).AddNodeIpHint" file="/src/internal/network/manifests_generator.go:528" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=cluster-state request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Creating content for node-ip-hint manifest" func=github.com/openshift/assisted-service/internal/network.createNodeIpHintContent file="/src/internal/network/manifests_generator.go:545" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=cluster-state request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=manifests request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/node-ip-hint-master.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Done creating manifest openshift/node-ip-hint-master.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=manifests request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Creating content for node-ip-hint manifest" func=github.com/openshift/assisted-service/internal/network.createNodeIpHintContent file="/src/internal/network/manifests_generator.go:545" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=cluster-state request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Creating manifest in cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:57" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=manifests request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/node-ip-hint-worker.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).Upload" file="/src/pkg/s3wrapper/filesystem.go:68" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Done creating manifest openshift/node-ip-hint-worker.yaml for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/manifests.(*Manifests).CreateClusterManifestInternal" file="/src/internal/manifests/manifests.go:109" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=manifests request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Successfully prepared cluster <348785c6-46bc-472b-80be-59bd077b9966> for installation" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).InstallClusterInternal" file="/src/internal/bminventory/inventory.go:1332" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=Inventory request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Selected network type OVNKubernetes for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/installcfg/builder.(*installConfigBuilder).getBasicInstallConfig" file="/src/internal/installcfg/builder/builder.go:79" pkg=installcfg
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[5045]: {"api_vips":[],"base_dns_domain":"outbound.vz.bos2.lab","cluster_networks":[{"cidr":"10.128.0.0/14","cluster_id":"348785c6-46bc-472b-80be-59bd077b9966","host_prefix":23}],"connectivity_majority_groups":"{\"192.168.14.0/27\":[],\"IPv4\":[],\"IPv6\":[]}","controller_logs_collected_at":"0001-01-01T00:00:00.000Z","controller_logs_started_at":"0001-01-01T00:00:00.000Z","cpu_architecture":"x86_64","created_at":"2023-06-06T02:05:42.297029Z","deleted_at":null,"disk_encryption":{"enable_on":"none","mode":"tpmv2"},"email_domain":"Unknown","enabled_host_count":1,"feature_usage":"{\"Custom manifest\":{\"id\":\"CUSTOM_MANIFEST\",\"name\":\"Custom manifest\"},\"Hyperthreading\":{\"data\":{\"hyperthreading_enabled\":\"all\"},\"id\":\"HYPERTHREADING\",\"name\":\"Hyperthreading\"},\"OVN network type\":{\"id\":\"OVN_NETWORK_TYPE\",\"name\":\"OVN network type\"},\"SNO\":{\"id\":\"SNO\",\"name\":\"SNO\"},\"Static Network Config\":{\"id\":\"STATIC_NETWORK_CONFIG\",\"name\":\"Static Network Config\"}}","high_availability_mode":"None","host_networks":null,"hosts":[{"bootstrap":true,"checked_in_at":"2023-06-06T02:06:43.562Z","cluster_id":"348785c6-46bc-472b-80be-59bd077b9966","created_at":"2023-06-06T02:05:43.3781Z","deleted_at":null,"discovery_agent_version":"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d","domain_name_resolutions":"{\"resolutions\":[{\"domain_name\":\"api.sno131.outbound.vz.bos2.lab\",\"ipv4_addresses\":[\"192.168.14.27\"],\"ipv6_addresses\":[]},{\"domain_name\":\"api-int.sno131.outbound.vz.bos2.lab\",\"ipv4_addresses\":[\"192.168.14.27\"],\"ipv6_addresses\":[]},{\"domain_name\":\"console-openshift-console.apps.sno131.outbound.vz.bos2.lab\",\"ipv4_addresses\":[\"192.168.14.27\"],\"ipv6_addresses\":[]},{\"domain_name\":\"validateNoWildcardDNS.sno131.outbound.vz.bos2.lab\",\"ipv4_addresses\":[],\"ipv6_addresses\":[]}]}","free_addresses":"[{\"free_addresses\":[\"192.168.14.0\",\"192.168.14.2\",\"192.168.14.3\",\"192.168.14.4\",\"192.168.14.6\",\"192.168.14.7\",\"192.168.14.8\",\"192.168.14.9\",\"192.168.14.10\",\"192.168.14.11\",\"192.168.14.12\",\"192.168.14.13\",\"192.168.14.14\",\"192.168.14.15\",\"192.168.14.16\",\"192.168.14.17\",\"192.168.14.18\",\"192.168.14.19\",\"192.168.14.20\",\"192.168.14.21\",\"192.168.14.22\",\"192.168.14.23\",\"192.168.14.24\",\"192.168.14.28\",\"192.168.14.30\",\"192.168.14.31\"],\"network\":\"192.168.14.0/27\"}]","href":"/api/assisted-install/v2/infra-envs/5f396111-46ed-4173-9648-bc0a9a818139/hosts/1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f","id":"1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f","infra_env_id":"5f396111-46ed-4173-9648-bc0a9a818139","installation_disk_id":"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001","installation_disk_path":"/dev/nvme0n1","inventory":"{\"bmc_address\":\"192.168.14.131\",\"bmc_v6address\":\"fe80::5eba:2cff:fe1f:6ce4\",\"boot\":{\"current_boot_mode\":\"uefi\"},\"cpu\":{\"architecture\":\"x86_64\",\"count\":64,\"flags\":[\"fpu\",\"vme\",\"de\",\"pse\",\"tsc\",\"msr\",\"pae\",\"mce\",\"cx8\",\"apic\",\"sep\",\"mtrr\",\"pge\",\"mca\",\"cmov\",\"pat\",\"pse36\",\"clflush\",\"dts\",\"acpi\",\"mmx\",\"fxsr\",\"sse\",\"sse2\",\"ss\",\"ht\",\"tm\",\"pbe\",\"syscall\",\"nx\",\"pdpe1gb\",\"rdtscp\",\"lm\",\"constant_tsc\",\"art\",\"arch_perfmon\",\"pebs\",\"bts\",\"rep_good\",\"nopl\",\"xtopology\",\"nonstop_tsc\",\"cpuid\",\"aperfmperf\",\"pni\",\"pclmulqdq\",\"dtes64\",\"monitor\",\"ds_cpl\",\"vmx\",\"smx\",\"est\",\"tm2\",\"ssse3\",\"sdbg\",\"fma\",\"cx16\",\"xtpr\",\"pdcm\",\"pcid\",\"dca\",\"sse4_1\",\"sse4_2\",\"x2apic\",\"movbe\",\"popcnt\",\"tsc_deadline_timer\",\"aes\",\"xsave\",\"avx\",\"f16c\",\"rdrand\",\"lahf_lm\",\"abm\",\"3dnowprefetch\",\"cpuid_fault\",\"epb\",\"cat_l3\",\"invpcid_single\",\"ssbd\",\"mba\",\"ibrs\",\"ibpb\",\"stibp\",\"ibrs_enhanced\",\"tpr_shadow\",\"vnmi\",\"flexpriority\",\"ept\",\"vpid\",\"ept_ad\",\"fsgsbase\",\"tsc_adjust\",\"bmi1\",\"avx2\",\"smep\",\"bmi2\",\"erms\",\"invpcid\",\"cqm\",\"rdt_a\",\"avx512f\",\"avx512dq\",\"rdseed\",\"adx\",\"smap\",\"avx512ifma\",\"clflushopt\",\"clwb\",\"intel_pt\",\"avx512cd\",\"sha_ni\",\"avx512bw\",\"avx512vl\",\"xsaveopt\",\"xsavec\",\"xgetbv1\",\"xsaves\",\"cqm_llc\",\"cqm_occup_llc\",\"cqm_mbm_total\",\"cqm_mbm_local\",\"split_lock_detect\",\"wbnoinvd\",\"dtherm\",\"ida\",\"arat\",\"pln\",\"pts\",\"hwp\",\"hwp_act_window\",\"hwp_pkg_req\",\"avx512vbmi\",\"umip\",\"pku\",\"ospke\",\"avx512_vbmi2\",\"gfni\",\"vaes\",\"vpclmulqdq\",\"avx512_vnni\",\"avx512_bitalg\",\"tme\",\"avx512_vpopcntdq\",\"la57\",\"rdpid\",\"fsrm\",\"md_clear\",\"pconfig\",\"flush_l1d\",\"arch_capabilities\"],\"frequency\":3500,\"model_name\":\"Intel(R) Xeon(R) Gold 6338N CPU @ 2.20GHz\"},\"disks\":[{\"by_id\":\"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\",\"by_path\":\"/dev/disk/by-path/pci-0000:c2:00.0-nvme-1\",\"drive_type\":\"SSD\",\"has_uuid\":true,\"id\":\"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\",\"installation_eligibility\":{\"eligible\":true,\"not_eligible_reasons\":null},\"model\":\"SAMSUNG MZ1LB1T9HALS-00007\",\"name\":\"nvme0n1\",\"path\":\"/dev/nvme0n1\",\"serial\":\"S436NA0R757305\",\"size_bytes\":1920383410176,\"wwn\":\"eui.34333630527573050025384100000001\"},{\"by_id\":\"/dev/disk/by-id/nvme-eui.34333630527572890025384100000001\",\"by_path\":\"/dev/disk/by-path/pci-0000:c3:00.0-nvme-1\",\"drive_type\":\"SSD\",\"has_uuid\":true,\"id\":\"/dev/disk/by-id/nvme-eui.34333630527572890025384100000001\",\"installation_eligibility\":{\"eligible\":true,\"not_eligible_reasons\":null},\"model\":\"SAMSUNG MZ1LB1T9HALS-00007\",\"name\":\"nvme1n1\",\"path\":\"/dev/nvme1n1\",\"serial\":\"S436NA0R757289\",\"size_bytes\":1920383410176,\"wwn\":\"eui.34333630527572890025384100000001\"},{\"by_path\":\"/dev/disk/by-path/pci-0000:01:00.4-usb-0:2:1.0-scsi-0:0:0:0\",\"drive_type\":\"ODD\",\"hctl\":\"0:0:0:0\",\"id\":\"/dev/disk/by-path/pci-0000:01:00.4-usb-0:2:1.0-scsi-0:0:0:0\",\"installation_eligibility\":{\"not_eligible_reasons\":[\"Disk is removable\",\"Disk is too small (disk only has 1.1 GB, but 100 GB are required)\",\"Drive type is ODD, it must be one of HDD, SSD, Multipath.\"]},\"is_installation_media\":true,\"model\":\"Virtual_DVD-ROM\",\"name\":\"sr0\",\"path\":\"/dev/sr0\",\"removable\":true,\"serial\":\"iLO_Virtual_DVD-ROM-0:0\",\"size_bytes\":1108533248,\"vendor\":\"iLO\"}],\"gpus\":[{\"address\":\"0000:01:00.1\"}],\"hostname\":\"sno131.outbound.vz.bos2.lab\",\"interfaces\":[{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"has_carrier\":true,\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"5c:ba:2c:1f:6c:e5\",\"mtu\":1500,\"name\":\"eno1\",\"product\":\"0x1537\",\"speed_mbps\":1000,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"has_carrier\":true,\"ipv4_addresses\":[\"192.168.14.27/27\"],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:d9:a4:64\",\"mtu\":1500,\"name\":\"ens1f0\",\"product\":\"0x1593\",\"speed_mbps\":25000,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:d9:a4:65\",\"mtu\":1500,\"name\":\"ens1f1\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:d9:a4:66\",\"mtu\":1500,\"name\":\"ens1f2\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:d9:a4:67\",\"mtu\":1500,\"name\":\"ens1f3\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:da:5a:c4\",\"mtu\":1500,\"name\":\"ens2f0\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:da:5a:c5\",\"mtu\":1500,\"name\":\"ens2f1\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:da:5a:c6\",\"mtu\":1500,\"name\":\"ens2f2\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"},{\"flags\":[\"up\",\"broadcast\",\"multicast\"],\"ipv4_addresses\":[],\"ipv6_addresses\":[],\"mac_address\":\"b4:96:91:da:5a:c7\",\"mtu\":1500,\"name\":\"ens2f3\",\"product\":\"0x1593\",\"speed_mbps\":-1,\"type\":\"physical\",\"vendor\":\"0x8086\"}],\"memory\":{\"physical_bytes\":137438953472,\"physical_bytes_method\":\"dmidecode\",\"usable_bytes\":134738038784},\"routes\":[{\"destination\":\"0.0.0.0\",\"family\":2,\"gateway\":\"192.168.14.1\",\"interface\":\"ens1f0\",\"metric\":101},{\"destination\":\"10.88.0.0\",\"family\":2,\"interface\":\"cni-podman0\"},{\"destination\":\"192.168.14.0\",\"family\":2,\"interface\":\"ens1f0\",\"metric\":101},{\"destination\":\"::1\",\"family\":10,\"interface\":\"lo\",\"metric\":256},{\"destination\":\"fe80::\",\"family\":10,\"interface\":\"cni-podman0\",\"metric\":256},{\"destination\":\"fe80::\",\"family\":10,\"interface\":\"veth32502cb4\",\"metric\":256},{\"destination\":\"fe80::\",\"family\":10,\"interface\":\"eno1\",\"metric\":1024}],\"system_vendor\":{\"manufacturer\":\"HPE\",\"product_name\":\"Edgeline e920t\",\"serial_number\":\"MXQ2140KJL\"},\"tpm_version\":\"2.0\"}","kind":"Host","logs_collected_at":"0001-01-01T00:00:00.000Z","logs_started_at":"0001-01-01T00:00:00.000Z","ntp_sources":"[{\"source_name\":\"x.ns.gin.ntt.net\",\"source_state\":\"synced\"},{\"source_name\":\"65-100-46-166.dia.static.qwest.net\",\"source_state\":\"combined\"},{\"source_name\":\"c-73-61-36-59.hsd1.nh.comcast.net\",\"source_state\":\"combined\"},{\"source_name\":\"pi3.rellim.com\",\"source_state\":\"not_combined\"}]","progress":{"stage_started_at":"0001-01-01T00:00:00.000Z","stage_updated_at":"0001-01-01T00:00:00.000Z"},"progress_stages":null,"registered_at":"2023-06-06T02:05:43.376Z","role":"master","stage_started_at":"0001-01-01T00:00:00.000Z","stage_updated_at":"0001-01-01T00:00:00.000Z","status":"known","status_info":"Host is ready to be installed","status_updated_at":"2023-06-06T02:06:50.350Z","suggested_role":"master","timestamp":1686017203,"updated_at":"2023-06-06T02:06:50.350593Z","user_name":"admin","validations_info":"{\"hardware\":[{\"id\":\"has-inventory\",\"status\":\"success\",\"message\":\"Valid inventory exists for the host\"},{\"id\":\"has-min-cpu-cores\",\"status\":\"success\",\"message\":\"Sufficient CPU cores\"},{\"id\":\"has-min-memory\",\"status\":\"success\",\"message\":\"Sufficient minimum RAM\"},{\"id\":\"has-min-valid-disks\",\"status\":\"success\",\"message\":\"Sufficient disk capacity\"},{\"id\":\"has-cpu-cores-for-role\",\"status\":\"success\",\"message\":\"Sufficient CPU cores for role master\"},{\"id\":\"has-memory-for-role\",\"status\":\"success\",\"message\":\"Sufficient RAM for role master\"},{\"id\":\"hostname-unique\",\"status\":\"success\",\"message\":\"Hostname sno131.outbound.vz.bos2.lab is unique in cluster\"},{\"id\":\"hostname-valid\",\"status\":\"success\",\"message\":\"Hostname sno131.outbound.vz.bos2.lab is allowed\"},{\"id\":\"sufficient-installation-disk-speed\",\"status\":\"success\",\"message\":\"Speed of installation disk has not yet been measured\"},{\"id\":\"compatible-with-cluster-platform\",\"status\":\"success\",\"message\":\"Host is compatible with cluster platform none\"},{\"id\":\"vsphere-disk-uuid-enabled\",\"status\":\"success\",\"message\":\"VSphere disk.EnableUUID is enabled for this virtual machine\"},{\"id\":\"compatible-agent\",\"status\":\"success\",\"message\":\"Host agent compatibility checking is disabled\"},{\"id\":\"no-skip-installation-disk\",\"status\":\"success\",\"message\":\"No request to skip formatting of the installation disk\"},{\"id\":\"no-skip-missing-disk\",\"status\":\"success\",\"message\":\"All disks that have skipped formatting are present in the host inventory\"}],\"network\":[{\"id\":\"connected\",\"status\":\"success\",\"message\":\"Host is connected\"},{\"id\":\"media-connected\",\"status\":\"success\",\"message\":\"Media device is connected\"},{\"id\":\"machine-cidr-defined\",\"status\":\"success\",\"message\":\"No Machine Network CIDR needed: User Managed Networking\"},{\"id\":\"belongs-to-machine-cidr\",\"status\":\"success\",\"message\":\"Host belongs to all machine network CIDRs\"},{\"id\":\"belongs-to-majority-group\",\"status\":\"success\",\"message\":\"Host has connectivity to the majority of hosts in the cluster\"},{\"id\":\"valid-platform-network-settings\",\"status\":\"success\",\"message\":\"Platform Edgeline e920t is allowed\"},{\"id\":\"ntp-synced\",\"status\":\"success\",\"message\":\"Host NTP is synced\"},{\"id\":\"time-synced-between-host-and-service\",\"status\":\"success\",\"message\":\"Host clock is synchronized with service\"},{\"id\":\"container-images-available\",\"status\":\"success\",\"message\":\"All required container images were either pulled successfully or no attempt was made to pull them\"},{\"id\":\"sufficient-network-latency-requirement-for-role\",\"status\":\"success\",\"message\":\"Network latency requirement has been satisfied.\"},{\"id\":\"sufficient-packet-loss-requirement-for-role\",\"status\":\"success\",\"message\":\"Packet loss requirement has been satisfied.\"},{\"id\":\"has-default-route\",\"status\":\"success\",\"message\":\"Host has been configured with at least one default route.\"},{\"id\":\"api-domain-name-resolved-correctly\",\"status\":\"success\",\"message\":\"Domain name resolution for the api.sno131.outbound.vz.bos2.lab domain was successful or not required\"},{\"id\":\"api-int-domain-name-resolved-correctly\",\"status\":\"success\",\"message\":\"Domain name resolution for the api-int.sno131.outbound.vz.bos2.lab domain was successful or not required\"},{\"id\":\"apps-domain-name-resolved-correctly\",\"status\":\"success\",\"message\":\"Domain name resolution for the *.apps.sno131.outbound.vz.bos2.lab domain was successful or not required\"},{\"id\":\"dns-wildcard-not-configured\",\"status\":\"success\",\"message\":\"DNS wildcard check was successful\"},{\"id\":\"non-overlapping-subnets\",\"status\":\"success\",\"message\":\"Host subnets are not overlapping\"},{\"id\":\"no-ip-collisions-in-network\",\"status\":\"success\",\"message\":\"No IP collisions were detected by host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f\"}],\"operators\":[{\"id\":\"cnv-requirements-satisfied\",\"status\":\"success\",\"message\":\"cnv is disabled\"},{\"id\":\"lso-requirements-satisfied\",\"status\":\"success\",\"message\":\"lso is disabled\"},{\"id\":\"lvm-requirements-satisfied\",\"status\":\"success\",\"message\":\"lvm is disabled\"},{\"id\":\"odf-requirements-satisfied\",\"status\":\"success\",\"message\":\"odf is disabled\"}]}"}],"href":"/api/assisted-install/v2/clusters/348785c6-46bc-472b-80be-59bd077b9966","hyperthreading":"all","id":"348785c6-46bc-472b-80be-59bd077b9966","ignition_endpoint":{},"image_info":{"created_at":"2023-06-06T02:05:42.297029Z","expires_at":"0001-01-01T00:00:00.000Z"},"ingress_vips":[],"install_completed_at":"0001-01-01T00:00:00.000Z","install_started_at":"2023-06-06T02:07:02.068Z","ip_collisions":"{}","kind":"Cluster","machine_networks":[{"cidr":"192.168.14.0/27","cluster_id":"348785c6-46bc-472b-80be-59bd077b9966"}],"monitored_operators":[{"cluster_id":"348785c6-46bc-472b-80be-59bd077b9966","name":"console","operator_type":"builtin","status_updated_at":"0001-01-01T00:00:00.000Z","timeout_seconds":3600}],"name":"sno131","network_type":"OVNKubernetes","ocp_release_image":"quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27","openshift_version":"4.13.2","platform":{"type":"none"},"progress":{},"pull_secret_set":true,"ready_host_count":1,"schedulable_masters":false,"schedulable_masters_forced_true":true,"service_networks":[{"cidr":"172.30.0.0/16","cluster_id":"348785c6-46bc-472b-80be-59bd077b9966"}],"ssh_public_key":"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQD74lZFSOSfH8fWf9L419M6TwfJQfruuEKODlf9jdFzxWji+Y8qUQqe3rV6bbc7joADJtKnB/amvMcBr3kl7uC3AvHQB+m/BY4EJAgxiGhnhQaznrHUFQhDF7OGw2c+DuzO+jZAO0ColKOr1oN5E8nZGqVJBNYvYdP3/vAx69oLvTTA5MMilL9Ftjbv3uq0iKqJJ6xQdCNIEoxpOaKm8tAC2o4Sae4pn1JJYvPyXjRBdtg9GO+0BpqTHMBz74IyVg6qgUTctymEAIFWFO0joFq7BadsChJD7Be7FJhilYxAPvFFsYuRnOuVbj9ZVV2hH2Hhqi7LwWFv/Hmz84xbl4+woPIuI5OnQ0ys9Ec+ZXeh1ImzRl7kkmJ7dHALY8kb886v2+mWEcv1IKYCcMssO8lf2ZCbau1VV0Z7H6aRrRzQDv0mETf+gTnyzT8uwKORSu208oLuWf4Asz979kcW8LF+gtRBpRgIY0INtNRoIRJCr8SHXGRveyzvMEDr2JRNDOM= root@hub-helper","status":"preparing-for-installation","status_info":"Preparing cluster for installation","status_updated_at":"2023-06-06T02:07:02.068Z","total_host_count":1,"updated_at":"2023-06-06T02:07:02.068868Z","user_managed_networking":true,"user_name":"admin","validations_info":"{\"configuration\":[{\"id\":\"pull-secret-set\",\"status\":\"success\",\"message\":\"The pull secret is set.\"}],\"hosts-data\":[{\"id\":\"all-hosts-are-ready-to-install\",\"status\":\"success\",\"message\":\"All hosts in the cluster are ready to install.\"},{\"id\":\"sufficient-masters-count\",\"status\":\"success\",\"message\":\"The cluster has the exact amount of dedicated control plane nodes.\"}],\"network\":[{\"id\":\"api-vips-defined\",\"status\":\"success\",\"message\":\"API virtual IPs are not required: User Managed Networking\"},{\"id\":\"api-vips-valid\",\"status\":\"success\",\"message\":\"API virtual IPs are not required: User Managed Networking\"},{\"id\":\"cluster-cidr-defined\",\"status\":\"success\",\"message\":\"The Cluster Network CIDR is defined.\"},{\"id\":\"dns-domain-defined\",\"status\":\"success\",\"message\":\"The base domain is defined.\"},{\"id\":\"ingress-vips-defined\",\"status\":\"success\",\"message\":\"Ingress virtual IPs are not required: User Managed Networking\"},{\"id\":\"ingress-vips-valid\",\"status\":\"success\",\"message\":\"Ingress virtual IPs are not required: User Managed Networking\"},{\"id\":\"machine-cidr-defined\",\"status\":\"success\",\"message\":\"The Machine Network CIDR is defined.\"},{\"id\":\"machine-cidr-equals-to-calculated-cidr\",\"status\":\"success\",\"message\":\"The Cluster Machine CIDR is not required: User Managed Networking\"},{\"id\":\"network-prefix-valid\",\"status\":\"success\",\"message\":\"The Cluster Network prefix is valid.\"},{\"id\":\"network-type-valid\",\"status\":\"success\",\"message\":\"The cluster has a valid network type\"},{\"id\":\"networks-same-address-families\",\"status\":\"success\",\"message\":\"Same address families for all networks.\"},{\"id\":\"no-cidrs-overlapping\",\"status\":\"success\",\"message\":\"No CIDRS are overlapping.\"},{\"id\":\"ntp-server-configured\",\"status\":\"success\",\"message\":\"No ntp problems found\"},{\"id\":\"service-cidr-defined\",\"status\":\"success\",\"message\":\"The Service Network CIDR is defined.\"}],\"operators\":[{\"id\":\"cnv-requirements-satisfied\",\"status\":\"success\",\"message\":\"cnv is disabled\"},{\"id\":\"lso-requirements-satisfied\",\"status\":\"success\",\"message\":\"lso is disabled\"},{\"id\":\"lvm-requirements-satisfied\",\"status\":\"success\",\"message\":\"lvm is disabled\"},{\"id\":\"odf-requirements-satisfied\",\"status\":\"success\",\"message\":\"odf is disabled\"}]}","vip_dhcp_allocation":false}
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="Selected bootstrap machine network CIDR 192.168.14.0/27 for cluster 348785c6-46bc-472b-80be-59bd077b9966" func=github.com/openshift/assisted-service/internal/provider.GetMachineNetworkForUserManagedNetworking file="/src/internal/provider/base.go:41" pkg=provider
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster installation started
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="No ImageContentSources in install-config to build ICSP file" func=github.com/openshift/assisted-service/internal/ignition.getIcspFileFromInstallConfig file="/src/internal/ignition/ignition.go:1890" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:02Z" level=info msg="extracting openshift-install binary to /data/install-config-generate/installercache/quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27" func="github.com/openshift/assisted-service/internal/oc.(*release).extractFromRelease" file="/src/internal/oc/release.go:352" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:06 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:06Z" level=info msg="host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f from infra env 5f396111-46ed-4173-9648-bc0a9a818139 has been updated with the following updates [status preparing-for-installation status_info Host finished successfully to prepare for installation logs_info  logs_started_at 0001-01-01T00:00:00.000Z logs_collected_at 0001-01-01T00:00:00.000Z status_updated_at 2023-06-06T02:07:06.347Z trigger_monitor_timestamp 2023-06-06 02:07:06.347178279 +0000 UTC m=+90.097444894]" func=github.com/openshift/assisted-service/internal/host/hostutil.UpdateHostStatus file="/src/internal/host/hostutil/update_host.go:77" go-id=199 pkg=host-state request_id=4a864cc7-b1a3-4943-bf42-f61a961c6334
Jun 06 02:07:07 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: preparing-for-installation
Jun 06 02:07:12 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: preparing-for-installation
Jun 06 02:07:17 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: preparing-for-installation
Jun 06 02:07:19 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:19Z" level=info msg="Successfully extracted openshift-install binary from the release to: /data/install-config-generate/installercache/quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27/openshift-install" func="github.com/openshift/assisted-service/internal/oc.(*release).extractFromRelease" file="/src/internal/oc/release.go:371" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:19 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:19Z" level=info msg="Found cluster TLS certs dir" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).importClusterTLSCerts" file="/src/internal/ignition/ignition.go:637" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 inputDir=/opt/agent/tls request_id=
Jun 06 02:07:19 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:19Z" level=info msg="Created cluster TLS certs dir" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).importClusterTLSCerts" file="/src/internal/ignition/ignition.go:644" cluster=348785c6-46bc-472b-80be-59bd077b9966 cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 inputDir=/opt/agent/tls outputDir=/data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/tls request_id=
Jun 06 02:07:19 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:19Z" level=info msg="Copying cluster TLS cert file" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).importClusterTLSCerts.func1" file="/src/internal/ignition/ignition.go:648" cluster=348785c6-46bc-472b-80be-59bd077b9966 cluster_id=348785c6-46bc-472b-80be-59bd077b9966 filename=admin-kubeconfig-signer.crt go-id=651 inputDir=/opt/agent/tls outputDir=/data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/tls request_id=
Jun 06 02:07:19 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:19Z" level=info msg="Copying cluster TLS cert file" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).importClusterTLSCerts.func1" file="/src/internal/ignition/ignition.go:648" cluster=348785c6-46bc-472b-80be-59bd077b9966 cluster_id=348785c6-46bc-472b-80be-59bd077b9966 filename=admin-kubeconfig-signer.key go-id=651 inputDir=/opt/agent/tls outputDir=/data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/tls request_id=
Jun 06 02:07:19 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:19Z" level=info msg="Copying cluster TLS cert file" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).importClusterTLSCerts.func1" file="/src/internal/ignition/ignition.go:648" cluster=348785c6-46bc-472b-80be-59bd077b9966 cluster_id=348785c6-46bc-472b-80be-59bd077b9966 filename=kube-apiserver-lb-signer.crt go-id=651 inputDir=/opt/agent/tls outputDir=/data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/tls request_id=
Jun 06 02:07:19 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:19Z" level=info msg="Copying cluster TLS cert file" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).importClusterTLSCerts.func1" file="/src/internal/ignition/ignition.go:648" cluster=348785c6-46bc-472b-80be-59bd077b9966 cluster_id=348785c6-46bc-472b-80be-59bd077b9966 filename=kube-apiserver-lb-signer.key go-id=651 inputDir=/opt/agent/tls outputDir=/data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/tls request_id=
Jun 06 02:07:19 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:19Z" level=info msg="Copying cluster TLS cert file" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).importClusterTLSCerts.func1" file="/src/internal/ignition/ignition.go:648" cluster=348785c6-46bc-472b-80be-59bd077b9966 cluster_id=348785c6-46bc-472b-80be-59bd077b9966 filename=kube-apiserver-localhost-signer.crt go-id=651 inputDir=/opt/agent/tls outputDir=/data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/tls request_id=
Jun 06 02:07:19 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:19Z" level=info msg="Copying cluster TLS cert file" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).importClusterTLSCerts.func1" file="/src/internal/ignition/ignition.go:648" cluster=348785c6-46bc-472b-80be-59bd077b9966 cluster_id=348785c6-46bc-472b-80be-59bd077b9966 filename=kube-apiserver-localhost-signer.key go-id=651 inputDir=/opt/agent/tls outputDir=/data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/tls request_id=
Jun 06 02:07:19 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:19Z" level=info msg="Copying cluster TLS cert file" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).importClusterTLSCerts.func1" file="/src/internal/ignition/ignition.go:648" cluster=348785c6-46bc-472b-80be-59bd077b9966 cluster_id=348785c6-46bc-472b-80be-59bd077b9966 filename=kube-apiserver-service-network-signer.crt go-id=651 inputDir=/opt/agent/tls outputDir=/data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/tls request_id=
Jun 06 02:07:19 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:19Z" level=info msg="Copying cluster TLS cert file" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).importClusterTLSCerts.func1" file="/src/internal/ignition/ignition.go:648" cluster=348785c6-46bc-472b-80be-59bd077b9966 cluster_id=348785c6-46bc-472b-80be-59bd077b9966 filename=kube-apiserver-service-network-signer.key go-id=651 inputDir=/opt/agent/tls outputDir=/data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/tls request_id=
Jun 06 02:07:19 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:19Z" level=info msg="Copying cluster TLS cert file" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).importClusterTLSCerts.func1" file="/src/internal/ignition/ignition.go:648" cluster=348785c6-46bc-472b-80be-59bd077b9966 cluster_id=348785c6-46bc-472b-80be-59bd077b9966 filename=kubeadmin-password.hash go-id=651 inputDir=/opt/agent/tls outputDir=/data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/tls request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/01-container-mount-ns-and-kubelet-conf-master-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/02-master-workload-partitioning-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/04-accelerated-container-startup-master-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/05-kdump-config-master-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/06-kdump-master-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/50-masters-chrony-configuration.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/50-workers-chrony-configuration.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/99-crio-disable-wipe-master-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/AmqSubscription-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/AmqSubscriptionNS-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/AmqSubscriptionOperGroup-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/PtpSubscription-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/PtpSubscriptionNS-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/PtpSubscriptionOperGroup-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/SriovSubscription-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/SriovSubscriptionNS-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/SriovSubscriptionOperGroup-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/StorageNS-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/StorageOperGroup-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/StorageSubscription-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/cluster-scheduler-02-config.yml.patch_ai_set_masters_schedulable to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/dnsmasq-bootstrap-in-place.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/enable-crun-master-0.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/node-ip-hint-master.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:20 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:20Z" level=info msg="adding manifest 348785c6-46bc-472b-80be-59bd077b9966/manifests/openshift/node-ip-hint-worker.yaml to working dir for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).Generate" file="/src/internal/ignition/ignition.go:430" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:22 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: preparing-for-installation
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Updated file /data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/bootstrap.ign" func="github.com/openshift/assisted-service/internal/ignition.(*installerGenerator).updateBootstrap" file="/src/internal/ignition/ignition.go:858" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/bootstrap.ign" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UploadStream" file="/src/pkg/s3wrapper/filesystem.go:134" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Updating timestamp of file /data/348785c6-46bc-472b-80be-59bd077b9966/bootstrap.ign" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UpdateObjectTimestamp" file="/src/pkg/s3wrapper/filesystem.go:205" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Uploaded file /data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/bootstrap.ign as object 348785c6-46bc-472b-80be-59bd077b9966/bootstrap.ign" func=github.com/openshift/assisted-service/internal/ignition.uploadToS3 file="/src/internal/ignition/ignition.go:1167" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/master.ign" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UploadStream" file="/src/pkg/s3wrapper/filesystem.go:134" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Updating timestamp of file /data/348785c6-46bc-472b-80be-59bd077b9966/master.ign" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UpdateObjectTimestamp" file="/src/pkg/s3wrapper/filesystem.go:205" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Uploaded file /data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/master.ign as object 348785c6-46bc-472b-80be-59bd077b9966/master.ign" func=github.com/openshift/assisted-service/internal/ignition.uploadToS3 file="/src/internal/ignition/ignition.go:1167" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/metadata.json" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UploadStream" file="/src/pkg/s3wrapper/filesystem.go:134" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Updating timestamp of file /data/348785c6-46bc-472b-80be-59bd077b9966/metadata.json" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UpdateObjectTimestamp" file="/src/pkg/s3wrapper/filesystem.go:205" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Uploaded file /data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/metadata.json as object 348785c6-46bc-472b-80be-59bd077b9966/metadata.json" func=github.com/openshift/assisted-service/internal/ignition.uploadToS3 file="/src/internal/ignition/ignition.go:1167" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/worker.ign" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UploadStream" file="/src/pkg/s3wrapper/filesystem.go:134" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Updating timestamp of file /data/348785c6-46bc-472b-80be-59bd077b9966/worker.ign" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UpdateObjectTimestamp" file="/src/pkg/s3wrapper/filesystem.go:205" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Uploaded file /data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/worker.ign as object 348785c6-46bc-472b-80be-59bd077b9966/worker.ign" func=github.com/openshift/assisted-service/internal/ignition.uploadToS3 file="/src/internal/ignition/ignition.go:1167" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/kubeconfig-noingress" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UploadStream" file="/src/pkg/s3wrapper/filesystem.go:134" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Updating timestamp of file /data/348785c6-46bc-472b-80be-59bd077b9966/kubeconfig-noingress" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UpdateObjectTimestamp" file="/src/pkg/s3wrapper/filesystem.go:205" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Uploaded file /data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/kubeconfig-noingress as object 348785c6-46bc-472b-80be-59bd077b9966/kubeconfig-noingress" func=github.com/openshift/assisted-service/internal/ignition.uploadToS3 file="/src/internal/ignition/ignition.go:1167" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/kubeadmin-password" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UploadStream" file="/src/pkg/s3wrapper/filesystem.go:134" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Updating timestamp of file /data/348785c6-46bc-472b-80be-59bd077b9966/kubeadmin-password" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UpdateObjectTimestamp" file="/src/pkg/s3wrapper/filesystem.go:205" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Uploaded file /data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/kubeadmin-password as object 348785c6-46bc-472b-80be-59bd077b9966/kubeadmin-password" func=github.com/openshift/assisted-service/internal/ignition.uploadToS3 file="/src/internal/ignition/ignition.go:1167" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/install-config.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UploadStream" file="/src/pkg/s3wrapper/filesystem.go:134" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Updating timestamp of file /data/348785c6-46bc-472b-80be-59bd077b9966/install-config.yaml" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UpdateObjectTimestamp" file="/src/pkg/s3wrapper/filesystem.go:205" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Uploaded file /data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/install-config.yaml as object 348785c6-46bc-472b-80be-59bd077b9966/install-config.yaml" func=github.com/openshift/assisted-service/internal/ignition.uploadToS3 file="/src/internal/ignition/ignition.go:1167" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/master-1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f.ign" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UploadStream" file="/src/pkg/s3wrapper/filesystem.go:134" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Updating timestamp of file /data/348785c6-46bc-472b-80be-59bd077b9966/master-1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f.ign" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UpdateObjectTimestamp" file="/src/pkg/s3wrapper/filesystem.go:205" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Uploaded file /data/install-config-generate/348785c6-46bc-472b-80be-59bd077b9966.1465975098/master-1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f.ign as object 348785c6-46bc-472b-80be-59bd077b9966/master-1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f.ign" func=github.com/openshift/assisted-service/internal/ignition.uploadToS3 file="/src/internal/ignition/ignition.go:1167" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 request_id=
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="generated ignition for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).InstallClusterInternal.func3" file="/src/internal/bminventory/inventory.go:1316" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=Inventory request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Storing OpenShift cluster ID of cluster 348785c6-46bc-472b-80be-59bd077b9966 to DB" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).InstallClusterInternal.func3" file="/src/internal/bminventory/inventory.go:1318" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=642 pkg=Inventory request_id=5fe7cf1a-91f2-4873-b9f3-3e884bf54f23
Jun 06 02:07:24 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:24Z" level=info msg="Successfully handled pre-installation success, cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/cluster.(*Manager).HandlePreInstallSuccess" file="/src/internal/cluster/cluster.go:946" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=651 pkg=cluster-state request_id=
Jun 06 02:07:27 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: preparing-for-installation
Jun 06 02:07:32 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: preparing-for-installation
Jun 06 02:07:37 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: preparing-for-installation
Jun 06 02:07:42 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: preparing-for-installation
Jun 06 02:07:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:43" level=warning msg="Certificate verification is turned off. This is not recommended in production environments" file="inventory_session.go:126"
Jun 06 02:07:43 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:43" level=info msg="Query for next steps" file="step_processor.go:233" request_id=00894069-70a3-4abd-a556-6157974c5a09
Jun 06 02:07:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:43Z" level=info msg="GetNextSteps infra_env: <5f396111-46ed-4173-9648-bc0a9a818139>, host: <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>, host status: <preparing-for-installation>" func="github.com/openshift/assisted-service/internal/host/hostcommands.(*InstructionManager).GetNextSteps" file="/src/internal/host/hostcommands/instruction_manager.go:160" go-id=1243 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=00894069-70a3-4abd-a556-6157974c5a09
Jun 06 02:07:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:43Z" level=info msg="Fetching image from OCP release (oc adm release info --image-for=machine-config-operator --insecure=false quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27)" func="github.com/openshift/assisted-service/internal/oc.(*release).getImageFromRelease" file="/src/internal/oc/release.go:287" pkg=instructions
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:44Z" level=info msg="Fetching image from OCP release (oc adm release info --image-for=must-gather --insecure=false quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27)" func="github.com/openshift/assisted-service/internal/oc.(*release).getImageFromRelease" file="/src/internal/oc/release.go:287" pkg=versions
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:44Z" level=info msg="Submitting step <installation-disk-speed-check> id <installation-disk-speed-check-5ce8e8a8> to infra_env <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>  Arguments: <[{\"path\":\"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\"} 480.00]>" func=github.com/openshift/assisted-service/internal/host/hostcommands.logSteps file="/src/internal/host/hostcommands/instruction_manager.go:287" go-id=1243 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=00894069-70a3-4abd-a556-6157974c5a09
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:44Z" level=info msg="Submitting step <container-image-availability> id <container-image-availability-e1a879f4> to infra_env <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>  Arguments: <[{\"images\":[\"quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27\",\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96\",\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26\",\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2eb852167902b07e2e072b4817c34710462fc5d7babed5cb7a95e47689c406\"],\"timeout\":960}]>" func=github.com/openshift/assisted-service/internal/host/hostcommands.logSteps file="/src/internal/host/hostcommands/instruction_manager.go:287" go-id=1243 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=00894069-70a3-4abd-a556-6157974c5a09
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:44" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- findmnt --raw --noheadings --output SOURCE,TARGET --target /run/media/iso]" file="execute.go:39"
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:44" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- findmnt --raw --noheadings --output SOURCE,TARGET --target /run/media/iso]" file="execute.go:39"
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:44" level=info msg="Creating execution step for container-image-availability container-image-availability-e1a879f4 args <[{\"images\":[\"quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27\",\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96\",\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26\",\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2eb852167902b07e2e072b4817c34710462fc5d7babed5cb7a95e47689c406\"],\"timeout\":960}]>" file="step_processor.go:123" request_id=00894069-70a3-4abd-a556-6157974c5a09
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:44" level=info msg="Validating image availability with args [{\"images\":[\"quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27\",\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96\",\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26\",\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2eb852167902b07e2e072b4817c34710462fc5d7babed5cb7a95e47689c406\"],\"timeout\":960}]" file="action.go:29"
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:44" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- podman images --quiet quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27]" file="execute.go:39"
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:44" level=info msg="Creating execution step for installation-disk-speed-check installation-disk-speed-check-5ce8e8a8 args <[{\"path\":\"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\"} 480.00]>" file="step_processor.go:123" request_id=00894069-70a3-4abd-a556-6157974c5a09
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:44" level=info msg="Validating disk performance with args [{\"path\":\"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\"} 480.00]" file="action.go:29"
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:44" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- sh -c id=`podman ps --quiet --filter \"name=disk_performance\"` ; test ! -z \"$id\" || timeout 480.00 podman run --privileged --rm --quiet -v /dev:/dev:rw -v /var/log:/var/log -v /run/systemd/journal/socket:/run/systemd/journal/socket --name disk_performance quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d disk_speed_check '{\"path\":\"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\"}']" file="execute.go:39"
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:44" level=info msg="Image quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27 exists locally before pull: true" file="container_image_availability.go:110"
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:44" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- timeout 959 podman pull quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27]" file="execute.go:39"
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(vethb16925eb) entered blocking state
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(vethb16925eb) entered disabled state
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab kernel: device vethb16925eb entered promiscuous mode
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017264.5176] manager: (vethb16925eb): new Veth device (/org/freedesktop/NetworkManager/Devices/14)
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab kernel: IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab kernel: IPv6: ADDRCONF(NETDEV_CHANGE): vethb16925eb: link becomes ready
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(vethb16925eb) entered blocking state
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(vethb16925eb) entered forwarding state
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017264.5216] device (vethb16925eb): carrier: link connected
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab systemd[1]: Started libpod-conmon-8aa41d4657be4e98844c9fc1e63e4425863828466f75be4e52fa098ab0d0bd08.scope.
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 8aa41d4657be4e98844c9fc1e63e4425863828466f75be4e52fa098ab0d0bd08.
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab disk_speed_chec[5641]: time="06-06-2023 02:07:44" level=info msg="Executing fio [--filename /dev/disk/by-id/nvme-eui.34333630527573050025384100000001 --name=test --rw=write --ioengine=sync --size=22m -bs=2300 --fdatasync=1 --output-format=json]" file="execute.go:39"
Jun 06 02:07:44 sno131.outbound.vz.bos2.lab disk_speed_chec[5641]: time="06-06-2023 02:07:44" level=info msg="Executing fio [--filename /dev/disk/by-id/nvme-eui.34333630527573050025384100000001 --name=test --rw=write --ioengine=sync --size=22m -bs=2300 --fdatasync=1 --output-format=json]" file="execute.go:39"
Jun 06 02:07:45 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:45" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- podman images --quiet quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96]" file="execute.go:39"
Jun 06 02:07:45 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:45" level=info msg="Image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96 exists locally before pull: false" file="container_image_availability.go:110"
Jun 06 02:07:45 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:45" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- timeout 959 podman pull quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96]" file="execute.go:39"
Jun 06 02:07:47 sno131.outbound.vz.bos2.lab disk_speed_chec[5641]: time="06-06-2023 02:07:47" level=info msg="FIO result on disk /dev/disk/by-id/nvme-eui.34333630527573050025384100000001 :fdatasync duration 0 ms" file="disk_speed_check.go:74"
Jun 06 02:07:47 sno131.outbound.vz.bos2.lab systemd[1]: libpod-8aa41d4657be4e98844c9fc1e63e4425863828466f75be4e52fa098ab0d0bd08.scope: Deactivated successfully.
Jun 06 02:07:47 sno131.outbound.vz.bos2.lab systemd[1]: libpod-8aa41d4657be4e98844c9fc1e63e4425863828466f75be4e52fa098ab0d0bd08.scope: Consumed 3.315s CPU time.
Jun 06 02:07:47 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(vethb16925eb) entered disabled state
Jun 06 02:07:47 sno131.outbound.vz.bos2.lab kernel: device vethb16925eb left promiscuous mode
Jun 06 02:07:47 sno131.outbound.vz.bos2.lab kernel: cni-podman0: port 2(vethb16925eb) entered disabled state
Jun 06 02:07:47 sno131.outbound.vz.bos2.lab systemd[1]: run-netns-netns\x2d1aab9a4b\x2d896b\x2dd809\x2d9cba\x2d3a52ead6fd6d.mount: Deactivated successfully.
Jun 06 02:07:47 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-8aa41d4657be4e98844c9fc1e63e4425863828466f75be4e52fa098ab0d0bd08-userdata-shm.mount: Deactivated successfully.
Jun 06 02:07:47 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-bf99ea808f80562c74674a0b2315a0aa048cb48017d0f4570493140d5c79699b-merged.mount: Deactivated successfully.
Jun 06 02:07:47 sno131.outbound.vz.bos2.lab systemd[1]: libpod-conmon-8aa41d4657be4e98844c9fc1e63e4425863828466f75be4e52fa098ab0d0bd08.scope: Deactivated successfully.
Jun 06 02:07:47 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:47" level=info msg="Sending step <installation-disk-speed-check-5ce8e8a8> reply output <{\"path\":\"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\"}> error <> exit-code <0>" file="step_processor.go:76" request_id=00894069-70a3-4abd-a556-6157974c5a09
Jun 06 02:07:47 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:47Z" level=info msg="Received step reply <installation-disk-speed-check-5ce8e8a8> from infra-env <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f> exit-code <0> stderr <> stdout <{\"path\":\"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\"}>" func=github.com/openshift/assisted-service/internal/bminventory.logReplyReceived file="/src/internal/bminventory/inventory.go:3423" go-id=1243 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=00894069-70a3-4abd-a556-6157974c5a09
Jun 06 02:07:47 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: preparing-for-installation
Jun 06 02:07:48 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:48" level=info msg="Pulling image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96 is available. Took 3.735166 seconds" file="container_image_availability.go:132"
Jun 06 02:07:48 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:48" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- podman image inspect --format={{.Size}} quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96]" file="execute.go:39"
Jun 06 02:07:49 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:49" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- podman images --quiet quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26]" file="execute.go:39"
Jun 06 02:07:49 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:49" level=info msg="Image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26 exists locally before pull: false" file="container_image_availability.go:110"
Jun 06 02:07:49 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:49" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- timeout 955 podman pull quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26]" file="execute.go:39"
Jun 06 02:07:52 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: preparing-for-installation
Jun 06 02:07:55 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:55" level=info msg="Pulling image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26 is available. Took 6.488246 seconds" file="container_image_availability.go:132"
Jun 06 02:07:55 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:55" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- podman image inspect --format={{.Size}} quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26]" file="execute.go:39"
Jun 06 02:07:55 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:55" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- podman images --quiet quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2eb852167902b07e2e072b4817c34710462fc5d7babed5cb7a95e47689c406]" file="execute.go:39"
Jun 06 02:07:55 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:55" level=info msg="Image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2eb852167902b07e2e072b4817c34710462fc5d7babed5cb7a95e47689c406 exists locally before pull: false" file="container_image_availability.go:110"
Jun 06 02:07:55 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:55" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- timeout 948 podman pull quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2eb852167902b07e2e072b4817c34710462fc5d7babed5cb7a95e47689c406]" file="execute.go:39"
Jun 06 02:07:57 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: preparing-for-installation
Jun 06 02:07:57 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:57" level=info msg="Pulling image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2eb852167902b07e2e072b4817c34710462fc5d7babed5cb7a95e47689c406 is available. Took 1.946462 seconds" file="container_image_availability.go:132"
Jun 06 02:07:57 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:57" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- podman image inspect --format={{.Size}} quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2eb852167902b07e2e072b4817c34710462fc5d7babed5cb7a95e47689c406]" file="execute.go:39"
Jun 06 02:07:57 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:07:57" level=info msg="Sending step <container-image-availability-e1a879f4> reply output <{\"images\":[{\"name\":\"quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27\",\"result\":\"success\"},{\"download_rate\":157.97972543002018,\"name\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96\",\"result\":\"success\",\"size_bytes\":590080480,\"time\":3.735165879},{\"download_rate\":83.36957634415009,\"name\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26\",\"result\":\"success\",\"size_bytes\":540922351,\"time\":6.488246369},{\"download_rate\":223.39547479671015,\"name\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2eb852167902b07e2e072b4817c34710462fc5d7babed5cb7a95e47689c406\",\"result\":\"success\",\"size_bytes\":434830909,\"time\":1.946462476}]}> error <> exit-code <0>" file="step_processor.go:76" request_id=00894069-70a3-4abd-a556-6157974c5a09
Jun 06 02:07:57 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:57Z" level=info msg="Received step reply <container-image-availability-e1a879f4> from infra-env <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f> exit-code <0> stderr <> stdout <{\"images\":[{\"name\":\"quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27\",\"result\":\"success\"},{\"download_rate\":157.97972543002018,\"name\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96\",\"result\":\"success\",\"size_bytes\":590080480,\"time\":3.735165879},{\"download_rate\":83.36957634415009,\"name\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26\",\"result\":\"success\",\"size_bytes\":540922351,\"time\":6.488246369},{\"download_rate\":223.39547479671015,\"name\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2eb852167902b07e2e072b4817c34710462fc5d7babed5cb7a95e47689c406\",\"result\":\"success\",\"size_bytes\":434830909,\"time\":1.946462476}]}>" func=github.com/openshift/assisted-service/internal/bminventory.logReplyReceived file="/src/internal/bminventory/inventory.go:3423" go-id=1243 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=00894069-70a3-4abd-a556-6157974c5a09
Jun 06 02:07:57 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:57Z" level=info msg="Adding new image status for quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27 with status success to host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f" func="github.com/openshift/assisted-service/internal/host.(*Manager).UpdateImageStatus" file="/src/internal/host/host.go:889" pkg=host-state
Jun 06 02:07:57 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:57Z" level=info msg="Adding new image status for quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96 with status success to host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f" func="github.com/openshift/assisted-service/internal/host.(*Manager).UpdateImageStatus" file="/src/internal/host/host.go:889" pkg=host-state
Jun 06 02:07:57 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:57Z" level=info msg="Adding new image status for quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26 with status success to host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f" func="github.com/openshift/assisted-service/internal/host.(*Manager).UpdateImageStatus" file="/src/internal/host/host.go:889" pkg=host-state
Jun 06 02:07:57 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:07:57Z" level=info msg="Adding new image status for quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2eb852167902b07e2e072b4817c34710462fc5d7babed5cb7a95e47689c406 with status success to host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f" func="github.com/openshift/assisted-service/internal/host.(*Manager).UpdateImageStatus" file="/src/internal/host/host.go:889" pkg=host-state
Jun 06 02:08:02 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:08:02Z" level=info msg="host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f from infra env 5f396111-46ed-4173-9648-bc0a9a818139 has been updated with the following updates [status preparing-successful status_info Host finished successfully to prepare for installation status_updated_at 2023-06-06T02:08:02.347Z trigger_monitor_timestamp 2023-06-06 02:08:02.347527458 +0000 UTC m=+146.097794070]" func=github.com/openshift/assisted-service/internal/host/hostutil.UpdateHostStatus file="/src/internal/host/hostutil/update_host.go:77" go-id=199 pkg=host-state request_id=bd8fa7cb-1481-4f78-a2ba-cc4e348489e3
Jun 06 02:08:02 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: preparing-for-installation
Jun 06 02:08:07 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: preparing-for-installation
Jun 06 02:08:08 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:08:08Z" level=info msg="cluster 348785c6-46bc-472b-80be-59bd077b9966 has been updated with the following updates [status installing status_info Installation in progress api_vip 192.168.14.27 ingress_vip 192.168.14.27 progress_preparing_for_installation_stage_percentage 100 progress_total_percentage 10 status_updated_at 2023-06-06T02:08:08.346Z trigger_monitor_timestamp 2023-06-06 02:08:08.346422639 +0000 UTC m=+152.096689252]" func=github.com/openshift/assisted-service/internal/cluster.updateClusterStatus file="/src/internal/cluster/common.go:75" go-id=198 pkg=cluster-state request_id=dfa9fd2e-b95e-46e9-8fd9-c4260b766738
Jun 06 02:08:10 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:08:10Z" level=info msg="host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f from infra env 5f396111-46ed-4173-9648-bc0a9a818139 has been updated with the following updates [status installing status_info Installation is in progress status_updated_at 2023-06-06T02:08:10.349Z trigger_monitor_timestamp 2023-06-06 02:08:10.349675641 +0000 UTC m=+154.099942256]" func=github.com/openshift/assisted-service/internal/host/hostutil.UpdateHostStatus file="/src/internal/host/hostutil/update_host.go:77" go-id=199 pkg=host-state request_id=cc64a666-c8d8-434a-a631-d82acd1242b8
Jun 06 02:08:12 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:08:17 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:08:22 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:08:27 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:08:32 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:08:37 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:08:42 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:08:44" level=warning msg="Certificate verification is turned off. This is not recommended in production environments" file="inventory_session.go:126"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:08:44" level=info msg="Query for next steps" file="step_processor.go:233" request_id=373fdb36-a8d9-4aa0-9bf5-f67065207ba2
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:08:44Z" level=info msg="GetNextSteps infra_env: <5f396111-46ed-4173-9648-bc0a9a818139>, host: <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>, host status: <installing>" func="github.com/openshift/assisted-service/internal/host/hostcommands.(*InstructionManager).GetNextSteps" file="/src/internal/host/hostcommands/instruction_manager.go:160" go-id=1416 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=373fdb36-a8d9-4aa0-9bf5-f67065207ba2
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:08:44Z" level=info msg="Install command releaseImage: quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27, mcoImage: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96" func="github.com/openshift/assisted-service/internal/host/hostcommands.(*installCmd).getFullInstallerCommand" file="/src/internal/host/hostcommands/install_cmd.go:128" pkg=instructions
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:08:44Z" level=info msg="Submitting step <install> id <install-b4e5d93c> to infra_env <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>  Arguments: <[{\"boot_device\":\"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\",\"check_cvo\":false,\"cluster_id\":\"348785c6-46bc-472b-80be-59bd077b9966\",\"controller_image\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:594d4998e68eb7ba35024b3f4dbcc812a3ce85ffe840fbeff58c03e178fb54ce\",\"disks_to_format\":[],\"high_availability_mode\":\"None\",\"host_id\":\"1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f\",\"infra_env_id\":\"5f396111-46ed-4173-9648-bc0a9a818139\",\"installer_args\":\"[\\\"--copy-network\\\"]\",\"installer_image\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2eb852167902b07e2e072b4817c34710462fc5d7babed5cb7a95e47689c406\",\"mco_image\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96\",\"must_gather_image\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26\",\"openshift_version\":\"4.13.2\",\"role\":\"bootstrap\",\"service_ips\":null}]>" func=github.com/openshift/assisted-service/internal/host/hostcommands.logSteps file="/src/internal/host/hostcommands/instruction_manager.go:287" go-id=1416 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=373fdb36-a8d9-4aa0-9bf5-f67065207ba2
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:08:44" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- findmnt --raw --noheadings --output SOURCE,TARGET --target /run/media/iso]" file="execute.go:39"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:08:44" level=info msg="Creating execution step for install install-b4e5d93c args <[{\"boot_device\":\"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\",\"check_cvo\":false,\"cluster_id\":\"348785c6-46bc-472b-80be-59bd077b9966\",\"controller_image\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:594d4998e68eb7ba35024b3f4dbcc812a3ce85ffe840fbeff58c03e178fb54ce\",\"disks_to_format\":[],\"high_availability_mode\":\"None\",\"host_id\":\"1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f\",\"infra_env_id\":\"5f396111-46ed-4173-9648-bc0a9a818139\",\"installer_args\":\"[\\\"--copy-network\\\"]\",\"installer_image\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2eb852167902b07e2e072b4817c34710462fc5d7babed5cb7a95e47689c406\",\"mco_image\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96\",\"must_gather_image\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26\",\"openshift_version\":\"4.13.2\",\"role\":\"bootstrap\",\"service_ips\":null}]>" file="step_processor.go:123" request_id=373fdb36-a8d9-4aa0-9bf5-f67065207ba2
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:08:44" level=info msg="Validating install with args [{\"boot_device\":\"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\",\"check_cvo\":false,\"cluster_id\":\"348785c6-46bc-472b-80be-59bd077b9966\",\"controller_image\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:594d4998e68eb7ba35024b3f4dbcc812a3ce85ffe840fbeff58c03e178fb54ce\",\"disks_to_format\":[],\"high_availability_mode\":\"None\",\"host_id\":\"1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f\",\"infra_env_id\":\"5f396111-46ed-4173-9648-bc0a9a818139\",\"installer_args\":\"[\\\"--copy-network\\\"]\",\"installer_image\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2eb852167902b07e2e072b4817c34710462fc5d7babed5cb7a95e47689c406\",\"mco_image\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96\",\"must_gather_image\":\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26\",\"openshift_version\":\"4.13.2\",\"role\":\"bootstrap\",\"service_ips\":null}]" file="action.go:29"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:08:44" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- sh -c podman run --privileged --pid=host --net=host --name=assisted-installer -v /dev:/dev:rw -v /opt:/opt:rw -v /var/log:/var/log:rw -v /run/systemd/journal/socket:/run/systemd/journal/socket -v /etc/pki:/etc/pki --env=PULL_SECRET_TOKEN quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2eb852167902b07e2e072b4817c34710462fc5d7babed5cb7a95e47689c406 --role bootstrap --infra-env-id 5f396111-46ed-4173-9648-bc0a9a818139 --cluster-id 348785c6-46bc-472b-80be-59bd077b9966 --host-id 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f --boot-device /dev/disk/by-id/nvme-eui.34333630527573050025384100000001 --url http://192.168.14.27:8090/ --controller-image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:594d4998e68eb7ba35024b3f4dbcc812a3ce85ffe840fbeff58c03e178fb54ce --agent-image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d --high-availability-mode None --mco-image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96 --must-gather-image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26 --openshift-version 4.13.2 --insecure --installer-args '[\"--copy-network\"]']" file="execute.go:39"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab systemd[1]: Started libpod-conmon-dcc9353ed46bfe02bb39a09d0da4b56fff96d25b64d998add4d71da3eed02c72.scope.
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container dcc9353ed46bfe02bb39a09d0da4b56fff96d25b64d998add4d71da3eed02c72.
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=warning msg="Agent Authentication Token not set"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Assisted installer started. Configuration is:\n struct Config {\n\tDryRunConfig: struct DryRunConfig {\n\t\tDryRunEnabled: false,\n\t\tFakeRebootMarkerPath: \"\",\n\t\tForcedHostID: \"\",\n\t\tDryRunClusterHostsPath: \"\",\n\t\tParsedClusterHosts: config.DryClusterHosts(nil),\n\t},\n\tRole: \"bootstrap\",\n\tClusterID: \"348785c6-46bc-472b-80be-59bd077b9966\",\n\tInfraEnvID: \"5f396111-46ed-4173-9648-bc0a9a818139\",\n\tHostID: \"1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f\",\n\tDevice: \"/dev/disk/by-id/nvme-eui.34333630527573050025384100000001\",\n\tURL: \"http://192.168.14.27:8090/\",\n\tVerbose: false,\n\tOpenshiftVersion: \"4.13.2\",\n\tMCOImage: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96\",\n\tControllerImage: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:594d4998e68eb7ba35024b3f4dbcc812a3ce85ffe840fbeff58c03e178fb54ce\",\n\tAgentImage: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:a0e17ec80e676b16a5772a5683f2a0a00ac0abab44fa20478bda83adc5185d4d\",\n\tPullSecretToken: <SECRET>,\n\tSkipCertVerification: true,\n\tCACertPath: \"\",\n\tHTTPProxy: \"\",\n\tHTTPSProxy: \"\",\n\tNoProxy: \"\",\n\tServiceIPs: \"\",\n\tInstallerArgs: []string{\"--copy-network\"},\n\tHighAvailabilityMode: \"None\",\n\tCheckClusterVersion: false,\n\tMustGatherImage: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4c357a92ae31f8c871ee60d7bd353a568096dfa7ccc6ec75fead84418f574b26\",\n\tDisksToFormat: config.ArrayFlags(nil),\n\tSkipInstallationDiskCleanup: false,\n}"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Dry configuration is:\n struct DryRunConfig {\n\tDryRunEnabled: false,\n\tFakeRebootMarkerPath: \"\",\n\tForcedHostID: \"\",\n\tDryRunClusterHostsPath: \"\",\n\tParsedClusterHosts: config.DryClusterHosts(nil),\n}"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=warning msg="Certificate verification is turned off. This is not recommended in production environments"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Installing node with role: bootstrap"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Updating node installation stage: Starting installation - bootstrap" request_id=14e45c8e-8921-40ea-a447-aebd7b709a65
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:08:44Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1418 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=14e45c8e-8921-40ea-a447-aebd7b709a65
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:08:44Z" level=info msg="host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f from infra env 5f396111-46ed-4173-9648-bc0a9a818139 has been updated with the following updates [status installing-in-progress status_info Starting installation progress_current_stage Starting installation progress_progress_info bootstrap progress_stage_updated_at 2023-06-06T02:08:44.596Z progress_installation_percentage 14.285714285714285 progress_stage_started_at 2023-06-06T02:08:44.596Z status_updated_at 2023-06-06T02:08:44.596Z trigger_monitor_timestamp 2023-06-06 02:08:44.596613222 +0000 UTC m=+188.346879835]" func=github.com/openshift/assisted-service/internal/host/hostutil.UpdateHostStatus file="/src/internal/host/hostutil/update_host.go:77" go-id=1418 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=host-state request_id=14e45c8e-8921-40ea-a447-aebd7b709a65
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:08:44Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Starting installation: bootstrap" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1418 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=14e45c8e-8921-40ea-a447-aebd7b709a65
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Resolving installation device /dev/disk/by-id/nvme-eui.34333630527573050025384100000001 symlink to /dev/nvme0n1 "
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Start cleaning up device /dev/nvme0n1"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="No devices found\n"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Creating directory: /opt/install-dir"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Updating node installation stage: Installing - bootstrap" request_id=9fd4c939-f4c5-4ad6-bba6-009ff89ae3c7
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:08:44Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1418 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=9fd4c939-f4c5-4ad6-bba6-009ff89ae3c7
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:08:44Z" level=info msg="service Logic Host Installation Phase Seconds phase Starting installation, vendor HPE product Edgeline e920t disk SSD result Done, duration 0.235636" go-id=1418 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 request_id=9fd4c939-f4c5-4ad6-bba6-009ff89ae3c7
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:08:44Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Installing: bootstrap" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1418 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=9fd4c939-f4c5-4ad6-bba6-009ff89ae3c7
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Installing single node openshift"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Running bootstrap"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Creating directory: /root/.ssh"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Getting bootstrap.ign file" request_id=8316d113-a835-410b-ac6a-05987f999fce
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Downloading file bootstrap.ign to /opt/install-dir/bootstrap.ign"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:08:44Z" level=info msg="Checking cluster file for download: bootstrap.ign for cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).checkFileForDownload" file="/src/internal/bminventory/inventory.go:3642" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=1418 pkg=Inventory request_id=8316d113-a835-410b-ac6a-05987f999fce
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Getting data from /opt/install-dir/bootstrap.ign"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Writing extracted content to tmp file /opt/extracted_from_ignition.json"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Moving /opt/extracted_from_ignition.json to /root/.docker/config.json"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:44Z" level=info msg="Extracting ignition to disk using quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96 mcoImage"
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab systemd[1]: Started libpod-conmon-835626f888367fd9873cb341dbcf92fc738fde47f75230471e9471b229c7533d.scope.
Jun 06 02:08:44 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 835626f888367fd9873cb341dbcf92fc738fde47f75230471e9471b229c7533d.
Jun 06 02:08:45 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:45Z" level=info msg="I0606 02:08:45.001346    6493 start.go:96] Version: v4.13.0-202305262054.p0.g5c5a902.assembly.stream-dirty (5c5a902aeb55c02b5abda80f90fae264a2d5ad69)\nI0606 02:08:45.001354    6493 start.go:109] Calling chroot(\"/rootfs\")\nI0606 02:08:45.001526    6493 update.go:2010] Running: systemctl daemon-reload\n"
Jun 06 02:08:45 sno131.outbound.vz.bos2.lab systemd[1]: Reloading.
Jun 06 02:08:45 sno131.outbound.vz.bos2.lab systemd[1]: Configuration file /etc/systemd/system.conf.d/10-default-env.conf is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
Jun 06 02:08:45 sno131.outbound.vz.bos2.lab systemd-rc-local-generator[6545]: /etc/rc.d/rc.local is not marked executable, skipping.
Jun 06 02:08:45 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:45Z" level=info msg="I0606 02:08:45.137663    6493 rpm-ostree.go:85] Enabled workaround for bug 2111817\n"
Jun 06 02:08:46 sno131.outbound.vz.bos2.lab systemd[1]: Starting rpm-ostree System Management Daemon...
Jun 06 02:08:46 sno131.outbound.vz.bos2.lab rpm-ostree[6559]: Reading config file '/etc/rpm-ostreed.conf'
Jun 06 02:08:46 sno131.outbound.vz.bos2.lab systemd[1]: Starting Authorization Manager...
Jun 06 02:08:46 sno131.outbound.vz.bos2.lab polkitd[6563]: Started polkitd version 0.117
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab polkitd[6563]: Loading rules from directory /etc/polkit-1/rules.d
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab polkitd[6563]: Loading rules from directory /usr/share/polkit-1/rules.d
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab polkitd[6563]: Finished loading, compiling and executing 3 rules
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab systemd[1]: Started Authorization Manager.
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab polkitd[6563]: Acquired the name org.freedesktop.PolicyKit1 on the system bus
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab rpm-ostree[6559]: In idle state; will auto-exit in 64 seconds
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab systemd[1]: Started rpm-ostree System Management Daemon.
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab rpm-ostree[6559]: client(id:cli dbus:1.95 unit:libpod-835626f888367fd9873cb341dbcf92fc738fde47f75230471e9471b229c7533d.scope uid:0) added; new total=1
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab rpm-ostree[6559]: client(id:cli dbus:1.95 unit:libpod-835626f888367fd9873cb341dbcf92fc738fde47f75230471e9471b229c7533d.scope uid:0) vanished; remaining=0
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab rpm-ostree[6559]: In idle state; will auto-exit in 62 seconds
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.737538    6493 daemon.go:260] Booted osImageURL:  (413.92.202305021736-0) f069b5aca6a53934461a7361690bd20ad4aa3e223b6d12e77d54dc3ab4f48360\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.794468    6493 file_writers.go:163] Writing file \"/etc/containers/registries.conf\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.796258    6493 file_writers.go:163] Writing file \"/etc/ignition-machine-config-encapsulated.json\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.797706    6493 file_writers.go:163] Writing file \"/etc/motd\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.799044    6493 file_writers.go:163] Writing file \"/etc/pki/ca-trust/source/anchors/ca.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.800167    6493 file_writers.go:163] Writing file \"/etc/profile.d/proxy.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.801414    6493 file_writers.go:163] Writing file \"/etc/systemd/system.conf.d/10-default-env.conf\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.802633    6493 file_writers.go:163] Writing file \"/root/.docker/config.json\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.803661    6493 file_writers.go:163] Writing file \"/usr/local/bin/approve-csr.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.804262    6493 file_writers.go:163] Writing file \"/usr/local/bin/bootkube.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.805265    6493 file_writers.go:163] Writing file \"/usr/local/bin/bootstrap-cluster-gather.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.806232    6493 file_writers.go:163] Writing file \"/usr/local/bin/bootstrap-pivot.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.807629    6493 file_writers.go:163] Writing file \"/usr/local/bin/bootstrap-service-record.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.808937    6493 file_writers.go:163] Writing file \"/usr/local/bin/bootstrap-verify-api-server-urls.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.810043    6493 file_writers.go:163] Writing file \"/usr/local/bin/crio-configure.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.811238    6493 file_writers.go:163] Writing file \"/usr/local/bin/installer-gather.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.811857    6493 file_writers.go:163] Writing file \"/usr/local/bin/installer-masters-gather.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.813365    6493 file_writers.go:163] Writing file \"/usr/local/bin/kubelet-pause-image.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.814166    6493 file_writers.go:163] Writing file \"/usr/local/bin/kubelet.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.814982    6493 file_writers.go:163] Writing file \"/usr/local/bin/release-image-download.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.816296    6493 file_writers.go:163] Writing file \"/usr/local/bin/release-image.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.817868    6493 file_writers.go:163] Writing file \"/usr/local/bin/report-progress.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.819284    6493 file_writers.go:163] Writing file \"/opt/openshift/manifests/cluster-config.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.820939    6493 file_writers.go:163] Writing file \"/opt/openshift/manifests/cluster-dns-02-config.yml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.822228    6493 file_writers.go:163] Writing file \"/opt/openshift/manifests/cluster-infrastructure-02-config.yml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.823205    6493 file_writers.go:163] Writing file \"/opt/openshift/manifests/cluster-ingress-02-config.yml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.824651    6493 file_writers.go:163] Writing file \"/opt/openshift/manifests/cluster-network-01-crd.yml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.825510    6493 file_writers.go:163] Writing file \"/opt/openshift/manifests/cluster-network-02-config.yml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.826178    6493 file_writers.go:163] Writing file \"/opt/openshift/manifests/cluster-proxy-01-config.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.826917    6493 file_writers.go:163] Writing file \"/opt/openshift/manifests/cluster-scheduler-02-config.yml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.827502    6493 file_writers.go:163] Writing file \"/opt/openshift/manifests/cvo-overrides.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.828207    6493 file_writers.go:163] Writing file \"/opt/openshift/manifests/kube-cloud-config.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.829434    6493 file_writers.go:163] Writing file \"/opt/openshift/manifests/kube-system-configmap-root-ca.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.830314    6493 file_writers.go:163] Writing file \"/opt/openshift/manifests/machine-config-server-tls-secret.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.831526    6493 file_writers.go:163] Writing file \"/opt/openshift/manifests/openshift-config-secret-pull-secret.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.832720    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/01-container-mount-ns-and-kubelet-conf-master-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.833759    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/02-master-workload-partitioning-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.834890    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/04-accelerated-container-startup-master-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.836129    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/05-kdump-config-master-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.837146    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/06-kdump-master-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.838568    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/50-masters-chrony-configuration.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.840181    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/50-workers-chrony-configuration.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.841883    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/99-crio-disable-wipe-master-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.843600    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/99_kubeadmin-password-secret.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.845276    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/AmqSubscription-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.846879    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/AmqSubscriptionNS-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.848052    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/AmqSubscriptionOperGroup-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.849807    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/PtpSubscription-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.851260    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/PtpSubscriptionNS-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.852839    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/PtpSubscriptionOperGroup-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.853920    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/SriovSubscription-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.854965    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/SriovSubscriptionNS-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.856239    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/SriovSubscriptionOperGroup-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.857556    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/StorageNS-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.859108    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/StorageOperGroup-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.860849    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/StorageSubscription-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.862524    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/dnsmasq-bootstrap-in-place.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.864175    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/enable-crun-master-0.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.866031    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/node-ip-hint-master.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.867696    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/node-ip-hint-worker.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.869332    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/openshift-install-manifests.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.871019    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/99_openshift-cluster-api_master-user-data-secret.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.872658    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/99_openshift-machineconfig_99-master-ssh.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.874305    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/99_openshift-machineconfig_99-worker-ssh.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.875919    6493 file_writers.go:163] Writing file \"/opt/openshift/openshift/99_openshift-cluster-api_worker-user-data-secret.yaml\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.877479    6493 file_writers.go:163] Writing file \"/opt/openshift/original_cvo_overrides.patch\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.879135    6493 file_writers.go:163] Writing file \"/opt/openshift/auth/kubeconfig\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.880906    6493 file_writers.go:163] Writing file \"/opt/openshift/auth/kubeconfig-kubelet\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.882306    6493 file_writers.go:163] Writing file \"/opt/openshift/auth/kubeconfig-loopback\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.883958    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/admin-kubeconfig-ca-bundle.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.885611    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/aggregator-ca.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.886914    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/aggregator-ca.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.887919    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/aggregator-ca-bundle.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.889551    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/aggregator-client.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.890998    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/aggregator-client.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.892195    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/aggregator-signer.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.893383    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/aggregator-signer.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.894876    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/apiserver-proxy.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.895704    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/apiserver-proxy.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.896589    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-lb-ca-bundle.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.897505    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-lb-server.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.898334    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-lb-server.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.899186    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-internal-lb-server.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.900128    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-internal-lb-server.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.900979    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-lb-signer.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.901833    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-lb-signer.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.902645    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-localhost-ca-bundle.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.903353    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-localhost-server.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.904381    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-localhost-server.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.905265    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-localhost-signer.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.906116    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-localhost-signer.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.906934    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-service-network-ca-bundle.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.907420    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-service-network-server.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.908234    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-service-network-server.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.909133    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-service-network-signer.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.910068    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-service-network-signer.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.910934    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-complete-server-ca-bundle.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.911771    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-complete-client-ca-bundle.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.912893    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-to-kubelet-ca-bundle.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.913740    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-to-kubelet-client.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.914796    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-to-kubelet-client.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.915743    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-to-kubelet-signer.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.916609    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-apiserver-to-kubelet-signer.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.917553    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-control-plane-ca-bundle.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.918091    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-control-plane-kube-controller-manager-client.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.919640    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-control-plane-kube-controller-manager-client.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.921047    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-control-plane-kube-scheduler-client.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.922143    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-control-plane-kube-scheduler-client.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.923233    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-control-plane-signer.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.923633    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kube-control-plane-signer.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.924219    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kubelet-bootstrap-kubeconfig-ca-bundle.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.925465    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kubelet-client-ca-bundle.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.926347    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kubelet-client.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.927227    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kubelet-client.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.928057    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kubelet-signer.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.928816    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kubelet-signer.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.929694    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/kubelet-serving-ca-bundle.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.930610    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/machine-config-server.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.931451    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/machine-config-server.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.932077    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/service-account.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.932949    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/service-account.pub\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.933933    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/journal-gatewayd.key\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.934715    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/journal-gatewayd.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.935572    6493 file_writers.go:163] Writing file \"/opt/openshift/tls/root-ca.crt\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.936343    6493 file_writers.go:163] Writing file \"/opt/openshift/bootstrap-in-place/bootstrap-in-place-post-reboot.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.937423    6493 file_writers.go:163] Writing file \"/opt/openshift/bootstrap-in-place/master-update.fcc\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.938330    6493 file_writers.go:163] Writing file \"/usr/local/bin/bootstrap-in-place.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.939194    6493 file_writers.go:163] Writing file \"/usr/local/bin/install-to-disk.sh\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.940069    6493 file_writers.go:223] Writing systemd unit \"approve-csr.service\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:47Z" level=info msg="I0606 02:08:47.941513    6493 file_writers.go:223] Writing systemd unit \"bootkube.service\"\n"
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab systemd[1]: Reloading.
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab systemd[1]: Configuration file /etc/systemd/system.conf.d/10-default-env.conf is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
Jun 06 02:08:47 sno131.outbound.vz.bos2.lab systemd-rc-local-generator[6626]: /etc/rc.d/rc.local is not marked executable, skipping.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="I0606 02:08:48.074127    6493 update.go:1483] Preset systemd unit bootkube.service\nI0606 02:08:48.074139    6493 file_writers.go:223] Writing systemd unit \"chown-gatewayd-key.service\"\n"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="I0606 02:08:48.075751    6493 file_writers.go:223] Writing systemd unit \"crio-configure.service\"\n"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Reloading.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Configuration file /etc/systemd/system.conf.d/10-default-env.conf is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd-rc-local-generator[6667]: /etc/rc.d/rc.local is not marked executable, skipping.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="I0606 02:08:48.209424    6493 update.go:1483] Preset systemd unit crio-configure.service\nI0606 02:08:48.209434    6493 file_writers.go:223] Writing systemd unit \"kubelet.service\"\n"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="I0606 02:08:48.210619    6493 file_writers.go:223] Writing systemd unit \"progress.service\"\n"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="I0606 02:08:48.215176    6493 update.go:1520] Could not reset unit preset for release-image-pivot.service, skipping. (Error msg: error running preset on unit: Failed to preset unit: Unit file release-image-pivot.service does not exist.\n)\nI0606 02:08:48.215188    6493 file_writers.go:223] Writing systemd unit \"release-image.service\"\n"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Reloading.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Configuration file /etc/systemd/system.conf.d/10-default-env.conf is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd-rc-local-generator[6709]: /etc/rc.d/rc.local is not marked executable, skipping.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="I0606 02:08:48.344054    6493 update.go:1483] Preset systemd unit release-image.service\nI0606 02:08:48.344066    6493 file_writers.go:137] Writing systemd unit dropin \"certs.conf\"\n"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Reloading.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Configuration file /etc/systemd/system.conf.d/10-default-env.conf is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd-rc-local-generator[6747]: /etc/rc.d/rc.local is not marked executable, skipping.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="I0606 02:08:48.476932    6493 update.go:1483] Preset systemd unit systemd-journal-gatewayd.service\nI0606 02:08:48.476946    6493 file_writers.go:137] Writing systemd unit dropin \"okd-machine-os-disabled.conf\"\n"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="I0606 02:08:48.481171    6493 update.go:1520] Could not reset unit preset for zincati.service, skipping. (Error msg: error running preset on unit: Failed to preset unit: Unit file zincati.service does not exist.\n)\nI0606 02:08:48.481179    6493 file_writers.go:223] Writing systemd unit \"install-to-disk.service\"\n"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Reloading.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Configuration file /etc/systemd/system.conf.d/10-default-env.conf is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd-rc-local-generator[6788]: /etc/rc.d/rc.local is not marked executable, skipping.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="I0606 02:08:48.614066    6493 update.go:1461] Enabled systemd units: [approve-csr.service chown-gatewayd-key.service kubelet.service progress.service systemd-journal-gatewayd.socket install-to-disk.service]\n"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: libpod-835626f888367fd9873cb341dbcf92fc738fde47f75230471e9471b229c7533d.scope: Deactivated successfully.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-835626f888367fd9873cb341dbcf92fc738fde47f75230471e9471b229c7533d-userdata-shm.mount: Deactivated successfully.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-cb63f78ed1a0b41a7c28f2c9db94abd071205905e49d54db1af2e6f021631c63-merged.mount: Deactivated successfully.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: libpod-conmon-835626f888367fd9873cb341dbcf92fc738fde47f75230471e9471b229c7533d.scope: Deactivated successfully.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="Done extracting ignition to filesystem"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="Running systemctl daemon-reload []"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Reloading.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Configuration file /etc/systemd/system.conf.d/10-default-env.conf is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd-rc-local-generator[6856]: /etc/rc.d/rc.local is not marked executable, skipping.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="Start checking localhostname"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="hostname is not localhost, no need to do anything"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="Filling template file /assisted-installer-controller/deploy/assisted-installer-controller-cm.yaml.template"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="Creating directory: /opt/openshift/manifests"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="Writing rendered data to /opt/openshift/manifests/assisted-installer-controller-cm.yaml"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="Filling template file /assisted-installer-controller/deploy/assisted-installer-controller-secret.yaml.template"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="Creating directory: /opt/openshift/manifests"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="Writing rendered data to /opt/openshift/manifests/assisted-installer-controller-secret.yaml"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="Filling template file /assisted-installer-controller/deploy/assisted-installer-controller-pod.yaml.template"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="Creating directory: /opt/openshift/manifests"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="Writing rendered data to /opt/openshift/manifests/assisted-installer-controller-pod.yaml"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:08:48Z" level=info msg="Running systemctl start [bootkube.service]"
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Reached target Host and Network Name Lookups.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Listening on RPCbind Server Activation Socket.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Reached target RPC Port Mapper.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Starting Generation of shadow ID ranges for CRI-O...
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Starting Download the OpenShift Release Image...
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Starting Notify NFS peers of a restart...
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Starting NFS status monitor for NFSv2/3 locking....
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab sm-notify[6881]: Version 2.5.4 starting
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Started Notify NFS peers of a restart.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Starting RPC Bind...
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: crio-subid.service: Deactivated successfully.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Finished Generation of shadow ID ranges for CRI-O.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab release-image-download.sh[6878]: Pulling quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27...
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Started RPC Bind.
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab rpc.statd[6901]: Version 2.5.4 starting
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab rpc.statd[6901]: Flags: TI-RPC
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab rpc.statd[6901]: Initializing NSM state
Jun 06 02:08:48 sno131.outbound.vz.bos2.lab systemd[1]: Started NFS status monitor for NFSv2/3 locking..
Jun 06 02:08:50 sno131.outbound.vz.bos2.lab release-image-download.sh[6903]: bd31af778e86d50ac082b75a2860143704fe333a4a07562202de6fc7593859a3
Jun 06 02:08:50 sno131.outbound.vz.bos2.lab systemd[1]: Finished Download the OpenShift Release Image.
Jun 06 02:08:50 sno131.outbound.vz.bos2.lab systemd[1]: Starting Configure CRI-O to use the pause image...
Jun 06 02:08:50 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 54c6cfcef067c12889731b52b555e2888602fbf91459b75a1c608b85198a1b67.
Jun 06 02:08:50 sno131.outbound.vz.bos2.lab systemd[1]: libpod-54c6cfcef067c12889731b52b555e2888602fbf91459b75a1c608b85198a1b67.scope: Deactivated successfully.
Jun 06 02:08:50 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-54c6cfcef067c12889731b52b555e2888602fbf91459b75a1c608b85198a1b67-userdata-shm.mount: Deactivated successfully.
Jun 06 02:08:50 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-0e9952f63369409b5018e3e82ab94c0c426fce7a901051ef368184a2b329fc81-merged.mount: Deactivated successfully.
Jun 06 02:08:50 sno131.outbound.vz.bos2.lab systemd[1]: Finished Configure CRI-O to use the pause image.
Jun 06 02:08:50 sno131.outbound.vz.bos2.lab systemd[1]: Starting Container Runtime Interface for OCI (CRI-O)...
Jun 06 02:08:52 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.039148715Z" level=info msg="Starting CRI-O, version: 1.26.3-3.rhaos4.13.git641290e.el9, git: unknown(clean)"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.042497756Z" level=info msg="Node configuration value for hugetlb cgroup is true"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.042506982Z" level=info msg="Node configuration value for pid cgroup is true"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.042533958Z" level=info msg="Node configuration value for memoryswap cgroup is true"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.042538673Z" level=info msg="Node configuration value for cgroup v2 is true"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.047804981Z" level=info msg="Node configuration value for systemd CollectMode is true"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.052425290Z" level=info msg="Node configuration value for systemd AllowedCPUs is true"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.052772806Z" level=info msg="Not using native diff for overlay, this may cause degraded performance for building images: kernel has CONFIG_OVERLAY_FS_REDIRECT_DIR enabled"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.053609928Z" level=info msg="Using default capabilities: CAP_CHOWN, CAP_DAC_OVERRIDE, CAP_FSETID, CAP_FOWNER, CAP_SETGID, CAP_SETUID, CAP_SETPCAP, CAP_NET_BIND_SERVICE, CAP_KILL"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.101794143Z" level=info msg="Checkpoint/restore support disabled"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.101808488Z" level=info msg="Using seccomp default profile when unspecified: true"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.101813200Z" level=info msg="Using the internal default seccomp profile"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.101817148Z" level=info msg="AppArmor is disabled by the system or at CRI-O build-time"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.101820909Z" level=info msg="No blockio config file specified, blockio not configured"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.101824631Z" level=info msg="RDT not available in the host system"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.103440715Z" level=info msg="Conmon does support the --sync option"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.103454116Z" level=info msg="Conmon does support the --log-global-size-max option"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.104665705Z" level=info msg="Conmon does support the --sync option"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.104679323Z" level=info msg="Conmon does support the --log-global-size-max option"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.107642266Z" level=info msg="Found CNI network crio (type=bridge) at /etc/cni/net.d/100-crio-bridge.conflist"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.109444961Z" level=info msg="Found CNI network loopback (type=loopback) at /etc/cni/net.d/200-loopback.conflist"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.109459148Z" level=info msg="Updated default CNI network name to crio"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.115286243Z" level=warning msg="Error encountered when checking whether cri-o should wipe containers: open /var/run/crio/version: no such file or directory"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.116450944Z" level=info msg="Starting seccomp notifier watcher"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.116492391Z" level=info msg="Create NRI interface"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.116497800Z" level=info msg="NRI interface is disabled in the configuration."
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.116643153Z" level=info msg="Serving metrics on :9537 via HTTP"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.117011780Z" level=error msg="Writing clean shutdown supported file: open /var/lib/crio/clean.shutdown.supported: no such file or directory"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:08:55.117025839Z" level=error msg="Failed to sync parent directory of clean shutdown file: open /var/lib/crio: no such file or directory"
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab systemd[1]: Started Container Runtime Interface for OCI (CRI-O).
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab systemd[1]: Starting Kubernetes Kubelet...
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 2051153a1ec51247304238fe0499b7a4dae453ea715b1eb48a526cdd6eb498b7.
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab systemd[1]: libpod-2051153a1ec51247304238fe0499b7a4dae453ea715b1eb48a526cdd6eb498b7.scope: Deactivated successfully.
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-2051153a1ec51247304238fe0499b7a4dae453ea715b1eb48a526cdd6eb498b7-userdata-shm.mount: Deactivated successfully.
Jun 06 02:08:55 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-3e96d4e676cc62ff57f5072f9d6bcbca1422dea411c3fa49f854dc7b9663ef00-merged.mount: Deactivated successfully.
Jun 06 02:08:57 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: Flag --anonymous-auth has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: Flag --runtime-request-timeout has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: Flag --address has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: Flag --pod-manifest-path has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: Flag --minimum-container-ttl-duration has been deprecated, Use --eviction-hard or --eviction-soft instead. Will be removed in a future version.
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: Flag --cluster-domain has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: Flag --cgroup-driver has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: Flag --serialize-image-pulls has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: Flag --volume-plugin-dir has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743042    7266 server.go:198] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743123    7266 flags.go:64] FLAG: --address="192.168.14.27"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743128    7266 flags.go:64] FLAG: --allowed-unsafe-sysctls="[]"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743134    7266 flags.go:64] FLAG: --anonymous-auth="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743137    7266 flags.go:64] FLAG: --application-metrics-count-limit="100"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743140    7266 flags.go:64] FLAG: --authentication-token-webhook="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743142    7266 flags.go:64] FLAG: --authentication-token-webhook-cache-ttl="2m0s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743146    7266 flags.go:64] FLAG: --authorization-mode="AlwaysAllow"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743149    7266 flags.go:64] FLAG: --authorization-webhook-cache-authorized-ttl="5m0s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743152    7266 flags.go:64] FLAG: --authorization-webhook-cache-unauthorized-ttl="30s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743154    7266 flags.go:64] FLAG: --azure-container-registry-config=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743156    7266 flags.go:64] FLAG: --boot-id-file="/proc/sys/kernel/random/boot_id"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743159    7266 flags.go:64] FLAG: --bootstrap-kubeconfig=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743161    7266 flags.go:64] FLAG: --cert-dir="/var/lib/kubelet/pki"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743163    7266 flags.go:64] FLAG: --cgroup-driver="systemd"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743166    7266 flags.go:64] FLAG: --cgroup-root=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743168    7266 flags.go:64] FLAG: --cgroups-per-qos="true"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743170    7266 flags.go:64] FLAG: --client-ca-file=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743172    7266 flags.go:64] FLAG: --cloud-config=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743174    7266 flags.go:64] FLAG: --cloud-provider=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743176    7266 flags.go:64] FLAG: --cluster-dns="[]"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743181    7266 flags.go:64] FLAG: --cluster-domain="cluster.local"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743184    7266 flags.go:64] FLAG: --config=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743186    7266 flags.go:64] FLAG: --container-hints="/etc/cadvisor/container_hints.json"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743188    7266 flags.go:64] FLAG: --container-log-max-files="5"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743191    7266 flags.go:64] FLAG: --container-log-max-size="10Mi"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743193    7266 flags.go:64] FLAG: --container-runtime="remote"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743196    7266 flags.go:64] FLAG: --container-runtime-endpoint="/var/run/crio/crio.sock"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743198    7266 flags.go:64] FLAG: --containerd="/run/containerd/containerd.sock"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743200    7266 flags.go:64] FLAG: --containerd-namespace="k8s.io"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743202    7266 flags.go:64] FLAG: --contention-profiling="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743205    7266 flags.go:64] FLAG: --cpu-cfs-quota="true"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743210    7266 flags.go:64] FLAG: --cpu-cfs-quota-period="100ms"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743212    7266 flags.go:64] FLAG: --cpu-manager-policy="none"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743214    7266 flags.go:64] FLAG: --cpu-manager-policy-options=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743217    7266 flags.go:64] FLAG: --cpu-manager-reconcile-period="10s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743219    7266 flags.go:64] FLAG: --enable-controller-attach-detach="true"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743222    7266 flags.go:64] FLAG: --enable-debugging-handlers="true"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743224    7266 flags.go:64] FLAG: --enable-load-reader="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743226    7266 flags.go:64] FLAG: --enable-server="true"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743230    7266 flags.go:64] FLAG: --enforce-node-allocatable="[pods]"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743236    7266 flags.go:64] FLAG: --event-burst="10"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743238    7266 flags.go:64] FLAG: --event-qps="5"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743240    7266 flags.go:64] FLAG: --event-storage-age-limit="default=0"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743243    7266 flags.go:64] FLAG: --event-storage-event-limit="default=0"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743245    7266 flags.go:64] FLAG: --eviction-hard=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743248    7266 flags.go:64] FLAG: --eviction-max-pod-grace-period="0"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743250    7266 flags.go:64] FLAG: --eviction-minimum-reclaim=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743252    7266 flags.go:64] FLAG: --eviction-pressure-transition-period="5m0s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743254    7266 flags.go:64] FLAG: --eviction-soft=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743256    7266 flags.go:64] FLAG: --eviction-soft-grace-period=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743259    7266 flags.go:64] FLAG: --exit-on-lock-contention="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743261    7266 flags.go:64] FLAG: --experimental-allocatable-ignore-eviction="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743263    7266 flags.go:64] FLAG: --experimental-mounter-path=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743266    7266 flags.go:64] FLAG: --fail-swap-on="true"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743268    7266 flags.go:64] FLAG: --feature-gates=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743271    7266 flags.go:64] FLAG: --file-check-frequency="20s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743273    7266 flags.go:64] FLAG: --global-housekeeping-interval="1m0s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743275    7266 flags.go:64] FLAG: --hairpin-mode="promiscuous-bridge"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743278    7266 flags.go:64] FLAG: --healthz-bind-address="127.0.0.1"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743281    7266 flags.go:64] FLAG: --healthz-port="10248"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743284    7266 flags.go:64] FLAG: --help="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743286    7266 flags.go:64] FLAG: --hostname-override=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743288    7266 flags.go:64] FLAG: --housekeeping-interval="10s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743291    7266 flags.go:64] FLAG: --http-check-frequency="20s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743293    7266 flags.go:64] FLAG: --image-credential-provider-bin-dir=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743295    7266 flags.go:64] FLAG: --image-credential-provider-config=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743297    7266 flags.go:64] FLAG: --image-gc-high-threshold="85"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743300    7266 flags.go:64] FLAG: --image-gc-low-threshold="80"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743302    7266 flags.go:64] FLAG: --image-service-endpoint=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743304    7266 flags.go:64] FLAG: --iptables-drop-bit="15"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743306    7266 flags.go:64] FLAG: --iptables-masquerade-bit="14"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743308    7266 flags.go:64] FLAG: --keep-terminated-pod-volumes="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743310    7266 flags.go:64] FLAG: --kernel-memcg-notification="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743312    7266 flags.go:64] FLAG: --kube-api-burst="10"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743314    7266 flags.go:64] FLAG: --kube-api-content-type="application/vnd.kubernetes.protobuf"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743317    7266 flags.go:64] FLAG: --kube-api-qps="5"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743319    7266 flags.go:64] FLAG: --kube-reserved=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743321    7266 flags.go:64] FLAG: --kube-reserved-cgroup=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743325    7266 flags.go:64] FLAG: --kubeconfig=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743327    7266 flags.go:64] FLAG: --kubelet-cgroups=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743329    7266 flags.go:64] FLAG: --local-storage-capacity-isolation="true"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743331    7266 flags.go:64] FLAG: --lock-file=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743333    7266 flags.go:64] FLAG: --log-cadvisor-usage="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743336    7266 flags.go:64] FLAG: --log-flush-frequency="5s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743338    7266 flags.go:64] FLAG: --log-json-info-buffer-size="0"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743342    7266 flags.go:64] FLAG: --log-json-split-stream="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743344    7266 flags.go:64] FLAG: --logging-format="text"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743346    7266 flags.go:64] FLAG: --machine-id-file="/etc/machine-id,/var/lib/dbus/machine-id"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743349    7266 flags.go:64] FLAG: --make-iptables-util-chains="true"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743351    7266 flags.go:64] FLAG: --manifest-url=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743353    7266 flags.go:64] FLAG: --manifest-url-header=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743356    7266 flags.go:64] FLAG: --master-service-namespace="default"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743358    7266 flags.go:64] FLAG: --max-housekeeping-interval="15s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743361    7266 flags.go:64] FLAG: --max-open-files="1000000"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743363    7266 flags.go:64] FLAG: --max-pods="110"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743366    7266 flags.go:64] FLAG: --maximum-dead-containers="-1"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743375    7266 flags.go:64] FLAG: --maximum-dead-containers-per-container="1"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743377    7266 flags.go:64] FLAG: --memory-manager-policy="None"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743380    7266 flags.go:64] FLAG: --minimum-container-ttl-duration="6m0s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743382    7266 flags.go:64] FLAG: --minimum-image-ttl-duration="2m0s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743385    7266 flags.go:64] FLAG: --node-ip="192.168.14.27"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743387    7266 flags.go:64] FLAG: --node-labels=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743389    7266 flags.go:64] FLAG: --node-status-max-images="50"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743392    7266 flags.go:64] FLAG: --node-status-update-frequency="10s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743394    7266 flags.go:64] FLAG: --oom-score-adj="-999"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743396    7266 flags.go:64] FLAG: --pod-cidr=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743398    7266 flags.go:64] FLAG: --pod-infra-container-image="quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4964f9b316ef38d1755f1a51287f9cbe290d3762525e003ac872a4506545186f"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743401    7266 flags.go:64] FLAG: --pod-manifest-path="/etc/kubernetes/manifests"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743404    7266 flags.go:64] FLAG: --pod-max-pids="-1"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743406    7266 flags.go:64] FLAG: --pods-per-core="0"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743408    7266 flags.go:64] FLAG: --port="10250"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743410    7266 flags.go:64] FLAG: --protect-kernel-defaults="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743412    7266 flags.go:64] FLAG: --provider-id=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743414    7266 flags.go:64] FLAG: --qos-reserved=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743416    7266 flags.go:64] FLAG: --read-only-port="10255"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743418    7266 flags.go:64] FLAG: --register-node="true"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743421    7266 flags.go:64] FLAG: --register-schedulable="true"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743426    7266 flags.go:64] FLAG: --register-with-taints=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743429    7266 flags.go:64] FLAG: --registry-burst="10"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743431    7266 flags.go:64] FLAG: --registry-qps="5"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743433    7266 flags.go:64] FLAG: --reserved-cpus=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743435    7266 flags.go:64] FLAG: --reserved-memory=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743439    7266 flags.go:64] FLAG: --resolv-conf="/etc/resolv.conf"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743441    7266 flags.go:64] FLAG: --root-dir="/var/lib/kubelet"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743443    7266 flags.go:64] FLAG: --rotate-certificates="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743445    7266 flags.go:64] FLAG: --rotate-server-certificates="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743447    7266 flags.go:64] FLAG: --runonce="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743449    7266 flags.go:64] FLAG: --runtime-cgroups=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743452    7266 flags.go:64] FLAG: --runtime-request-timeout="10m0s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743455    7266 flags.go:64] FLAG: --seccomp-default="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743457    7266 flags.go:64] FLAG: --serialize-image-pulls="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743459    7266 flags.go:64] FLAG: --storage-driver-buffer-duration="1m0s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743461    7266 flags.go:64] FLAG: --storage-driver-db="cadvisor"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743463    7266 flags.go:64] FLAG: --storage-driver-host="localhost:8086"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743465    7266 flags.go:64] FLAG: --storage-driver-password="root"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743467    7266 flags.go:64] FLAG: --storage-driver-secure="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743470    7266 flags.go:64] FLAG: --storage-driver-table="stats"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743474    7266 flags.go:64] FLAG: --storage-driver-user="root"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743476    7266 flags.go:64] FLAG: --streaming-connection-idle-timeout="4h0m0s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743478    7266 flags.go:64] FLAG: --sync-frequency="1m0s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743481    7266 flags.go:64] FLAG: --system-cgroups=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743483    7266 flags.go:64] FLAG: --system-reserved=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743485    7266 flags.go:64] FLAG: --system-reserved-cgroup=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743487    7266 flags.go:64] FLAG: --tls-cert-file=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743489    7266 flags.go:64] FLAG: --tls-cipher-suites="[]"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743493    7266 flags.go:64] FLAG: --tls-min-version=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743495    7266 flags.go:64] FLAG: --tls-private-key-file=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743497    7266 flags.go:64] FLAG: --topology-manager-policy="none"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743499    7266 flags.go:64] FLAG: --topology-manager-policy-options=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743501    7266 flags.go:64] FLAG: --topology-manager-scope="container"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743503    7266 flags.go:64] FLAG: --v="2"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743506    7266 flags.go:64] FLAG: --version="false"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743511    7266 flags.go:64] FLAG: --vmodule=""
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743514    7266 flags.go:64] FLAG: --volume-plugin-dir="/etc/kubernetes/kubelet-plugins/volume/exec"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743516    7266 flags.go:64] FLAG: --volume-stats-agg-period="1m0s"
Jun 06 02:09:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:00.743582    7266 feature_gate.go:250] feature gates: &{map[]}
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.073949    7266 server.go:412] "Kubelet version" kubeletVersion="v1.26.3+b404935"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.073963    7266 server.go:414] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.073988    7266 feature_gate.go:250] feature gates: &{map[]}
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.074040    7266 feature_gate.go:250] feature gates: &{map[]}
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.075028    7266 server.go:575] "Standalone mode, no API client"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.077673    7266 fs.go:133] Filesystem UUIDs: map[2023-06-06-01-58-25-46:/dev/sr0 2d7960a1-0e61-4db5-9918-b809dec15f28:/dev/loop0]
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.077686    7266 fs.go:134] Filesystem partitions: map[/dev/loop0:{mountpoint:/var major:7 minor:0 fsType:xfs blockSize:0} /dev/shm:{mountpoint:/dev/shm major:0 minor:23 fsType:tmpfs blockSize:0} /run:{mountpoint:/run major:0 minor:25 fsType:tmpfs blockSize:0} /run/ephemeral_base:{mountpoint:/run/ephemeral_base major:0 minor:30 fsType:tmpfs blockSize:0} /run/netns:{mountpoint:/run/netns major:0 minor:25 fsType:tmpfs blockSize:0} /tmp:{mountpoint:/tmp major:0 minor:33 fsType:tmpfs blockSize:0} /var/lib/containers/storage/overlay-containers/361d59273eefae6f5a76a2f69b781d5baa1e2a52ae0f3607ee7acf6de1e8e5f2/userdata/shm:{mountpoint:/var/lib/containers/storage/overlay-containers/361d59273eefae6f5a76a2f69b781d5baa1e2a52ae0f3607ee7acf6de1e8e5f2/userdata/shm major:0 minor:45 fsType:tmpfs blockSize:0} /var/lib/containers/storage/overlay-containers/960e231b14850e73ea3702ecb0d9222bf5d681df20c9d96af44776c3f8027026/userdata/shm:{mountpoint:/var/lib/containers/storage/overlay-containers/960e231b14850e73ea3702ecb0d9222bf5d681df20c9d96af44776c3f8027026/userdata/shm major:0 minor:78 fsType:tmpfs blockSize:0} /var/lib/containers/storage/overlay-containers/dcc9353ed46bfe02bb39a09d0da4b56fff96d25b64d998add4d71da3eed02c72/userdata/shm:{mountpoint:/var/lib/containers/storage/overlay-containers/dcc9353ed46bfe02bb39a09d0da4b56fff96d25b64d998add4d71da3eed02c72/userdata/shm major:0 minor:82 fsType:tmpfs blockSize:0} overlay_0-46:{mountpoint:/var/lib/containers/storage/overlay/a5d8d5a86f114d81a3a2c18acf98c37cfc20d1a35fe75c232bab9a74cef25cbf/merged major:0 minor:46 fsType:overlay blockSize:0} overlay_0-58:{mountpoint:/var/lib/containers/storage/overlay/fd23b0c8c11a76bc827a4a49ee1840b62b670c7a8eb197e34a8f111ecac208c8/merged major:0 minor:58 fsType:overlay blockSize:0} overlay_0-68:{mountpoint:/var/lib/containers/storage/overlay/3c8ddf1b3b1b32577b9c6aa797001a4ba53d489a63e221b145c0541af93be6a5/merged major:0 minor:68 fsType:overlay blockSize:0} overlay_0-79:{mountpoint:/var/lib/containers/storage/overlay/acb0cf32d89889d369b11751653b5ed8a9c98f251717d4ec5e8104ccd677da79/merged major:0 minor:79 fsType:overlay blockSize:0} overlay_0-83:{mountpoint:/var/lib/containers/storage/overlay/3ec30e56d4d56950c03cd747de38ff45ad12c631e30ccba060c79b24787f5d17/merged major:0 minor:83 fsType:overlay blockSize:0}]
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.078419    7266 nvidia.go:55] NVIDIA GPU metrics disabled
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.105768    7266 manager.go:212] Machine: {Timestamp:2023-06-06 02:09:01.101961118 +0000 UTC m=+3.946560581 CPUVendorID:GenuineIntel NumCores:64 NumPhysicalCores:32 NumSockets:1 CpuFrequency:3500000 MemoryCapacity:134738038784 MemoryByType:map[Registered-DDR4:0xc000c9c4b0] NVMInfo:{MemoryModeCapacity:0 AppDirectModeCapacity:0 AvgPowerBudget:0} HugePages:[{PageSize:1048576 NumPages:0} {PageSize:2048 NumPages:0}] MachineID:a0c1be0936ce4e95ba9bfd63e3f4325c SystemUUID:38303450-3339-584d-5132-3134304b4a4c BootID:1c4de38f-9407-4ca6-8d60-1949f93a762e Filesystems:[{Device:/run/netns DeviceMajor:0 DeviceMinor:25 Capacity:26947608576 Type:vfs Inodes:819200 HasInodes:true} {Device:/var/lib/containers/storage/overlay-containers/960e231b14850e73ea3702ecb0d9222bf5d681df20c9d96af44776c3f8027026/userdata/shm DeviceMajor:0 DeviceMinor:78 Capacity:65536000 Type:vfs Inodes:16447514 HasInodes:true} {Device:overlay_0-79 DeviceMajor:0 DeviceMinor:79 Capacity:67336126464 Type:vfs Inodes:32894976 HasInodes:true} {Device:/dev/loop1 DeviceMajor:7 DeviceMinor:1 Capacity:979501056 Type:vfs Inodes:36848 HasInodes:true} {Device:/run DeviceMajor:0 DeviceMinor:25 Capacity:26947608576 Type:vfs Inodes:819200 HasInodes:true} {Device:/run/ephemeral_base DeviceMajor:0 DeviceMinor:30 Capacity:67369021440 Type:vfs Inodes:16447514 HasInodes:true} {Device:overlay_0-68 DeviceMajor:0 DeviceMinor:68 Capacity:67336126464 Type:vfs Inodes:32894976 HasInodes:true} {Device:/var/lib/containers/storage/overlay-containers/dcc9353ed46bfe02bb39a09d0da4b56fff96d25b64d998add4d71da3eed02c72/userdata/shm DeviceMajor:0 DeviceMinor:82 Capacity:65536000 Type:vfs Inodes:16447514 HasInodes:true} {Device:/dev/loop0 DeviceMajor:7 DeviceMinor:0 Capacity:67336126464 Type:vfs Inodes:32894976 HasInodes:true} {Device:overlay_0-46 DeviceMajor:0 DeviceMinor:46 Capacity:67336126464 Type:vfs Inodes:32894976 HasInodes:true} {Device:overlay_0-58 DeviceMajor:0 DeviceMinor:58 Capacity:67336126464 Type:vfs Inodes:32894976 HasInodes:true} {Device:overlay_0-83 DeviceMajor:0 DeviceMinor:83 Capacity:67336126464 Type:vfs Inodes:32894976 HasInodes:true} {Device:/dev/shm DeviceMajor:0 DeviceMinor:23 Capacity:67369017344 Type:vfs Inodes:16447514 HasInodes:true} {Device:/var/lib/containers/storage/overlay-containers/361d59273eefae6f5a76a2f69b781d5baa1e2a52ae0f3607ee7acf6de1e8e5f2/userdata/shm DeviceMajor:0 DeviceMinor:45 Capacity:65536000 Type:vfs Inodes:16447514 HasInodes:true} {Device:/tmp DeviceMajor:0 DeviceMinor:33 Capacity:67369021440 Type:vfs Inodes:1048576 HasInodes:true}] DiskMap:map[259:0:{Name:nvme1n1 Major:259 Minor:0 Size:1920383410176 Scheduler:none} 259:1:{Name:nvme0n1 Major:259 Minor:1 Size:1920383410176 Scheduler:none}] NetworkDevices:[{Name:cni-podman0 MacAddress:32:0b:12:25:7a:9e Speed:10000 Mtu:1500} {Name:eno1 MacAddress:5c:ba:2c:1f:6c:e5 Speed:1000 Mtu:1500} {Name:ens1f0 MacAddress:b4:96:91:d9:a4:64 Speed:25000 Mtu:1500} {Name:ens1f1 MacAddress:b4:96:91:d9:a4:65 Speed:-1 Mtu:1500} {Name:ens1f2 MacAddress:b4:96:91:d9:a4:66 Speed:-1 Mtu:1500} {Name:ens1f3 MacAddress:b4:96:91:d9:a4:67 Speed:-1 Mtu:1500} {Name:ens2f0 MacAddress:b4:96:91:da:5a:c4 Speed:-1 Mtu:1500} {Name:ens2f1 MacAddress:b4:96:91:da:5a:c5 Speed:-1 Mtu:1500} {Name:ens2f2 MacAddress:b4:96:91:da:5a:c6 Speed:-1 Mtu:1500} {Name:ens2f3 MacAddress:b4:96:91:da:5a:c7 Speed:-1 Mtu:1500}] Topology:[{Id:0 Memory:134738038784 HugePages:[{PageSize:1048576 NumPages:0} {PageSize:2048 NumPages:0}] Cores:[{Id:0 Threads:[0 32] Caches:[{Id:0 Size:49152 Type:Data Level:1} {Id:0 Size:32768 Type:Instruction Level:1} {Id:0 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:1 Threads:[1 33] Caches:[{Id:1 Size:49152 Type:Data Level:1} {Id:1 Size:32768 Type:Instruction Level:1} {Id:1 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:10 Threads:[10 42] Caches:[{Id:10 Size:49152 Type:Data Level:1} {Id:10 Size:32768 Type:Instruction Level:1} {Id:10 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:11 Threads:[11 43] Caches:[{Id:11 Size:49152 Type:Data Level:1} {Id:11 Size:32768 Type:Instruction Level:1} {Id:11 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:12 Threads:[12 44] Caches:[{Id:12 Size:49152 Type:Data Level:1} {Id:12 Size:32768 Type:Instruction Level:1} {Id:12 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:13 Threads:[13 45] Caches:[{Id:13 Size:49152 Type:Data Level:1} {Id:13 Size:32768 Type:Instruction Level:1} {Id:13 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:14 Threads:[14 46] Caches:[{Id:14 Size:49152 Type:Data Level:1} {Id:14 Size:32768 Type:Instruction Level:1} {Id:14 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:15 Threads:[15 47] Caches:[{Id:15 Size:49152 Type:Data Level:1} {Id:15 Size:32768 Type:Instruction Level:1} {Id:15 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:16 Threads:[16 48] Caches:[{Id:16 Size:49152 Type:Data Level:1} {Id:16 Size:32768 Type:Instruction Level:1} {Id:16 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:17 Threads:[17 49] Caches:[{Id:17 Size:49152 Type:Data Level:1} {Id:17 Size:32768 Type:Instruction Level:1} {Id:17 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:18 Threads:[18 50] Caches:[{Id:18 Size:49152 Type:Data Level:1} {Id:18 Size:32768 Type:Instruction Level:1} {Id:18 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:19 Threads:[19 51] Caches:[{Id:19 Size:49152 Type:Data Level:1} {Id:19 Size:32768 Type:Instruction Level:1} {Id:19 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:2 Threads:[2 34] Caches:[{Id:2 Size:49152 Type:Data Level:1} {Id:2 Size:32768 Type:Instruction Level:1} {Id:2 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:20 Threads:[20 52] Caches:[{Id:20 Size:49152 Type:Data Level:1} {Id:20 Size:32768 Type:Instruction Level:1} {Id:20 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:21 Threads:[21 53] Caches:[{Id:21 Size:49152 Type:Data Level:1} {Id:21 Size:32768 Type:Instruction Level:1} {Id:21 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:22 Threads:[22 54] Caches:[{Id:22 Size:49152 Type:Data Level:1} {Id:22 Size:32768 Type:Instruction Level:1} {Id:22 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:23 Threads:[23 55] Caches:[{Id:23 Size:49152 Type:Data Level:1} {Id:23 Size:32768 Type:Instruction Level:1} {Id:23 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:24 Threads:[24 56] Caches:[{Id:24 Size:49152 Type:Data Level:1} {Id:24 Size:32768 Type:Instruction Level:1} {Id:24 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:25 Threads:[25 57] Caches:[{Id:25 Size:49152 Type:Data Level:1} {Id:25 Size:32768 Type:Instruction Level:1} {Id:25 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:26 Threads:[26 58] Caches:[{Id:26 Size:49152 Type:Data Level:1} {Id:26 Size:32768 Type:Instruction Level:1} {Id:26 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:27 Threads:[27 59] Caches:[{Id:27 Size:49152 Type:Data Level:1} {Id:27 Size:32768 Type:Instruction Level:1} {Id:27 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:28 Threads:[28 60] Caches:[{Id:28 Size:49152 Type:Data Level:1} {Id:28 Size:32768 Type:Instruction Level:1} {Id:28 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:29 Threads:[29 61] Caches:[{Id:29 Size:49152 Type:Data Level:1} {Id:29 Size:32768 Type:Instruction Level:1} {Id:29 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:3 Threads:[3 35] Caches:[{Id:3 Size:49152 Type:Data Level:1} {Id:3 Size:32768 Type:Instruction Level:1} {Id:3 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:30 Threads:[30 62] Caches:[{Id:30 Size:49152 Type:Data Level:1} {Id:30 Size:32768 Type:Instruction Level:1} {Id:30 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:31 Threads:[31 63] Caches:[{Id:31 Size:49152 Type:Data Level:1} {Id:31 Size:32768 Type:Instruction Level:1} {Id:31 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:4 Threads:[36 4] Caches:[{Id:4 Size:49152 Type:Data Level:1} {Id:4 Size:32768 Type:Instruction Level:1} {Id:4 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:5 Threads:[37 5] Caches:[{Id:5 Size:49152 Type:Data Level:1} {Id:5 Size:32768 Type:Instruction Level:1} {Id:5 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:6 Threads:[38 6] Caches:[{Id:6 Size:49152 Type:Data Level:1} {Id:6 Size:32768 Type:Instruction Level:1} {Id:6 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:7 Threads:[39 7] Caches:[{Id:7 Size:49152 Type:Data Level:1} {Id:7 Size:32768 Type:Instruction Level:1} {Id:7 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:8 Threads:[40 8] Caches:[{Id:8 Size:49152 Type:Data Level:1} {Id:8 Size:32768 Type:Instruction Level:1} {Id:8 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0} {Id:9 Threads:[41 9] Caches:[{Id:9 Size:49152 Type:Data Level:1} {Id:9 Size:32768 Type:Instruction Level:1} {Id:9 Size:1310720 Type:Unified Level:2}] UncoreCaches:[] SocketID:0}] Caches:[{Id:0 Size:50331648 Type:Unified Level:3}] Distances:[10]}] CloudProvider:Unknown InstanceType:Unknown InstanceID:None}
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.106623    7266 manager_no_libpfm.go:29] cAdvisor is build without cgo and/or libpfm support. Perf event counters are not available.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.106804    7266 manager.go:228] Version: {KernelVersion:5.14.0-284.13.1.el9_2.x86_64 ContainerOsVersion:Red Hat Enterprise Linux CoreOS 413.92.202305021736-0 (Plow) DockerVersion: DockerAPIVersion: CadvisorVersion: CadvisorRevision:}
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.106855    7266 server.go:463] "No api server defined - no events will be sent to API server"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.106864    7266 server.go:659] "--cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulting to /"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.107517    7266 container_manager_linux.go:267] "Container manager verified user specified cgroup-root exists" cgroupRoot=[]
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.107544    7266 container_manager_linux.go:272] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: KubeletOOMScoreAdj:-999 ContainerRuntime: CgroupsPerQOS:true CgroupRoot:/ CgroupDriver:systemd KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[]} QOSReserved:map[] CPUManagerPolicy:none CPUManagerPolicyOptions:map[] ExperimentalTopologyManagerScope:container CPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none ExperimentalTopologyManagerPolicyOptions:map[]}
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.107554    7266 topology_manager.go:134] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.107561    7266 container_manager_linux.go:308] "Creating device plugin manager"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.107885    7266 manager.go:125] "Creating Device Plugin manager" path="/var/lib/kubelet/device-plugins/kubelet.sock"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.107894    7266 server.go:66] "Creating device plugin registration server" version="v1beta1" socket="/var/lib/kubelet/device-plugins/kubelet.sock"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.107935    7266 state_mem.go:36] "Initialized new in-memory state store"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.107968    7266 util_unix.go:103] "Using this endpoint is deprecated, please consider using full URL format" endpoint="/var/run/crio/crio.sock" URL="unix:///var/run/crio/crio.sock"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.112454    7266 remote_runtime.go:121] "Validated CRI v1 runtime API"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.112473    7266 util_unix.go:103] "Using this endpoint is deprecated, please consider using full URL format" endpoint="/var/run/crio/crio.sock" URL="unix:///var/run/crio/crio.sock"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.113732    7266 remote_image.go:97] "Validated CRI v1 image API"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.113747    7266 server.go:1147] "Using root directory" path="/var/lib/kubelet"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.113757    7266 kubelet.go:413] "Kubelet is running in standalone mode, will skip API server sync"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.113765    7266 kubelet.go:295] "Adding static pod path" path="/etc/kubernetes/manifests"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.113775    7266 file.go:69] "Watching path" path="/etc/kubernetes/manifests"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.115524    7266 kuberuntime_manager.go:244] "Container runtime initialized" containerRuntime="cri-o" version="1.26.3-3.rhaos4.13.git641290e.el9" apiVersion="v1"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116536    7266 volume_host.go:75] "KubeClient is nil. Skip initialization of CSIDriverLister"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116599    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/azure-disk"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116609    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/azure-file"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116614    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/vsphere-volume"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116624    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/portworx-volume"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116630    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/rbd"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116634    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/aws-ebs"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116639    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/gce-pd"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116646    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/empty-dir"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116652    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/git-repo"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116658    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/host-path"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116663    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/nfs"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116968    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/secret"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116974    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/iscsi"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116980    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/cephfs"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116986    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/downward-api"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116990    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/fc"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.116995    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/configmap"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.117000    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/projected"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.117005    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/local-volume"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: W0606 02:09:01.117803    7266 csi_plugin.go:189] kubernetes.io/csi: kubeclient not set, assuming standalone kubelet
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: W0606 02:09:01.117813    7266 csi_plugin.go:266] Skipping CSINode initialization, kubelet running in standalone mode
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.117819    7266 plugins.go:646] "Loaded volume plugin" pluginName="kubernetes.io/csi"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.117921    7266 server.go:1186] "Started kubelet"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.118034    7266 server.go:161] "Starting to listen" address="192.168.14.27" port=10250
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.118073    7266 server.go:193] "Starting to listen read-only" address="192.168.14.27" port=10255
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: E0606 02:09:01.118184    7266 kubelet.go:1399] "Image garbage collection failed once. Stats initialization may not have completed yet" err="failed to get imageFs info: unable to find data in memory cache"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.118205    7266 kubelet.go:1522] "No API server defined - no node status update will be sent"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: Started Kubernetes Kubelet.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.118870    7266 server.go:451] "Adding debug handlers to kubelet server"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.118893    7266 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.118949    7266 volume_manager.go:291] "The desired_state_of_world populator starts"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.118959    7266 volume_manager.go:293] "Starting Kubelet Volume Manager"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.118976    7266 desired_state_of_world_populator.go:151] "Desired state populator starts to run"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:01.119281222Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4964f9b316ef38d1755f1a51287f9cbe290d3762525e003ac872a4506545186f" id=1aa4b912-650b-4104-90db-cafda7eda408 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:01.119521940Z" level=info msg="Image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4964f9b316ef38d1755f1a51287f9cbe290d3762525e003ac872a4506545186f not found" id=1aa4b912-650b-4104-90db-cafda7eda408 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.120081    7266 factory.go:153] Registering CRI-O factory
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.120172    7266 factory.go:55] Registering systemd factory
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.120184    7266 factory.go:103] Registering Raw factory
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.120189    7266 manager.go:1201] Started watching for new ooms in manager
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.120351    7266 manager.go:302] Starting recovery of all containers
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.121423    7266 manager.go:307] Recovery completed
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.130934    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.131758    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.131771    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.131777    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.132451    7266 cpu_manager.go:215] "Starting CPU manager" policy="none"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.132461    7266 cpu_manager.go:216] "Reconciling" reconcilePeriod="10s"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.132474    7266 state_mem.go:36] "Initialized new in-memory state store"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.134188    7266 policy_none.go:49] "None policy: Start"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.134330    7266 memory_manager.go:169] "Starting memorymanager" policy="None"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.134342    7266 state_mem.go:35] "Initializing new in-memory state store"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: Started Bootstrap a Kubernetes cluster.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:09:01Z" level=info msg="Running systemctl start [approve-csr.service]"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: Created slice libcontainer container kubepods.slice.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: Created slice libcontainer container kubepods-besteffort.slice.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: Created slice libcontainer container kubepods-burstable.slice.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: Started Approve CSRs during bootstrap phase.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.163187    7266 manager.go:281] "Starting Device Plugin manager"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.163213    7266 manager.go:455] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.164024    7266 server.go:79] "Starting device plugin registration server"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.164178    7266 plugin_watcher.go:52] "Plugin Watcher Start" path="/var/lib/kubelet/plugins_registry"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.164205    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.164209    7266 plugin_manager.go:116] "The desired_state_of_world populator (plugin watcher) starts"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.164235    7266 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:09:01Z" level=info msg="Running systemctl start [progress.service]"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.166779    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.166796    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.166802    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: Started Report the completion of the cluster bootstrap process.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:09:01Z" level=info msg="Done setting up bootstrap"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:09:01Z" level=info msg="Waiting for bootkube to complete"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:09:01Z" level=info msg="Updating node installation stage: Waiting for bootkube - " request_id=e6384bca-5ca7-4cec-8579-3cc1e7189399
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:09:01Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1418 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=e6384bca-5ca7-4cec-8579-3cc1e7189399
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:09:01Z" level=info msg="service Logic Host Installation Phase Seconds phase Installing, vendor HPE product Edgeline e920t disk SSD result Done, duration 16.363152" go-id=1418 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 request_id=e6384bca-5ca7-4cec-8579-3cc1e7189399
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:09:01Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Waiting for bootkube" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1418 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=e6384bca-5ca7-4cec-8579-3cc1e7189399
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.198049    7266 kubelet_network_linux.go:63] "Initialized iptables rules." protocol=IPv4
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.224063    7266 kubelet_network_linux.go:63] "Initialized iptables rules." protocol=IPv6
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.224082    7266 status_manager.go:172] "Kubernetes client is nil, not starting status manager"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.224091    7266 kubelet.go:2133] "Starting kubelet main sync loop"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: E0606 02:09:01.224132    7266 kubelet.go:2157] "Skipping pod synchronization" err="PLEG is not healthy: pleg has yet to be successful"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab approve-csr.sh[7327]: Approving all CSR requests until bootstrapping is complete...
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab report-progress.sh[7345]: Waiting for bootstrap to complete...
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.324572    7266 kubelet.go:2219] "SyncLoop ADD" source="file" pods="[]"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 69f719c861b9f7f0fde065d2bef6d986505205ab728a999be9c7b00ec0629289.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.419400    7266 desired_state_of_world_populator.go:159] "Finished populating initial desired state of world"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:01.420511    7266 reconciler.go:41] "Reconciler: start to sync state"
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: libpod-69f719c861b9f7f0fde065d2bef6d986505205ab728a999be9c7b00ec0629289.scope: Deactivated successfully.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-69f719c861b9f7f0fde065d2bef6d986505205ab728a999be9c7b00ec0629289-userdata-shm.mount: Deactivated successfully.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-ca1770c058786c17d75d95e0335573afa29f974ec0d0b90ede6435ebe27d1182-merged.mount: Deactivated successfully.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 99bfc94952e7059eb3c7304b6b94dd87601f1fc1776757d598bb124dfb2b5057.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: libpod-99bfc94952e7059eb3c7304b6b94dd87601f1fc1776757d598bb124dfb2b5057.scope: Deactivated successfully.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container d9db95f7a63ed3740163cb9913a527f6d6d8fca0a16d381ec98e81d11679b8f3.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: libpod-d9db95f7a63ed3740163cb9913a527f6d6d8fca0a16d381ec98e81d11679b8f3.scope: Deactivated successfully.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 23d4a33cc00d37d01d7fa5209bac37322248483b51839d2584bf89d1c458ca6d.
Jun 06 02:09:01 sno131.outbound.vz.bos2.lab systemd[1]: libpod-23d4a33cc00d37d01d7fa5209bac37322248483b51839d2584bf89d1c458ca6d.scope: Deactivated successfully.
Jun 06 02:09:02 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container d1746b1b15c193a61d52eb18a6f806104f6d59499d2798cf3cd9af277fe165e9.
Jun 06 02:09:02 sno131.outbound.vz.bos2.lab systemd[1]: libpod-d1746b1b15c193a61d52eb18a6f806104f6d59499d2798cf3cd9af277fe165e9.scope: Deactivated successfully.
Jun 06 02:09:02 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 7d3de542d32b60e6c9054726a25ff8c95f8ca9232afac5c0710e2d2452472ed2.
Jun 06 02:09:02 sno131.outbound.vz.bos2.lab systemd[1]: libpod-7d3de542d32b60e6c9054726a25ff8c95f8ca9232afac5c0710e2d2452472ed2.scope: Deactivated successfully.
Jun 06 02:09:02 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-7d3de542d32b60e6c9054726a25ff8c95f8ca9232afac5c0710e2d2452472ed2-userdata-shm.mount: Deactivated successfully.
Jun 06 02:09:02 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-1ca06af35e56463bb0ed947ed4ad84f25079d46cdda8fdeabd636974af5ae123-merged.mount: Deactivated successfully.
Jun 06 02:09:02 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 8a6bf9ca2aedb7ed1b5c2e479719f2907755d5aa0f0afd0484958b93b3129f55.
Jun 06 02:09:02 sno131.outbound.vz.bos2.lab systemd[1]: libpod-8a6bf9ca2aedb7ed1b5c2e479719f2907755d5aa0f0afd0484958b93b3129f55.scope: Deactivated successfully.
Jun 06 02:09:02 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 36a48d58390bea18fa7372266bf914e7a05c5cb51a5412384f2b13a00e668e13.
Jun 06 02:09:02 sno131.outbound.vz.bos2.lab systemd[1]: libpod-36a48d58390bea18fa7372266bf914e7a05c5cb51a5412384f2b13a00e668e13.scope: Deactivated successfully.
Jun 06 02:09:02 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:09:02 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container d9b06a4ef9bb57e63702f2b9d71adf2606b1cc7c3833a6796537f251de3c97d6.
Jun 06 02:09:02 sno131.outbound.vz.bos2.lab systemd[1]: libpod-d9b06a4ef9bb57e63702f2b9d71adf2606b1cc7c3833a6796537f251de3c97d6.scope: Deactivated successfully.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container d4416b5b305d2a134c40f4359a59476dc5285d09fc0800f35344e04240faf0ad.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: libpod-d4416b5b305d2a134c40f4359a59476dc5285d09fc0800f35344e04240faf0ad.scope: Deactivated successfully.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container ab62d1170e39bb34bc74b60ef86e8f3840962ca0ae3cf85930a7da9449cbbdbf.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: libpod-ab62d1170e39bb34bc74b60ef86e8f3840962ca0ae3cf85930a7da9449cbbdbf.scope: Deactivated successfully.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-be7a51c7884ad5d0527aefabdfb4845569b0fb0a9114bd15cc6ff03071359f1e-merged.mount: Deactivated successfully.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-8a6bf9ca2aedb7ed1b5c2e479719f2907755d5aa0f0afd0484958b93b3129f55-userdata-shm.mount: Deactivated successfully.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container b051a38891a4bb386c023d84a6f850fd5ee2959108c2a2cbed1aa353fe89d0db.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: libpod-b051a38891a4bb386c023d84a6f850fd5ee2959108c2a2cbed1aa353fe89d0db.scope: Deactivated successfully.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-b051a38891a4bb386c023d84a6f850fd5ee2959108c2a2cbed1aa353fe89d0db-userdata-shm.mount: Deactivated successfully.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-8a27583f713e953d1c55db15f56cf317fd3ae9383d80b95a7cffdc9ea8b1bc3f-merged.mount: Deactivated successfully.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 0ae6dec8c6845ab86e1346b0a93cdc43792c8a2fc67f54f29852dae22ad75ad0.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: libpod-0ae6dec8c6845ab86e1346b0a93cdc43792c8a2fc67f54f29852dae22ad75ad0.scope: Deactivated successfully.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 396e07f0bf33457e86f2b248877b1e57ad48ceb1da07fa409230dfc1f5e014a2.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: libpod-396e07f0bf33457e86f2b248877b1e57ad48ceb1da07fa409230dfc1f5e014a2.scope: Deactivated successfully.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 659efb0f4aa4c8e0e8e9849cbef25c27d9c6fb9945610ecce07fca43bf806230.
Jun 06 02:09:03 sno131.outbound.vz.bos2.lab systemd[1]: libpod-659efb0f4aa4c8e0e8e9849cbef25c27d9c6fb9945610ecce07fca43bf806230.scope: Deactivated successfully.
Jun 06 02:09:04 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container f16a770d018be4199b7adddd9221b7c71a115bf1faebeb1c4b5d837cfe501061.
Jun 06 02:09:04 sno131.outbound.vz.bos2.lab systemd[1]: libpod-f16a770d018be4199b7adddd9221b7c71a115bf1faebeb1c4b5d837cfe501061.scope: Deactivated successfully.
Jun 06 02:09:04 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container f50843583c0ffc0704b30e2aaedb8e902240cfc8ac52719160cbc1d7a3031768.
Jun 06 02:09:04 sno131.outbound.vz.bos2.lab systemd[1]: libpod-f50843583c0ffc0704b30e2aaedb8e902240cfc8ac52719160cbc1d7a3031768.scope: Deactivated successfully.
Jun 06 02:09:04 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-0ae6dec8c6845ab86e1346b0a93cdc43792c8a2fc67f54f29852dae22ad75ad0-userdata-shm.mount: Deactivated successfully.
Jun 06 02:09:04 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-f50843583c0ffc0704b30e2aaedb8e902240cfc8ac52719160cbc1d7a3031768-userdata-shm.mount: Deactivated successfully.
Jun 06 02:09:04 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-1c1b4245691be35b87713f52202a3d2832ae582af8de27484ddf195e8cbbc0bc-merged.mount: Deactivated successfully.
Jun 06 02:09:04 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 991a34072c06d6bea86dca5950e60497ce4020a84dc2b55b6e9883341fb600fc.
Jun 06 02:09:04 sno131.outbound.vz.bos2.lab systemd[1]: libpod-991a34072c06d6bea86dca5950e60497ce4020a84dc2b55b6e9883341fb600fc.scope: Deactivated successfully.
Jun 06 02:09:04 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container e620e5bf292b5eceab79784f60aff8f433c7d52fe8384d59d2cbe3a9a9351446.
Jun 06 02:09:04 sno131.outbound.vz.bos2.lab systemd[1]: libpod-e620e5bf292b5eceab79784f60aff8f433c7d52fe8384d59d2cbe3a9a9351446.scope: Deactivated successfully.
Jun 06 02:09:04 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Moving OpenShift manifests in with the rest of them
Jun 06 02:09:04 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Rendering Cluster Version Operator Manifests...
Jun 06 02:09:04 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 6b3d76de8ce60aa7cb9673e6e67e3bbbde7a9850295b8176bc46cd72ab458df8.
Jun 06 02:09:04 sno131.outbound.vz.bos2.lab systemd[1]: libpod-6b3d76de8ce60aa7cb9673e6e67e3bbbde7a9850295b8176bc46cd72ab458df8.scope: Deactivated successfully.
Jun 06 02:09:05 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Rendering CEO Manifests...
Jun 06 02:09:05 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-243437b9f6bce7aa3ef2c9a1b1965b56cd85bed034e83c43931db4ec0bb6c501-merged.mount: Deactivated successfully.
Jun 06 02:09:05 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-991a34072c06d6bea86dca5950e60497ce4020a84dc2b55b6e9883341fb600fc-userdata-shm.mount: Deactivated successfully.
Jun 06 02:09:06 sno131.outbound.vz.bos2.lab approve-csr.sh[7400]: E0606 02:09:06.958674    7400 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:06 sno131.outbound.vz.bos2.lab approve-csr.sh[7400]: E0606 02:09:06.958954    7400 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:06 sno131.outbound.vz.bos2.lab approve-csr.sh[7400]: E0606 02:09:06.960526    7400 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:06 sno131.outbound.vz.bos2.lab approve-csr.sh[7400]: E0606 02:09:06.962405    7400 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:06 sno131.outbound.vz.bos2.lab approve-csr.sh[7400]: E0606 02:09:06.963720    7400 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:06 sno131.outbound.vz.bos2.lab approve-csr.sh[7400]: The connection to the server localhost:6443 was refused - did you specify the right host or port?
Jun 06 02:09:07 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:11.172094    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:11.172903    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:11.172920    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:11.172928    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 98fe76509b7e12e41055e6a431668af1a71289f1183fd2b7569db0351b4e4009.
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996238       1 bootstrap_ip_linux.go:35] retrieved Address map map[0xc0009622a0:[10.88.0.1/16 cni-podman0 fe80::300b:12ff:fe25:7a9e/64] 0xc000809ad0:[127.0.0.1/8 lo ::1/128] 0xc000809c70:[192.168.14.27/27 ens1f0] 0xc000962380:[fe80::e434:33ff:fe49:4895/64]]
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996345       1 bootstrap_ip_linux.go:54] Ignoring route non Router advertisement route {Ifindex: 1 Dst: ::1/128 Src: <nil> Gw: <nil> Flags: [] Table: 254}
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996355       1 bootstrap_ip_linux.go:54] Ignoring route non Router advertisement route {Ifindex: 11 Dst: fe80::/64 Src: <nil> Gw: <nil> Flags: [] Table: 254}
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996359       1 bootstrap_ip_linux.go:54] Ignoring route non Router advertisement route {Ifindex: 12 Dst: fe80::/64 Src: <nil> Gw: <nil> Flags: [] Table: 254}
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996363       1 bootstrap_ip_linux.go:64] Retrieved route map map[]
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996378       1 bootstrap_ip.go:158] Filtered address 127.0.0.1/8 lo
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996382       1 bootstrap_ip.go:158] Filtered address ::1/128
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996389       1 bootstrap_ip.go:187] Checking whether address 192.168.14.27/27 ens1f0 contains VIP 192.168.14.27
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996394       1 bootstrap_ip.go:189] Address 192.168.14.27/27 ens1f0 contains VIP 192.168.14.27
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996399       1 bootstrap_ip.go:187] Checking whether address 192.168.14.27/27 ens1f0 contains VIP 10.88.0.1
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996403       1 bootstrap_ip.go:158] Filtered address 10.88.0.1/16 cni-podman0
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996406       1 bootstrap_ip.go:158] Filtered address fe80::300b:12ff:fe25:7a9e/64
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996409       1 bootstrap_ip.go:158] Filtered address fe80::e434:33ff:fe49:4895/64
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996412       1 bootstrap_ip.go:200] Found routable IPs [192.168.14.27]
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996415       1 render.go:414] using bootstrap IP 192.168.14.27
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: I0606 02:09:11.996425       1 render.go:597] Bootstrapping etcd using: "BootstrapInPlaceStrategy"
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: WARNING: Validity period of the certificate for "etcd-signer" is greater than 5 years!
Jun 06 02:09:11 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: WARNING: By security reasons it is strongly recommended to change this period and make it smaller!
Jun 06 02:09:12 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: WARNING: Validity period of the certificate for "etcd-metric-signer" is greater than 5 years!
Jun 06 02:09:12 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: WARNING: By security reasons it is strongly recommended to change this period and make it smaller!
Jun 06 02:09:12 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: Writing asset: /assets/etcd-bootstrap/manifests/etcd-signer-secret.yaml
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: Writing asset: /assets/etcd-bootstrap/manifests/openshift-etcd-svc.yaml
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: Writing asset: /assets/etcd-bootstrap/manifests/00_openshift-etcd-ns.yaml
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: Writing asset: /assets/etcd-bootstrap/manifests/etcd-client-secret.yaml
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: Writing asset: /assets/etcd-bootstrap/manifests/etcd-metric-client-secret.yaml
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: Writing asset: /assets/etcd-bootstrap/manifests/etcd-metric-signer-secret.yaml
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: Writing asset: /assets/etcd-bootstrap/manifests/etcd-serving-ca-configmap.yaml
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: Writing asset: /assets/etcd-bootstrap/manifests/00_etcd-endpoints-cm.yaml
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: Writing asset: /assets/etcd-bootstrap/manifests/etcd-ca-bundle-configmap.yaml
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: Writing asset: /assets/etcd-bootstrap/manifests/etcd-metric-serving-ca-configmap.yaml
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab bootkube.sh[9043]: Writing asset: /assets/etcd-bootstrap/etc-kubernetes/manifests/etcd-member-pod.yaml
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab systemd[1]: libpod-98fe76509b7e12e41055e6a431668af1a71289f1183fd2b7569db0351b4e4009.scope: Deactivated successfully.
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab systemd[1]: libpod-98fe76509b7e12e41055e6a431668af1a71289f1183fd2b7569db0351b4e4009.scope: Consumed 1.102s CPU time.
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-98fe76509b7e12e41055e6a431668af1a71289f1183fd2b7569db0351b4e4009-userdata-shm.mount: Deactivated successfully.
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-b5d0a5927d88ffbb857629876aa6d0cff95a0af3ad8b9fc84295053fd1abbf65-merged.mount: Deactivated successfully.
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.075530    7266 kubelet.go:2219] "SyncLoop ADD" source="file" pods="[openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab]"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.075553    7266 topology_manager.go:210] "Topology Admit Handler"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.075587    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.076318    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.076335    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.076341    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab systemd[1]: Created slice libcontainer container kubepods-burstable-podec8f40282bde3cfe7272900cd1fbf751.slice.
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.102903    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"certs\" (UniqueName: \"kubernetes.io/host-path/ec8f40282bde3cfe7272900cd1fbf751-certs\") pod \"etcd-bootstrap-member-sno131.outbound.vz.bos2.lab\" (UID: \"ec8f40282bde3cfe7272900cd1fbf751\") " pod="openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.102925    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"data-dir\" (UniqueName: \"kubernetes.io/host-path/ec8f40282bde3cfe7272900cd1fbf751-data-dir\") pod \"etcd-bootstrap-member-sno131.outbound.vz.bos2.lab\" (UID: \"ec8f40282bde3cfe7272900cd1fbf751\") " pod="openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.113902    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.114566    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.114581    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.114586    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Rendering cluster config manifests...
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.203669    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"certs\" (UniqueName: \"kubernetes.io/host-path/ec8f40282bde3cfe7272900cd1fbf751-certs\") pod \"etcd-bootstrap-member-sno131.outbound.vz.bos2.lab\" (UID: \"ec8f40282bde3cfe7272900cd1fbf751\") " pod="openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.203692    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"data-dir\" (UniqueName: \"kubernetes.io/host-path/ec8f40282bde3cfe7272900cd1fbf751-data-dir\") pod \"etcd-bootstrap-member-sno131.outbound.vz.bos2.lab\" (UID: \"ec8f40282bde3cfe7272900cd1fbf751\") " pod="openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.203724    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"data-dir\" (UniqueName: \"kubernetes.io/host-path/ec8f40282bde3cfe7272900cd1fbf751-data-dir\") pod \"etcd-bootstrap-member-sno131.outbound.vz.bos2.lab\" (UID: \"ec8f40282bde3cfe7272900cd1fbf751\") " pod="openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.203755    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"certs\" (UniqueName: \"kubernetes.io/host-path/ec8f40282bde3cfe7272900cd1fbf751-certs\") pod \"etcd-bootstrap-member-sno131.outbound.vz.bos2.lab\" (UID: \"ec8f40282bde3cfe7272900cd1fbf751\") " pod="openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:13.415487    7266 util.go:30] "No sandbox for pod can be found. Need to start a new one" pod="openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:13.416330765Z" level=info msg="Running pod sandbox: openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab/POD" id=bc6737ef-0658-465b-88b4-0739d35788ba name=/runtime.v1.RuntimeService/RunPodSandbox
Jun 06 02:09:13 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:13.416378379Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 2a06fcb159d1d8bc2187ea7bab9a4b02c0ee2cf48dbbf2ed2a357bd0de32c49e.
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:14.795303621Z" level=info msg="Ran pod sandbox a6a6b4c7a25b3682ed086883c31ecd3eccc53e7d114c1affa094cbb4b947f6d0 with infra container: openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab/POD" id=bc6737ef-0658-465b-88b4-0739d35788ba name=/runtime.v1.RuntimeService/RunPodSandbox
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:14.796330292Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cf6d1bd2361806194ed27dcae9da890e59977a8629144a4b2f4dbd497c7f80c9" id=31dd1aa9-01ef-4627-8b7e-5374b28b53bb name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:14.796443838Z" level=info msg="Image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cf6d1bd2361806194ed27dcae9da890e59977a8629144a4b2f4dbd497c7f80c9 not found" id=31dd1aa9-01ef-4627-8b7e-5374b28b53bb name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:14.796579    7266 provider.go:102] Refreshing cache for provider: *credentialprovider.defaultDockerConfigProvider
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:14.796642    7266 provider.go:82] Docker config file not found: couldn't find valid .dockercfg after checking in [/var/lib/kubelet   /]
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:14.796793718Z" level=info msg="Pulling image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cf6d1bd2361806194ed27dcae9da890e59977a8629144a4b2f4dbd497c7f80c9" id=21af62f5-10a0-48b1-ad4c-646a45a84d1d name=/runtime.v1.ImageService/PullImage
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:14.797964462Z" level=info msg="Trying to access \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cf6d1bd2361806194ed27dcae9da890e59977a8629144a4b2f4dbd497c7f80c9\""
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_project.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_apiserver-Default.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_authentication.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_03_security-openshift_01_scc.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_ingress.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_network.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_03_authorization-openshift_01_rolebindingrestriction.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_03_config-operator_01_proxy.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_console.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_image.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_imagecontentpolicy.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_imagedigestmirrorset.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_imagetagmirrorset.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_infrastructure-Default.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_03_quota-openshift_01_clusterresourcequota.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_build.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_node.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_scheduler.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_featuregate.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_imagecontentsourcepolicy.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_oauth.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_03_securityinternal-openshift_02_rangeallocation.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[9208]: Writing asset: /assets/config-bootstrap/manifests/0000_10_config-operator_01_dns.crd.yaml
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab systemd[1]: libpod-2a06fcb159d1d8bc2187ea7bab9a4b02c0ee2cf48dbbf2ed2a357bd0de32c49e.scope: Deactivated successfully.
Jun 06 02:09:14 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Rendering Kubernetes API server core manifests...
Jun 06 02:09:15 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:15.103682110Z" level=info msg="Trying to access \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cf6d1bd2361806194ed27dcae9da890e59977a8629144a4b2f4dbd497c7f80c9\""
Jun 06 02:09:15 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:15.243923    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab" event=&{ID:ec8f40282bde3cfe7272900cd1fbf751 Type:ContainerStarted Data:a6a6b4c7a25b3682ed086883c31ecd3eccc53e7d114c1affa094cbb4b947f6d0}
Jun 06 02:09:15 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-4e5cbae01c0c97f51a891f7b5f2e308e56d6cddbffc465ed27d7c5ef3ed7c30a-merged.mount: Deactivated successfully.
Jun 06 02:09:15 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-2a06fcb159d1d8bc2187ea7bab9a4b02c0ee2cf48dbbf2ed2a357bd0de32c49e-userdata-shm.mount: Deactivated successfully.
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.408071024Z" level=info msg="Pulled image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cf6d1bd2361806194ed27dcae9da890e59977a8629144a4b2f4dbd497c7f80c9" id=21af62f5-10a0-48b1-ad4c-646a45a84d1d name=/runtime.v1.ImageService/PullImage
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.408630645Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cf6d1bd2361806194ed27dcae9da890e59977a8629144a4b2f4dbd497c7f80c9" id=db7cc135-bef5-4eb5-8c6b-db75441e0b95 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.409413775Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:67c9b588397ec7dd1c00ab7baef963b86e278632d65740cb66f476a72f07cb55,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cf6d1bd2361806194ed27dcae9da890e59977a8629144a4b2f4dbd497c7f80c9],Size_:439810835,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=db7cc135-bef5-4eb5-8c6b-db75441e0b95 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.410302878Z" level=info msg="Creating container: openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab/etcdctl" id=81426460-93cb-477d-bd8d-647fdc6eb6a4 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.410366189Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.416392193Z" level=info msg="Container \"9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357\" is a burstable pod. Skip PreStart." id=81426460-93cb-477d-bd8d-647fdc6eb6a4 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container be7c9ceb320466b27975e71530ef8925b6146a3f36caf564b36f7f46d31e3588.
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab systemd[1]: Started crio-conmon-9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357.scope.
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357.
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.523996875Z" level=info msg="Created container 9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357: openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab/etcdctl" id=81426460-93cb-477d-bd8d-647fdc6eb6a4 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.524449361Z" level=info msg="Starting container: 9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357" id=be92be5a-886d-4c96-b217-785e2dc5f561 name=/runtime.v1.RuntimeService/StartContainer
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.530678269Z" level=info msg="Started container" PID=9435 containerID=9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357 description=openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab/etcdctl id=be92be5a-886d-4c96-b217-785e2dc5f561 name=/runtime.v1.RuntimeService/StartContainer sandboxID=a6a6b4c7a25b3682ed086883c31ecd3eccc53e7d114c1affa094cbb4b947f6d0
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.548775187Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cf6d1bd2361806194ed27dcae9da890e59977a8629144a4b2f4dbd497c7f80c9" id=c370a3a4-de9a-4e9e-a05d-5e6a24c7daee name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.549614164Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:67c9b588397ec7dd1c00ab7baef963b86e278632d65740cb66f476a72f07cb55,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cf6d1bd2361806194ed27dcae9da890e59977a8629144a4b2f4dbd497c7f80c9],Size_:439810835,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=c370a3a4-de9a-4e9e-a05d-5e6a24c7daee name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.549939095Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cf6d1bd2361806194ed27dcae9da890e59977a8629144a4b2f4dbd497c7f80c9" id=6ec8f8a6-addf-441e-bc20-df3884f67eb7 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.550674440Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:67c9b588397ec7dd1c00ab7baef963b86e278632d65740cb66f476a72f07cb55,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cf6d1bd2361806194ed27dcae9da890e59977a8629144a4b2f4dbd497c7f80c9],Size_:439810835,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=6ec8f8a6-addf-441e-bc20-df3884f67eb7 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.551259493Z" level=info msg="Creating container: openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab/etcd" id=e61b0fe2-590f-4efa-ba3b-f1d7c943ae9d name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.551317876Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.555801526Z" level=info msg="Container \"92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd\" is a burstable pod. Skip PreStart." id=e61b0fe2-590f-4efa-ba3b-f1d7c943ae9d name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab systemd[1]: Started crio-conmon-92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd.scope.
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd.
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.660153114Z" level=info msg="Created container 92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd: openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab/etcd" id=e61b0fe2-590f-4efa-ba3b-f1d7c943ae9d name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.660600117Z" level=info msg="Starting container: 92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd" id=f4dc4771-dea1-477b-b40d-ba4a86a89268 name=/runtime.v1.RuntimeService/StartContainer
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:17.666727326Z" level=info msg="Started container" PID=9483 containerID=92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd description=openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab/etcd id=f4dc4771-dea1-477b-b40d-ba4a86a89268 name=/runtime.v1.RuntimeService/StartContainer sandboxID=a6a6b4c7a25b3682ed086883c31ecd3eccc53e7d114c1affa094cbb4b947f6d0
Jun 06 02:09:17 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/bootstrap-manifests/kube-apiserver-pod.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_scc-hostnetwork.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_scc-nonroot-v2.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/apiserver.openshift.io_apirequestcount.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_cr-scc-anyuid.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_cr-scc-restricted.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_scc-restricted-v2.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/00_openshift-kube-apiserver-ns.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/secret-localhost-serving-signer.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_scc-anyuid.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/configmap-admin-kubeconfig-client-ca.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/secret-bound-sa-token-signing-key.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_cr-scc-hostnetwork-v2.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_cr-scc-restricted-v2.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_crb-systemauthenticated-scc-restricted-v2.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_scc-privileged.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_scc-restricted.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/secret-control-plane-client-signer.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/secret-kube-apiserver-to-kubelet-signer.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_cr-scc-hostaccess.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_cr-scc-nonroot.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/00_openshift-kube-apiserver-operator-ns.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/configmap-sa-token-signing-certs.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/secret-aggregator-client-signer.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/secret-service-network-serving-signer.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_cr-scc-nonroot-v2.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/cluster-role-kube-apiserver.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/configmap-csr-controller-ca.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/configmap-kubelet-bootstrap-kubeconfig-ca.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/secret-loadbalancer-serving-signer.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_cr-scc-hostnetwork.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_cr-scc-privileged.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/cluster-role-binding-kube-apiserver.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_cr-scc-hostmount-anyuid.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_scc-hostaccess.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_scc-hostmount-anyuid.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_scc-hostnetwork-v2.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[9345]: Writing asset: /assets/kube-apiserver-bootstrap/manifests/0000_20_kube-apiserver-operator_00_scc-nonroot.yaml
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab systemd[1]: libpod-be7c9ceb320466b27975e71530ef8925b6146a3f36caf564b36f7f46d31e3588.scope: Deactivated successfully.
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:18.249716    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab" event=&{ID:ec8f40282bde3cfe7272900cd1fbf751 Type:ContainerStarted Data:92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd}
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:18.249734    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab" event=&{ID:ec8f40282bde3cfe7272900cd1fbf751 Type:ContainerStarted Data:9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357}
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:18.249842    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:18.250733    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:18.250750    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:18.250756    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Rendering Kubernetes Controller Manager core manifests...
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-8b62056b46c0bbc81d3a48af1f460610ba6f65096402ef13053fd28b3c711ead-merged.mount: Deactivated successfully.
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-be7c9ceb320466b27975e71530ef8925b6146a3f36caf564b36f7f46d31e3588-userdata-shm.mount: Deactivated successfully.
Jun 06 02:09:18 sno131.outbound.vz.bos2.lab chronyd[2259]: Selected source 65.100.46.166 (2.rhel.pool.ntp.org)
Jun 06 02:09:19 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:19.251955    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:19 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:19.252818    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:19 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:19.252836    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:19 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:19.252843    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:20 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container aa4dbfb201b9fffb8d17fbb0e56d20d26cabaf7aceec89505bc5bd5eb89aae8a.
Jun 06 02:09:20 sno131.outbound.vz.bos2.lab bootkube.sh[9573]: Writing asset: /assets/kube-controller-manager-bootstrap/bootstrap-manifests/kube-controller-manager-pod.yaml
Jun 06 02:09:20 sno131.outbound.vz.bos2.lab bootkube.sh[9573]: Writing asset: /assets/kube-controller-manager-bootstrap/manifests/secret-csr-signer-signer.yaml
Jun 06 02:09:20 sno131.outbound.vz.bos2.lab bootkube.sh[9573]: Writing asset: /assets/kube-controller-manager-bootstrap/manifests/0000_00_namespace-openshift-infra.yaml
Jun 06 02:09:20 sno131.outbound.vz.bos2.lab bootkube.sh[9573]: Writing asset: /assets/kube-controller-manager-bootstrap/manifests/00_openshift-kube-controller-manager-ns.yaml
Jun 06 02:09:20 sno131.outbound.vz.bos2.lab bootkube.sh[9573]: Writing asset: /assets/kube-controller-manager-bootstrap/manifests/00_openshift-kube-controller-manager-operator-ns.yaml
Jun 06 02:09:20 sno131.outbound.vz.bos2.lab bootkube.sh[9573]: Writing asset: /assets/kube-controller-manager-bootstrap/manifests/00_podsecurity-admission-label-syncer-controller-clusterrole.yaml
Jun 06 02:09:20 sno131.outbound.vz.bos2.lab bootkube.sh[9573]: Writing asset: /assets/kube-controller-manager-bootstrap/manifests/00_podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml
Jun 06 02:09:20 sno131.outbound.vz.bos2.lab bootkube.sh[9573]: Writing asset: /assets/kube-controller-manager-bootstrap/manifests/00_namespace-security-allocation-controller-clusterrole.yaml
Jun 06 02:09:20 sno131.outbound.vz.bos2.lab bootkube.sh[9573]: Writing asset: /assets/kube-controller-manager-bootstrap/manifests/00_namespace-security-allocation-controller-clusterrolebinding.yaml
Jun 06 02:09:20 sno131.outbound.vz.bos2.lab bootkube.sh[9573]: Writing asset: /assets/kube-controller-manager-bootstrap/manifests/secret-initial-kube-controller-manager-service-account-private-key.yaml
Jun 06 02:09:20 sno131.outbound.vz.bos2.lab systemd[1]: libpod-aa4dbfb201b9fffb8d17fbb0e56d20d26cabaf7aceec89505bc5bd5eb89aae8a.scope: Deactivated successfully.
Jun 06 02:09:20 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-aa4dbfb201b9fffb8d17fbb0e56d20d26cabaf7aceec89505bc5bd5eb89aae8a-userdata-shm.mount: Deactivated successfully.
Jun 06 02:09:20 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-f42a8a2b5fc56b46ad95abe6aadcf01ab2db09c820a81d2b4add19dd31e24ebb-merged.mount: Deactivated successfully.
Jun 06 02:09:20 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Rendering Kubernetes Scheduler core manifests...
Jun 06 02:09:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:21.178068    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:21.178846    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:21.178865    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:21.178876    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:22 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:09:22 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 624e5ffa2e439cf5c2458a95c0f6074dac0d099b0e6d7b0c345bd79a6c41f65f.
Jun 06 02:09:23 sno131.outbound.vz.bos2.lab bootkube.sh[9703]: Writing asset: /assets/kube-scheduler-bootstrap/bootstrap-manifests/kube-scheduler-pod.yaml
Jun 06 02:09:23 sno131.outbound.vz.bos2.lab bootkube.sh[9703]: Writing asset: /assets/kube-scheduler-bootstrap/manifests/00_openshift-kube-scheduler-ns.yaml
Jun 06 02:09:23 sno131.outbound.vz.bos2.lab systemd[1]: libpod-624e5ffa2e439cf5c2458a95c0f6074dac0d099b0e6d7b0c345bd79a6c41f65f.scope: Deactivated successfully.
Jun 06 02:09:23 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-624e5ffa2e439cf5c2458a95c0f6074dac0d099b0e6d7b0c345bd79a6c41f65f-userdata-shm.mount: Deactivated successfully.
Jun 06 02:09:23 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-acd6b00ae9653f408f19c3bc60b46464fc03b85856a66a4e0191246c5b33a819-merged.mount: Deactivated successfully.
Jun 06 02:09:23 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Rendering Ingress Operator core manifests...
Jun 06 02:09:24 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container d2dd28eea582a636d2b32312d4851f2b18ea7daddc815571b7f35af642ff5818.
Jun 06 02:09:24 sno131.outbound.vz.bos2.lab bootkube.sh[9831]: wrote /assets/ingress-operator-manifests/cluster-ingress-00-custom-resource-definition.yaml
Jun 06 02:09:24 sno131.outbound.vz.bos2.lab bootkube.sh[9831]: wrote /assets/ingress-operator-manifests/cluster-ingress-00-namespace.yaml
Jun 06 02:09:24 sno131.outbound.vz.bos2.lab systemd[1]: libpod-d2dd28eea582a636d2b32312d4851f2b18ea7daddc815571b7f35af642ff5818.scope: Deactivated successfully.
Jun 06 02:09:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-d2dd28eea582a636d2b32312d4851f2b18ea7daddc815571b7f35af642ff5818-userdata-shm.mount: Deactivated successfully.
Jun 06 02:09:24 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-6a87357b6b03709557cdb51738d19d995a2e5f7cb5ada218364303b88a1bd565-merged.mount: Deactivated successfully.
Jun 06 02:09:25 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Rendering Node Tuning core manifests...
Jun 06 02:09:27 sno131.outbound.vz.bos2.lab approve-csr.sh[9986]: E0606 02:09:27.014656    9986 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:27 sno131.outbound.vz.bos2.lab approve-csr.sh[9986]: E0606 02:09:27.014933    9986 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:27 sno131.outbound.vz.bos2.lab approve-csr.sh[9986]: E0606 02:09:27.016733    9986 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:27 sno131.outbound.vz.bos2.lab approve-csr.sh[9986]: E0606 02:09:27.018656    9986 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:27 sno131.outbound.vz.bos2.lab approve-csr.sh[9986]: E0606 02:09:27.020540    9986 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:27 sno131.outbound.vz.bos2.lab approve-csr.sh[9986]: The connection to the server localhost:6443 was refused - did you specify the right host or port?
Jun 06 02:09:27 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:09:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:31.189933    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:31.190593    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:31.190609    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:31.190614    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:32 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 0cd5dcd32d45f2ed0af7fb38bf6df4a349cc8cc15dec51c4c5e0310a9ad0ad8a.
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.166088       1 render.go:71] Rendering files into: /assets/node-tuning-bootstrap
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.203884       1 render.go:128] skipping "/assets/manifests/01-container-mount-ns-and-kubelet-conf-master-0.yaml" [1] manifest because of unhandled *v1.MachineConfig
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.204275       1 render.go:128] skipping "/assets/manifests/02-master-workload-partitioning-0.yaml" [1] manifest because of unhandled *v1.MachineConfig
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.205117       1 render.go:128] skipping "/assets/manifests/04-accelerated-container-startup-master-0.yaml" [1] manifest because of unhandled *v1.MachineConfig
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.205580       1 render.go:128] skipping "/assets/manifests/05-kdump-config-master-0.yaml" [1] manifest because of unhandled *v1.MachineConfig
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.205960       1 render.go:128] skipping "/assets/manifests/06-kdump-master-0.yaml" [1] manifest because of unhandled *v1.MachineConfig
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.206226       1 render.go:128] skipping "/assets/manifests/50-masters-chrony-configuration.yaml" [1] manifest because of unhandled *v1.MachineConfig
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.206702       1 render.go:128] skipping "/assets/manifests/50-workers-chrony-configuration.yaml" [1] manifest because of unhandled *v1.MachineConfig
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.207037       1 render.go:128] skipping "/assets/manifests/99-crio-disable-wipe-master-0.yaml" [1] manifest because of unhandled *v1.MachineConfig
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.208507       1 render.go:128] skipping "/assets/manifests/99_openshift-machineconfig_99-master-ssh.yaml" [1] manifest because of unhandled *v1.MachineConfig
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.208784       1 render.go:128] skipping "/assets/manifests/99_openshift-machineconfig_99-worker-ssh.yaml" [1] manifest because of unhandled *v1.MachineConfig
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.212184       1 render.go:128] skipping "/assets/manifests/cluster-dns-02-config.yml" [1] manifest because of unhandled *v1.DNS
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.218249       1 render.go:128] skipping "/assets/manifests/cluster-ingress-02-config.yml" [1] manifest because of unhandled *v1.Ingress
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.218939       1 render.go:128] skipping "/assets/manifests/cluster-network-02-config.yml" [1] manifest because of unhandled *v1.Network
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.219016       1 render.go:128] skipping "/assets/manifests/cluster-proxy-01-config.yaml" [1] manifest because of unhandled *v1.Proxy
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.219719       1 render.go:128] skipping "/assets/manifests/cluster-scheduler-02-config.yml" [1] manifest because of unhandled *v1.Scheduler
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.221692       1 render.go:128] skipping "/assets/manifests/cvo-overrides.yaml" [1] manifest because of unhandled *v1.ClusterVersion
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.222165       1 render.go:128] skipping "/assets/manifests/dnsmasq-bootstrap-in-place.yaml" [1] manifest because of unhandled *v1.MachineConfig
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.234617       1 render.go:128] skipping "/assets/manifests/node-ip-hint-master.yaml" [1] manifest because of unhandled *v1.MachineConfig
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: I0606 02:09:34.234816       1 render.go:128] skipping "/assets/manifests/node-ip-hint-worker.yaml" [1] manifest because of unhandled *v1.MachineConfig
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[9959]: W0606 02:09:34.237334       1 render.go:134] zero performance profiles were found
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab systemd[1]: libpod-0cd5dcd32d45f2ed0af7fb38bf6df4a349cc8cc15dec51c4c5e0310a9ad0ad8a.scope: Deactivated successfully.
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-0cd5dcd32d45f2ed0af7fb38bf6df4a349cc8cc15dec51c4c5e0310a9ad0ad8a-userdata-shm.mount: Deactivated successfully.
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-8d3ab3ef7fa7e6eb86213dfb7c48ec45ebb5743b17f84ba9793778f6a57f15ab-merged.mount: Deactivated successfully.
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Rendering MCO manifests...
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container bdeca9bc1cd2c173b2085ef059ece28f1bce734aa043e5c80daac2230b527d71.
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab systemd[1]: libpod-bdeca9bc1cd2c173b2085ef059ece28f1bce734aa043e5c80daac2230b527d71.scope: Deactivated successfully.
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container ecbccbae941ec9b8b716d9c429b756fc186abd8d0fd8a13d9e08510dcff6d71e.
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[10216]: I0606 02:09:34.626497       1 bootstrap.go:115] Version: v4.13.0-202305262054.p0.g5c5a902.assembly.stream-dirty (5c5a902aeb55c02b5abda80f90fae264a2d5ad69)
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[10216]: I0606 02:09:34.630245       1 bootstrap.go:189] manifests/machineconfigcontroller/controllerconfig.yaml
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[10216]: I0606 02:09:34.631402       1 bootstrap.go:189] manifests/master.machineconfigpool.yaml
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[10216]: I0606 02:09:34.631448       1 bootstrap.go:189] manifests/worker.machineconfigpool.yaml
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[10216]: I0606 02:09:34.631482       1 bootstrap.go:189] manifests/bootstrap-pod-v2.yaml
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[10216]: I0606 02:09:34.631607       1 bootstrap.go:189] manifests/machineconfigserver/csr-bootstrap-role-binding.yaml
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[10216]: I0606 02:09:34.631651       1 bootstrap.go:189] manifests/machineconfigserver/kube-apiserver-serving-ca-configmap.yaml
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab systemd[1]: libpod-ecbccbae941ec9b8b716d9c429b756fc186abd8d0fd8a13d9e08510dcff6d71e.scope: Deactivated successfully.
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.679730    7266 kubelet.go:2219] "SyncLoop ADD" source="file" pods="[default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab]"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.679754    7266 topology_manager.go:210] "Topology Admit Handler"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.679786    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.680863    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.680882    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.680894    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab systemd[1]: Created slice libcontainer container kubepods-burstable-pod070c3b17cea2a10b725491c11e825998.slice.
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.698639    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.700829    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.700844    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.700850    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Check if API and API-Int URLs are resolvable during bootstrap
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Checking if api.sno131.outbound.vz.bos2.lab of type API_URL is resolvable
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Starting stage resolve-api-url
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Successfully resolved API_URL api.sno131.outbound.vz.bos2.lab
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Checking if api-int.sno131.outbound.vz.bos2.lab of type API_INT_URL is resolvable
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Starting stage resolve-api-int-url
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Successfully resolved API_INT_URL api-int.sno131.outbound.vz.bos2.lab
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Rendering CCO manifests...
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.878565    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"server-certs\" (UniqueName: \"kubernetes.io/host-path/070c3b17cea2a10b725491c11e825998-server-certs\") pod \"bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab\" (UID: \"070c3b17cea2a10b725491c11e825998\") " pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.878593    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"bootstrap-kubeconfig\" (UniqueName: \"kubernetes.io/host-path/070c3b17cea2a10b725491c11e825998-bootstrap-kubeconfig\") pod \"bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab\" (UID: \"070c3b17cea2a10b725491c11e825998\") " pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.878614    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"server-basedir\" (UniqueName: \"kubernetes.io/host-path/070c3b17cea2a10b725491c11e825998-server-basedir\") pod \"bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab\" (UID: \"070c3b17cea2a10b725491c11e825998\") " pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.878628    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"bootstrap-manifests\" (UniqueName: \"kubernetes.io/host-path/070c3b17cea2a10b725491c11e825998-bootstrap-manifests\") pod \"bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab\" (UID: \"070c3b17cea2a10b725491c11e825998\") " pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.978888    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"server-certs\" (UniqueName: \"kubernetes.io/host-path/070c3b17cea2a10b725491c11e825998-server-certs\") pod \"bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab\" (UID: \"070c3b17cea2a10b725491c11e825998\") " pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.978911    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"bootstrap-kubeconfig\" (UniqueName: \"kubernetes.io/host-path/070c3b17cea2a10b725491c11e825998-bootstrap-kubeconfig\") pod \"bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab\" (UID: \"070c3b17cea2a10b725491c11e825998\") " pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.978927    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"server-basedir\" (UniqueName: \"kubernetes.io/host-path/070c3b17cea2a10b725491c11e825998-server-basedir\") pod \"bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab\" (UID: \"070c3b17cea2a10b725491c11e825998\") " pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.978941    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"bootstrap-manifests\" (UniqueName: \"kubernetes.io/host-path/070c3b17cea2a10b725491c11e825998-bootstrap-manifests\") pod \"bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab\" (UID: \"070c3b17cea2a10b725491c11e825998\") " pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.978977    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"bootstrap-manifests\" (UniqueName: \"kubernetes.io/host-path/070c3b17cea2a10b725491c11e825998-bootstrap-manifests\") pod \"bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab\" (UID: \"070c3b17cea2a10b725491c11e825998\") " pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.978995    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"server-certs\" (UniqueName: \"kubernetes.io/host-path/070c3b17cea2a10b725491c11e825998-server-certs\") pod \"bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab\" (UID: \"070c3b17cea2a10b725491c11e825998\") " pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.979018    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"server-basedir\" (UniqueName: \"kubernetes.io/host-path/070c3b17cea2a10b725491c11e825998-server-basedir\") pod \"bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab\" (UID: \"070c3b17cea2a10b725491c11e825998\") " pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:34 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:34.979002    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"bootstrap-kubeconfig\" (UniqueName: \"kubernetes.io/host-path/070c3b17cea2a10b725491c11e825998-bootstrap-kubeconfig\") pod \"bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab\" (UID: \"070c3b17cea2a10b725491c11e825998\") " pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:35.001327    7266 util.go:30] "No sandbox for pod can be found. Need to start a new one" pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:35.002022939Z" level=info msg="Running pod sandbox: default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab/POD" id=a47df600-811c-4f89-9322-76507e717d7e name=/runtime.v1.RuntimeService/RunPodSandbox
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:35.002067707Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:35.006224786Z" level=info msg="Ran pod sandbox f2820e5707a18f4ef617ae3772b978eee02370d83a76f69ec104a3ce00390d50 with infra container: default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab/POD" id=a47df600-811c-4f89-9322-76507e717d7e name=/runtime.v1.RuntimeService/RunPodSandbox
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:35.007045149Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96" id=86feea51-4fcf-431a-b4cc-2198eb46bd04 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:35.007148304Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:599e0f50ede7330e7228ff67c93c8d8a119e36bd31081bebf37bcd4d88bdd45c,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96],Size_:590080480,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=86feea51-4fcf-431a-b4cc-2198eb46bd04 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:35.007571946Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96" id=f9534740-7ef4-4fb8-b9ed-4f7507d1d853 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:35.007681996Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:599e0f50ede7330e7228ff67c93c8d8a119e36bd31081bebf37bcd4d88bdd45c,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96],Size_:590080480,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=f9534740-7ef4-4fb8-b9ed-4f7507d1d853 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:35.008224104Z" level=info msg="Creating container: default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab/machine-config-controller" id=97caf7ce-29f1-409e-a888-a1214201cbbc name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:35.008274996Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:35.012117519Z" level=info msg="Container \"e820d14bc6b4208effb94a359e5ce33ba0698e508092c6f7d7647ac01bf8de13\" is a burstable pod. Skip PreStart." id=97caf7ce-29f1-409e-a888-a1214201cbbc name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab systemd[1]: Started crio-conmon-e820d14bc6b4208effb94a359e5ce33ba0698e508092c6f7d7647ac01bf8de13.scope.
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container e820d14bc6b4208effb94a359e5ce33ba0698e508092c6f7d7647ac01bf8de13.
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:35.122671935Z" level=info msg="Created container e820d14bc6b4208effb94a359e5ce33ba0698e508092c6f7d7647ac01bf8de13: default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab/machine-config-controller" id=97caf7ce-29f1-409e-a888-a1214201cbbc name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:35.123002006Z" level=info msg="Starting container: e820d14bc6b4208effb94a359e5ce33ba0698e508092c6f7d7647ac01bf8de13" id=75fa576d-b52b-4582-bdcc-8d37d6b54377 name=/runtime.v1.RuntimeService/StartContainer
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:35.140251481Z" level=info msg="Started container" PID=10394 containerID=e820d14bc6b4208effb94a359e5ce33ba0698e508092c6f7d7647ac01bf8de13 description=default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab/machine-config-controller id=75fa576d-b52b-4582-bdcc-8d37d6b54377 name=/runtime.v1.RuntimeService/StartContainer sandboxID=f2820e5707a18f4ef617ae3772b978eee02370d83a76f69ec104a3ce00390d50
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:35.275976    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab" event=&{ID:070c3b17cea2a10b725491c11e825998 Type:ContainerStarted Data:e820d14bc6b4208effb94a359e5ce33ba0698e508092c6f7d7647ac01bf8de13}
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:35.275995    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab" event=&{ID:070c3b17cea2a10b725491c11e825998 Type:ContainerStarted Data:f2820e5707a18f4ef617ae3772b978eee02370d83a76f69ec104a3ce00390d50}
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:35.276105    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:35.276953    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:35.276969    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:35.276975    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab systemd[1]: crio-e820d14bc6b4208effb94a359e5ce33ba0698e508092c6f7d7647ac01bf8de13.scope: Deactivated successfully.
Jun 06 02:09:35 sno131.outbound.vz.bos2.lab systemd[1]: crio-conmon-e820d14bc6b4208effb94a359e5ce33ba0698e508092c6f7d7647ac01bf8de13.scope: Deactivated successfully.
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:36.278728    7266 generic.go:332] "Generic (PLEG): container finished" podID=070c3b17cea2a10b725491c11e825998 containerID="e820d14bc6b4208effb94a359e5ce33ba0698e508092c6f7d7647ac01bf8de13" exitCode=0
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:36.278754    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab" event=&{ID:070c3b17cea2a10b725491c11e825998 Type:ContainerDied Data:e820d14bc6b4208effb94a359e5ce33ba0698e508092c6f7d7647ac01bf8de13}
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:36.278850    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:36.279571    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:36.279587    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:36.279604    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:36.279849199Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96" id=02c08290-f9ad-4d8e-8988-63ac65603bf7 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:36.279992104Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:599e0f50ede7330e7228ff67c93c8d8a119e36bd31081bebf37bcd4d88bdd45c,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96],Size_:590080480,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=02c08290-f9ad-4d8e-8988-63ac65603bf7 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:36.280273250Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96" id=7ed2c350-198e-432a-aa42-c53c6e44823c name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:36.280409516Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:599e0f50ede7330e7228ff67c93c8d8a119e36bd31081bebf37bcd4d88bdd45c,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1096df81ff95963af03e309e0bd3fb2316e42094c539950d73f7dd8d7044fc96],Size_:590080480,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=7ed2c350-198e-432a-aa42-c53c6e44823c name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:36.280732293Z" level=info msg="Creating container: default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab/machine-config-server" id=18f51a14-02fa-4a8e-8a59-96215c80e644 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:36.280798819Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:36.285997713Z" level=info msg="Container \"ea02af4e20c2bc5d42b48b0343b09e9197b6bd6d6eb9260f3171b5650f6a9982\" is a burstable pod. Skip PreStart." id=18f51a14-02fa-4a8e-8a59-96215c80e644 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab systemd[1]: Started crio-conmon-ea02af4e20c2bc5d42b48b0343b09e9197b6bd6d6eb9260f3171b5650f6a9982.scope.
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container ea02af4e20c2bc5d42b48b0343b09e9197b6bd6d6eb9260f3171b5650f6a9982.
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:36.403975473Z" level=info msg="Created container ea02af4e20c2bc5d42b48b0343b09e9197b6bd6d6eb9260f3171b5650f6a9982: default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab/machine-config-server" id=18f51a14-02fa-4a8e-8a59-96215c80e644 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:36.404445423Z" level=info msg="Starting container: ea02af4e20c2bc5d42b48b0343b09e9197b6bd6d6eb9260f3171b5650f6a9982" id=1482dff3-3f5f-4309-b043-707b49ae88cc name=/runtime.v1.RuntimeService/StartContainer
Jun 06 02:09:36 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:36.422173690Z" level=info msg="Started container" PID=10456 containerID=ea02af4e20c2bc5d42b48b0343b09e9197b6bd6d6eb9260f3171b5650f6a9982 description=default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab/machine-config-server id=1482dff3-3f5f-4309-b043-707b49ae88cc name=/runtime.v1.RuntimeService/StartContainer sandboxID=f2820e5707a18f4ef617ae3772b978eee02370d83a76f69ec104a3ce00390d50
Jun 06 02:09:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:37.281937    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab" event=&{ID:070c3b17cea2a10b725491c11e825998 Type:ContainerStarted Data:ea02af4e20c2bc5d42b48b0343b09e9197b6bd6d6eb9260f3171b5650f6a9982}
Jun 06 02:09:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:37.282045    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:37.282862    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:37.282878    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:37.282884    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:37 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:09:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:38.283811    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:38.286102    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:38.286119    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:38.286126    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:39 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container f1e01a088a0edaeb42f3cc4f8ee6cf9cfd855e73ff63c524df4ba0004f7fbdbc.
Jun 06 02:09:39 sno131.outbound.vz.bos2.lab bootkube.sh[10356]: time="2023-06-06T02:09:39Z" level=info msg="Rendering files to /assets/cco-bootstrap"
Jun 06 02:09:39 sno131.outbound.vz.bos2.lab bootkube.sh[10356]: time="2023-06-06T02:09:39Z" level=info msg="Writing file: /assets/cco-bootstrap/manifests/cco-cloudcredential_v1_operator_config_custresdef.yaml"
Jun 06 02:09:39 sno131.outbound.vz.bos2.lab bootkube.sh[10356]: time="2023-06-06T02:09:39Z" level=info msg="Writing file: /assets/cco-bootstrap/manifests/cco-cloudcredential_v1_credentialsrequest_crd.yaml"
Jun 06 02:09:39 sno131.outbound.vz.bos2.lab bootkube.sh[10356]: time="2023-06-06T02:09:39Z" level=info msg="Writing file: /assets/cco-bootstrap/manifests/cco-namespace.yaml"
Jun 06 02:09:39 sno131.outbound.vz.bos2.lab bootkube.sh[10356]: time="2023-06-06T02:09:39Z" level=info msg="Writing file: /assets/cco-bootstrap/manifests/cco-operator-config.yaml"
Jun 06 02:09:39 sno131.outbound.vz.bos2.lab bootkube.sh[10356]: time="2023-06-06T02:09:39Z" level=info msg="Rendering static pod"
Jun 06 02:09:39 sno131.outbound.vz.bos2.lab bootkube.sh[10356]: time="2023-06-06T02:09:39Z" level=info msg="writing file: /assets/cco-bootstrap/bootstrap-manifests/cloud-credential-operator-pod.yaml"
Jun 06 02:09:39 sno131.outbound.vz.bos2.lab systemd[1]: libpod-f1e01a088a0edaeb42f3cc4f8ee6cf9cfd855e73ff63c524df4ba0004f7fbdbc.scope: Deactivated successfully.
Jun 06 02:09:39 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-f1e01a088a0edaeb42f3cc4f8ee6cf9cfd855e73ff63c524df4ba0004f7fbdbc-userdata-shm.mount: Deactivated successfully.
Jun 06 02:09:39 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-29e12ce41cd0311521dcb0635813c0f87fc383b5e56f0e3a65046e8e00b5e099-merged.mount: Deactivated successfully.
Jun 06 02:09:39 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container af89e77665673b5fb965a725d54fa44e16cf359e8f6801009f2a2bfd375b1773.
Jun 06 02:09:39 sno131.outbound.vz.bos2.lab bootkube.sh[10606]: https://localhost:2379 is healthy: successfully committed proposal: took = 6.08246ms
Jun 06 02:09:39 sno131.outbound.vz.bos2.lab systemd[1]: libpod-af89e77665673b5fb965a725d54fa44e16cf359e8f6801009f2a2bfd375b1773.scope: Deactivated successfully.
Jun 06 02:09:39 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Starting cluster-bootstrap...
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.196367    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.197589    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.197604    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.197610    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: E0606 02:09:41.510680    7266 file.go:109] "Unable to process watch event" err="can't process config file \"/etc/kubernetes/manifests\": read /etc/kubernetes/manifests: is a directory"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 82f70280578565865ed2e407b334a7cfc18496689d4a510108e44d1062430b27.
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Starting temporary bootstrap control plane...
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Waiting up to 20m0s for the Kubernetes API
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.595974    7266 kubelet.go:2219] "SyncLoop ADD" source="file" pods="[openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab]"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.595998    7266 topology_manager.go:210] "Topology Admit Handler"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.596025    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.597018    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.597034    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.597042    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.597093    7266 kubelet.go:2219] "SyncLoop ADD" source="file" pods="[openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab]"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.597103    7266 topology_manager.go:210] "Topology Admit Handler"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.597122    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.597671    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.597683    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.597687    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.597727    7266 kubelet.go:2219] "SyncLoop ADD" source="file" pods="[openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab]"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.597735    7266 topology_manager.go:210] "Topology Admit Handler"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.597772    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.598387    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.598397    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.598402    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.599175    7266 kubelet.go:2219] "SyncLoop ADD" source="file" pods="[kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab]"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.599190    7266 topology_manager.go:210] "Topology Admit Handler"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.599222    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.599692    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.599705    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.599711    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.600186    7266 kubelet.go:2219] "SyncLoop ADD" source="file" pods="[kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab]"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.600197    7266 topology_manager.go:210] "Topology Admit Handler"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.600219    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.600746    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.600755    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.600761    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab systemd[1]: Created slice libcontainer container kubepods-besteffort-pod64a8f6eb7c6e0cf4f9d62c71924bd30a.slice.
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.643961    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.644740    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.644753    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.644759    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab systemd[1]: Created slice libcontainer container kubepods-besteffort-pod8d6c6c46375623d290ed5865fa13e701.slice.
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.649543    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.651723    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.651752    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.651760    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab systemd[1]: Created slice libcontainer container kubepods-burstable-pod25c1466359fc8946267f656756984e2d.slice.
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.679055    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.681175    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.681186    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.681191    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab systemd[1]: Created slice libcontainer container kubepods-burstable-pod082e8bbce893a060432eb17e10fe12e8.slice.
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.683604    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.685751    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.685764    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.685769    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab systemd[1]: Created slice libcontainer container kubepods-burstable-pod19832dab34653130be3733c41dfa1508.slice.
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.687639    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.689799    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.689812    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.689817    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704166    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"audit-dir\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-audit-dir\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704189    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-config\") pod \"bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") " pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704203    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"logs\" (UniqueName: \"kubernetes.io/host-path/19832dab34653130be3733c41dfa1508-logs\") pod \"bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab\" (UID: \"19832dab34653130be3733c41dfa1508\") " pod="kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704219    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ssl-certs\" (UniqueName: \"kubernetes.io/host-path/64a8f6eb7c6e0cf4f9d62c71924bd30a-etc-ssl-certs\") pod \"bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab\" (UID: \"64a8f6eb7c6e0cf4f9d62c71924bd30a\") " pod="openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704253    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-secrets\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704287    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"logs\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-logs\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704310    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ssl-certs-host\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-ssl-certs-host\") pod \"bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") " pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704337    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"logs\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-logs\") pod \"bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") " pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704356    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/19832dab34653130be3733c41dfa1508-secrets\") pod \"bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab\" (UID: \"19832dab34653130be3733c41dfa1508\") " pod="kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704376    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/64a8f6eb7c6e0cf4f9d62c71924bd30a-kubeconfig\") pod \"bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab\" (UID: \"64a8f6eb7c6e0cf4f9d62c71924bd30a\") " pod="openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704394    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-config\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704415    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-kubernetes-cloud\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-etc-kubernetes-cloud\") pod \"bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") " pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704429    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-secrets\") pod \"bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") " pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704470    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/8d6c6c46375623d290ed5865fa13e701-secrets\") pod \"cloud-credential-operator-sno131.outbound.vz.bos2.lab\" (UID: \"8d6c6c46375623d290ed5865fa13e701\") " pod="openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704498    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-kubernetes-cloud\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-etc-kubernetes-cloud\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.704511    7266 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ssl-certs-host\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-ssl-certs-host\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.804909    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-secrets\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.804873    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-secrets\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.804960    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"logs\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-logs\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.804975    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"audit-dir\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-audit-dir\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.804988    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"config\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-config\") pod \"bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") " pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805003    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"logs\" (UniqueName: \"kubernetes.io/host-path/19832dab34653130be3733c41dfa1508-logs\") pod \"bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab\" (UID: \"19832dab34653130be3733c41dfa1508\") " pod="kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805016    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"etc-ssl-certs\" (UniqueName: \"kubernetes.io/host-path/64a8f6eb7c6e0cf4f9d62c71924bd30a-etc-ssl-certs\") pod \"bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab\" (UID: \"64a8f6eb7c6e0cf4f9d62c71924bd30a\") " pod="openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805030    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"ssl-certs-host\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-ssl-certs-host\") pod \"bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") " pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805044    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"logs\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-logs\") pod \"bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") " pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805057    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/19832dab34653130be3733c41dfa1508-secrets\") pod \"bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab\" (UID: \"19832dab34653130be3733c41dfa1508\") " pod="kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805071    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/64a8f6eb7c6e0cf4f9d62c71924bd30a-kubeconfig\") pod \"bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab\" (UID: \"64a8f6eb7c6e0cf4f9d62c71924bd30a\") " pod="openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805086    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"config\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-config\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805100    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"etc-kubernetes-cloud\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-etc-kubernetes-cloud\") pod \"bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") " pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805105    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"logs\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-logs\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805114    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"etc-kubernetes-cloud\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-etc-kubernetes-cloud\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805136    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"ssl-certs-host\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-ssl-certs-host\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805151    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-secrets\") pod \"bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") " pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805154    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"logs\" (UniqueName: \"kubernetes.io/host-path/19832dab34653130be3733c41dfa1508-logs\") pod \"bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab\" (UID: \"19832dab34653130be3733c41dfa1508\") " pod="kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805167    7266 reconciler_common.go:228] "operationExecutor.MountVolume started for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/8d6c6c46375623d290ed5865fa13e701-secrets\") pod \"cloud-credential-operator-sno131.outbound.vz.bos2.lab\" (UID: \"8d6c6c46375623d290ed5865fa13e701\") " pod="openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805177    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"etc-ssl-certs\" (UniqueName: \"kubernetes.io/host-path/64a8f6eb7c6e0cf4f9d62c71924bd30a-etc-ssl-certs\") pod \"bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab\" (UID: \"64a8f6eb7c6e0cf4f9d62c71924bd30a\") " pod="openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805197    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"config\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-config\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805207    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"audit-dir\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-audit-dir\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805084    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"config\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-config\") pod \"bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") " pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805217    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/64a8f6eb7c6e0cf4f9d62c71924bd30a-kubeconfig\") pod \"bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab\" (UID: \"64a8f6eb7c6e0cf4f9d62c71924bd30a\") " pod="openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805227    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"etc-kubernetes-cloud\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-etc-kubernetes-cloud\") pod \"bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") " pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805239    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"ssl-certs-host\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-ssl-certs-host\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805253    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"ssl-certs-host\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-ssl-certs-host\") pod \"bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") " pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805258    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-secrets\") pod \"bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") " pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805258    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/8d6c6c46375623d290ed5865fa13e701-secrets\") pod \"cloud-credential-operator-sno131.outbound.vz.bos2.lab\" (UID: \"8d6c6c46375623d290ed5865fa13e701\") " pod="openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805136    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"etc-kubernetes-cloud\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-etc-kubernetes-cloud\") pod \"bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab\" (UID: \"25c1466359fc8946267f656756984e2d\") " pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805279    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/19832dab34653130be3733c41dfa1508-secrets\") pod \"bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab\" (UID: \"19832dab34653130be3733c41dfa1508\") " pod="kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.805279    7266 operation_generator.go:740] "MountVolume.SetUp succeeded for volume \"logs\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-logs\") pod \"bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") " pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.945975    7266 util.go:30] "No sandbox for pod can be found. Need to start a new one" pod="openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.946851324Z" level=info msg="Running pod sandbox: openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab/POD" id=822268b9-0847-4c47-849b-273e94e8bda0 name=/runtime.v1.RuntimeService/RunPodSandbox
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.946927360Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.951207633Z" level=info msg="Ran pod sandbox c825a9ddba5029fed0dff1a640f8dcd9d0d5c0c48e82d1a2fe05e16e927a534f with infra container: openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab/POD" id=822268b9-0847-4c47-849b-273e94e8bda0 name=/runtime.v1.RuntimeService/RunPodSandbox
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.951719936Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27" id=da0000be-c232-48b7-98cc-7be5bf4e81c8 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.951826462Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:bd31af778e86d50ac082b75a2860143704fe333a4a07562202de6fc7593859a3,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27],Size_:434501910,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=da0000be-c232-48b7-98cc-7be5bf4e81c8 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.951897    7266 util.go:30] "No sandbox for pod can be found. Need to start a new one" pod="openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.952223536Z" level=info msg="Pulling image: quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27" id=3e0789b7-bb88-4fda-8a7e-0b2a308d52de name=/runtime.v1.ImageService/PullImage
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.952229181Z" level=info msg="Running pod sandbox: openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab/POD" id=575fa2c9-bed0-4c0d-92c7-2145d7b9193d name=/runtime.v1.RuntimeService/RunPodSandbox
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.952275786Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.953347952Z" level=info msg="Trying to access \"quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27\""
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.955807149Z" level=info msg="Ran pod sandbox e99b0b1ca36c59595a541e34b3b07590e21ab03aef3257fd1bb1a42dcb61b605 with infra container: openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab/POD" id=575fa2c9-bed0-4c0d-92c7-2145d7b9193d name=/runtime.v1.RuntimeService/RunPodSandbox
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.956512555Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:72d27946eed40e604ebad5c07d9c43993ec6c0f23d12daf82b14130b04e7ee7a" id=19b89bb6-8864-4457-afb0-305e617f6025 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.956607463Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:386706c74eb2c1b7783597761308cb6b24246a6e1866691f04e060c3ed1a879d,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:72d27946eed40e604ebad5c07d9c43993ec6c0f23d12daf82b14130b04e7ee7a],Size_:637700020,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=19b89bb6-8864-4457-afb0-305e617f6025 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.956772672Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:72d27946eed40e604ebad5c07d9c43993ec6c0f23d12daf82b14130b04e7ee7a" id=f22559da-7a26-4291-a41d-adf3f5b8b8f3 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.956860185Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:386706c74eb2c1b7783597761308cb6b24246a6e1866691f04e060c3ed1a879d,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:72d27946eed40e604ebad5c07d9c43993ec6c0f23d12daf82b14130b04e7ee7a],Size_:637700020,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=f22559da-7a26-4291-a41d-adf3f5b8b8f3 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.957103413Z" level=info msg="Creating container: openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab/cloud-credential-operator" id=f53da8e3-8915-40fb-afcc-f63ea9f635cd name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.957156887Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.959142311Z" level=info msg="Container \"6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d\" is a besteffort pod. Skip PreStart." id=f53da8e3-8915-40fb-afcc-f63ea9f635cd name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.981399    7266 util.go:30] "No sandbox for pod can be found. Need to start a new one" pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.981796185Z" level=info msg="Running pod sandbox: openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab/POD" id=ca7e1f8d-9240-41a3-b8f4-9f065cd6762d name=/runtime.v1.RuntimeService/RunPodSandbox
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.981825381Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.985446164Z" level=info msg="Ran pod sandbox 7a04a2e79f7e04f2e0774716267d2db0ecf05f84aad4f5dc618aa6ee4bf839a5 with infra container: openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab/POD" id=ca7e1f8d-9240-41a3-b8f4-9f065cd6762d name=/runtime.v1.RuntimeService/RunPodSandbox
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.985894882Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab" id=5f878378-a417-4d81-ba90-051832c44e7f name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.985921    7266 util.go:30] "No sandbox for pod can be found. Need to start a new one" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.985994012Z" level=info msg="Image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab not found" id=5f878378-a417-4d81-ba90-051832c44e7f name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.986068438Z" level=info msg="Running pod sandbox: kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab/POD" id=6c9ffbda-e7ff-47e0-b27f-6ea30e8113a9 name=/runtime.v1.RuntimeService/RunPodSandbox
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.986095377Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.986141625Z" level=info msg="Pulling image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab" id=24c1f5f6-9376-4e0a-95c2-9777b9bd1be0 name=/runtime.v1.ImageService/PullImage
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.986999572Z" level=info msg="Trying to access \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab\""
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:41.990313    7266 util.go:30] "No sandbox for pod can be found. Need to start a new one" pod="kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.990494682Z" level=info msg="Running pod sandbox: kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab/POD" id=144f9718-bec7-40fa-9fcd-dc58f9fb53fc name=/runtime.v1.RuntimeService/RunPodSandbox
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.990526834Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.990686064Z" level=info msg="Ran pod sandbox 0a31ad41e175257b843cae11b2bb1dee259adc3f3c874a51ab46e710f71184d0 with infra container: kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab/POD" id=6c9ffbda-e7ff-47e0-b27f-6ea30e8113a9 name=/runtime.v1.RuntimeService/RunPodSandbox
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.990938069Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab" id=daefd11f-d6f3-4047-be32-0f6b0aa0e608 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.991043085Z" level=info msg="Image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab not found" id=daefd11f-d6f3-4047-be32-0f6b0aa0e608 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.991176525Z" level=info msg="Pulling image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab" id=24869e3a-88df-459a-8ceb-7b02941a2218 name=/runtime.v1.ImageService/PullImage
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.993053516Z" level=info msg="Trying to access \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab\""
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.994046569Z" level=info msg="Ran pod sandbox af66091721aacdb548a64ff56916ca8446e308f2e6c9891728173b7c266a9874 with infra container: kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab/POD" id=144f9718-bec7-40fa-9fcd-dc58f9fb53fc name=/runtime.v1.RuntimeService/RunPodSandbox
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.994302261Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab" id=a4959a71-4d98-4b24-8438-092168768151 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.994408808Z" level=info msg="Image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab not found" id=a4959a71-4d98-4b24-8438-092168768151 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.994546311Z" level=info msg="Pulling image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab" id=ed1dc3d8-f10a-427b-91d9-598457a0ac1c name=/runtime.v1.ImageService/PullImage
Jun 06 02:09:41 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:41.995889205Z" level=info msg="Trying to access \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab\""
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab systemd[1]: Started crio-conmon-6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d.scope.
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d.
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:42.070362422Z" level=info msg="Created container 6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d: openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab/cloud-credential-operator" id=f53da8e3-8915-40fb-afcc-f63ea9f635cd name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:42.070752911Z" level=info msg="Starting container: 6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d" id=96e337d1-a6e5-4ca0-b624-6fa046a50178 name=/runtime.v1.RuntimeService/StartContainer
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:42.075900587Z" level=info msg="Started container" PID=10785 containerID=6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d description=openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab/cloud-credential-operator id=96e337d1-a6e5-4ca0-b624-6fa046a50178 name=/runtime.v1.RuntimeService/StartContainer sandboxID=e99b0b1ca36c59595a541e34b3b07590e21ab03aef3257fd1bb1a42dcb61b605
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:42.221677531Z" level=info msg="Pulled image: quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27" id=3e0789b7-bb88-4fda-8a7e-0b2a308d52de name=/runtime.v1.ImageService/PullImage
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:42.222132879Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27" id=0806a609-ddaa-4891-b1fc-94e885e52f99 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:42.222257561Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:bd31af778e86d50ac082b75a2860143704fe333a4a07562202de6fc7593859a3,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-release@sha256:6ef3cf4bed1970d547dce08a6e334b675d361b212427c4493151dcad6e093d27],Size_:434501910,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=0806a609-ddaa-4891-b1fc-94e885e52f99 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:42.222695389Z" level=info msg="Creating container: openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab/cluster-version-operator" id=1a24a829-893f-42a4-a509-615bac32f10c name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:42.222776928Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:42.226864787Z" level=info msg="Container \"66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754\" is a besteffort pod. Skip PreStart." id=1a24a829-893f-42a4-a509-615bac32f10c name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab systemd[1]: Started crio-conmon-66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754.scope.
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:42.290872    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab" event=&{ID:19832dab34653130be3733c41dfa1508 Type:ContainerStarted Data:af66091721aacdb548a64ff56916ca8446e308f2e6c9891728173b7c266a9874}
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:42.291482896Z" level=info msg="Trying to access \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab\""
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:42.291854    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab" event=&{ID:082e8bbce893a060432eb17e10fe12e8 Type:ContainerStarted Data:0a31ad41e175257b843cae11b2bb1dee259adc3f3c874a51ab46e710f71184d0}
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:42.293098    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab" event=&{ID:25c1466359fc8946267f656756984e2d Type:ContainerStarted Data:7a04a2e79f7e04f2e0774716267d2db0ecf05f84aad4f5dc618aa6ee4bf839a5}
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:42.293215853Z" level=info msg="Trying to access \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab\""
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:42.294816    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab" event=&{ID:8d6c6c46375623d290ed5865fa13e701 Type:ContainerStarted Data:6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d}
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:42.294833    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab" event=&{ID:8d6c6c46375623d290ed5865fa13e701 Type:ContainerStarted Data:e99b0b1ca36c59595a541e34b3b07590e21ab03aef3257fd1bb1a42dcb61b605}
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:42.294945    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:42.296853    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:42.296888    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:42.296900    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:42.297064    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab" event=&{ID:64a8f6eb7c6e0cf4f9d62c71924bd30a Type:ContainerStarted Data:c825a9ddba5029fed0dff1a640f8dcd9d0d5c0c48e82d1a2fe05e16e927a534f}
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754.
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:42.337638737Z" level=info msg="Created container 66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754: openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab/cluster-version-operator" id=1a24a829-893f-42a4-a509-615bac32f10c name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:42.338061928Z" level=info msg="Starting container: 66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754" id=269b13af-e929-4614-85d5-7eb8e014c552 name=/runtime.v1.RuntimeService/StartContainer
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:42.344842052Z" level=info msg="Started container" PID=10836 containerID=66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754 description=openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab/cluster-version-operator id=269b13af-e929-4614-85d5-7eb8e014c552 name=/runtime.v1.RuntimeService/StartContainer sandboxID=c825a9ddba5029fed0dff1a640f8dcd9d0d5c0c48e82d1a2fe05e16e927a534f
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Still waiting for the Kubernetes API: Get "https://localhost:6443/readyz": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:42 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:09:43 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:43.299887    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:43 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:43.299965    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:43 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:43.300074    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab" event=&{ID:64a8f6eb7c6e0cf4f9d62c71924bd30a Type:ContainerStarted Data:66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754}
Jun 06 02:09:43 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:43.300971    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:43 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:43.300988    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:43 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:43.300994    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:43 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:43.301072    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:43 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:43.301084    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:43 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:43.301089    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:43 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:43.307806063Z" level=info msg="Trying to access \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab\""
Jun 06 02:09:44 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:44.301985    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:44 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:44.302845    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:44 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:44.302861    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:44 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:44.302867    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:09:44" level=warning msg="Certificate verification is turned off. This is not recommended in production environments" file="inventory_session.go:126"
Jun 06 02:09:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:09:44" level=info msg="Query for next steps" file="step_processor.go:233" request_id=c7917472-8d23-4d2a-b7a2-92b6acad2afe
Jun 06 02:09:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:09:44Z" level=info msg="GetNextSteps infra_env: <5f396111-46ed-4173-9648-bc0a9a818139>, host: <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>, host status: <installing-in-progress>" func="github.com/openshift/assisted-service/internal/host/hostcommands.(*InstructionManager).GetNextSteps" file="/src/internal/host/hostcommands/instruction_manager.go:160" go-id=1470 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=c7917472-8d23-4d2a-b7a2-92b6acad2afe
Jun 06 02:09:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:09:44Z" level=info msg="No steps required for infraEnv <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>" func=github.com/openshift/assisted-service/internal/host/hostcommands.logSteps file="/src/internal/host/hostcommands/instruction_manager.go:284" go-id=1470 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=c7917472-8d23-4d2a-b7a2-92b6acad2afe
Jun 06 02:09:47 sno131.outbound.vz.bos2.lab approve-csr.sh[10913]: E0606 02:09:47.069644   10913 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:47 sno131.outbound.vz.bos2.lab approve-csr.sh[10913]: E0606 02:09:47.070079   10913 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:47 sno131.outbound.vz.bos2.lab approve-csr.sh[10913]: E0606 02:09:47.071414   10913 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:47 sno131.outbound.vz.bos2.lab approve-csr.sh[10913]: E0606 02:09:47.072693   10913 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:47 sno131.outbound.vz.bos2.lab approve-csr.sh[10913]: E0606 02:09:47.074366   10913 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:09:47 sno131.outbound.vz.bos2.lab approve-csr.sh[10913]: The connection to the server localhost:6443 was refused - did you specify the right host or port?
Jun 06 02:09:47 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.041397731Z" level=info msg="Pulled image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab" id=24c1f5f6-9376-4e0a-95c2-9777b9bd1be0 name=/runtime.v1.ImageService/PullImage
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.042017764Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab" id=0fec61e5-978f-4fe7-892e-e21c883ff6ae name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.042767947Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:db310921b315a64d26cd29b0f30dc9bb82f7c0a72c9ccbe89212605c94b30868,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab],Size_:878727714,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=0fec61e5-978f-4fe7-892e-e21c883ff6ae name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.043255557Z" level=info msg="Creating container: openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab/setup" id=00f65bc8-6977-41ff-94be-f341f8bf0be0 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.043318858Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.047909561Z" level=info msg="Container \"879627050f06ae240ecae7ed418ee74c9917c81f786f3f977eb8ae18316cb8ab\" is a burstable pod. Skip PreStart." id=00f65bc8-6977-41ff-94be-f341f8bf0be0 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab systemd[1]: Started crio-conmon-879627050f06ae240ecae7ed418ee74c9917c81f786f3f977eb8ae18316cb8ab.scope.
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 879627050f06ae240ecae7ed418ee74c9917c81f786f3f977eb8ae18316cb8ab.
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.171551809Z" level=info msg="Created container 879627050f06ae240ecae7ed418ee74c9917c81f786f3f977eb8ae18316cb8ab: openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab/setup" id=00f65bc8-6977-41ff-94be-f341f8bf0be0 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.171947746Z" level=info msg="Starting container: 879627050f06ae240ecae7ed418ee74c9917c81f786f3f977eb8ae18316cb8ab" id=35196071-82ca-4aef-b50b-87ed0fb87b6a name=/runtime.v1.RuntimeService/StartContainer
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.189535638Z" level=info msg="Started container" PID=10955 containerID=879627050f06ae240ecae7ed418ee74c9917c81f786f3f977eb8ae18316cb8ab description=openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab/setup id=35196071-82ca-4aef-b50b-87ed0fb87b6a name=/runtime.v1.RuntimeService/StartContainer sandboxID=7a04a2e79f7e04f2e0774716267d2db0ecf05f84aad4f5dc618aa6ee4bf839a5
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab systemd[1]: crio-879627050f06ae240ecae7ed418ee74c9917c81f786f3f977eb8ae18316cb8ab.scope: Deactivated successfully.
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab systemd[1]: crio-conmon-879627050f06ae240ecae7ed418ee74c9917c81f786f3f977eb8ae18316cb8ab.scope: Deactivated successfully.
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:48.308045    7266 generic.go:332] "Generic (PLEG): container finished" podID=25c1466359fc8946267f656756984e2d containerID="879627050f06ae240ecae7ed418ee74c9917c81f786f3f977eb8ae18316cb8ab" exitCode=0
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:48.308069    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab" event=&{ID:25c1466359fc8946267f656756984e2d Type:ContainerDied Data:879627050f06ae240ecae7ed418ee74c9917c81f786f3f977eb8ae18316cb8ab}
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:48.308176    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:48.308809    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:48.308826    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:48.308833    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.309016939Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab" id=450e25c4-758f-4e91-9fd4-333189eaa76a name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.309854604Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:db310921b315a64d26cd29b0f30dc9bb82f7c0a72c9ccbe89212605c94b30868,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab],Size_:878727714,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=450e25c4-758f-4e91-9fd4-333189eaa76a name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:48.309960    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:48.310521    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:48.310531    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:48.310537    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.310678800Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab" id=b39d754b-0a0c-4809-9fad-3d4c8f5581ea name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.313030437Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:db310921b315a64d26cd29b0f30dc9bb82f7c0a72c9ccbe89212605c94b30868,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab],Size_:878727714,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=b39d754b-0a0c-4809-9fad-3d4c8f5581ea name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.313796662Z" level=info msg="Creating container: openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab/kube-apiserver" id=e0fe3db7-5320-4629-9234-ab7476781944 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.313864846Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.316696186Z" level=info msg="Container \"ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239\" is a burstable pod. Skip PreStart." id=e0fe3db7-5320-4629-9234-ab7476781944 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab systemd[1]: Started crio-conmon-ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239.scope.
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239.
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.410316877Z" level=info msg="Created container ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239: openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab/kube-apiserver" id=e0fe3db7-5320-4629-9234-ab7476781944 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.410834522Z" level=info msg="Starting container: ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239" id=b1c7f16c-6f08-4b9a-9f2c-172c72518692 name=/runtime.v1.RuntimeService/StartContainer
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.416218573Z" level=info msg="Started container" PID=10999 containerID=ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239 description=openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab/kube-apiserver id=b1c7f16c-6f08-4b9a-9f2c-172c72518692 name=/runtime.v1.RuntimeService/StartContainer sandboxID=7a04a2e79f7e04f2e0774716267d2db0ecf05f84aad4f5dc618aa6ee4bf839a5
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.434883642Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:7270ceb168750f0c4ae0afb0086b6dc111dd0da5a96ef32638e8c414b288d228" id=18adecbe-c906-4f54-9f16-787de3417d52 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.435007700Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:34359b114a1ad8169a4a35170fceb427ec4a4959cd3fdcd36ec425f9724fc677,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:7270ceb168750f0c4ae0afb0086b6dc111dd0da5a96ef32638e8c414b288d228],Size_:459372937,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=18adecbe-c906-4f54-9f16-787de3417d52 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.435809648Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:7270ceb168750f0c4ae0afb0086b6dc111dd0da5a96ef32638e8c414b288d228" id=a5f97454-7b05-4945-9d8e-50d11de281a7 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.435908830Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:34359b114a1ad8169a4a35170fceb427ec4a4959cd3fdcd36ec425f9724fc677,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:7270ceb168750f0c4ae0afb0086b6dc111dd0da5a96ef32638e8c414b288d228],Size_:459372937,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=a5f97454-7b05-4945-9d8e-50d11de281a7 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.436381913Z" level=info msg="Creating container: openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab/kube-apiserver-insecure-readyz" id=bc07d26d-9629-4119-8f37-314098cdd29d name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.436455501Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.438797256Z" level=info msg="Container \"23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127\" is a burstable pod. Skip PreStart." id=bc07d26d-9629-4119-8f37-314098cdd29d name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab systemd[1]: Started crio-conmon-23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127.scope.
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127.
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.552461098Z" level=info msg="Created container 23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127: openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab/kube-apiserver-insecure-readyz" id=bc07d26d-9629-4119-8f37-314098cdd29d name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.552936660Z" level=info msg="Starting container: 23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127" id=21259e38-a3e3-4be8-900b-31de2e9605d5 name=/runtime.v1.RuntimeService/StartContainer
Jun 06 02:09:48 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:48.558556698Z" level=info msg="Started container" PID=11049 containerID=23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127 description=openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab/kube-apiserver-insecure-readyz id=21259e38-a3e3-4be8-900b-31de2e9605d5 name=/runtime.v1.RuntimeService/StartContainer sandboxID=7a04a2e79f7e04f2e0774716267d2db0ecf05f84aad4f5dc618aa6ee4bf839a5
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:49.311431    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab" event=&{ID:25c1466359fc8946267f656756984e2d Type:ContainerStarted Data:23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127}
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:49.311455    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab" event=&{ID:25c1466359fc8946267f656756984e2d Type:ContainerStarted Data:ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239}
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:49.311539    7266 kubelet.go:2323] "SyncLoop (probe)" probe="readiness" status="" pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:49.311553    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:49.312237    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:49.312254    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:49.312260    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: API is up
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: All self-hosted control plane components successfully started
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Sending bootstrap-success event.[#1] context canceled
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Waiting for remaining assets to be created.
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_00_cluster-version-operator_00_namespace.yaml" namespaces.v1./openshift-cluster-version -n
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "0000_00_cluster-version-operator_01_adminack_configmap.yaml" configmaps.v1./admin-acks -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "0000_00_cluster-version-operator_01_admingate_configmap.yaml" configmaps.v1./admin-gates -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_00_cluster-version-operator_01_clusteroperator.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/clusteroperators.config.openshift.io -n
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_00_cluster-version-operator_01_clusterversion.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/clusterversions.config.openshift.io -n
Jun 06 02:09:49 sno131.outbound.vz.bos2.lab systemd[1]: rpm-ostreed.service: Deactivated successfully.
Jun 06 02:09:50 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_00_cluster-version-operator_02_roles.yaml" clusterrolebindings.v1.rbac.authorization.k8s.io/cluster-version-operator -n
Jun 06 02:09:50 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:50.313649    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:50 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:50.314527    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:50 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:50.314544    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:50 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:50.314558    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:51.055571585Z" level=info msg="Pulled image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab" id=ed1dc3d8-f10a-427b-91d9-598457a0ac1c name=/runtime.v1.ImageService/PullImage
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:51.056352796Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab" id=1490b314-a875-4399-b6c3-eb89357a71c2 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:51.057141694Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:db310921b315a64d26cd29b0f30dc9bb82f7c0a72c9ccbe89212605c94b30868,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab],Size_:878727714,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=1490b314-a875-4399-b6c3-eb89357a71c2 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:51.057666568Z" level=info msg="Creating container: kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab/kube-scheduler" id=0c811921-a159-406e-a590-8586bb33d639 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:51.057733524Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:51.060924753Z" level=info msg="Container \"f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414\" is a burstable pod. Skip PreStart." id=0c811921-a159-406e-a590-8586bb33d639 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab systemd[1]: Started crio-conmon-f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414.scope.
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414.
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:51.164847878Z" level=info msg="Created container f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414: kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab/kube-scheduler" id=0c811921-a159-406e-a590-8586bb33d639 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:51.165126718Z" level=info msg="Starting container: f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414" id=6d7f9c77-5be1-4de2-a608-430079ac3615 name=/runtime.v1.RuntimeService/StartContainer
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:51.182717377Z" level=info msg="Started container" PID=11182 containerID=f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414 description=kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab/kube-scheduler id=6d7f9c77-5be1-4de2-a608-430079ac3615 name=/runtime.v1.RuntimeService/StartContainer sandboxID=af66091721aacdb548a64ff56916ca8446e308f2e6c9891728173b7c266a9874
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:51.205082    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:51.206005    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:51.206020    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:51.206026    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:51.315753    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab" event=&{ID:19832dab34653130be3733c41dfa1508 Type:ContainerStarted Data:f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414}
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:51.315860    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:51.316418    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:51.316433    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:51.316439    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:52 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:52.317381    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:09:52 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:52.318160    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:09:52 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:52.318177    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:09:52 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:52.318184    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:09:52 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:09:53 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:53.987115380Z" level=info msg="Pulled image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab" id=24869e3a-88df-459a-8ceb-7b02941a2218 name=/runtime.v1.ImageService/PullImage
Jun 06 02:09:53 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:53.987746585Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab" id=bb599823-04c9-4e74-8c0a-b07892d2c68d name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:53 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:53.987854486Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:db310921b315a64d26cd29b0f30dc9bb82f7c0a72c9ccbe89212605c94b30868,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:122e8bfb9fe99f2c47c0312be9c535cd524c4c148c3963fc72a00d7d625d1fab],Size_:878727714,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=bb599823-04c9-4e74-8c0a-b07892d2c68d name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:53 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:53.988395801Z" level=info msg="Creating container: kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab/kube-controller-manager" id=da5a1bfe-3c43-4318-8aa6-4d57ba67e912 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:53 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:53.988461889Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:09:53 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:53.991291735Z" level=info msg="Container \"01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae\" is a burstable pod. Skip PreStart." id=da5a1bfe-3c43-4318-8aa6-4d57ba67e912 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:54 sno131.outbound.vz.bos2.lab systemd[1]: Started crio-conmon-01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae.scope.
Jun 06 02:09:54 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae.
Jun 06 02:09:54 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:54.107187925Z" level=info msg="Created container 01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae: kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab/kube-controller-manager" id=da5a1bfe-3c43-4318-8aa6-4d57ba67e912 name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:09:54 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:54.107598083Z" level=info msg="Starting container: 01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae" id=3d4d3776-6afa-43f9-b906-471ee6b8098e name=/runtime.v1.RuntimeService/StartContainer
Jun 06 02:09:54 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:54.112855803Z" level=info msg="Started container" PID=11247 containerID=01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae description=kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab/kube-controller-manager id=3d4d3776-6afa-43f9-b906-471ee6b8098e name=/runtime.v1.RuntimeService/StartContainer sandboxID=0a31ad41e175257b843cae11b2bb1dee259adc3f3c874a51ab46e710f71184d0
Jun 06 02:09:54 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:54.130617748Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f13dcbb050aebb739b58fb95e6af0633585def9b30d255817e83345f660f6730" id=2a91208b-5ccd-49e6-9d0a-7da2b4ef61f6 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:54 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:54.130744355Z" level=info msg="Image quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f13dcbb050aebb739b58fb95e6af0633585def9b30d255817e83345f660f6730 not found" id=2a91208b-5ccd-49e6-9d0a-7da2b4ef61f6 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:09:54 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:54.130989134Z" level=info msg="Pulling image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f13dcbb050aebb739b58fb95e6af0633585def9b30d255817e83345f660f6730" id=29aa0deb-e4b8-4794-81e9-a4c9a1a317c7 name=/runtime.v1.ImageService/PullImage
Jun 06 02:09:54 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:54.132147617Z" level=info msg="Trying to access \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f13dcbb050aebb739b58fb95e6af0633585def9b30d255817e83345f660f6730\""
Jun 06 02:09:54 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:09:54.322025    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab" event=&{ID:082e8bbce893a060432eb17e10fe12e8 Type:ContainerStarted Data:01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae}
Jun 06 02:09:55 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:09:55.113135858Z" level=info msg="Trying to access \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f13dcbb050aebb739b58fb95e6af0633585def9b30d255817e83345f660f6730\""
Jun 06 02:09:57 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:10:00 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "0000_00_cluster-version-operator_03_deployment.yaml" deployments.v1.apps/cluster-version-operator -n openshift-cluster-version: deployments.apps "cluster-version-operator" is forbidden: quota.openshift.io/ClusterResourceQuota: caches not synchronized
Jun 06 02:10:00 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_00_namespace-openshift-infra.yaml" namespaces.v1./openshift-infra -n
Jun 06 02:10:00 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_03_authorization-openshift_01_rolebindingrestriction.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/rolebindingrestrictions.authorization.openshift.io -n
Jun 06 02:10:00 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_03_config-operator_01_proxy.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/proxies.config.openshift.io -n
Jun 06 02:10:00 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_03_quota-openshift_01_clusterresourcequota.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/clusterresourcequotas.quota.openshift.io -n
Jun 06 02:10:00 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_03_security-openshift_01_scc.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/securitycontextconstraints.security.openshift.io -n
Jun 06 02:10:00 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_03_securityinternal-openshift_02_rangeallocation.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/rangeallocations.security.internal.openshift.io -n
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.119193    7266 kubelet_getters.go:182] "Pod status updated" pod="openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.119213    7266 kubelet_getters.go:182] "Pod status updated" pod="openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.119219    7266 kubelet_getters.go:182] "Pod status updated" pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.119224    7266 kubelet_getters.go:182] "Pod status updated" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab" status=Pending
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.119229    7266 kubelet_getters.go:182] "Pod status updated" pod="kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.119234    7266 kubelet_getters.go:182] "Pod status updated" pod="openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.119239    7266 kubelet_getters.go:182] "Pod status updated" pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_apiserver-Default.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/apiservers.config.openshift.io -n
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.213918    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.214898    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.214913    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.214920    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:10:01.519720416Z" level=info msg="Pulled image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f13dcbb050aebb739b58fb95e6af0633585def9b30d255817e83345f660f6730" id=29aa0deb-e4b8-4794-81e9-a4c9a1a317c7 name=/runtime.v1.ImageService/PullImage
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:10:01.520191885Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f13dcbb050aebb739b58fb95e6af0633585def9b30d255817e83345f660f6730" id=5f57869b-86b9-4913-b645-7c31d7f141f7 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:10:01.520966175Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:d20dfa3c0895eceead5aa5c45a0e10baa053f96492c7957dfeb2fe47214b729c,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f13dcbb050aebb739b58fb95e6af0633585def9b30d255817e83345f660f6730],Size_:439570427,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=5f57869b-86b9-4913-b645-7c31d7f141f7 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:10:01.521551672Z" level=info msg="Creating container: kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab/cluster-policy-controller" id=577ce4d5-df4e-4730-8956-5350e322c1ed name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:10:01.521612728Z" level=warning msg="Allowed annotations are specified for workload [io.containers.trace-syscall]"
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:10:01.524695821Z" level=info msg="Container \"b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd\" is a burstable pod. Skip PreStart." id=577ce4d5-df4e-4730-8956-5350e322c1ed name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab systemd[1]: Started crio-conmon-b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd.scope.
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd.
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_authentication.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/authentications.config.openshift.io -n
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:10:01.633251149Z" level=info msg="Created container b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd: kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab/cluster-policy-controller" id=577ce4d5-df4e-4730-8956-5350e322c1ed name=/runtime.v1.RuntimeService/CreateContainer
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:10:01.633735689Z" level=info msg="Starting container: b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd" id=a35e7592-ebea-4856-940d-e9639971b5a7 name=/runtime.v1.RuntimeService/StartContainer
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:10:01.651668599Z" level=info msg="Started container" PID=11366 containerID=b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd description=kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab/cluster-policy-controller id=a35e7592-ebea-4856-940d-e9639971b5a7 name=/runtime.v1.RuntimeService/StartContainer sandboxID=0a31ad41e175257b843cae11b2bb1dee259adc3f3c874a51ab46e710f71184d0
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.987982    7266 kubelet.go:2323] "SyncLoop (probe)" probe="readiness" status="ready" pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab"
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.988139    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.988948    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.988970    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:01.988984    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:02 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_build.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/builds.config.openshift.io -n
Jun 06 02:10:02 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:02.338958    7266 kubelet.go:2251] "SyncLoop (PLEG): event for pod" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab" event=&{ID:082e8bbce893a060432eb17e10fe12e8 Type:ContainerStarted Data:b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd}
Jun 06 02:10:02 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:02.339128    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:02 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:02.339927    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:02 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:02.339943    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:02 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:02.339949    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:02 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_console.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/consoles.config.openshift.io -n
Jun 06 02:10:02 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_dns.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/dnses.config.openshift.io -n
Jun 06 02:10:02 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:10:03 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_featuregate.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/featuregates.config.openshift.io -n
Jun 06 02:10:03 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:03.340758    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:03 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:03.341506    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:03 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:03.341523    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:03 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:03.341529    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:03 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_image.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/images.config.openshift.io -n
Jun 06 02:10:04 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_imagecontentpolicy.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/imagecontentpolicies.config.openshift.io -n
Jun 06 02:10:04 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_imagecontentsourcepolicy.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/imagecontentsourcepolicies.operator.openshift.io -n
Jun 06 02:10:04 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_imagedigestmirrorset.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/imagedigestmirrorsets.config.openshift.io -n
Jun 06 02:10:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_imagetagmirrorset.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/imagetagmirrorsets.config.openshift.io -n
Jun 06 02:10:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_infrastructure-Default.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/infrastructures.config.openshift.io -n
Jun 06 02:10:06 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_ingress.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/ingresses.config.openshift.io -n
Jun 06 02:10:06 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_network.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/networks.config.openshift.io -n
Jun 06 02:10:06 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_node.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/nodes.config.openshift.io -n
Jun 06 02:10:07 sno131.outbound.vz.bos2.lab approve-csr.sh[11439]: No resources found
Jun 06 02:10:07 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_oauth.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/oauths.config.openshift.io -n
Jun 06 02:10:07 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_project.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/projects.config.openshift.io -n
Jun 06 02:10:08 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_10_config-operator_01_scheduler.crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/schedulers.config.openshift.io -n
Jun 06 02:10:08 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:10:08 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_cr-scc-anyuid.yaml" clusterroles.v1.rbac.authorization.k8s.io/system:openshift:scc:anyuid -n
Jun 06 02:10:08 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_cr-scc-hostaccess.yaml" clusterroles.v1.rbac.authorization.k8s.io/system:openshift:scc:hostaccess -n
Jun 06 02:10:09 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_cr-scc-hostmount-anyuid.yaml" clusterroles.v1.rbac.authorization.k8s.io/system:openshift:scc:hostmount -n
Jun 06 02:10:09 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_cr-scc-hostnetwork-v2.yaml" clusterroles.v1.rbac.authorization.k8s.io/system:openshift:scc:hostnetwork-v2 -n
Jun 06 02:10:10 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_cr-scc-hostnetwork.yaml" clusterroles.v1.rbac.authorization.k8s.io/system:openshift:scc:hostnetwork -n
Jun 06 02:10:10 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_cr-scc-nonroot-v2.yaml" clusterroles.v1.rbac.authorization.k8s.io/system:openshift:scc:nonroot-v2 -n
Jun 06 02:10:10 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_cr-scc-nonroot.yaml" clusterroles.v1.rbac.authorization.k8s.io/system:openshift:scc:nonroot -n
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_cr-scc-privileged.yaml" clusterroles.v1.rbac.authorization.k8s.io/system:openshift:scc:privileged -n
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:11.221756    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:11.223096    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:11.223113    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:11.223119    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_cr-scc-restricted-v2.yaml" clusterroles.v1.rbac.authorization.k8s.io/system:openshift:scc:restricted-v2 -n
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:11.986761    7266 kubelet.go:2323] "SyncLoop (probe)" probe="startup" status="unhealthy" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:11.986776    7266 kubelet.go:2323] "SyncLoop (probe)" probe="readiness" status="" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:11.986782    7266 kubelet.go:2323] "SyncLoop (probe)" probe="readiness" status="" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:11.986788    7266 kubelet.go:2323] "SyncLoop (probe)" probe="startup" status="unhealthy" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:11.986911    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:11.987761    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:11.987775    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:11.987780    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:11.989359    7266 kubelet.go:2323] "SyncLoop (probe)" probe="startup" status="started" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:10:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:11.989668    7266 kubelet.go:2323] "SyncLoop (probe)" probe="startup" status="started" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:10:12 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_cr-scc-restricted.yaml" clusterroles.v1.rbac.authorization.k8s.io/system:openshift:scc:restricted -n
Jun 06 02:10:12 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:12.356705    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:12 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:12.357225    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:12 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:12.357238    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:12 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:12.357244    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:12 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:12.359251    7266 kubelet.go:2323] "SyncLoop (probe)" probe="readiness" status="ready" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:10:12 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:12.359537    7266 kubelet.go:2323] "SyncLoop (probe)" probe="readiness" status="ready" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab"
Jun 06 02:10:12 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_crb-systemauthenticated-scc-restricted-v2.yaml" clusterrolebindings.v1.rbac.authorization.k8s.io/system:openshift:scc:restricted-v2 -n
Jun 06 02:10:12 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_scc-anyuid.yaml" securitycontextconstraints.v1.security.openshift.io/anyuid -n
Jun 06 02:10:13 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:10:13 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_scc-hostaccess.yaml" securitycontextconstraints.v1.security.openshift.io/hostaccess -n
Jun 06 02:10:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:13.358600    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:13.359285    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:13.359298    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:13 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:13.359303    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:13 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_scc-hostmount-anyuid.yaml" securitycontextconstraints.v1.security.openshift.io/hostmount-anyuid -n
Jun 06 02:10:14 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_scc-hostnetwork-v2.yaml" securitycontextconstraints.v1.security.openshift.io/hostnetwork-v2 -n
Jun 06 02:10:14 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:14.360435    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:14 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:14.361104    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:14 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:14.361118    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:14 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:14.361123    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:14 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_scc-hostnetwork.yaml" securitycontextconstraints.v1.security.openshift.io/hostnetwork -n
Jun 06 02:10:14 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_scc-nonroot-v2.yaml" securitycontextconstraints.v1.security.openshift.io/nonroot-v2 -n
Jun 06 02:10:15 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_scc-nonroot.yaml" securitycontextconstraints.v1.security.openshift.io/nonroot -n
Jun 06 02:10:15 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_scc-privileged.yaml" securitycontextconstraints.v1.security.openshift.io/privileged -n
Jun 06 02:10:16 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_scc-restricted-v2.yaml" securitycontextconstraints.v1.security.openshift.io/restricted-v2 -n
Jun 06 02:10:16 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_20_kube-apiserver-operator_00_scc-restricted.yaml" securitycontextconstraints.v1.security.openshift.io/restricted -n
Jun 06 02:10:16 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0001_00_cluster-version-operator_03_service.yaml" services.v1./cluster-version-operator -n openshift-cluster-version
Jun 06 02:10:17 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "00_etcd-endpoints-cm.yaml" configmaps.v1./etcd-endpoints -n openshift-etcd: namespaces "openshift-etcd" not found
Jun 06 02:10:17 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "00_namespace-security-allocation-controller-clusterrole.yaml" clusterroles.v1.rbac.authorization.k8s.io/system:openshift:controller:namespace-security-allocation-controller -n
Jun 06 02:10:18 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "00_namespace-security-allocation-controller-clusterrolebinding.yaml" clusterrolebindings.v1.rbac.authorization.k8s.io/system:openshift:controller:namespace-security-allocation-controller -n
Jun 06 02:10:18 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:10:18 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "00_openshift-etcd-ns.yaml" namespaces.v1./openshift-etcd -n
Jun 06 02:10:18 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "00_openshift-kube-apiserver-ns.yaml" namespaces.v1./openshift-kube-apiserver -n
Jun 06 02:10:19 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "00_openshift-kube-apiserver-operator-ns.yaml" namespaces.v1./openshift-kube-apiserver-operator -n
Jun 06 02:10:19 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "00_openshift-kube-controller-manager-ns.yaml" namespaces.v1./openshift-kube-controller-manager -n
Jun 06 02:10:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "00_openshift-kube-controller-manager-operator-ns.yaml" namespaces.v1./openshift-kube-controller-manager-operator -n
Jun 06 02:10:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "00_openshift-kube-scheduler-ns.yaml" namespaces.v1./openshift-kube-scheduler -n
Jun 06 02:10:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "00_podsecurity-admission-label-syncer-controller-clusterrole.yaml" clusterroles.v1.rbac.authorization.k8s.io/system:openshift:controller:podsecurity-admission-label-syncer-controller -n
Jun 06 02:10:21 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "00_podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" clusterrolebindings.v1.rbac.authorization.k8s.io/system:openshift:controller:podsecurity-admission-label-syncer-controller -n
Jun 06 02:10:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:21.230363    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:21.231265    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:21.231281    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:21.231288    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:21 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "01-container-mount-ns-and-kubelet-conf-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/container-mount-namespace-and-kubelet-conf-master -n : the server could not find the requested resource
Jun 06 02:10:22 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "02-master-workload-partitioning-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/02-master-workload-partitioning -n : the server could not find the requested resource
Jun 06 02:10:22 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "04-accelerated-container-startup-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/04-accelerated-container-startup-master -n : the server could not find the requested resource
Jun 06 02:10:22 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "05-kdump-config-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/05-kdump-config-master -n : the server could not find the requested resource
Jun 06 02:10:23 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:10:23 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "06-kdump-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/06-kdump-enable-master -n : the server could not find the requested resource
Jun 06 02:10:23 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "50-masters-chrony-configuration.yaml" machineconfigs.v1.machineconfiguration.openshift.io/50-masters-chrony-configuration -n : the server could not find the requested resource
Jun 06 02:10:24 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "50-workers-chrony-configuration.yaml" machineconfigs.v1.machineconfiguration.openshift.io/50-workers-chrony-configuration -n : the server could not find the requested resource
Jun 06 02:10:24 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "99-crio-disable-wipe-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/99-crio-disable-wipe-master -n : the server could not find the requested resource
Jun 06 02:10:24 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "99_kubeadmin-password-secret.yaml" secrets.v1./kubeadmin -n kube-system
Jun 06 02:10:25 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "99_openshift-cluster-api_master-user-data-secret.yaml" secrets.v1./master-user-data -n openshift-machine-api: namespaces "openshift-machine-api" not found
Jun 06 02:10:25 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "99_openshift-cluster-api_worker-user-data-secret.yaml" secrets.v1./worker-user-data -n openshift-machine-api: namespaces "openshift-machine-api" not found
Jun 06 02:10:26 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "99_openshift-machineconfig_99-master-ssh.yaml" machineconfigs.v1.machineconfiguration.openshift.io/99-master-ssh -n : the server could not find the requested resource
Jun 06 02:10:26 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "99_openshift-machineconfig_99-worker-ssh.yaml" machineconfigs.v1.machineconfiguration.openshift.io/99-worker-ssh -n : the server could not find the requested resource
Jun 06 02:10:26 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "AmqSubscriptionNS-0.yaml" namespaces.v1./amq-router -n
Jun 06 02:10:27 sno131.outbound.vz.bos2.lab approve-csr.sh[11585]: No resources found
Jun 06 02:10:27 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "PtpSubscriptionNS-0.yaml" namespaces.v1./openshift-ptp -n
Jun 06 02:10:27 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "SriovSubscriptionNS-0.yaml" namespaces.v1./openshift-sriov-network-operator -n
Jun 06 02:10:28 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "StorageNS-0.yaml" namespaces.v1./openshift-local-storage -n
Jun 06 02:10:28 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:10:28 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "apiserver.openshift.io_apirequestcount.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/apirequestcounts.apiserver.openshift.io -n
Jun 06 02:10:28 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "assisted-installer-controller-cm.yaml" configmaps.v1./assisted-installer-controller-config -n assisted-installer: namespaces "assisted-installer" not found
Jun 06 02:10:29 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "assisted-installer-controller-nm.yaml" namespaces.v1./assisted-installer -n
Jun 06 02:10:29 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "assisted-installer-controller-pod.yaml" jobs.v1.batch/assisted-installer-controller -n assisted-installer
Jun 06 02:10:30 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "assisted-installer-controller-role-binding.yaml" clusterrolebindings.v1.rbac.authorization.k8s.io/assisted-installer-controller -n assisted-installer
Jun 06 02:10:30 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "assisted-installer-controller-role.yaml" clusterroles.v1.rbac.authorization.k8s.io/assisted-installer-controller -n assisted-installer
Jun 06 02:10:30 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "assisted-installer-controller-sa.yaml" serviceaccounts.v1./assisted-installer-controller -n assisted-installer
Jun 06 02:10:31 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "assisted-installer-controller-secret.yaml" secrets.v1./assisted-installer-controller-secret -n assisted-installer
Jun 06 02:10:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:31.237877    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:31.239205    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:31.239222    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:31.239229    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:31 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cco-cloudcredential_v1_credentialsrequest_crd.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/credentialsrequests.cloudcredential.openshift.io -n
Jun 06 02:10:32 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cco-cloudcredential_v1_operator_config_custresdef.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/cloudcredentials.operator.openshift.io -n
Jun 06 02:10:32 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cco-namespace.yaml" namespaces.v1./openshift-cloud-credential-operator -n
Jun 06 02:10:33 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:10:33 sno131.outbound.vz.bos2.lab sshd[11652]: main: sshd: ssh-rsa algorithm is disabled
Jun 06 02:10:34 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cco-operator-config.yaml" cloudcredentials.v1.operator.openshift.io/cluster -n
Jun 06 02:10:34 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cluster-config.yaml" configmaps.v1./cluster-config-v1 -n kube-system
Jun 06 02:10:34 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cluster-dns-02-config.yml" dnses.v1.config.openshift.io/cluster -n
Jun 06 02:10:34 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Updated status for "cluster-dns-02-config.yml" dnses.v1.config.openshift.io/cluster -n
Jun 06 02:10:34 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: W0606 02:10:34.824137       1 warnings.go:70] unknown field "status.cpuPartitioning"
Jun 06 02:10:34 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cluster-infrastructure-02-config.yml" infrastructures.v1.config.openshift.io/cluster -n
Jun 06 02:10:34 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: W0606 02:10:34.828013       1 warnings.go:70] unknown field "status.cpuPartitioning"
Jun 06 02:10:34 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Updated status for "cluster-infrastructure-02-config.yml" infrastructures.v1.config.openshift.io/cluster -n
Jun 06 02:10:34 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cluster-ingress-00-custom-resource-definition.yaml" customresourcedefinitions.v1.apiextensions.k8s.io/ingresscontrollers.operator.openshift.io -n
Jun 06 02:10:35 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cluster-ingress-00-namespace.yaml" namespaces.v1./openshift-ingress-operator -n
Jun 06 02:10:35 sno131.outbound.vz.bos2.lab sshd[11652]: Accepted publickey for core from 192.168.58.15 port 44558 ssh2: RSA SHA256:ltZ47o/fDXlJWgy139p4iY4V9dEJkhH4Iqtjrso8YTQ
Jun 06 02:10:35 sno131.outbound.vz.bos2.lab systemd[1]: Created slice User Slice of UID 1000.
Jun 06 02:10:35 sno131.outbound.vz.bos2.lab systemd[1]: Starting User Runtime Directory /run/user/1000...
Jun 06 02:10:35 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cluster-ingress-02-config.yml" ingresses.v1.config.openshift.io/cluster -n
Jun 06 02:10:35 sno131.outbound.vz.bos2.lab systemd-logind[2202]: New session 1 of user core.
Jun 06 02:10:35 sno131.outbound.vz.bos2.lab systemd[1]: Finished User Runtime Directory /run/user/1000.
Jun 06 02:10:35 sno131.outbound.vz.bos2.lab systemd[1]: Starting User Manager for UID 1000...
Jun 06 02:10:35 sno131.outbound.vz.bos2.lab systemd[11674]: pam_unix(systemd-user:session): session opened for user core(uid=1000) by (uid=0)
Jun 06 02:10:35 sno131.outbound.vz.bos2.lab systemd[1]: Started User Manager for UID 1000.
Jun 06 02:10:35 sno131.outbound.vz.bos2.lab systemd[1]: Started Session 1 of User core.
Jun 06 02:10:35 sno131.outbound.vz.bos2.lab sshd[11652]: pam_unix(sshd:session): session opened for user core(uid=1000) by (uid=0)
Jun 06 02:10:35 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Updated status for "cluster-ingress-02-config.yml" ingresses.v1.config.openshift.io/cluster -n
Jun 06 02:10:35 sno131.outbound.vz.bos2.lab systemd[1]: Starting Hostname Service...
Jun 06 02:10:35 sno131.outbound.vz.bos2.lab systemd[1]: Started Hostname Service.
Jun 06 02:10:36 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Skipped "cluster-network-01-crd.yml" customresourcedefinitions.v1.apiextensions.k8s.io/networks.config.openshift.io -n  as it already exists
Jun 06 02:10:36 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cluster-network-02-config.yml" networks.v1.config.openshift.io/cluster -n
Jun 06 02:10:36 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cluster-proxy-01-config.yaml" proxies.v1.config.openshift.io/cluster -n
Jun 06 02:10:37 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Updated status for "cluster-proxy-01-config.yaml" proxies.v1.config.openshift.io/cluster -n
Jun 06 02:10:37 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cluster-role-binding-kube-apiserver.yaml" clusterrolebindings.v1.rbac.authorization.k8s.io/kube-apiserver -n
Jun 06 02:10:37 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cluster-role-kube-apiserver.yaml" clusterroles.v1.rbac.authorization.k8s.io/kube-apiserver -n
Jun 06 02:10:38 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:10:38 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cluster-scheduler-02-config.yml" schedulers.v1.config.openshift.io/cluster -n
Jun 06 02:10:38 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Updated status for "cluster-scheduler-02-config.yml" schedulers.v1.config.openshift.io/cluster -n
Jun 06 02:10:38 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "configmap-admin-kubeconfig-client-ca.yaml" configmaps.v1./admin-kubeconfig-client-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:39 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "configmap-csr-controller-ca.yaml" configmaps.v1./csr-controller-ca -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:10:39 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "configmap-kubelet-bootstrap-kubeconfig-ca.yaml" configmaps.v1./kubelet-bootstrap-kubeconfig -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:10:40 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "configmap-sa-token-signing-certs.yaml" configmaps.v1./sa-token-signing-certs -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:10:40 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "csr-bootstrap-role-binding.yaml" clusterrolebindings.v1.rbac.authorization.k8s.io/system-bootstrap-node-bootstrapper -n
Jun 06 02:10:40 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "cvo-overrides.yaml" clusterversions.v1.config.openshift.io/version -n openshift-cluster-version
Jun 06 02:10:41 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "dnsmasq-bootstrap-in-place.yaml" machineconfigs.v1.machineconfiguration.openshift.io/50-master-dnsmasq-configuration -n : the server could not find the requested resource
Jun 06 02:10:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:41.245911    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:41.247381    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:41.247397    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:41.247404    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:41 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-ca-bundle-configmap.yaml" configmaps.v1./etcd-ca-bundle -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:42 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-client-secret.yaml" secrets.v1./etcd-client -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:42 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-metric-client-secret.yaml" secrets.v1./etcd-metric-client -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:42 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-metric-serving-ca-configmap.yaml" configmaps.v1./etcd-metric-serving-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:43 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:10:43 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-metric-signer-secret.yaml" secrets.v1./etcd-metric-signer -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:43 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-serving-ca-configmap.yaml" configmaps.v1./etcd-serving-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:44 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-signer-secret.yaml" secrets.v1./etcd-signer -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:10:44" level=warning msg="Certificate verification is turned off. This is not recommended in production environments" file="inventory_session.go:126"
Jun 06 02:10:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:10:44" level=info msg="Query for next steps" file="step_processor.go:233" request_id=f4c0002c-b07b-4ef7-8ea1-0e3fd4fef01c
Jun 06 02:10:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:10:44Z" level=info msg="GetNextSteps infra_env: <5f396111-46ed-4173-9648-bc0a9a818139>, host: <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>, host status: <installing-in-progress>" func="github.com/openshift/assisted-service/internal/host/hostcommands.(*InstructionManager).GetNextSteps" file="/src/internal/host/hostcommands/instruction_manager.go:160" go-id=1597 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=f4c0002c-b07b-4ef7-8ea1-0e3fd4fef01c
Jun 06 02:10:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:10:44Z" level=info msg="No steps required for infraEnv <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>" func=github.com/openshift/assisted-service/internal/host/hostcommands.logSteps file="/src/internal/host/hostcommands/instruction_manager.go:284" go-id=1597 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=f4c0002c-b07b-4ef7-8ea1-0e3fd4fef01c
Jun 06 02:10:44 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "kube-apiserver-serving-ca-configmap.yaml" configmaps.v1./initial-kube-apiserver-server-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:44 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "kube-cloud-config.yaml" secrets.v1./kube-cloud-cfg -n kube-system
Jun 06 02:10:45 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "kube-system-configmap-root-ca.yaml" configmaps.v1./root-ca -n kube-system
Jun 06 02:10:45 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "machine-config-server-tls-secret.yaml" secrets.v1./machine-config-server-tls -n openshift-machine-config-operator: namespaces "openshift-machine-config-operator" not found
Jun 06 02:10:46 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "node-ip-hint-master.yaml" machineconfigs.v1.machineconfiguration.openshift.io/10-masters-node-ip-hint -n : the server could not find the requested resource
Jun 06 02:10:46 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:46.224766    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:46 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:46.227543    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:46 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:46.227566    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:46 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:46.227573    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:46 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "node-ip-hint-worker.yaml" machineconfigs.v1.machineconfiguration.openshift.io/10-workers-node-ip-hint -n : the server could not find the requested resource
Jun 06 02:10:46 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "openshift-config-secret-pull-secret.yaml" secrets.v1./pull-secret -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:47 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "openshift-etcd-svc.yaml" services.v1./etcd -n openshift-etcd
Jun 06 02:10:47 sno131.outbound.vz.bos2.lab approve-csr.sh[11805]: E0606 02:10:47.245124   11805 memcache.go:255] couldn't get resource list for monitoring.coreos.com/v1beta1: the server could not find the requested resource
Jun 06 02:10:47 sno131.outbound.vz.bos2.lab approve-csr.sh[11805]: E0606 02:10:47.245614   11805 memcache.go:255] couldn't get resource list for imageregistry.operator.openshift.io/v1: the server could not find the requested resource
Jun 06 02:10:47 sno131.outbound.vz.bos2.lab approve-csr.sh[11805]: E0606 02:10:47.245815   11805 memcache.go:255] couldn't get resource list for monitoring.coreos.com/v1alpha1: the server could not find the requested resource
Jun 06 02:10:47 sno131.outbound.vz.bos2.lab approve-csr.sh[11805]: No resources found
Jun 06 02:10:47 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "openshift-install-manifests.yaml" configmaps.v1./openshift-install-manifests -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:48 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "secret-aggregator-client-signer.yaml" secrets.v1./aggregator-client-signer -n openshift-kube-apiserver-operator
Jun 06 02:10:48 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:10:48 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "secret-bound-sa-token-signing-key.yaml" secrets.v1./next-bound-service-account-signing-key -n openshift-kube-apiserver-operator
Jun 06 02:10:48 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "secret-control-plane-client-signer.yaml" secrets.v1./kube-control-plane-signer -n openshift-kube-apiserver-operator
Jun 06 02:10:49 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "secret-csr-signer-signer.yaml" secrets.v1./csr-signer-signer -n openshift-kube-controller-manager-operator
Jun 06 02:10:49 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "secret-initial-kube-controller-manager-service-account-private-key.yaml" secrets.v1./initial-service-account-private-key -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:50 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "secret-kube-apiserver-to-kubelet-signer.yaml" secrets.v1./kube-apiserver-to-kubelet-signer -n openshift-kube-apiserver-operator
Jun 06 02:10:50 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "secret-loadbalancer-serving-signer.yaml" secrets.v1./loadbalancer-serving-signer -n openshift-kube-apiserver-operator
Jun 06 02:10:50 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "secret-localhost-serving-signer.yaml" secrets.v1./localhost-serving-signer -n openshift-kube-apiserver-operator
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "secret-service-network-serving-signer.yaml" secrets.v1./service-network-serving-signer -n openshift-kube-apiserver-operator
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: [#1] failed to create some manifests:
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "0000_00_cluster-version-operator_01_adminack_configmap.yaml": failed to create configmaps.v1./admin-acks -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "0000_00_cluster-version-operator_01_admingate_configmap.yaml": failed to create configmaps.v1./admin-gates -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "0000_00_cluster-version-operator_03_deployment.yaml": failed to create deployments.v1.apps/cluster-version-operator -n openshift-cluster-version: deployments.apps "cluster-version-operator" is forbidden: quota.openshift.io/ClusterResourceQuota: caches not synchronized
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "00_etcd-endpoints-cm.yaml": failed to create configmaps.v1./etcd-endpoints -n openshift-etcd: namespaces "openshift-etcd" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "01-container-mount-ns-and-kubelet-conf-master-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/container-mount-namespace-and-kubelet-conf-master -n : the server could not find the requested resource
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "02-master-workload-partitioning-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/02-master-workload-partitioning -n : the server could not find the requested resource
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "04-accelerated-container-startup-master-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/04-accelerated-container-startup-master -n : the server could not find the requested resource
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "05-kdump-config-master-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/05-kdump-config-master -n : the server could not find the requested resource
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "06-kdump-master-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/06-kdump-enable-master -n : the server could not find the requested resource
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "50-masters-chrony-configuration.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/50-masters-chrony-configuration -n : the server could not find the requested resource
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "50-workers-chrony-configuration.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/50-workers-chrony-configuration -n : the server could not find the requested resource
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "99-crio-disable-wipe-master-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/99-crio-disable-wipe-master -n : the server could not find the requested resource
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "99_openshift-cluster-api_master-user-data-secret.yaml": failed to create secrets.v1./master-user-data -n openshift-machine-api: namespaces "openshift-machine-api" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "99_openshift-cluster-api_worker-user-data-secret.yaml": failed to create secrets.v1./worker-user-data -n openshift-machine-api: namespaces "openshift-machine-api" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "99_openshift-machineconfig_99-master-ssh.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/99-master-ssh -n : the server could not find the requested resource
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "99_openshift-machineconfig_99-worker-ssh.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/99-worker-ssh -n : the server could not find the requested resource
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "AmqSubscription-0.yaml": unable to get REST mapping for "AmqSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "AmqSubscriptionOperGroup-0.yaml": unable to get REST mapping for "AmqSubscriptionOperGroup-0.yaml": no matches for kind "OperatorGroup" in version "operators.coreos.com/v1"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "PtpSubscription-0.yaml": unable to get REST mapping for "PtpSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "PtpSubscriptionOperGroup-0.yaml": unable to get REST mapping for "PtpSubscriptionOperGroup-0.yaml": no matches for kind "OperatorGroup" in version "operators.coreos.com/v1"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "SriovSubscription-0.yaml": unable to get REST mapping for "SriovSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "SriovSubscriptionOperGroup-0.yaml": unable to get REST mapping for "SriovSubscriptionOperGroup-0.yaml": no matches for kind "OperatorGroup" in version "operators.coreos.com/v1"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "StorageOperGroup-0.yaml": unable to get REST mapping for "StorageOperGroup-0.yaml": no matches for kind "OperatorGroup" in version "operators.coreos.com/v1"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "StorageSubscription-0.yaml": unable to get REST mapping for "StorageSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "assisted-installer-controller-cm.yaml": failed to create configmaps.v1./assisted-installer-controller-config -n assisted-installer: namespaces "assisted-installer" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "configmap-admin-kubeconfig-client-ca.yaml": failed to create configmaps.v1./admin-kubeconfig-client-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "configmap-csr-controller-ca.yaml": failed to create configmaps.v1./csr-controller-ca -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "configmap-kubelet-bootstrap-kubeconfig-ca.yaml": failed to create configmaps.v1./kubelet-bootstrap-kubeconfig -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "configmap-sa-token-signing-certs.yaml": failed to create configmaps.v1./sa-token-signing-certs -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "dnsmasq-bootstrap-in-place.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/50-master-dnsmasq-configuration -n : the server could not find the requested resource
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "enable-crun-master-0.yaml": unable to get REST mapping for "enable-crun-master-0.yaml": no matches for kind "ContainerRuntimeConfig" in version "machineconfiguration.openshift.io/v1"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-ca-bundle-configmap.yaml": failed to create configmaps.v1./etcd-ca-bundle -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-client-secret.yaml": failed to create secrets.v1./etcd-client -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-metric-client-secret.yaml": failed to create secrets.v1./etcd-metric-client -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-metric-serving-ca-configmap.yaml": failed to create configmaps.v1./etcd-metric-serving-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-metric-signer-secret.yaml": failed to create secrets.v1./etcd-metric-signer -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-serving-ca-configmap.yaml": failed to create configmaps.v1./etcd-serving-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-signer-secret.yaml": failed to create secrets.v1./etcd-signer -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "kube-apiserver-serving-ca-configmap.yaml": failed to create configmaps.v1./initial-kube-apiserver-server-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "machine-config-server-tls-secret.yaml": failed to create secrets.v1./machine-config-server-tls -n openshift-machine-config-operator: namespaces "openshift-machine-config-operator" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "node-ip-hint-master.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/10-masters-node-ip-hint -n : the server could not find the requested resource
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "node-ip-hint-worker.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/10-workers-node-ip-hint -n : the server could not find the requested resource
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "openshift-config-secret-pull-secret.yaml": failed to create secrets.v1./pull-secret -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "openshift-install-manifests.yaml": failed to create configmaps.v1./openshift-install-manifests -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "secret-initial-kube-controller-manager-service-account-private-key.yaml": failed to create secrets.v1./initial-service-account-private-key -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:51.224573    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:51.225361    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:51.225386    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:51.225392    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:51.254228    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:51.254822    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:51.254837    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:51.254842    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab sshd[11652]: pam_unix(sshd:session): session closed for user core
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab systemd[1]: session-1.scope: Deactivated successfully.
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab systemd-logind[2202]: Session 1 logged out. Waiting for processes to exit.
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab systemd-logind[2202]: Removed session 1.
Jun 06 02:10:51 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "0000_00_cluster-version-operator_01_adminack_configmap.yaml" configmaps.v1./admin-acks -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:52 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "0000_00_cluster-version-operator_01_admingate_configmap.yaml" configmaps.v1./admin-gates -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:10:52 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:52.225384    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:10:52 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:52.226474    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:10:52 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:52.226491    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:10:52 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:10:52.226496    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:10:52 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_00_cluster-version-operator_03_deployment.yaml" deployments.v1.apps/cluster-version-operator -n openshift-cluster-version
Jun 06 02:10:52 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "00_etcd-endpoints-cm.yaml" configmaps.v1./etcd-endpoints -n openshift-etcd
Jun 06 02:10:53 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "01-container-mount-ns-and-kubelet-conf-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/container-mount-namespace-and-kubelet-conf-master -n : the server could not find the requested resource
Jun 06 02:10:53 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:10:53 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "02-master-workload-partitioning-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/02-master-workload-partitioning -n : the server could not find the requested resource
Jun 06 02:10:53 sno131.outbound.vz.bos2.lab sshd[11866]: main: sshd: ssh-rsa algorithm is disabled
Jun 06 02:10:54 sno131.outbound.vz.bos2.lab sshd[11866]: Accepted publickey for core from 192.168.58.15 port 44574 ssh2: RSA SHA256:ltZ47o/fDXlJWgy139p4iY4V9dEJkhH4Iqtjrso8YTQ
Jun 06 02:10:54 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "04-accelerated-container-startup-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/04-accelerated-container-startup-master -n : the server could not find the requested resource
Jun 06 02:10:54 sno131.outbound.vz.bos2.lab systemd-logind[2202]: New session 3 of user core.
Jun 06 02:10:54 sno131.outbound.vz.bos2.lab systemd[1]: Started Session 3 of User core.
Jun 06 02:10:54 sno131.outbound.vz.bos2.lab sshd[11866]: pam_unix(sshd:session): session opened for user core(uid=1000) by (uid=0)
Jun 06 02:10:54 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "05-kdump-config-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/05-kdump-config-master -n : the server could not find the requested resource
Jun 06 02:10:54 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "06-kdump-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/06-kdump-enable-master -n : the server could not find the requested resource
Jun 06 02:10:55 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "50-masters-chrony-configuration.yaml" machineconfigs.v1.machineconfiguration.openshift.io/50-masters-chrony-configuration -n : the server could not find the requested resource
Jun 06 02:10:55 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "50-workers-chrony-configuration.yaml" machineconfigs.v1.machineconfiguration.openshift.io/50-workers-chrony-configuration -n : the server could not find the requested resource
Jun 06 02:10:56 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "99-crio-disable-wipe-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/99-crio-disable-wipe-master -n : the server could not find the requested resource
Jun 06 02:10:56 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "99_openshift-cluster-api_master-user-data-secret.yaml" secrets.v1./master-user-data -n openshift-machine-api: namespaces "openshift-machine-api" not found
Jun 06 02:10:56 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "99_openshift-cluster-api_worker-user-data-secret.yaml" secrets.v1./worker-user-data -n openshift-machine-api: namespaces "openshift-machine-api" not found
Jun 06 02:10:57 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "99_openshift-machineconfig_99-master-ssh.yaml" machineconfigs.v1.machineconfiguration.openshift.io/99-master-ssh -n : the server could not find the requested resource
Jun 06 02:10:57 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "99_openshift-machineconfig_99-worker-ssh.yaml" machineconfigs.v1.machineconfiguration.openshift.io/99-worker-ssh -n : the server could not find the requested resource
Jun 06 02:10:58 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "assisted-installer-controller-cm.yaml" configmaps.v1./assisted-installer-controller-config -n assisted-installer
Jun 06 02:10:58 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:10:58 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "configmap-admin-kubeconfig-client-ca.yaml" configmaps.v1./admin-kubeconfig-client-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:10:58 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "configmap-csr-controller-ca.yaml" configmaps.v1./csr-controller-ca -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:10:59 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "configmap-kubelet-bootstrap-kubeconfig-ca.yaml" configmaps.v1./kubelet-bootstrap-kubeconfig -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:10:59 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "configmap-sa-token-signing-certs.yaml" configmaps.v1./sa-token-signing-certs -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:11:00 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "dnsmasq-bootstrap-in-place.yaml" machineconfigs.v1.machineconfiguration.openshift.io/50-master-dnsmasq-configuration -n : the server could not find the requested resource
Jun 06 02:11:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:00.224572    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:11:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:00.225577    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:11:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:00.225596    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:11:00 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:00.225602    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:11:00 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-ca-bundle-configmap.yaml" configmaps.v1./etcd-ca-bundle -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:00 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-client-secret.yaml" secrets.v1./etcd-client -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:01.120117    7266 kubelet_getters.go:182] "Pod status updated" pod="openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:11:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:01.120197    7266 kubelet_getters.go:182] "Pod status updated" pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:11:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:01.120217    7266 kubelet_getters.go:182] "Pod status updated" pod="openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:11:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:01.120235    7266 kubelet_getters.go:182] "Pod status updated" pod="openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:11:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:01.120253    7266 kubelet_getters.go:182] "Pod status updated" pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:11:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:01.120272    7266 kubelet_getters.go:182] "Pod status updated" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:11:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:01.120289    7266 kubelet_getters.go:182] "Pod status updated" pod="kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:11:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:01.261541    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:11:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:01.262336    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:11:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:01.262351    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:11:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:01.262356    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:11:01 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-metric-client-secret.yaml" secrets.v1./etcd-metric-client -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:01 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-metric-serving-ca-configmap.yaml" configmaps.v1./etcd-metric-serving-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:02 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-metric-signer-secret.yaml" secrets.v1./etcd-metric-signer -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:02 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-serving-ca-configmap.yaml" configmaps.v1./etcd-serving-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:02 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-signer-secret.yaml" secrets.v1./etcd-signer -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:03 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "kube-apiserver-serving-ca-configmap.yaml" configmaps.v1./initial-kube-apiserver-server-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:03 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:11:03 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "machine-config-server-tls-secret.yaml" secrets.v1./machine-config-server-tls -n openshift-machine-config-operator
Jun 06 02:11:04 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "node-ip-hint-master.yaml" machineconfigs.v1.machineconfiguration.openshift.io/10-masters-node-ip-hint -n : the server could not find the requested resource
Jun 06 02:11:04 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "node-ip-hint-worker.yaml" machineconfigs.v1.machineconfiguration.openshift.io/10-workers-node-ip-hint -n : the server could not find the requested resource
Jun 06 02:11:04 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "openshift-config-secret-pull-secret.yaml" secrets.v1./pull-secret -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "openshift-install-manifests.yaml" configmaps.v1./openshift-install-manifests -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "secret-initial-kube-controller-manager-service-account-private-key.yaml" secrets.v1./initial-service-account-private-key -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: [#2] failed to create some manifests:
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "0000_00_cluster-version-operator_01_adminack_configmap.yaml": failed to create configmaps.v1./admin-acks -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "0000_00_cluster-version-operator_01_admingate_configmap.yaml": failed to create configmaps.v1./admin-gates -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "01-container-mount-ns-and-kubelet-conf-master-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/container-mount-namespace-and-kubelet-conf-master -n : the server could not find the requested resource
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "02-master-workload-partitioning-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/02-master-workload-partitioning -n : the server could not find the requested resource
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "04-accelerated-container-startup-master-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/04-accelerated-container-startup-master -n : the server could not find the requested resource
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "05-kdump-config-master-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/05-kdump-config-master -n : the server could not find the requested resource
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "06-kdump-master-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/06-kdump-enable-master -n : the server could not find the requested resource
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "50-masters-chrony-configuration.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/50-masters-chrony-configuration -n : the server could not find the requested resource
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "50-workers-chrony-configuration.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/50-workers-chrony-configuration -n : the server could not find the requested resource
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "99-crio-disable-wipe-master-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/99-crio-disable-wipe-master -n : the server could not find the requested resource
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "99_openshift-cluster-api_master-user-data-secret.yaml": failed to create secrets.v1./master-user-data -n openshift-machine-api: namespaces "openshift-machine-api" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "99_openshift-cluster-api_worker-user-data-secret.yaml": failed to create secrets.v1./worker-user-data -n openshift-machine-api: namespaces "openshift-machine-api" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "99_openshift-machineconfig_99-master-ssh.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/99-master-ssh -n : the server could not find the requested resource
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "99_openshift-machineconfig_99-worker-ssh.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/99-worker-ssh -n : the server could not find the requested resource
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "AmqSubscription-0.yaml": unable to get REST mapping for "AmqSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "AmqSubscriptionOperGroup-0.yaml": unable to get REST mapping for "AmqSubscriptionOperGroup-0.yaml": no matches for kind "OperatorGroup" in version "operators.coreos.com/v1"
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "PtpSubscription-0.yaml": unable to get REST mapping for "PtpSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "PtpSubscriptionOperGroup-0.yaml": unable to get REST mapping for "PtpSubscriptionOperGroup-0.yaml": no matches for kind "OperatorGroup" in version "operators.coreos.com/v1"
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "SriovSubscription-0.yaml": unable to get REST mapping for "SriovSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "SriovSubscriptionOperGroup-0.yaml": unable to get REST mapping for "SriovSubscriptionOperGroup-0.yaml": no matches for kind "OperatorGroup" in version "operators.coreos.com/v1"
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "StorageOperGroup-0.yaml": unable to get REST mapping for "StorageOperGroup-0.yaml": no matches for kind "OperatorGroup" in version "operators.coreos.com/v1"
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "StorageSubscription-0.yaml": unable to get REST mapping for "StorageSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "configmap-admin-kubeconfig-client-ca.yaml": failed to create configmaps.v1./admin-kubeconfig-client-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "configmap-csr-controller-ca.yaml": failed to create configmaps.v1./csr-controller-ca -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "configmap-kubelet-bootstrap-kubeconfig-ca.yaml": failed to create configmaps.v1./kubelet-bootstrap-kubeconfig -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "configmap-sa-token-signing-certs.yaml": failed to create configmaps.v1./sa-token-signing-certs -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "dnsmasq-bootstrap-in-place.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/50-master-dnsmasq-configuration -n : the server could not find the requested resource
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "enable-crun-master-0.yaml": unable to get REST mapping for "enable-crun-master-0.yaml": no matches for kind "ContainerRuntimeConfig" in version "machineconfiguration.openshift.io/v1"
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-ca-bundle-configmap.yaml": failed to create configmaps.v1./etcd-ca-bundle -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-client-secret.yaml": failed to create secrets.v1./etcd-client -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-metric-client-secret.yaml": failed to create secrets.v1./etcd-metric-client -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-metric-serving-ca-configmap.yaml": failed to create configmaps.v1./etcd-metric-serving-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-metric-signer-secret.yaml": failed to create secrets.v1./etcd-metric-signer -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-serving-ca-configmap.yaml": failed to create configmaps.v1./etcd-serving-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-signer-secret.yaml": failed to create secrets.v1./etcd-signer -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "kube-apiserver-serving-ca-configmap.yaml": failed to create configmaps.v1./initial-kube-apiserver-server-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "node-ip-hint-master.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/10-masters-node-ip-hint -n : the server could not find the requested resource
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "node-ip-hint-worker.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/10-workers-node-ip-hint -n : the server could not find the requested resource
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "openshift-config-secret-pull-secret.yaml": failed to create secrets.v1./pull-secret -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "openshift-install-manifests.yaml": failed to create configmaps.v1./openshift-install-manifests -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:05 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "secret-initial-kube-controller-manager-service-account-private-key.yaml": failed to create secrets.v1./initial-service-account-private-key -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:06 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "0000_00_cluster-version-operator_01_adminack_configmap.yaml" configmaps.v1./admin-acks -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:06 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "0000_00_cluster-version-operator_01_admingate_configmap.yaml" configmaps.v1./admin-gates -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:11:06 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "01-container-mount-ns-and-kubelet-conf-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/container-mount-namespace-and-kubelet-conf-master -n : the server could not find the requested resource
Jun 06 02:11:07 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "02-master-workload-partitioning-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/02-master-workload-partitioning -n : the server could not find the requested resource
Jun 06 02:11:07 sno131.outbound.vz.bos2.lab approve-csr.sh[12001]: No resources found
Jun 06 02:11:07 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "04-accelerated-container-startup-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/04-accelerated-container-startup-master -n : the server could not find the requested resource
Jun 06 02:11:08 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "05-kdump-config-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/05-kdump-config-master -n : the server could not find the requested resource
Jun 06 02:11:08 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:11:08 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "06-kdump-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/06-kdump-enable-master -n : the server could not find the requested resource
Jun 06 02:11:08 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "50-masters-chrony-configuration.yaml" machineconfigs.v1.machineconfiguration.openshift.io/50-masters-chrony-configuration -n : the server could not find the requested resource
Jun 06 02:11:09 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "50-workers-chrony-configuration.yaml" machineconfigs.v1.machineconfiguration.openshift.io/50-workers-chrony-configuration -n : the server could not find the requested resource
Jun 06 02:11:09 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "99-crio-disable-wipe-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/99-crio-disable-wipe-master -n : the server could not find the requested resource
Jun 06 02:11:10 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "99_openshift-cluster-api_master-user-data-secret.yaml" secrets.v1./master-user-data -n openshift-machine-api: namespaces "openshift-machine-api" not found
Jun 06 02:11:10 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "99_openshift-cluster-api_worker-user-data-secret.yaml" secrets.v1./worker-user-data -n openshift-machine-api: namespaces "openshift-machine-api" not found
Jun 06 02:11:10 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "99_openshift-machineconfig_99-master-ssh.yaml" machineconfigs.v1.machineconfiguration.openshift.io/99-master-ssh -n : the server could not find the requested resource
Jun 06 02:11:11 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "99_openshift-machineconfig_99-worker-ssh.yaml" machineconfigs.v1.machineconfiguration.openshift.io/99-worker-ssh -n : the server could not find the requested resource
Jun 06 02:11:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:11.271447    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:11:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:11.272435    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:11:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:11.272452    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:11:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:11.272460    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:11:11 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "AmqSubscriptionOperGroup-0.yaml" operatorgroups.v1.operators.coreos.com/amq-router -n amq-router
Jun 06 02:11:12 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "PtpSubscriptionOperGroup-0.yaml" operatorgroups.v1.operators.coreos.com/ptp-operators -n openshift-ptp
Jun 06 02:11:12 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "SriovSubscriptionOperGroup-0.yaml" operatorgroups.v1.operators.coreos.com/sriov-network-operators -n openshift-sriov-network-operator
Jun 06 02:11:12 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "StorageOperGroup-0.yaml" operatorgroups.v1.operators.coreos.com/openshift-local-storage -n openshift-local-storage
Jun 06 02:11:13 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "configmap-admin-kubeconfig-client-ca.yaml" configmaps.v1./admin-kubeconfig-client-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:13 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:11:13 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "configmap-csr-controller-ca.yaml" configmaps.v1./csr-controller-ca -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:11:14 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "configmap-kubelet-bootstrap-kubeconfig-ca.yaml" configmaps.v1./kubelet-bootstrap-kubeconfig -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:11:14 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "configmap-sa-token-signing-certs.yaml" configmaps.v1./sa-token-signing-certs -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:11:14 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "dnsmasq-bootstrap-in-place.yaml" machineconfigs.v1.machineconfiguration.openshift.io/50-master-dnsmasq-configuration -n
Jun 06 02:11:15 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-ca-bundle-configmap.yaml" configmaps.v1./etcd-ca-bundle -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:15 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-client-secret.yaml" secrets.v1./etcd-client -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:16 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-metric-client-secret.yaml" secrets.v1./etcd-metric-client -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:16 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-metric-serving-ca-configmap.yaml" configmaps.v1./etcd-metric-serving-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:16 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-metric-signer-secret.yaml" secrets.v1./etcd-metric-signer -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:17 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-serving-ca-configmap.yaml" configmaps.v1./etcd-serving-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:17 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "etcd-signer-secret.yaml" secrets.v1./etcd-signer -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:18 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "kube-apiserver-serving-ca-configmap.yaml" configmaps.v1./initial-kube-apiserver-server-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:18 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:11:18 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "node-ip-hint-master.yaml" machineconfigs.v1.machineconfiguration.openshift.io/10-masters-node-ip-hint -n
Jun 06 02:11:18 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "node-ip-hint-worker.yaml" machineconfigs.v1.machineconfiguration.openshift.io/10-workers-node-ip-hint -n
Jun 06 02:11:19 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:19.225518    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:11:19 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:19.228000    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:11:19 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:19.228203    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:11:19 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:19.228212    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:11:19 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "openshift-config-secret-pull-secret.yaml" secrets.v1./pull-secret -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:19 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Failed to create "openshift-install-manifests.yaml" configmaps.v1./openshift-install-manifests -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "secret-initial-kube-controller-manager-service-account-private-key.yaml" secrets.v1./initial-service-account-private-key -n openshift-config
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: [#3] failed to create some manifests:
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "0000_00_cluster-version-operator_01_adminack_configmap.yaml": failed to create configmaps.v1./admin-acks -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "0000_00_cluster-version-operator_01_admingate_configmap.yaml": failed to create configmaps.v1./admin-gates -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "01-container-mount-ns-and-kubelet-conf-master-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/container-mount-namespace-and-kubelet-conf-master -n : the server could not find the requested resource
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "02-master-workload-partitioning-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/02-master-workload-partitioning -n : the server could not find the requested resource
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "04-accelerated-container-startup-master-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/04-accelerated-container-startup-master -n : the server could not find the requested resource
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "05-kdump-config-master-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/05-kdump-config-master -n : the server could not find the requested resource
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "06-kdump-master-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/06-kdump-enable-master -n : the server could not find the requested resource
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "50-masters-chrony-configuration.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/50-masters-chrony-configuration -n : the server could not find the requested resource
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "50-workers-chrony-configuration.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/50-workers-chrony-configuration -n : the server could not find the requested resource
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "99-crio-disable-wipe-master-0.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/99-crio-disable-wipe-master -n : the server could not find the requested resource
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "99_openshift-cluster-api_master-user-data-secret.yaml": failed to create secrets.v1./master-user-data -n openshift-machine-api: namespaces "openshift-machine-api" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "99_openshift-cluster-api_worker-user-data-secret.yaml": failed to create secrets.v1./worker-user-data -n openshift-machine-api: namespaces "openshift-machine-api" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "99_openshift-machineconfig_99-master-ssh.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/99-master-ssh -n : the server could not find the requested resource
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "99_openshift-machineconfig_99-worker-ssh.yaml": failed to create machineconfigs.v1.machineconfiguration.openshift.io/99-worker-ssh -n : the server could not find the requested resource
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "AmqSubscription-0.yaml": unable to get REST mapping for "AmqSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "PtpSubscription-0.yaml": unable to get REST mapping for "PtpSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "SriovSubscription-0.yaml": unable to get REST mapping for "SriovSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "StorageSubscription-0.yaml": unable to get REST mapping for "StorageSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "configmap-admin-kubeconfig-client-ca.yaml": failed to create configmaps.v1./admin-kubeconfig-client-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "configmap-csr-controller-ca.yaml": failed to create configmaps.v1./csr-controller-ca -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "configmap-kubelet-bootstrap-kubeconfig-ca.yaml": failed to create configmaps.v1./kubelet-bootstrap-kubeconfig -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "configmap-sa-token-signing-certs.yaml": failed to create configmaps.v1./sa-token-signing-certs -n openshift-config-managed: namespaces "openshift-config-managed" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "enable-crun-master-0.yaml": unable to get REST mapping for "enable-crun-master-0.yaml": no matches for kind "ContainerRuntimeConfig" in version "machineconfiguration.openshift.io/v1"
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-ca-bundle-configmap.yaml": failed to create configmaps.v1./etcd-ca-bundle -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-client-secret.yaml": failed to create secrets.v1./etcd-client -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-metric-client-secret.yaml": failed to create secrets.v1./etcd-metric-client -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-metric-serving-ca-configmap.yaml": failed to create configmaps.v1./etcd-metric-serving-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-metric-signer-secret.yaml": failed to create secrets.v1./etcd-metric-signer -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-serving-ca-configmap.yaml": failed to create configmaps.v1./etcd-serving-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "etcd-signer-secret.yaml": failed to create secrets.v1./etcd-signer -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "kube-apiserver-serving-ca-configmap.yaml": failed to create configmaps.v1./initial-kube-apiserver-server-ca -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "openshift-config-secret-pull-secret.yaml": failed to create secrets.v1./pull-secret -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "openshift-install-manifests.yaml": failed to create configmaps.v1./openshift-install-manifests -n openshift-config: namespaces "openshift-config" not found
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_00_cluster-version-operator_01_adminack_configmap.yaml" configmaps.v1./admin-acks -n openshift-config
Jun 06 02:11:20 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "0000_00_cluster-version-operator_01_admingate_configmap.yaml" configmaps.v1./admin-gates -n openshift-config-managed
Jun 06 02:11:21 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "01-container-mount-ns-and-kubelet-conf-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/container-mount-namespace-and-kubelet-conf-master -n
Jun 06 02:11:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:21.278437    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:11:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:21.279160    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:11:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:21.279176    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:11:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:21.279183    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:11:21 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "02-master-workload-partitioning-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/02-master-workload-partitioning -n
Jun 06 02:11:22 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "04-accelerated-container-startup-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/04-accelerated-container-startup-master -n
Jun 06 02:11:22 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "05-kdump-config-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/05-kdump-config-master -n
Jun 06 02:11:22 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "06-kdump-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/06-kdump-enable-master -n
Jun 06 02:11:23 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "50-masters-chrony-configuration.yaml" machineconfigs.v1.machineconfiguration.openshift.io/50-masters-chrony-configuration -n
Jun 06 02:11:23 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:11:23 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "50-workers-chrony-configuration.yaml" machineconfigs.v1.machineconfiguration.openshift.io/50-workers-chrony-configuration -n
Jun 06 02:11:24 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "99-crio-disable-wipe-master-0.yaml" machineconfigs.v1.machineconfiguration.openshift.io/99-crio-disable-wipe-master -n
Jun 06 02:11:24 sno131.outbound.vz.bos2.lab systemd[1]: systemd-hostnamed.service: Deactivated successfully.
Jun 06 02:11:24 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "99_openshift-cluster-api_master-user-data-secret.yaml" secrets.v1./master-user-data -n openshift-machine-api
Jun 06 02:11:24 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "99_openshift-cluster-api_worker-user-data-secret.yaml" secrets.v1./worker-user-data -n openshift-machine-api
Jun 06 02:11:25 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "99_openshift-machineconfig_99-master-ssh.yaml" machineconfigs.v1.machineconfiguration.openshift.io/99-master-ssh -n
Jun 06 02:11:25 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:25.225136    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:11:25 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:25.226283    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:11:25 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:25.226303    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:11:25 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:25.226309    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:11:25 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "99_openshift-machineconfig_99-worker-ssh.yaml" machineconfigs.v1.machineconfiguration.openshift.io/99-worker-ssh -n
Jun 06 02:11:26 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "configmap-admin-kubeconfig-client-ca.yaml" configmaps.v1./admin-kubeconfig-client-ca -n openshift-config
Jun 06 02:11:26 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "configmap-csr-controller-ca.yaml" configmaps.v1./csr-controller-ca -n openshift-config-managed
Jun 06 02:11:26 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "configmap-kubelet-bootstrap-kubeconfig-ca.yaml" configmaps.v1./kubelet-bootstrap-kubeconfig -n openshift-config-managed
Jun 06 02:11:27 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "configmap-sa-token-signing-certs.yaml" configmaps.v1./sa-token-signing-certs -n openshift-config-managed
Jun 06 02:11:27 sno131.outbound.vz.bos2.lab approve-csr.sh[12149]: No resources found
Jun 06 02:11:27 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "enable-crun-master-0.yaml" containerruntimeconfigs.v1.machineconfiguration.openshift.io/enable-crun-master -n
Jun 06 02:11:28 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "etcd-ca-bundle-configmap.yaml" configmaps.v1./etcd-ca-bundle -n openshift-config
Jun 06 02:11:28 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:11:28 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "etcd-client-secret.yaml" secrets.v1./etcd-client -n openshift-config
Jun 06 02:11:28 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "etcd-metric-client-secret.yaml" secrets.v1./etcd-metric-client -n openshift-config
Jun 06 02:11:29 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "etcd-metric-serving-ca-configmap.yaml" configmaps.v1./etcd-metric-serving-ca -n openshift-config
Jun 06 02:11:29 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "etcd-metric-signer-secret.yaml" secrets.v1./etcd-metric-signer -n openshift-config
Jun 06 02:11:30 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "etcd-serving-ca-configmap.yaml" configmaps.v1./etcd-serving-ca -n openshift-config
Jun 06 02:11:30 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "etcd-signer-secret.yaml" secrets.v1./etcd-signer -n openshift-config
Jun 06 02:11:30 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "kube-apiserver-serving-ca-configmap.yaml" configmaps.v1./initial-kube-apiserver-server-ca -n openshift-config
Jun 06 02:11:31 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "openshift-config-secret-pull-secret.yaml" secrets.v1./pull-secret -n openshift-config
Jun 06 02:11:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:31.225133    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:11:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:31.225925    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:11:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:31.225943    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:11:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:31.225950    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:11:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:31.285441    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:11:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:31.286488    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:11:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:31.286504    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:11:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:31.286509    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:11:31 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "openshift-install-manifests.yaml" configmaps.v1./openshift-install-manifests -n openshift-config
Jun 06 02:11:31 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: [#4] failed to create some manifests:
Jun 06 02:11:31 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "AmqSubscription-0.yaml": unable to get REST mapping for "AmqSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:11:31 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "PtpSubscription-0.yaml": unable to get REST mapping for "PtpSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:11:31 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "SriovSubscription-0.yaml": unable to get REST mapping for "SriovSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:11:31 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: "StorageSubscription-0.yaml": unable to get REST mapping for "StorageSubscription-0.yaml": no matches for kind "Subscription" in version "operators.coreos.com/v1alpha1"
Jun 06 02:11:32 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "AmqSubscription-0.yaml" subscriptions.v1alpha1.operators.coreos.com/amq7-interconnect-subscription -n amq-router
Jun 06 02:11:32 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "PtpSubscription-0.yaml" subscriptions.v1alpha1.operators.coreos.com/ptp-operator-subscription -n openshift-ptp
Jun 06 02:11:32 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "SriovSubscription-0.yaml" subscriptions.v1alpha1.operators.coreos.com/sriov-network-operator-subscription -n openshift-sriov-network-operator
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Tearing down temporary bootstrap control plane...
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Created "StorageSubscription-0.yaml" subscriptions.v1alpha1.operators.coreos.com/local-storage-operator -n openshift-local-storage
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.215696    7266 kubelet.go:2229] "SyncLoop REMOVE" source="file" pods="[openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab]"
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.215725    7266 kubelet.go:2229] "SyncLoop REMOVE" source="file" pods="[openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab]"
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.215736    7266 kubelet.go:2229] "SyncLoop REMOVE" source="file" pods="[openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab]"
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.215746    7266 kubelet.go:2229] "SyncLoop REMOVE" source="file" pods="[kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab]"
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.215756    7266 kubelet.go:2229] "SyncLoop REMOVE" source="file" pods="[kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab]"
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.215850    7266 kuberuntime_container.go:709] "Killing container with a grace period" pod="kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab" podUID=19832dab34653130be3733c41dfa1508 containerName="kube-scheduler" containerID="cri-o://f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414" gracePeriod=30
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.216037    7266 kuberuntime_container.go:709] "Killing container with a grace period" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab" podUID=082e8bbce893a060432eb17e10fe12e8 containerName="kube-controller-manager" containerID="cri-o://01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae" gracePeriod=30
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.216071    7266 kuberuntime_container.go:709] "Killing container with a grace period" pod="kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab" podUID=082e8bbce893a060432eb17e10fe12e8 containerName="cluster-policy-controller" containerID="cri-o://b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd" gracePeriod=30
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.216136    7266 kuberuntime_container.go:709] "Killing container with a grace period" pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab" podUID=25c1466359fc8946267f656756984e2d containerName="kube-apiserver" containerID="cri-o://ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239" gracePeriod=15
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.216166414Z" level=info msg="Stopping container: f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414 (timeout: 30s)" id=f931851b-05c5-4956-a7cf-7c272e7c84ae name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.216190    7266 kuberuntime_container.go:709] "Killing container with a grace period" pod="openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab" podUID=25c1466359fc8946267f656756984e2d containerName="kube-apiserver-insecure-readyz" containerID="cri-o://23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127" gracePeriod=15
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.216232    7266 kuberuntime_container.go:709] "Killing container with a grace period" pod="openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab" podUID=8d6c6c46375623d290ed5865fa13e701 containerName="cloud-credential-operator" containerID="cri-o://6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d" gracePeriod=30
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.216238    7266 kuberuntime_container.go:709] "Killing container with a grace period" pod="openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab" podUID=64a8f6eb7c6e0cf4f9d62c71924bd30a containerName="cluster-version-operator" containerID="cri-o://66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754" gracePeriod=130
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.216301814Z" level=info msg="Stopping container: 23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127 (timeout: 15s)" id=c00aef17-33fe-4e08-8462-1909c5a1e628 name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.216395013Z" level=info msg="Stopping container: 66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754 (timeout: 130s)" id=74368732-b85d-4e88-a8fe-4e3f16792f4f name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.216631720Z" level=info msg="Stopping container: 01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae (timeout: 30s)" id=e94d7727-196b-4e05-8a93-86dd1961701f name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.216648077Z" level=info msg="Stopping container: ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239 (timeout: 15s)" id=6b618b4d-ae83-4ceb-bd1b-6beb05831348 name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.216662228Z" level=info msg="Stopping container: b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd (timeout: 30s)" id=2d6a65ed-ca86-48fa-b682-94d435b7bf66 name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.216637099Z" level=info msg="Stopping container: 6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d (timeout: 30s)" id=b2a8b5e5-f050-4c69-b309-74d25949ab70 name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: libpod-82f70280578565865ed2e407b334a7cfc18496689d4a510108e44d1062430b27.scope: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: crio-6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d.scope: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: crio-conmon-66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754.scope: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: crio-conmon-f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414.scope: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: crio-66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754.scope: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: crio-66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754.scope: Consumed 2.683s CPU time.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: crio-conmon-23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127.scope: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: crio-conmon-01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae.scope: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: crio-f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414.scope: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: crio-23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127.scope: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: crio-01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae.scope: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: crio-01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae.scope: Consumed 2.845s CPU time.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: crio-conmon-6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d.scope: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-82f70280578565865ed2e407b334a7cfc18496689d4a510108e44d1062430b27-userdata-shm.mount: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-302803ab65ae8c150ccf478b1b291b7b43daf9eaa8dfcc30ed374beca1c722f1-merged.mount: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab bootkube.sh[10695]: Sending bootstrap-finished event.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Stop etcd static pod by moving the manifest
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.327629    7266 kubelet.go:2229] "SyncLoop REMOVE" source="file" pods="[openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab]"
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.327765    7266 kuberuntime_container.go:709] "Killing container with a grace period" pod="openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab" podUID=ec8f40282bde3cfe7272900cd1fbf751 containerName="etcdctl" containerID="cri-o://9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357" gracePeriod=30
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.327843    7266 kuberuntime_container.go:709] "Killing container with a grace period" pod="openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab" podUID=ec8f40282bde3cfe7272900cd1fbf751 containerName="etcd" containerID="cri-o://92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd" gracePeriod=30
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.328140692Z" level=info msg="Stopping container: 92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd (timeout: 30s)" id=45c1a4ce-66f7-40e4-b8c6-d4b6748b38f6 name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.328244705Z" level=info msg="Stopping container: 9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357 (timeout: 30s)" id=2ac1e92e-c1d5-4d94-b28e-3c1f51c49cf4 name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-1b53b2ccd43f0d9aae5ec65ab2088e0b9d067047c2853b5c8033c7fcab95c27a-merged.mount: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: crio-92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd.scope: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: crio-92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd.scope: Consumed 4.548s CPU time.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: crio-conmon-92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd.scope: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.361878831Z" level=info msg="Stopped container 66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754: openshift-cluster-version/bootstrap-cluster-version-operator-sno131.outbound.vz.bos2.lab/cluster-version-operator" id=74368732-b85d-4e88-a8fe-4e3f16792f4f name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.362366964Z" level=info msg="Stopping pod sandbox: c825a9ddba5029fed0dff1a640f8dcd9d0d5c0c48e82d1a2fe05e16e927a534f" id=586401a2-234e-4952-bcf4-a27400f26196 name=/runtime.v1.RuntimeService/StopPodSandbox
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.363306931Z" level=info msg="Stopped pod sandbox: c825a9ddba5029fed0dff1a640f8dcd9d0d5c0c48e82d1a2fe05e16e927a534f" id=586401a2-234e-4952-bcf4-a27400f26196 name=/runtime.v1.RuntimeService/StopPodSandbox
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-db55240169b191815b17c8a791eb3f21337e545ffafffc338a8e2e134c104983-merged.mount: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: run-netns-464f4a1d\x2d627f\x2d4138\x2d983d\x2da710617e8596.mount: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: run-ipcns-464f4a1d\x2d627f\x2d4138\x2d983d\x2da710617e8596.mount: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: run-utsns-464f4a1d\x2d627f\x2d4138\x2d983d\x2da710617e8596.mount: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: run-containers-storage-overlay\x2dcontainers-c825a9ddba5029fed0dff1a640f8dcd9d0d5c0c48e82d1a2fe05e16e927a534f-userdata-shm.mount: Deactivated successfully.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.371919028Z" level=info msg="Stopped container 23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127: openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab/kube-apiserver-insecure-readyz" id=c00aef17-33fe-4e08-8462-1909c5a1e628 name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.381900684Z" level=info msg="Stopped container f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414: kube-system/bootstrap-kube-scheduler-sno131.outbound.vz.bos2.lab/kube-scheduler" id=f931851b-05c5-4956-a7cf-7c272e7c84ae name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.382115981Z" level=info msg="Stopping pod sandbox: af66091721aacdb548a64ff56916ca8446e308f2e6c9891728173b7c266a9874" id=b5bd11c6-1125-49f5-92c9-841b53147dc3 name=/runtime.v1.RuntimeService/StopPodSandbox
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.383020775Z" level=info msg="Stopped container 01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae: kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab/kube-controller-manager" id=e94d7727-196b-4e05-8a93-86dd1961701f name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.383342212Z" level=info msg="Stopped pod sandbox: af66091721aacdb548a64ff56916ca8446e308f2e6c9891728173b7c266a9874" id=b5bd11c6-1125-49f5-92c9-841b53147dc3 name=/runtime.v1.RuntimeService/StopPodSandbox
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.393927688Z" level=info msg="Stopped container 6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d: openshift-cloud-credential-operator/cloud-credential-operator-sno131.outbound.vz.bos2.lab/cloud-credential-operator" id=b2a8b5e5-f050-4c69-b309-74d25949ab70 name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.394146714Z" level=info msg="Stopping pod sandbox: e99b0b1ca36c59595a541e34b3b07590e21ab03aef3257fd1bb1a42dcb61b605" id=34b1247e-db48-4aea-b678-efc43c4b38d5 name=/runtime.v1.RuntimeService/StopPodSandbox
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.394611828Z" level=info msg="Stopped pod sandbox: e99b0b1ca36c59595a541e34b3b07590e21ab03aef3257fd1bb1a42dcb61b605" id=34b1247e-db48-4aea-b678-efc43c4b38d5 name=/runtime.v1.RuntimeService/StopPodSandbox
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.480422    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"logs\" (UniqueName: \"kubernetes.io/host-path/19832dab34653130be3733c41dfa1508-logs\") pod \"19832dab34653130be3733c41dfa1508\" (UID: \"19832dab34653130be3733c41dfa1508\") "
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.480472    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/64a8f6eb7c6e0cf4f9d62c71924bd30a-etc-ssl-certs" (OuterVolumeSpecName: "etc-ssl-certs") pod "64a8f6eb7c6e0cf4f9d62c71924bd30a" (UID: "64a8f6eb7c6e0cf4f9d62c71924bd30a"). InnerVolumeSpecName "etc-ssl-certs". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.480505    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/19832dab34653130be3733c41dfa1508-logs" (OuterVolumeSpecName: "logs") pod "19832dab34653130be3733c41dfa1508" (UID: "19832dab34653130be3733c41dfa1508"). InnerVolumeSpecName "logs". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.480536    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"etc-ssl-certs\" (UniqueName: \"kubernetes.io/host-path/64a8f6eb7c6e0cf4f9d62c71924bd30a-etc-ssl-certs\") pod \"64a8f6eb7c6e0cf4f9d62c71924bd30a\" (UID: \"64a8f6eb7c6e0cf4f9d62c71924bd30a\") "
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.480566    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/64a8f6eb7c6e0cf4f9d62c71924bd30a-kubeconfig\") pod \"64a8f6eb7c6e0cf4f9d62c71924bd30a\" (UID: \"64a8f6eb7c6e0cf4f9d62c71924bd30a\") "
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.480578    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/19832dab34653130be3733c41dfa1508-secrets\") pod \"19832dab34653130be3733c41dfa1508\" (UID: \"19832dab34653130be3733c41dfa1508\") "
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.480603    7266 reconciler_common.go:295] "Volume detached for volume \"logs\" (UniqueName: \"kubernetes.io/host-path/19832dab34653130be3733c41dfa1508-logs\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.480611    7266 reconciler_common.go:295] "Volume detached for volume \"etc-ssl-certs\" (UniqueName: \"kubernetes.io/host-path/64a8f6eb7c6e0cf4f9d62c71924bd30a-etc-ssl-certs\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.480627    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/19832dab34653130be3733c41dfa1508-secrets" (OuterVolumeSpecName: "secrets") pod "19832dab34653130be3733c41dfa1508" (UID: "19832dab34653130be3733c41dfa1508"). InnerVolumeSpecName "secrets". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.480643    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/64a8f6eb7c6e0cf4f9d62c71924bd30a-kubeconfig" (OuterVolumeSpecName: "kubeconfig") pod "64a8f6eb7c6e0cf4f9d62c71924bd30a" (UID: "64a8f6eb7c6e0cf4f9d62c71924bd30a"). InnerVolumeSpecName "kubeconfig". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:33.481147587Z" level=info msg="Stopped container 92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd: openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab/etcd" id=45c1a4ce-66f7-40e4-b8c6-d4b6748b38f6 name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.498093    7266 generic.go:332] "Generic (PLEG): container finished" podID=64a8f6eb7c6e0cf4f9d62c71924bd30a containerID="66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754" exitCode=0
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.498122    7266 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="c825a9ddba5029fed0dff1a640f8dcd9d0d5c0c48e82d1a2fe05e16e927a534f"
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.499188    7266 generic.go:332] "Generic (PLEG): container finished" podID=ec8f40282bde3cfe7272900cd1fbf751 containerID="92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd" exitCode=0
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.499556    7266 generic.go:332] "Generic (PLEG): container finished" podID=19832dab34653130be3733c41dfa1508 containerID="f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414" exitCode=0
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.499637    7266 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="af66091721aacdb548a64ff56916ca8446e308f2e6c9891728173b7c266a9874"
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.500452    7266 generic.go:332] "Generic (PLEG): container finished" podID=082e8bbce893a060432eb17e10fe12e8 containerID="01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae" exitCode=0
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.501110    7266 generic.go:332] "Generic (PLEG): container finished" podID=25c1466359fc8946267f656756984e2d containerID="23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127" exitCode=0
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: Removed slice libcontainer container kubepods-besteffort-pod64a8f6eb7c6e0cf4f9d62c71924bd30a.slice.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.502085    7266 generic.go:332] "Generic (PLEG): container finished" podID=8d6c6c46375623d290ed5865fa13e701 containerID="6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d" exitCode=0
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.502102    7266 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="e99b0b1ca36c59595a541e34b3b07590e21ab03aef3257fd1bb1a42dcb61b605"
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: kubepods-besteffort-pod64a8f6eb7c6e0cf4f9d62c71924bd30a.slice: Consumed 2.683s CPU time.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: Removed slice libcontainer container kubepods-burstable-pod19832dab34653130be3733c41dfa1508.slice.
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.581156    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/8d6c6c46375623d290ed5865fa13e701-secrets\") pod \"8d6c6c46375623d290ed5865fa13e701\" (UID: \"8d6c6c46375623d290ed5865fa13e701\") "
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.581186    7266 reconciler_common.go:295] "Volume detached for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/64a8f6eb7c6e0cf4f9d62c71924bd30a-kubeconfig\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.581193    7266 reconciler_common.go:295] "Volume detached for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/19832dab34653130be3733c41dfa1508-secrets\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.581216    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/8d6c6c46375623d290ed5865fa13e701-secrets" (OuterVolumeSpecName: "secrets") pod "8d6c6c46375623d290ed5865fa13e701" (UID: "8d6c6c46375623d290ed5865fa13e701"). InnerVolumeSpecName "secrets". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:33.681442    7266 reconciler_common.go:295] "Volume detached for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/8d6c6c46375623d290ed5865fa13e701-secrets\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:33 sno131.outbound.vz.bos2.lab systemd[1]: Removed slice libcontainer container kubepods-besteffort-pod8d6c6c46375623d290ed5865fa13e701.slice.
Jun 06 02:11:34 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-c1ed2a8706985d12eaa617f34eeb00a619f2fb7730618f2dced9b2634db128be-merged.mount: Deactivated successfully.
Jun 06 02:11:34 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-a09b343db1df670f88299f973a12cbc14da0af70aa4e8a45226e71ae7bce30e3-merged.mount: Deactivated successfully.
Jun 06 02:11:34 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-f8016ee611222f361d104dfcaeb1d3ca7df98f4c68b2cdf679fbd7cd2f1ed49f-merged.mount: Deactivated successfully.
Jun 06 02:11:34 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-0ac4bb550f723d054927a5c594fd4aa93f7e6060e704db91c1acd650ab7be28c-merged.mount: Deactivated successfully.
Jun 06 02:11:34 sno131.outbound.vz.bos2.lab systemd[1]: run-netns-f562094f\x2d53b3\x2d481f\x2d91c5\x2d705a3a55ac64.mount: Deactivated successfully.
Jun 06 02:11:34 sno131.outbound.vz.bos2.lab systemd[1]: run-ipcns-f562094f\x2d53b3\x2d481f\x2d91c5\x2d705a3a55ac64.mount: Deactivated successfully.
Jun 06 02:11:34 sno131.outbound.vz.bos2.lab systemd[1]: run-utsns-f562094f\x2d53b3\x2d481f\x2d91c5\x2d705a3a55ac64.mount: Deactivated successfully.
Jun 06 02:11:34 sno131.outbound.vz.bos2.lab systemd[1]: run-containers-storage-overlay\x2dcontainers-af66091721aacdb548a64ff56916ca8446e308f2e6c9891728173b7c266a9874-userdata-shm.mount: Deactivated successfully.
Jun 06 02:11:34 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-aaaf1abdd08051a5165e01e35a4b31e7f5708421b5b8200e6a86864dfda81fa6-merged.mount: Deactivated successfully.
Jun 06 02:11:34 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-05a6fc824fc69b7a4b56b5aad7ac469417bcb5bfb9effde43bb7a42d33ba652d-merged.mount: Deactivated successfully.
Jun 06 02:11:34 sno131.outbound.vz.bos2.lab systemd[1]: run-netns-699ee735\x2d5af8\x2d484d\x2d9b24\x2d7c0e0df15633.mount: Deactivated successfully.
Jun 06 02:11:34 sno131.outbound.vz.bos2.lab systemd[1]: run-ipcns-699ee735\x2d5af8\x2d484d\x2d9b24\x2d7c0e0df15633.mount: Deactivated successfully.
Jun 06 02:11:34 sno131.outbound.vz.bos2.lab systemd[1]: run-utsns-699ee735\x2d5af8\x2d484d\x2d9b24\x2d7c0e0df15633.mount: Deactivated successfully.
Jun 06 02:11:34 sno131.outbound.vz.bos2.lab systemd[1]: run-containers-storage-overlay\x2dcontainers-e99b0b1ca36c59595a541e34b3b07590e21ab03aef3257fd1bb1a42dcb61b605-userdata-shm.mount: Deactivated successfully.
Jun 06 02:11:34 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-282d5f9e63cf795513b0f27e1a0d8ada97154af3ea55b091b0614410828dcf63-merged.mount: Deactivated successfully.
Jun 06 02:11:35 sno131.outbound.vz.bos2.lab bootkube.sh[12297]: 9d66a0400f36d       quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cf6d1bd2361806194ed27dcae9da890e59977a8629144a4b2f4dbd497c7f80c9   2 minutes ago        Running             etcdctl                     0                   a6a6b4c7a25b3       etcd-bootstrap-member-sno131.outbound.vz.bos2.lab
Jun 06 02:11:35 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Waiting for etcd to go down
Jun 06 02:11:35 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:35.227178    7266 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=19832dab34653130be3733c41dfa1508 path="/var/lib/kubelet/pods/19832dab34653130be3733c41dfa1508/volumes"
Jun 06 02:11:35 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:35.227283    7266 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=64a8f6eb7c6e0cf4f9d62c71924bd30a path="/var/lib/kubelet/pods/64a8f6eb7c6e0cf4f9d62c71924bd30a/volumes"
Jun 06 02:11:35 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:35.227362    7266 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=8d6c6c46375623d290ed5865fa13e701 path="/var/lib/kubelet/pods/8d6c6c46375623d290ed5865fa13e701/volumes"
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab systemd[1]: crio-ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239.scope: Deactivated successfully.
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab systemd[1]: crio-ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239.scope: Consumed 41.789s CPU time.
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab systemd[1]: crio-conmon-ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239.scope: Deactivated successfully.
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-ae094b84ecb6d2e9af07c59250d637d3c9550556b6de410fec375ead5e38ddc3-merged.mount: Deactivated successfully.
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:37.403163030Z" level=info msg="Stopped container ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239: openshift-kube-apiserver/bootstrap-kube-apiserver-sno131.outbound.vz.bos2.lab/kube-apiserver" id=6b618b4d-ae83-4ceb-bd1b-6beb05831348 name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:37.403537783Z" level=info msg="Stopping pod sandbox: 7a04a2e79f7e04f2e0774716267d2db0ecf05f84aad4f5dc618aa6ee4bf839a5" id=8b9671db-c078-4064-9957-1f2cf25d29c1 name=/runtime.v1.RuntimeService/StopPodSandbox
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:37.404723006Z" level=info msg="Stopped pod sandbox: 7a04a2e79f7e04f2e0774716267d2db0ecf05f84aad4f5dc618aa6ee4bf839a5" id=8b9671db-c078-4064-9957-1f2cf25d29c1 name=/runtime.v1.RuntimeService/StopPodSandbox
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-8790192e3316ab8d300bbddba2baca51bcb39300fbcd36243894d132888d35f9-merged.mount: Deactivated successfully.
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab systemd[1]: run-netns-8859bd34\x2d14e6\x2d4e71\x2d937e\x2d3402524491fe.mount: Deactivated successfully.
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab systemd[1]: run-ipcns-8859bd34\x2d14e6\x2d4e71\x2d937e\x2d3402524491fe.mount: Deactivated successfully.
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab systemd[1]: run-utsns-8859bd34\x2d14e6\x2d4e71\x2d937e\x2d3402524491fe.mount: Deactivated successfully.
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab systemd[1]: run-containers-storage-overlay\x2dcontainers-7a04a2e79f7e04f2e0774716267d2db0ecf05f84aad4f5dc618aa6ee4bf839a5-userdata-shm.mount: Deactivated successfully.
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.510321    7266 generic.go:332] "Generic (PLEG): container finished" podID=25c1466359fc8946267f656756984e2d containerID="ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239" exitCode=0
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.510342    7266 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="7a04a2e79f7e04f2e0774716267d2db0ecf05f84aad4f5dc618aa6ee4bf839a5"
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.610973    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"logs\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-logs\") pod \"25c1466359fc8946267f656756984e2d\" (UID: \"25c1466359fc8946267f656756984e2d\") "
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.610993    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"etc-kubernetes-cloud\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-etc-kubernetes-cloud\") pod \"25c1466359fc8946267f656756984e2d\" (UID: \"25c1466359fc8946267f656756984e2d\") "
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.611004    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"ssl-certs-host\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-ssl-certs-host\") pod \"25c1466359fc8946267f656756984e2d\" (UID: \"25c1466359fc8946267f656756984e2d\") "
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.611015    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-secrets\") pod \"25c1466359fc8946267f656756984e2d\" (UID: \"25c1466359fc8946267f656756984e2d\") "
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.611025    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"audit-dir\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-audit-dir\") pod \"25c1466359fc8946267f656756984e2d\" (UID: \"25c1466359fc8946267f656756984e2d\") "
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.611036    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"config\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-config\") pod \"25c1466359fc8946267f656756984e2d\" (UID: \"25c1466359fc8946267f656756984e2d\") "
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.611049    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-etc-kubernetes-cloud" (OuterVolumeSpecName: "etc-kubernetes-cloud") pod "25c1466359fc8946267f656756984e2d" (UID: "25c1466359fc8946267f656756984e2d"). InnerVolumeSpecName "etc-kubernetes-cloud". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.611061    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-config" (OuterVolumeSpecName: "config") pod "25c1466359fc8946267f656756984e2d" (UID: "25c1466359fc8946267f656756984e2d"). InnerVolumeSpecName "config". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.611075    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-ssl-certs-host" (OuterVolumeSpecName: "ssl-certs-host") pod "25c1466359fc8946267f656756984e2d" (UID: "25c1466359fc8946267f656756984e2d"). InnerVolumeSpecName "ssl-certs-host". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.611075    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-logs" (OuterVolumeSpecName: "logs") pod "25c1466359fc8946267f656756984e2d" (UID: "25c1466359fc8946267f656756984e2d"). InnerVolumeSpecName "logs". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.611086    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-secrets" (OuterVolumeSpecName: "secrets") pod "25c1466359fc8946267f656756984e2d" (UID: "25c1466359fc8946267f656756984e2d"). InnerVolumeSpecName "secrets". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.611094    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-audit-dir" (OuterVolumeSpecName: "audit-dir") pod "25c1466359fc8946267f656756984e2d" (UID: "25c1466359fc8946267f656756984e2d"). InnerVolumeSpecName "audit-dir". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.711575    7266 reconciler_common.go:295] "Volume detached for volume \"config\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-config\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.711589    7266 reconciler_common.go:295] "Volume detached for volume \"audit-dir\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-audit-dir\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.711595    7266 reconciler_common.go:295] "Volume detached for volume \"logs\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-logs\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.711603    7266 reconciler_common.go:295] "Volume detached for volume \"etc-kubernetes-cloud\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-etc-kubernetes-cloud\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.711614    7266 reconciler_common.go:295] "Volume detached for volume \"ssl-certs-host\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-ssl-certs-host\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:37.711620    7266 reconciler_common.go:295] "Volume detached for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/25c1466359fc8946267f656756984e2d-secrets\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab systemd[1]: Removed slice libcontainer container kubepods-burstable-pod25c1466359fc8946267f656756984e2d.slice.
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab systemd[1]: kubepods-burstable-pod25c1466359fc8946267f656756984e2d.slice: Consumed 41.859s CPU time.
Jun 06 02:11:37 sno131.outbound.vz.bos2.lab sshd[12523]: main: sshd: ssh-rsa algorithm is disabled
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab sshd[12523]: Accepted publickey for core from 192.168.58.15 port 44612 ssh2: RSA SHA256:ltZ47o/fDXlJWgy139p4iY4V9dEJkhH4Iqtjrso8YTQ
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd-logind[2202]: New session 4 of user core.
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd[1]: Started Session 4 of User core.
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab sshd[12523]: pam_unix(sshd:session): session opened for user core(uid=1000) by (uid=0)
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab sshd[12523]: pam_unix(sshd:session): session closed for user core
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd[1]: session-4.scope: Deactivated successfully.
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd-logind[2202]: Session 4 logged out. Waiting for processes to exit.
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd-logind[2202]: Removed session 4.
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd[1]: crio-b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd.scope: Deactivated successfully.
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd[1]: crio-b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd.scope: Consumed 1.168s CPU time.
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd[1]: crio-conmon-b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd.scope: Deactivated successfully.
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-09db7d4a1db1dcbbcd39471ee178cf3455a461e09ee6772fe4f0435afb5100d7-merged.mount: Deactivated successfully.
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:38.331137014Z" level=info msg="Stopped container b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd: kube-system/bootstrap-kube-controller-manager-sno131.outbound.vz.bos2.lab/cluster-policy-controller" id=2d6a65ed-ca86-48fa-b682-94d435b7bf66 name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:38.331785066Z" level=info msg="Stopping pod sandbox: 0a31ad41e175257b843cae11b2bb1dee259adc3f3c874a51ab46e710f71184d0" id=93382ae9-96e3-4a1a-bbc6-60e337532725 name=/runtime.v1.RuntimeService/StopPodSandbox
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:11:38.332319676Z" level=info msg="Stopped pod sandbox: 0a31ad41e175257b843cae11b2bb1dee259adc3f3c874a51ab46e710f71184d0" id=93382ae9-96e3-4a1a-bbc6-60e337532725 name=/runtime.v1.RuntimeService/StopPodSandbox
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-74efaf18479c38e870dad1722139b2954129cf36cdf45f62410f838afc698df5-merged.mount: Deactivated successfully.
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd[1]: run-netns-dc9f9c76\x2def73\x2d48c9\x2db97f\x2d9fa2d1cb6569.mount: Deactivated successfully.
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd[1]: run-ipcns-dc9f9c76\x2def73\x2d48c9\x2db97f\x2d9fa2d1cb6569.mount: Deactivated successfully.
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd[1]: run-utsns-dc9f9c76\x2def73\x2d48c9\x2db97f\x2d9fa2d1cb6569.mount: Deactivated successfully.
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd[1]: run-containers-storage-overlay\x2dcontainers-0a31ad41e175257b843cae11b2bb1dee259adc3f3c874a51ab46e710f71184d0-userdata-shm.mount: Deactivated successfully.
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.512828    7266 generic.go:332] "Generic (PLEG): container finished" podID=082e8bbce893a060432eb17e10fe12e8 containerID="b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd" exitCode=0
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.512849    7266 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="0a31ad41e175257b843cae11b2bb1dee259adc3f3c874a51ab46e710f71184d0"
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.515183    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"config\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-config\") pod \"082e8bbce893a060432eb17e10fe12e8\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") "
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.515196    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-secrets\") pod \"082e8bbce893a060432eb17e10fe12e8\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") "
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.515212    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"logs\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-logs\") pod \"082e8bbce893a060432eb17e10fe12e8\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") "
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.515224    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"ssl-certs-host\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-ssl-certs-host\") pod \"082e8bbce893a060432eb17e10fe12e8\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") "
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.515235    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"etc-kubernetes-cloud\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-etc-kubernetes-cloud\") pod \"082e8bbce893a060432eb17e10fe12e8\" (UID: \"082e8bbce893a060432eb17e10fe12e8\") "
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.515261    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-etc-kubernetes-cloud" (OuterVolumeSpecName: "etc-kubernetes-cloud") pod "082e8bbce893a060432eb17e10fe12e8" (UID: "082e8bbce893a060432eb17e10fe12e8"). InnerVolumeSpecName "etc-kubernetes-cloud". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.515269    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-secrets" (OuterVolumeSpecName: "secrets") pod "082e8bbce893a060432eb17e10fe12e8" (UID: "082e8bbce893a060432eb17e10fe12e8"). InnerVolumeSpecName "secrets". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.515282    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-ssl-certs-host" (OuterVolumeSpecName: "ssl-certs-host") pod "082e8bbce893a060432eb17e10fe12e8" (UID: "082e8bbce893a060432eb17e10fe12e8"). InnerVolumeSpecName "ssl-certs-host". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.515275    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-logs" (OuterVolumeSpecName: "logs") pod "082e8bbce893a060432eb17e10fe12e8" (UID: "082e8bbce893a060432eb17e10fe12e8"). InnerVolumeSpecName "logs". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.515292    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-config" (OuterVolumeSpecName: "config") pod "082e8bbce893a060432eb17e10fe12e8" (UID: "082e8bbce893a060432eb17e10fe12e8"). InnerVolumeSpecName "config". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.615880    7266 reconciler_common.go:295] "Volume detached for volume \"config\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-config\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.615893    7266 reconciler_common.go:295] "Volume detached for volume \"logs\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-logs\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.615900    7266 reconciler_common.go:295] "Volume detached for volume \"secrets\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-secrets\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.615908    7266 reconciler_common.go:295] "Volume detached for volume \"ssl-certs-host\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-ssl-certs-host\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:38.615914    7266 reconciler_common.go:295] "Volume detached for volume \"etc-kubernetes-cloud\" (UniqueName: \"kubernetes.io/host-path/082e8bbce893a060432eb17e10fe12e8-etc-kubernetes-cloud\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd[1]: Removed slice libcontainer container kubepods-burstable-pod082e8bbce893a060432eb17e10fe12e8.slice.
Jun 06 02:11:38 sno131.outbound.vz.bos2.lab systemd[1]: kubepods-burstable-pod082e8bbce893a060432eb17e10fe12e8.slice: Consumed 4.013s CPU time.
Jun 06 02:11:39 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:39.227447    7266 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=082e8bbce893a060432eb17e10fe12e8 path="/var/lib/kubelet/pods/082e8bbce893a060432eb17e10fe12e8/volumes"
Jun 06 02:11:39 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:39.227560    7266 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=25c1466359fc8946267f656756984e2d path="/var/lib/kubelet/pods/25c1466359fc8946267f656756984e2d/volumes"
Jun 06 02:11:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:41.293665    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:11:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:41.294687    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:11:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:41.294701    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:11:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:41.294706    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:11:43 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:11:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:11:44" level=warning msg="Certificate verification is turned off. This is not recommended in production environments" file="inventory_session.go:126"
Jun 06 02:11:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:11:44" level=info msg="Query for next steps" file="step_processor.go:233" request_id=b5a4296a-f432-4a5c-a9b1-6053baf011ba
Jun 06 02:11:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:11:44Z" level=info msg="GetNextSteps infra_env: <5f396111-46ed-4173-9648-bc0a9a818139>, host: <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>, host status: <installing-in-progress>" func="github.com/openshift/assisted-service/internal/host/hostcommands.(*InstructionManager).GetNextSteps" file="/src/internal/host/hostcommands/instruction_manager.go:160" go-id=1750 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=b5a4296a-f432-4a5c-a9b1-6053baf011ba
Jun 06 02:11:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:11:44Z" level=info msg="No steps required for infraEnv <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>" func=github.com/openshift/assisted-service/internal/host/hostcommands.logSteps file="/src/internal/host/hostcommands/instruction_manager.go:284" go-id=1750 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=b5a4296a-f432-4a5c-a9b1-6053baf011ba
Jun 06 02:11:45 sno131.outbound.vz.bos2.lab bootkube.sh[12628]: 9d66a0400f36d       quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cf6d1bd2361806194ed27dcae9da890e59977a8629144a4b2f4dbd497c7f80c9   2 minutes ago       Running             etcdctl                 0                   a6a6b4c7a25b3       etcd-bootstrap-member-sno131.outbound.vz.bos2.lab
Jun 06 02:11:45 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Waiting for etcd to go down
Jun 06 02:11:47 sno131.outbound.vz.bos2.lab approve-csr.sh[12641]: E0606 02:11:47.410899   12641 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:11:47 sno131.outbound.vz.bos2.lab approve-csr.sh[12641]: E0606 02:11:47.411155   12641 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:11:47 sno131.outbound.vz.bos2.lab approve-csr.sh[12641]: E0606 02:11:47.413052   12641 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:11:47 sno131.outbound.vz.bos2.lab approve-csr.sh[12641]: E0606 02:11:47.413563   12641 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:11:47 sno131.outbound.vz.bos2.lab approve-csr.sh[12641]: E0606 02:11:47.414918   12641 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:11:47 sno131.outbound.vz.bos2.lab approve-csr.sh[12641]: The connection to the server localhost:6443 was refused - did you specify the right host or port?
Jun 06 02:11:48 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:11:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017509.9157] policy: auto-activating connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:11:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017509.9165] device (eno1): Activation: starting connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:11:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017509.9166] device (eno1): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'managed')
Jun 06 02:11:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017509.9167] device (eno1): state change: prepare -> config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:11:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017509.9176] device (eno1): state change: config -> ip-config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:11:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017509.9184] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:11:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:51.300234    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:11:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:51.303041    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:11:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:51.303058    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:11:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:51.303065    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:11:52 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:52.225174    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:11:52 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:52.225812    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:11:52 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:52.225826    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:11:52 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:11:52.225831    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:11:53 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:11:55 sno131.outbound.vz.bos2.lab bootkube.sh[12716]: 9d66a0400f36d       quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cf6d1bd2361806194ed27dcae9da890e59977a8629144a4b2f4dbd497c7f80c9   2 minutes ago       Running             etcdctl                 0                   a6a6b4c7a25b3       etcd-bootstrap-member-sno131.outbound.vz.bos2.lab
Jun 06 02:11:55 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Waiting for etcd to go down
Jun 06 02:11:58 sno131.outbound.vz.bos2.lab sshd[12730]: main: sshd: ssh-rsa algorithm is disabled
Jun 06 02:11:58 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:11:58 sno131.outbound.vz.bos2.lab sshd[12730]: Accepted publickey for core from 192.168.58.15 port 44642 ssh2: RSA SHA256:ltZ47o/fDXlJWgy139p4iY4V9dEJkhH4Iqtjrso8YTQ
Jun 06 02:11:58 sno131.outbound.vz.bos2.lab systemd-logind[2202]: New session 5 of user core.
Jun 06 02:11:58 sno131.outbound.vz.bos2.lab systemd[1]: Started Session 5 of User core.
Jun 06 02:11:58 sno131.outbound.vz.bos2.lab sshd[12730]: pam_unix(sshd:session): session opened for user core(uid=1000) by (uid=0)
Jun 06 02:11:58 sno131.outbound.vz.bos2.lab sshd[12730]: pam_unix(sshd:session): session closed for user core
Jun 06 02:11:58 sno131.outbound.vz.bos2.lab systemd[1]: session-5.scope: Deactivated successfully.
Jun 06 02:11:58 sno131.outbound.vz.bos2.lab systemd-logind[2202]: Session 5 logged out. Waiting for processes to exit.
Jun 06 02:11:58 sno131.outbound.vz.bos2.lab systemd-logind[2202]: Removed session 5.
Jun 06 02:12:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:01.121036    7266 kubelet_getters.go:182] "Pod status updated" pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:12:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:01.309019    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:12:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:01.309697    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:12:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:01.309712    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:12:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:01.309718    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:12:03.334752722Z" level=warning msg="Stopping container 9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357 with stop signal timed out: timeout reached after 30 seconds waiting for container process to exit" id=2ac1e92e-c1d5-4d94-b28e-3c1f51c49cf4 name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab systemd[1]: crio-9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357.scope: Deactivated successfully.
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab conmon[9417]: conmon 9d66a0400f36da29300b <ninfo>: container 9435 exited with status 137
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab conmon[9417]: conmon 9d66a0400f36da29300b <nwarn>: Failed to open cgroups file: /sys/fs/cgroup/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podec8f40282bde3cfe7272900cd1fbf751.slice/crio-9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357.scope/memory.events
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab systemd[1]: crio-conmon-9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357.scope: Deactivated successfully.
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-e83cdbd92d8f6bc3fb035bc0011da3fbf0357bf545b97a68254ed273d1b829d2-merged.mount: Deactivated successfully.
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:12:03.390878702Z" level=info msg="Stopped container 9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357: openshift-etcd/etcd-bootstrap-member-sno131.outbound.vz.bos2.lab/etcdctl" id=2ac1e92e-c1d5-4d94-b28e-3c1f51c49cf4 name=/runtime.v1.RuntimeService/StopContainer
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:12:03.391221099Z" level=info msg="Stopping pod sandbox: a6a6b4c7a25b3682ed086883c31ecd3eccc53e7d114c1affa094cbb4b947f6d0" id=b13a81dc-a858-42b3-8ab1-a0010301f086 name=/runtime.v1.RuntimeService/StopPodSandbox
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:12:03.392443113Z" level=info msg="Stopped pod sandbox: a6a6b4c7a25b3682ed086883c31ecd3eccc53e7d114c1affa094cbb4b947f6d0" id=b13a81dc-a858-42b3-8ab1-a0010301f086 name=/runtime.v1.RuntimeService/StopPodSandbox
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-1d1800171771ebb364eb38240572fc04360cd5bb94d078c7be09319dac98242d-merged.mount: Deactivated successfully.
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab systemd[1]: run-netns-e02ba844\x2dce69\x2d4ceb\x2d81ba\x2d691a21586e0e.mount: Deactivated successfully.
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab systemd[1]: run-ipcns-e02ba844\x2dce69\x2d4ceb\x2d81ba\x2d691a21586e0e.mount: Deactivated successfully.
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab systemd[1]: run-utsns-e02ba844\x2dce69\x2d4ceb\x2d81ba\x2d691a21586e0e.mount: Deactivated successfully.
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab systemd[1]: run-containers-storage-overlay\x2dcontainers-a6a6b4c7a25b3682ed086883c31ecd3eccc53e7d114c1affa094cbb4b947f6d0-userdata-shm.mount: Deactivated successfully.
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:03.407546    7266 logs.go:323] "Finished parsing log file" path="/var/log/pods/openshift-etcd_etcd-bootstrap-member-sno131.outbound.vz.bos2.lab_ec8f40282bde3cfe7272900cd1fbf751/etcdctl/0.log"
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:03.500336    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"data-dir\" (UniqueName: \"kubernetes.io/host-path/ec8f40282bde3cfe7272900cd1fbf751-data-dir\") pod \"ec8f40282bde3cfe7272900cd1fbf751\" (UID: \"ec8f40282bde3cfe7272900cd1fbf751\") "
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:03.500356    7266 reconciler_common.go:169] "operationExecutor.UnmountVolume started for volume \"certs\" (UniqueName: \"kubernetes.io/host-path/ec8f40282bde3cfe7272900cd1fbf751-certs\") pod \"ec8f40282bde3cfe7272900cd1fbf751\" (UID: \"ec8f40282bde3cfe7272900cd1fbf751\") "
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:03.500387    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/ec8f40282bde3cfe7272900cd1fbf751-certs" (OuterVolumeSpecName: "certs") pod "ec8f40282bde3cfe7272900cd1fbf751" (UID: "ec8f40282bde3cfe7272900cd1fbf751"). InnerVolumeSpecName "certs". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:03.500401    7266 operation_generator.go:900] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/ec8f40282bde3cfe7272900cd1fbf751-data-dir" (OuterVolumeSpecName: "data-dir") pod "ec8f40282bde3cfe7272900cd1fbf751" (UID: "ec8f40282bde3cfe7272900cd1fbf751"). InnerVolumeSpecName "data-dir". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:03.557233    7266 logs.go:323] "Finished parsing log file" path="/var/log/pods/openshift-etcd_etcd-bootstrap-member-sno131.outbound.vz.bos2.lab_ec8f40282bde3cfe7272900cd1fbf751/etcdctl/0.log"
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:03.557260    7266 generic.go:332] "Generic (PLEG): container finished" podID=ec8f40282bde3cfe7272900cd1fbf751 containerID="9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357" exitCode=137
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:03.557277    7266 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="a6a6b4c7a25b3682ed086883c31ecd3eccc53e7d114c1affa094cbb4b947f6d0"
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab systemd[1]: Removed slice libcontainer container kubepods-burstable-podec8f40282bde3cfe7272900cd1fbf751.slice.
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab systemd[1]: kubepods-burstable-podec8f40282bde3cfe7272900cd1fbf751.slice: Consumed 4.562s CPU time.
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:03.601314    7266 reconciler_common.go:295] "Volume detached for volume \"data-dir\" (UniqueName: \"kubernetes.io/host-path/ec8f40282bde3cfe7272900cd1fbf751-data-dir\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:12:03 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:03.601326    7266 reconciler_common.go:295] "Volume detached for volume \"certs\" (UniqueName: \"kubernetes.io/host-path/ec8f40282bde3cfe7272900cd1fbf751-certs\") on node \"sno131.outbound.vz.bos2.lab\" DevicePath \"\""
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:05.226926    7266 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=ec8f40282bde3cfe7272900cd1fbf751 path="/var/lib/kubelet/pods/ec8f40282bde3cfe7272900cd1fbf751/volumes"
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Creating master ignition and writing it to disk
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab bootkube.sh[12857]:   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab bootkube.sh[12857]:                                  Dload  Upload   Total   Spent    Left  Speed
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab bootkube.sh[12857]: [158B blob data]
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Gathering installer bootstrap logs
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: Gathering bootstrap service records ...
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab sudo[12865]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/cp -r /var/log/openshift/agent.json /var/log/openshift/approve-csr.json /var/log/openshift/assisted-service-pod.json /var/log/openshift/bootkube.json /var/log/openshift/crio-configure.json /var/log/openshift/kubelet.json /var/log/openshift/progress.json /var/log/openshift/release-image.json /tmp/artifacts-bootstrap/bootstrap/services/
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[1]: Created slice User Slice of UID 0.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[1]: Starting User Runtime Directory /run/user/0...
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[1]: Finished User Runtime Directory /run/user/0.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[1]: Starting User Manager for UID 0...
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[12868]: pam_unix(systemd-user:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[12868]: Queued start job for default target Main User Target.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[12868]: Created slice User Application Slice.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[12868]: Started Daily Cleanup of User's Temporary Directories.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[12868]: Reached target Paths.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[12868]: Reached target Timers.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[12868]: Starting D-Bus User Message Bus Socket...
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[12868]: Starting Create User's Volatile Files and Directories...
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[12868]: Listening on D-Bus User Message Bus Socket.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[12868]: Finished Create User's Volatile Files and Directories.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[12868]: Reached target Sockets.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[12868]: Reached target Basic System.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[12868]: Reached target Main User Target.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[12868]: Startup finished in 67ms.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[1]: Started User Manager for UID 0.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c1 of User root.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab sudo[12865]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab sudo[12865]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: Gathering bootstrap systemd summary ...
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[1]: session-c1.scope: Deactivated successfully.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: Gathering bootstrap failed systemd unit status ...
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: Gathering bootstrap journals ...
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: Gathering bootstrap networking ...
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: Gathering bootstrap containers ...
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab sudo[12911]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl ps --all --quiet
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c2 of User root.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab sudo[12911]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab sudo[12911]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[1]: session-c2.scope: Deactivated successfully.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab sudo[12925]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl ps -a --id b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd -v
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c3 of User root.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab sudo[12925]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab sudo[12925]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[1]: session-c3.scope: Deactivated successfully.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab sudo[12938]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl logs b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c4 of User root.
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab sudo[12938]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab sudo[12938]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:05 sno131.outbound.vz.bos2.lab systemd[1]: session-c4.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[12950]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl inspect b5e9dda24be65925bdef68c1ad02b2b5668c4cfbee57807d68f66061b10d9dcd
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c5 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[12950]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[12950]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c5.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[12964]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl ps -a --id 01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae -v
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c6 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[12964]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[12964]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c6.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[12976]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl logs 01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c7 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[12976]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[12976]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c7.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[12988]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl inspect 01976fdcfeb579b724ce17bff935596e6e1b4bbf27a1e0857d2566e6cc2351ae
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c8 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[12988]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[12988]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c8.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13001]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl ps -a --id f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414 -v
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c9 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13001]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13001]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c9.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13014]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl logs f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c10 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13014]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13014]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c10.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13025]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl inspect f9409916ab3ae973c978f316d033ef0dedc7b9b897e8aff7075a05c7471fc414
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c11 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13025]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13025]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c11.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13039]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl ps -a --id 23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127 -v
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c12 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13039]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13039]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c12.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13051]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl logs 23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c13 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13051]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13051]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c13.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13063]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl inspect 23b01b256c002a22557f11d2856c26b0133e2e13b04bc3f5dcf419d5a62b8127
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c14 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13063]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13063]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c14.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13078]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl ps -a --id ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239 -v
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c15 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13078]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13078]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c15.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13091]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl logs ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c16 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13091]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13091]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c16.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13104]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl inspect ff9060587686849642a5476ecf36e3da45cbb2dc95781d7a22c1d8d70ad42239
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c17 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13104]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13104]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c17.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13116]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl ps -a --id 879627050f06ae240ecae7ed418ee74c9917c81f786f3f977eb8ae18316cb8ab -v
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c18 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13116]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13116]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c18.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13130]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl logs 879627050f06ae240ecae7ed418ee74c9917c81f786f3f977eb8ae18316cb8ab
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c19 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13130]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13130]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c19.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13142]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl inspect 879627050f06ae240ecae7ed418ee74c9917c81f786f3f977eb8ae18316cb8ab
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c20 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13142]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13142]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c20.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13155]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl ps -a --id 66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754 -v
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c21 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13155]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13155]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c21.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13169]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl logs 66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c22 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13169]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13169]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c22.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13181]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl inspect 66c8bc632b4f590641f29a0c606dd98f4b0105efb348672b05b2a9efa49ef754
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c23 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13181]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13181]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c23.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13194]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl ps -a --id 6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d -v
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c24 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13194]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13194]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: session-c24.scope: Deactivated successfully.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13207]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl logs 6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c25 of User root.
Jun 06 02:12:06 sno131.outbound.vz.bos2.lab sudo[13207]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13207]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c25.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13219]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl inspect 6722085d9041addae69ff3e9452a94c6e85bccc0a9cf4a0f09ff56c563c62f4d
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c26 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13219]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13219]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c26.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13233]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl ps -a --id ea02af4e20c2bc5d42b48b0343b09e9197b6bd6d6eb9260f3171b5650f6a9982 -v
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c27 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13233]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13233]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c27.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13246]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl logs ea02af4e20c2bc5d42b48b0343b09e9197b6bd6d6eb9260f3171b5650f6a9982
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c28 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13246]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13246]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c28.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13258]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl inspect ea02af4e20c2bc5d42b48b0343b09e9197b6bd6d6eb9260f3171b5650f6a9982
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c29 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13258]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13258]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c29.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13271]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl ps -a --id e820d14bc6b4208effb94a359e5ce33ba0698e508092c6f7d7647ac01bf8de13 -v
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c30 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13271]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13271]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c30.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13283]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl logs e820d14bc6b4208effb94a359e5ce33ba0698e508092c6f7d7647ac01bf8de13
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c31 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13283]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13283]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c31.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13295]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl inspect e820d14bc6b4208effb94a359e5ce33ba0698e508092c6f7d7647ac01bf8de13
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c32 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13295]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13295]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c32.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13308]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl ps -a --id 92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd -v
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c33 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13308]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13308]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c33.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13321]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl logs 92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c34 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13321]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13321]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c34.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13346]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl inspect 92db44dd503374b050b1e2ec8ba790a71b1f22b15ddd57bc8c8a05642f0acbdd
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab approve-csr.sh[13323]: E0606 02:12:07.473201   13323 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab approve-csr.sh[13323]: E0606 02:12:07.473503   13323 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab approve-csr.sh[13323]: E0606 02:12:07.474773   13323 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab approve-csr.sh[13323]: E0606 02:12:07.476726   13323 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab approve-csr.sh[13323]: E0606 02:12:07.478672   13323 memcache.go:238] couldn't get current server API group list: Get "https://localhost:6443/api?timeout=32s": dial tcp [::1]:6443: connect: connection refused
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab approve-csr.sh[13323]: The connection to the server localhost:6443 was refused - did you specify the right host or port?
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c35 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13346]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13346]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c35.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13362]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl ps -a --id 9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357 -v
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c36 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13362]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13362]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c36.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13375]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl logs 9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c37 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13375]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13375]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c37.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13387]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/crictl inspect 9d66a0400f36da29300b56593b26031bfe2da3ca9c3be90870ba6fcd78534357
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c38 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13387]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13387]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c38.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13400]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/cp -r /var/log/bootstrap-control-plane/ /tmp/artifacts-bootstrap/bootstrap/containers
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c39 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13400]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13400]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c39.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13404]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/podman ps --all --format {{ .ID }} {{ .Names }}
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c40 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13404]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13404]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c40.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13418]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/podman logs 361d59273eef
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c41 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13418]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13418]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c41.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13431]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/podman inspect 361d59273eef
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c42 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13431]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13431]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c42.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13444]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/podman logs 1a132fbc1365
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c43 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13444]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13444]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: session-c43.scope: Deactivated successfully.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13458]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/podman inspect 1a132fbc1365
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c44 of User root.
Jun 06 02:12:07 sno131.outbound.vz.bos2.lab sudo[13458]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13458]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c44.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13471]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/podman logs e8d3d8160983
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c45 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13471]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13471]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c45.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13485]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/podman inspect e8d3d8160983
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c46 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13485]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13485]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c46.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13500]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/podman logs f6fecb4ca43d
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c47 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13500]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13500]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c47.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13514]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/podman inspect f6fecb4ca43d
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c48 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13514]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13514]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c48.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13529]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/podman logs 960e231b1485
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c49 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13529]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13529]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c49.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13542]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/podman inspect 960e231b1485
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c50 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13542]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13542]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c50.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13556]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/podman logs dcc9353ed46b
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c51 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13556]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13556]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c51.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13569]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/podman inspect dcc9353ed46b
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c52 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13569]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13569]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c52.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13584]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/podman logs 835626f88836
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c53 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13584]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13584]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c53.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13598]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/podman inspect 835626f88836
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c54 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13598]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13598]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c54.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: Gathering bootstrap rpm-ostree info ...
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13615]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/rpm-ostree status
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c55 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13615]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Starting rpm-ostree System Management Daemon...
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab rpm-ostree[13629]: Reading config file '/etc/rpm-ostreed.conf'
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab rpm-ostree[13629]: In idle state; will auto-exit in 60 seconds
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started rpm-ostree System Management Daemon.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab rpm-ostree[13629]: Allowing active client :1.388 (uid 0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab rpm-ostree[13629]: client(id:cli dbus:1.388 unit:session-c55.scope uid:0) added; new total=1
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab rpm-ostree[13629]: client(id:cli dbus:1.388 unit:session-c55.scope uid:0) vanished; remaining=0
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab rpm-ostree[13629]: In idle state; will auto-exit in 63 seconds
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13615]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c55.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13636]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/rpm-ostree ex history
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c56 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13636]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13636]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c56.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: Gathering rendered assets...
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13641]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/cp -r /var/opt/openshift/ /tmp/artifacts-bootstrap/rendered-assets
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c57 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13641]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13641]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c57.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13644]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/chown -R : /tmp/artifacts-bootstrap/rendered-assets
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c58 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13644]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13644]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c58.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13647]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/find /tmp/artifacts-bootstrap/rendered-assets -type d -print0
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c59 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13647]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13647]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c59.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13652]:     root : PWD=/var/opt/openshift ; USER=root ; COMMAND=/bin/chmod u+x /tmp/artifacts-bootstrap/rendered-assets /tmp/artifacts-bootstrap/rendered-assets/openshift /tmp/artifacts-bootstrap/rendered-assets/openshift/kube-controller-manager-bootstrap /tmp/artifacts-bootstrap/rendered-assets/openshift/kube-controller-manager-bootstrap/bootstrap-manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/kube-controller-manager-bootstrap/manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/config-bootstrap /tmp/artifacts-bootstrap/rendered-assets/openshift/config-bootstrap/bootstrap-manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/config-bootstrap/manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/etcd-bootstrap /tmp/artifacts-bootstrap/rendered-assets/openshift/etcd-bootstrap/tls /tmp/artifacts-bootstrap/rendered-assets/openshift/etcd-bootstrap/etc-kubernetes
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13652]:     root : (command continued) /tmp/artifacts-bootstrap/rendered-assets/openshift/etcd-bootstrap/etc-kubernetes/manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/etcd-bootstrap/etc-kubernetes/static-pod-resources /tmp/artifacts-bootstrap/rendered-assets/openshift/etcd-bootstrap/etc-kubernetes/static-pod-resources/etcd-member /tmp/artifacts-bootstrap/rendered-assets/openshift/etcd-bootstrap/etc-kubernetes/static-pod-resources/etcd-member/etcd-all-certs /tmp/artifacts-bootstrap/rendered-assets/openshift/etcd-bootstrap/manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/bootstrap-in-place /tmp/artifacts-bootstrap/rendered-assets/openshift/auth /tmp/artifacts-bootstrap/rendered-assets/openshift/manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/bootstrap-manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/cco-bootstrap /tmp/artifacts-bootstrap/rendered-assets/openshift/cco-bootstrap/bootstrap-manifests
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13652]:     root : (command continued) /tmp/artifacts-bootstrap/rendered-assets/openshift/cco-bootstrap/manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/cvo-bootstrap /tmp/artifacts-bootstrap/rendered-assets/openshift/cvo-bootstrap/bootstrap /tmp/artifacts-bootstrap/rendered-assets/openshift/cvo-bootstrap/manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/mco-bootstrap /tmp/artifacts-bootstrap/rendered-assets/openshift/mco-bootstrap/manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/mco-bootstrap/bootstrap /tmp/artifacts-bootstrap/rendered-assets/openshift/mco-bootstrap/bootstrap/manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/node-tuning-bootstrap /tmp/artifacts-bootstrap/rendered-assets/openshift/ingress-operator-manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/kube-scheduler-bootstrap /tmp/artifacts-bootstrap/rendered-assets/openshift/kube-scheduler-bootstrap/manifests
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13652]:     root : (command continued) /tmp/artifacts-bootstrap/rendered-assets/openshift/kube-scheduler-bootstrap/bootstrap-manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/kube-apiserver-bootstrap /tmp/artifacts-bootstrap/rendered-assets/openshift/kube-apiserver-bootstrap/manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/kube-apiserver-bootstrap/bootstrap-manifests /tmp/artifacts-bootstrap/rendered-assets/openshift/tls /tmp/artifacts-bootstrap/rendered-assets/openshift/openshift
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c60 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13652]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13652]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c60.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: Using /opt/openshift/auth/kubeconfig as KUBECONFIG
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: Gathering cluster resources ...
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13676]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get nodes -o jsonpath -l node-role.kubernetes.io/master --template {range .items[*]}{.metadata.name}{"\n"}{end}
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13680]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get pods --all-namespaces --template {{ range .items }}{{ $name := .metadata.name }}{{ $ns := .metadata.namespace }}{{ range .spec.containers }}-n {{ $ns }} {{ $name }} -c {{ .name }}{{ "\n" }}{{ end }}{{ range .spec.initContainers }}-n {{ $ns }} {{ $name }} -c {{ .name }}{{ "\n" }}{{ end }}{{ end }}
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13672]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get nodes -o jsonpath --template {range .items[*]}{.metadata.name}{"\n"}{end}
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13684]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get pods -l apiserver=true --all-namespaces --template {{ range .items }}-n {{ .metadata.namespace }} {{ .metadata.name }}{{ "\n" }}{{ end }}
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13688]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get apiservices -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13692]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get clusteroperators -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c61 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13704]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get configmaps --all-namespaces -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13699]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get clusterversion -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13709]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get csr -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13714]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get endpoints --all-namespaces -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c62 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c63 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c64 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13725]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get kubeapiserver -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13720]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get events --all-namespaces -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13730]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get kubecontrollermanager -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c65 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13676]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c66 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c67 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c68 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c69 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: Waiting for logs ...
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c70 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13680]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13672]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13684]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13737]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get machines --all-namespaces -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13749]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get namespaces -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13745]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get machineconfigs -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13757]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get openshiftapiserver -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13766]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get rolebindings --all-namespaces -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13753]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get nodes -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13761]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get pods --all-namespaces -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13741]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get machineconfigpools -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13778]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get secrets --all-namespaces
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c71 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c72 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13787]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get secrets --all-namespaces -o=custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,TYPE:.type,ANNOTATIONS:.metadata.annotations
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13791]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get services --all-namespaces -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13771]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get roles --all-namespaces -o json
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13798]:     root : PWD=/var/opt/openshift ; USER=root ; ENV=KUBECONFIG=/opt/openshift/auth/kubeconfig ; COMMAND=/bin/oc --request-timeout=5s get --raw /openapi/v2
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c73 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13688]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13692]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13704]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13709]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13714]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13699]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c74 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13725]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c75 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c76 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.951359   13765 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c77 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.952364   13765 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.953460   13765 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.954236   13765 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c78 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.956288   13765 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c79 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c80 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c81 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c82 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.966032   13811 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13720]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.966921   13811 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.967971   13819 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.969017   13811 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.969231   13819 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c83 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.969953   13811 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.970345   13819 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.970775   13827 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.971268   13819 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c84 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.971545   13827 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.971706   13811 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.973090   13819 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.973367   13827 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c85 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.975231   13827 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: Started Session c86 of User root.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.976994   13827 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13730]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13737]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13757]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.982827   13846 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.983711   13846 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.984581   13846 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13766]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.986515   13846 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13753]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.988072   13858 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.988384   13846 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.988663   13858 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13741]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.989198   13848 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.990290   13848 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.990797   13858 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.991187   13848 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13745]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13676]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.991525   13858 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab systemd[1]: session-c61.scope: Deactivated successfully.
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.992719   13858 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.993140   13848 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.994666   13868 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13749]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.995027   13848 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: Gather remote logs
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.995555   13868 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: No masters found!
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.996026   13882 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.997044   13882 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13778]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.997556   13868 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.997559   13882 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.999298   13899 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.999500   13868 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:08.999508   13882 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:08 sno131.outbound.vz.bos2.lab sudo[13761]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.000355   13899 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.001436   13882 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.001436   13868 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.001445   13899 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13791]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.002403   13899 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.002812   13934 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.003368   13899 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.003736   13934 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13787]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.005831   13934 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13771]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13680]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13672]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c62.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.007975   13934 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c63.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.008761   13934 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13798]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=0)
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13684]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13688]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13704]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13692]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13714]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13709]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c65.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13699]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c64.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c67.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c66.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c68.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c69.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c70.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13725]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c71.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.029118   14027 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.030172   14027 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.031213   14027 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.032172   14027 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.033348   14027 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.034490   14048 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.035057   14065 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.035290   14048 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.035907   14065 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.036822   14048 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13720]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.038045   14052 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.038083   14065 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c72.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.038913   14052 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.038936   14065 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.038965   14048 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.040350   14082 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.040767   14048 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.040781   14065 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.040783   14052 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.041160   14101 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.041300   14082 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.042046   14101 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.042598   14052 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.043202   14082 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.043948   14101 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.044506   14052 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.045145   14082 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13757]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13730]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.045838   14101 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c73.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c75.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.047415   14082 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.047699   14073 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.047712   14101 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.048498   14073 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.048850   14122 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.049644   14122 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.049695   14145 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.050108   14171 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.050406   14145 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.050410   14073 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13737]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13753]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13741]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.050897   14171 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.051578   14122 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c77.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c78.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.052183   14191 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.052384   14145 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.052393   14171 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.052413   14073 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c74.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.052895   14191 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.053352   14122 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.053833   14073 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.054080   14171 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.054125   14145 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.054730   14191 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.055381   14122 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.055401   14201 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.055884   14171 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.056248   14201 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.056268   14145 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.056708   14191 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13766]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13745]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c76.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.058091   14201 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c79.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.058483   14191 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.058505   14216 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.059277   14216 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.060143   14201 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.060184   14227 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13749]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13778]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.060950   14227 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.061331   14216 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13761]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c81.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.062047   14201 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c80.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.062402   14227 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.062535   14216 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c82.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.064399   14216 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.064432   14227 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13791]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13798]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c83.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: E0606 02:12:09.066746   14227 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=5s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: The connection to the server api-int.sno131.outbound.vz.bos2.lab:6443 was refused - did you specify the right host or port?
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c86.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13787]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab sudo[13771]: pam_unix(sudo:session): session closed for user root
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c84.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: session-c85.scope: Deactivated successfully.
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[12864]: Log bundle written to log-bundle-bootstrap.tar.gz
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Adding bootstrap control plane and bootstrap installer-gather bundle to master ignition
Jun 06 02:12:09 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container c42e29d554fb6ef61eeaa7e5d5870abecef527c6235386b50496cca07aa418a3.
Jun 06 02:12:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:11.315082    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:12:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:11.315937    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:12:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:11.315957    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:12:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:11.315963    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:12:13 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:12:15 sno131.outbound.vz.bos2.lab systemd[1]: libpod-c42e29d554fb6ef61eeaa7e5d5870abecef527c6235386b50496cca07aa418a3.scope: Deactivated successfully.
Jun 06 02:12:15 sno131.outbound.vz.bos2.lab systemd[1]: libpod-c42e29d554fb6ef61eeaa7e5d5870abecef527c6235386b50496cca07aa418a3.scope: Consumed 5.922s CPU time.
Jun 06 02:12:15 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay\x2dcontainers-c42e29d554fb6ef61eeaa7e5d5870abecef527c6235386b50496cca07aa418a3-userdata-shm.mount: Deactivated successfully.
Jun 06 02:12:15 sno131.outbound.vz.bos2.lab systemd[1]: var-lib-containers-storage-overlay-1207e1492b9a35ac0c44bb2b0728bee50846c25d3b78e98da545c7ca8aa85ac0-merged.mount: Deactivated successfully.
Jun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Check if API and API-Int URLs are reachable during bootstrap
Jun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Checking if api.sno131.outbound.vz.bos2.lab of type API_URL reachable
Jun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Unable to reach API_URL's https endpoint at https://api.sno131.outbound.vz.bos2.lab:6443/version
Jun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Unable to validate. https://api.sno131.outbound.vz.bos2.lab:6443/version is currently unreachable.
Jun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Checking if api-int.sno131.outbound.vz.bos2.lab of type API_INT_URL reachable
Jun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Unable to reach API_INT_URL's https endpoint at https://api-int.sno131.outbound.vz.bos2.lab:6443/version
Jun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Unable to validate. https://api-int.sno131.outbound.vz.bos2.lab:6443/version is currently unreachable.
Jun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: bootkube.service complete
Jun 06 02:12:15 sno131.outbound.vz.bos2.lab systemd[1]: bootkube.service: Deactivated successfully.
Jun 06 02:12:15 sno131.outbound.vz.bos2.lab systemd[1]: bootkube.service: Consumed 23.595s CPU time.
Jun 06 02:12:16 sno131.outbound.vz.bos2.lab report-progress.sh[7345]: Reporting install progress...
Jun 06 02:12:16 sno131.outbound.vz.bos2.lab report-progress.sh[14593]: E0606 02:12:16.392626   14593 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:16 sno131.outbound.vz.bos2.lab report-progress.sh[14593]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:16 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:16Z" level=info msg="bootkube service completed"
Jun 06 02:12:16 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:16Z" level=info msg="○ bootkube.service - Bootstrap a Kubernetes cluster\n     Loaded: loaded (/etc/systemd/system/bootkube.service; static)\n     Active: inactive (dead) since Tue 2023-06-06 02:12:15 UTC; 1s ago\n   Duration: 3min 14.091s\n    Process: 7311 ExecStart=/usr/local/bin/bootkube.sh (code=exited, status=0/SUCCESS)\n   Main PID: 7311 (code=exited, status=0/SUCCESS)\n        CPU: 23.595s\n\nJun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Check if API and API-Int URLs are reachable during bootstrap\nJun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Checking if api.sno131.outbound.vz.bos2.lab of type API_URL reachable\nJun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Unable to reach API_URL's https endpoint at https://api.sno131.outbound.vz.bos2.lab:6443/version\nJun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Unable to validate. https://api.sno131.outbound.vz.bos2.lab:6443/version is currently unreachable.\nJun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Checking if api-int.sno131.outbound.vz.bos2.lab of type API_INT_URL reachable\nJun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Unable to reach API_INT_URL's https endpoint at https://api-int.sno131.outbound.vz.bos2.lab:6443/version\nJun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: Unable to validate. https://api-int.sno131.outbound.vz.bos2.lab:6443/version is currently unreachable.\nJun 06 02:12:15 sno131.outbound.vz.bos2.lab bootkube.sh[7311]: bootkube.service complete\nJun 06 02:12:15 sno131.outbound.vz.bos2.lab systemd[1]: bootkube.service: Deactivated successfully.\nJun 06 02:12:15 sno131.outbound.vz.bos2.lab systemd[1]: bootkube.service: Consumed 23.595s CPU time."
Jun 06 02:12:16 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:16Z" level=info msg="  File: /opt/openshift/master.ign\n  Size: 5693398   \tBlocks: 11120      IO Block: 4096   regular file\nDevice: 700h/1792d\tInode: 35252078    Links: 1\nAccess: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)\nContext: system_u:object_r:container_file_t:s0\nAccess: 2023-06-06 02:12:15.013231492 +0000\nModify: 2023-06-06 02:12:15.013231492 +0000\nChange: 2023-06-06 02:12:15.013231492 +0000\n Birth: 2023-06-06 02:12:15.013231492 +0000\n"
Jun 06 02:12:16 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:16Z" level=info msg="Getting master-1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f.ign file" request_id=70847f2b-37ec-4fdf-a162-5e8f71156bf5
Jun 06 02:12:16 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:16Z" level=info msg="Updating node installation stage: Writing image to disk - " request_id=e86214b9-0ad3-491a-9379-564490cd9b0d
Jun 06 02:12:16 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:12:16Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=e86214b9-0ad3-491a-9379-564490cd9b0d
Jun 06 02:12:16 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:12:16Z" level=info msg="service Logic Host Installation Phase Seconds phase Waiting for bootkube, vendor HPE product Edgeline e920t disk SSD result Done, duration 195.546814" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 request_id=e86214b9-0ad3-491a-9379-564490cd9b0d
Jun 06 02:12:16 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:12:16Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=e86214b9-0ad3-491a-9379-564490cd9b0d
Jun 06 02:12:16 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:16Z" level=info msg="Writing image and ignition to disk with arguments: [install --insecure -i /opt/openshift/master.ign --copy-network /dev/nvme0n1]"
Jun 06 02:12:17 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:17Z" level=info msg="Installing Red Hat Enterprise Linux CoreOS 413.92.202305021736-0 (Plow) x86_64 (512-byte sectors)\n"
Jun 06 02:12:18 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:18Z" level=info msg="Read disk 146.6 MiB/3.5 GiB (4%)\n"
Jun 06 02:12:18 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[1]: Stopping User Manager for UID 0...
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[12868]: Activating special unit Exit the Session...
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[12868]: Stopped target Main User Target.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[12868]: Stopped target Basic System.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[12868]: Stopped target Paths.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[12868]: Stopped target Sockets.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[12868]: Stopped target Timers.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[12868]: Stopped Daily Cleanup of User's Temporary Directories.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[12868]: Closed D-Bus User Message Bus Socket.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[12868]: Stopped Create User's Volatile Files and Directories.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[12868]: Removed slice User Application Slice.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[12868]: Reached target Shutdown.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[12868]: Finished Exit the Session.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[12868]: Reached target Exit the Session.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[1]: user@0.service: Deactivated successfully.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[1]: Stopped User Manager for UID 0.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[1]: Stopping User Runtime Directory /run/user/0...
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[1]: run-user-0.mount: Deactivated successfully.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[1]: user-runtime-dir@0.service: Deactivated successfully.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[1]: Stopped User Runtime Directory /run/user/0.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[1]: Removed slice User Slice of UID 0.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab systemd[1]: user-0.slice: Consumed 4.161s CPU time.
Jun 06 02:12:19 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:19Z" level=info msg="Read disk 152.5 MiB/3.5 GiB (4%)\n"
Jun 06 02:12:20 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:20Z" level=info msg="Read disk 160.6 MiB/3.5 GiB (4%)\n"
Jun 06 02:12:20 sno131.outbound.vz.bos2.lab sshd[14649]: main: sshd: ssh-rsa algorithm is disabled
Jun 06 02:12:20 sno131.outbound.vz.bos2.lab sshd[14649]: Accepted publickey for core from 192.168.58.15 port 44658 ssh2: RSA SHA256:ltZ47o/fDXlJWgy139p4iY4V9dEJkhH4Iqtjrso8YTQ
Jun 06 02:12:20 sno131.outbound.vz.bos2.lab systemd-logind[2202]: New session 7 of user core.
Jun 06 02:12:20 sno131.outbound.vz.bos2.lab systemd[1]: Started Session 7 of User core.
Jun 06 02:12:20 sno131.outbound.vz.bos2.lab sshd[14649]: pam_unix(sshd:session): session opened for user core(uid=1000) by (uid=0)
Jun 06 02:12:20 sno131.outbound.vz.bos2.lab sshd[14649]: pam_unix(sshd:session): session closed for user core
Jun 06 02:12:20 sno131.outbound.vz.bos2.lab systemd[1]: session-7.scope: Deactivated successfully.
Jun 06 02:12:20 sno131.outbound.vz.bos2.lab systemd-logind[2202]: Session 7 logged out. Waiting for processes to exit.
Jun 06 02:12:20 sno131.outbound.vz.bos2.lab systemd-logind[2202]: Removed session 7.
Jun 06 02:12:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:21.321647    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:12:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:21.322596    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:12:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:21.322614    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:12:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:21.322620    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:12:21 sno131.outbound.vz.bos2.lab report-progress.sh[14669]: E0606 02:12:21.437807   14669 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:21 sno131.outbound.vz.bos2.lab report-progress.sh[14669]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:21 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:21Z" level=info msg="Read disk 166.5 MiB/3.5 GiB (4%)\n"
Jun 06 02:12:22 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:22Z" level=info msg="Read disk 172.4 MiB/3.5 GiB (4%)\n"
Jun 06 02:12:23 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:12:23 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:23Z" level=info msg="Read disk 178.1 MiB/3.5 GiB (5%)\n"
Jun 06 02:12:23 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:12:23Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=2da6503d-4544-4327-92b9-797cae0bc5b7
Jun 06 02:12:23 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:12:23Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 5%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=2da6503d-4544-4327-92b9-797cae0bc5b7
Jun 06 02:12:24 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:24Z" level=info msg="Read disk 184.1 MiB/3.5 GiB (5%)\n"
Jun 06 02:12:25 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:25Z" level=info msg="Read disk 190.9 MiB/3.5 GiB (5%)\n"
Jun 06 02:12:26 sno131.outbound.vz.bos2.lab report-progress.sh[14710]: E0606 02:12:26.481727   14710 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:26 sno131.outbound.vz.bos2.lab report-progress.sh[14710]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:26 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:26Z" level=info msg="Read disk 196.9 MiB/3.5 GiB (5%)\n"
Jun 06 02:12:27 sno131.outbound.vz.bos2.lab systemd[1]: approve-csr.service: Deactivated successfully.
Jun 06 02:12:27 sno131.outbound.vz.bos2.lab systemd[1]: approve-csr.service: Consumed 1.026s CPU time.
Jun 06 02:12:27 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:27Z" level=info msg="Read disk 205.0 MiB/3.5 GiB (5%)\n"
Jun 06 02:12:28 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:12:28 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:28Z" level=info msg="Read disk 209.3 MiB/3.5 GiB (5%)\n"
Jun 06 02:12:29 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:29Z" level=info msg="Read disk 215.3 MiB/3.5 GiB (6%)\n"
Jun 06 02:12:30 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:30Z" level=info msg="Read disk 221.3 MiB/3.5 GiB (6%)\n"
Jun 06 02:12:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:31.328401    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:12:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:31.329157    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:12:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:31.329173    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:12:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:31.329179    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:12:31 sno131.outbound.vz.bos2.lab report-progress.sh[14761]: E0606 02:12:31.524920   14761 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:31 sno131.outbound.vz.bos2.lab report-progress.sh[14761]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:31 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:31Z" level=info msg="Read disk 225.6 MiB/3.5 GiB (6%)\n"
Jun 06 02:12:32 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:32Z" level=info msg="Read disk 231.8 MiB/3.5 GiB (6%)\n"
Jun 06 02:12:33 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:12:33 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:33Z" level=info msg="Read disk 237.6 MiB/3.5 GiB (6%)\n"
Jun 06 02:12:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017554.9172] device (eno1): state change: ip-config -> failed (reason 'ip-config-unavailable', sys-iface-state: 'managed')
Jun 06 02:12:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <warn>  [1686017554.9176] device (eno1): Activation: failed for connection 'Wired connection 1'
Jun 06 02:12:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017554.9177] device (eno1): state change: failed -> disconnected (reason 'none', sys-iface-state: 'managed')
Jun 06 02:12:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017554.9191] dhcp4 (eno1): canceled DHCP transaction
Jun 06 02:12:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017554.9191] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:12:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017554.9191] dhcp4 (eno1): state changed no lease
Jun 06 02:12:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017554.9199] policy: auto-activating connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:12:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017554.9202] device (eno1): Activation: starting connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:12:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017554.9202] device (eno1): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'managed')
Jun 06 02:12:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017554.9203] device (eno1): state change: prepare -> config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:12:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017554.9210] device (eno1): state change: config -> ip-config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:12:34 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017554.9217] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:12:34 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:34Z" level=info msg="Read disk 242.6 MiB/3.5 GiB (6%)\n"
Jun 06 02:12:36 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:36Z" level=info msg="Read disk 246.0 MiB/3.5 GiB (6%)\n"
Jun 06 02:12:36 sno131.outbound.vz.bos2.lab report-progress.sh[14802]: E0606 02:12:36.568594   14802 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:36 sno131.outbound.vz.bos2.lab report-progress.sh[14802]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:37 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:37Z" level=info msg="Read disk 246.8 MiB/3.5 GiB (6%)\n"
Jun 06 02:12:38 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:38Z" level=info msg="Read disk 249.1 MiB/3.5 GiB (7%)\n"
Jun 06 02:12:38 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:12:39 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:39Z" level=info msg="Read disk 250.4 MiB/3.5 GiB (7%)\n"
Jun 06 02:12:40 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:40Z" level=info msg="Read disk 252.5 MiB/3.5 GiB (7%)\n"
Jun 06 02:12:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:41.334530    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:12:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:41.335717    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:12:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:41.335732    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:12:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:41.335738    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:12:41 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:41Z" level=info msg="Read disk 253.1 MiB/3.5 GiB (7%)\n"
Jun 06 02:12:41 sno131.outbound.vz.bos2.lab report-progress.sh[14844]: E0606 02:12:41.613067   14844 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:41 sno131.outbound.vz.bos2.lab report-progress.sh[14844]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:42 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:42Z" level=info msg="Read disk 261.0 MiB/3.5 GiB (7%)\n"
Jun 06 02:12:43 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:43Z" level=info msg="Read disk 475.7 MiB/3.5 GiB (13%)\n"
Jun 06 02:12:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:12:43Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=bc3137e6-8dc0-45c7-98ed-e34ad6e66553
Jun 06 02:12:43 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:12:43Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 13%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=bc3137e6-8dc0-45c7-98ed-e34ad6e66553
Jun 06 02:12:43 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:12:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:12:44" level=warning msg="Certificate verification is turned off. This is not recommended in production environments" file="inventory_session.go:126"
Jun 06 02:12:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:12:44" level=info msg="Query for next steps" file="step_processor.go:233" request_id=bc720c4b-30c0-4bbf-b0c4-36e08a9f9c97
Jun 06 02:12:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:12:44Z" level=info msg="GetNextSteps infra_env: <5f396111-46ed-4173-9648-bc0a9a818139>, host: <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>, host status: <installing-in-progress>" func="github.com/openshift/assisted-service/internal/host/hostcommands.(*InstructionManager).GetNextSteps" file="/src/internal/host/hostcommands/instruction_manager.go:160" go-id=1857 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=bc720c4b-30c0-4bbf-b0c4-36e08a9f9c97
Jun 06 02:12:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:12:44Z" level=info msg="No steps required for infraEnv <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>" func=github.com/openshift/assisted-service/internal/host/hostcommands.logSteps file="/src/internal/host/hostcommands/instruction_manager.go:284" go-id=1857 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=bc720c4b-30c0-4bbf-b0c4-36e08a9f9c97
Jun 06 02:12:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:44Z" level=info msg="Read disk 513.2 MiB/3.5 GiB (14%)\n"
Jun 06 02:12:45 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:45Z" level=info msg="Read disk 513.8 MiB/3.5 GiB (14%)\n"
Jun 06 02:12:46 sno131.outbound.vz.bos2.lab report-progress.sh[14889]: E0606 02:12:46.661069   14889 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:46 sno131.outbound.vz.bos2.lab report-progress.sh[14889]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:47Z" level=info msg="Read disk 514.4 MiB/3.5 GiB (14%)\n"
Jun 06 02:12:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:48Z" level=info msg="Read disk 515.4 MiB/3.5 GiB (14%)\n"
Jun 06 02:12:48 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:12:49 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:49Z" level=info msg="Read disk 517.6 MiB/3.5 GiB (14%)\n"
Jun 06 02:12:50 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:50Z" level=info msg="Read disk 595.7 MiB/3.5 GiB (16%)\n"
Jun 06 02:12:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:51.341272    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:12:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:51.342327    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:12:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:51.342343    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:12:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:12:51.342351    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:12:51 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:51Z" level=info msg="Read disk 597.8 MiB/3.5 GiB (16%)\n"
Jun 06 02:12:51 sno131.outbound.vz.bos2.lab report-progress.sh[14931]: E0606 02:12:51.705484   14931 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:51 sno131.outbound.vz.bos2.lab report-progress.sh[14931]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:12:52 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:52Z" level=info msg="Read disk 605.6 MiB/3.5 GiB (17%)\n"
Jun 06 02:12:53 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:53Z" level=info msg="Read disk 627.3 MiB/3.5 GiB (17%)\n"
Jun 06 02:12:53 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:12:54 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:54Z" level=info msg="Read disk 654.3 MiB/3.5 GiB (18%)\n"
Jun 06 02:12:54 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:12:54Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=1ac58fb4-bf35-4367-b81b-3ea3aaf10c50
Jun 06 02:12:54 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:12:54Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 18%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=1ac58fb4-bf35-4367-b81b-3ea3aaf10c50
Jun 06 02:12:55 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:55Z" level=info msg="Read disk 665.8 MiB/3.5 GiB (18%)\n"
Jun 06 02:12:56 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:56Z" level=info msg="Read disk 682.7 MiB/3.5 GiB (19%)\n"
Jun 06 02:12:57 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:57Z" level=info msg="Read disk 711.4 MiB/3.5 GiB (20%)\n"
Jun 06 02:12:58 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:58Z" level=info msg="Read disk 762.9 MiB/3.5 GiB (21%)\n"
Jun 06 02:12:58 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:12:59 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:12:59Z" level=info msg="Read disk 763.5 MiB/3.5 GiB (21%)\n"
Jun 06 02:13:00 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:00Z" level=info msg="Read disk 764.6 MiB/3.5 GiB (21%)\n"
Jun 06 02:13:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:01.121494    7266 kubelet_getters.go:182] "Pod status updated" pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:13:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:01.347594    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:13:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:01.348339    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:13:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:01.348353    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:13:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:01.348358    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:13:01 sno131.outbound.vz.bos2.lab report-progress.sh[14972]: E0606 02:13:01.753346   14972 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:01 sno131.outbound.vz.bos2.lab report-progress.sh[14972]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:01 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:01Z" level=info msg="Read disk 766.3 MiB/3.5 GiB (21%)\n"
Jun 06 02:13:02 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:02Z" level=info msg="Read disk 769.5 MiB/3.5 GiB (21%)\n"
Jun 06 02:13:03 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:13:03 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:03Z" level=info msg="Read disk 778.6 MiB/3.5 GiB (21%)\n"
Jun 06 02:13:04 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:04Z" level=info msg="Read disk 785.5 MiB/3.5 GiB (22%)\n"
Jun 06 02:13:05 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:05Z" level=info msg="Read disk 791.6 MiB/3.5 GiB (22%)\n"
Jun 06 02:13:06 sno131.outbound.vz.bos2.lab report-progress.sh[15041]: E0606 02:13:06.800823   15041 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:06 sno131.outbound.vz.bos2.lab report-progress.sh[15041]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:06 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:06Z" level=info msg="Read disk 798.4 MiB/3.5 GiB (22%)\n"
Jun 06 02:13:07 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:07Z" level=info msg="Read disk 820.4 MiB/3.5 GiB (23%)\n"
Jun 06 02:13:07 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:07Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=e16bfe65-25a1-4bba-9267-c54be961d718
Jun 06 02:13:07 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:07Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 23%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=e16bfe65-25a1-4bba-9267-c54be961d718
Jun 06 02:13:08 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:13:09 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:09Z" level=info msg="Read disk 831.2 MiB/3.5 GiB (23%)\n"
Jun 06 02:13:10 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:10Z" level=info msg="Read disk 839.0 MiB/3.5 GiB (23%)\n"
Jun 06 02:13:11 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:11Z" level=info msg="Read disk 844.8 MiB/3.5 GiB (23%)\n"
Jun 06 02:13:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:11.353535    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:13:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:11.354491    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:13:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:11.354508    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:13:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:11.354514    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:13:11 sno131.outbound.vz.bos2.lab report-progress.sh[15083]: E0606 02:13:11.845808   15083 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:11 sno131.outbound.vz.bos2.lab report-progress.sh[15083]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:11 sno131.outbound.vz.bos2.lab systemd[1]: rpm-ostreed.service: Deactivated successfully.
Jun 06 02:13:12 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:12Z" level=info msg="Read disk 849.8 MiB/3.5 GiB (23%)\n"
Jun 06 02:13:13 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:13Z" level=info msg="Read disk 867.6 MiB/3.5 GiB (24%)\n"
Jun 06 02:13:13 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:13:14 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:14Z" level=info msg="Read disk 879.9 MiB/3.5 GiB (24%)\n"
Jun 06 02:13:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:15Z" level=info msg="Read disk 895.2 MiB/3.5 GiB (25%)\n"
Jun 06 02:13:16 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:16Z" level=info msg="Read disk 902.5 MiB/3.5 GiB (25%)\n"
Jun 06 02:13:16 sno131.outbound.vz.bos2.lab report-progress.sh[15127]: E0606 02:13:16.890095   15127 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:16 sno131.outbound.vz.bos2.lab report-progress.sh[15127]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:17 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:17Z" level=info msg="Read disk 923.2 MiB/3.5 GiB (26%)\n"
Jun 06 02:13:18 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:18Z" level=info msg="Read disk 925.2 MiB/3.5 GiB (26%)\n"
Jun 06 02:13:18 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:13:19 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:19Z" level=info msg="Read disk 927.5 MiB/3.5 GiB (26%)\n"
Jun 06 02:13:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017599.9154] device (eno1): state change: ip-config -> failed (reason 'ip-config-unavailable', sys-iface-state: 'managed')
Jun 06 02:13:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <warn>  [1686017599.9162] device (eno1): Activation: failed for connection 'Wired connection 1'
Jun 06 02:13:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017599.9165] device (eno1): state change: failed -> disconnected (reason 'none', sys-iface-state: 'managed')
Jun 06 02:13:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017599.9178] dhcp4 (eno1): canceled DHCP transaction
Jun 06 02:13:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017599.9178] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:13:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017599.9178] dhcp4 (eno1): state changed no lease
Jun 06 02:13:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017599.9184] policy: auto-activating connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:13:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017599.9186] device (eno1): Activation: starting connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:13:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017599.9186] device (eno1): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'managed')
Jun 06 02:13:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017599.9187] device (eno1): state change: prepare -> config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:13:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017599.9193] device (eno1): state change: config -> ip-config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:13:19 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017599.9200] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:13:20 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:20Z" level=info msg="Read disk 933.0 MiB/3.5 GiB (26%)\n"
Jun 06 02:13:21 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:21Z" level=info msg="Read disk 938.6 MiB/3.5 GiB (26%)\n"
Jun 06 02:13:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:21.224984    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:13:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:21.225967    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:13:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:21.225986    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:13:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:21.225993    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:13:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:21.359948    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:13:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:21.361142    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:13:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:21.361155    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:13:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:21.361161    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:13:21 sno131.outbound.vz.bos2.lab report-progress.sh[15168]: E0606 02:13:21.935962   15168 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:21 sno131.outbound.vz.bos2.lab report-progress.sh[15168]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:22 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:22Z" level=info msg="Read disk 946.3 MiB/3.5 GiB (26%)\n"
Jun 06 02:13:23 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:23Z" level=info msg="Read disk 961.1 MiB/3.5 GiB (27%)\n"
Jun 06 02:13:23 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:13:24 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:24Z" level=info msg="Read disk 981.1 MiB/3.5 GiB (27%)\n"
Jun 06 02:13:25 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:25Z" level=info msg="Read disk 1000.2 MiB/3.5 GiB (28%)\n"
Jun 06 02:13:25 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:25Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=4cffad02-4aee-4e29-8299-6457ee732395
Jun 06 02:13:25 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:25Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 28%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=4cffad02-4aee-4e29-8299-6457ee732395
Jun 06 02:13:26 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:26Z" level=info msg="Read disk 1.0 GiB/3.5 GiB (29%)\n"
Jun 06 02:13:26 sno131.outbound.vz.bos2.lab report-progress.sh[15210]: E0606 02:13:26.980010   15210 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:26 sno131.outbound.vz.bos2.lab report-progress.sh[15210]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:27 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:27Z" level=info msg="Read disk 1.0 GiB/3.5 GiB (29%)\n"
Jun 06 02:13:28 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:28Z" level=info msg="Read disk 1.1 GiB/3.5 GiB (30%)\n"
Jun 06 02:13:28 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:13:29 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:29Z" level=info msg="Read disk 1.1 GiB/3.5 GiB (31%)\n"
Jun 06 02:13:30 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:30Z" level=info msg="Read disk 1.1 GiB/3.5 GiB (32%)\n"
Jun 06 02:13:31 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:31Z" level=info msg="Read disk 1.2 GiB/3.5 GiB (34%)\n"
Jun 06 02:13:31 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:31Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=004acb3c-d50b-4b2c-8e78-3b2d546006fc
Jun 06 02:13:31 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:31Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 34%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=004acb3c-d50b-4b2c-8e78-3b2d546006fc
Jun 06 02:13:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:31.366536    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:13:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:31.367408    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:13:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:31.367426    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:13:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:31.367432    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:13:32 sno131.outbound.vz.bos2.lab report-progress.sh[15252]: E0606 02:13:32.024996   15252 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:32 sno131.outbound.vz.bos2.lab report-progress.sh[15252]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:32 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:32Z" level=info msg="Read disk 1.2 GiB/3.5 GiB (35%)\n"
Jun 06 02:13:33 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:33Z" level=info msg="Read disk 1.3 GiB/3.5 GiB (38%)\n"
Jun 06 02:13:33 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:13:34 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:34Z" level=info msg="Read disk 1.4 GiB/3.5 GiB (39%)\n"
Jun 06 02:13:34 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:34Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=fbf66fce-7605-46c3-bee5-c7f65c14c892
Jun 06 02:13:34 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:34Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 39%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=fbf66fce-7605-46c3-bee5-c7f65c14c892
Jun 06 02:13:34 sno131.outbound.vz.bos2.lab sshd[15278]: main: sshd: ssh-rsa algorithm is disabled
Jun 06 02:13:34 sno131.outbound.vz.bos2.lab sshd[15278]: Accepted publickey for core from 192.168.58.15 port 44724 ssh2: RSA SHA256:ltZ47o/fDXlJWgy139p4iY4V9dEJkhH4Iqtjrso8YTQ
Jun 06 02:13:34 sno131.outbound.vz.bos2.lab systemd-logind[2202]: New session 8 of user core.
Jun 06 02:13:34 sno131.outbound.vz.bos2.lab systemd[1]: Started Session 8 of User core.
Jun 06 02:13:34 sno131.outbound.vz.bos2.lab sshd[15278]: pam_unix(sshd:session): session opened for user core(uid=1000) by (uid=0)
Jun 06 02:13:34 sno131.outbound.vz.bos2.lab sshd[15278]: pam_unix(sshd:session): session closed for user core
Jun 06 02:13:34 sno131.outbound.vz.bos2.lab systemd[1]: session-8.scope: Deactivated successfully.
Jun 06 02:13:34 sno131.outbound.vz.bos2.lab systemd-logind[2202]: Session 8 logged out. Waiting for processes to exit.
Jun 06 02:13:34 sno131.outbound.vz.bos2.lab systemd-logind[2202]: Removed session 8.
Jun 06 02:13:35 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:35Z" level=info msg="Read disk 1.4 GiB/3.5 GiB (39%)\n"
Jun 06 02:13:36 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:36Z" level=info msg="Read disk 1.4 GiB/3.5 GiB (39%)\n"
Jun 06 02:13:37 sno131.outbound.vz.bos2.lab report-progress.sh[15313]: E0606 02:13:37.068599   15313 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:37 sno131.outbound.vz.bos2.lab report-progress.sh[15313]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:37 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:37Z" level=info msg="Read disk 1.4 GiB/3.5 GiB (39%)\n"
Jun 06 02:13:38 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:38Z" level=info msg="Read disk 1.4 GiB/3.5 GiB (39%)\n"
Jun 06 02:13:39 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:13:39 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:39Z" level=info msg="Read disk 1.4 GiB/3.5 GiB (40%)\n"
Jun 06 02:13:40 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:40Z" level=info msg="Read disk 1.4 GiB/3.5 GiB (40%)\n"
Jun 06 02:13:41 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:41Z" level=info msg="Read disk 1.4 GiB/3.5 GiB (41%)\n"
Jun 06 02:13:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:41.373161    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:13:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:41.374059    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:13:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:41.374075    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:13:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:41.374082    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:13:42 sno131.outbound.vz.bos2.lab report-progress.sh[15355]: E0606 02:13:42.112113   15355 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:42 sno131.outbound.vz.bos2.lab report-progress.sh[15355]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:42 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:42Z" level=info msg="Read disk 1.5 GiB/3.5 GiB (42%)\n"
Jun 06 02:13:43 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:43Z" level=info msg="Read disk 1.5 GiB/3.5 GiB (43%)\n"
Jun 06 02:13:44 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:13:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:44Z" level=info msg="Read disk 1.5 GiB/3.5 GiB (43%)\n"
Jun 06 02:13:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:13:44" level=warning msg="Certificate verification is turned off. This is not recommended in production environments" file="inventory_session.go:126"
Jun 06 02:13:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:13:44" level=info msg="Query for next steps" file="step_processor.go:233" request_id=e323dc6a-af31-449d-9033-379439a2b595
Jun 06 02:13:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:44Z" level=info msg="GetNextSteps infra_env: <5f396111-46ed-4173-9648-bc0a9a818139>, host: <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>, host status: <installing-in-progress>" func="github.com/openshift/assisted-service/internal/host/hostcommands.(*InstructionManager).GetNextSteps" file="/src/internal/host/hostcommands/instruction_manager.go:160" go-id=1968 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=e323dc6a-af31-449d-9033-379439a2b595
Jun 06 02:13:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:44Z" level=info msg="No steps required for infraEnv <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>" func=github.com/openshift/assisted-service/internal/host/hostcommands.logSteps file="/src/internal/host/hostcommands/instruction_manager.go:284" go-id=1968 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=e323dc6a-af31-449d-9033-379439a2b595
Jun 06 02:13:45 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:45Z" level=info msg="Read disk 1.7 GiB/3.5 GiB (49%)\n"
Jun 06 02:13:45 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:45Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=27e1caa7-bf4a-47ea-b340-4948dbec3dff
Jun 06 02:13:45 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:45Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 49%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=27e1caa7-bf4a-47ea-b340-4948dbec3dff
Jun 06 02:13:46 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:46Z" level=info msg="Read disk 1.9 GiB/3.5 GiB (55%)\n"
Jun 06 02:13:46 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:46Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=b2ece173-4549-441a-a832-3079b4b6b710
Jun 06 02:13:46 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:46Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 55%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=b2ece173-4549-441a-a832-3079b4b6b710
Jun 06 02:13:47 sno131.outbound.vz.bos2.lab report-progress.sh[15396]: E0606 02:13:47.156243   15396 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:47 sno131.outbound.vz.bos2.lab report-progress.sh[15396]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:47 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:47Z" level=info msg="Read disk 2.0 GiB/3.5 GiB (58%)\n"
Jun 06 02:13:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:48Z" level=info msg="Read disk 2.1 GiB/3.5 GiB (59%)\n"
Jun 06 02:13:49 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:13:49 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:49Z" level=info msg="Read disk 2.1 GiB/3.5 GiB (60%)\n"
Jun 06 02:13:49 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:49Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=e1be2e4f-6667-4ca5-b0ce-90218c34bb1f
Jun 06 02:13:49 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:49Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 60%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=e1be2e4f-6667-4ca5-b0ce-90218c34bb1f
Jun 06 02:13:50 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:50Z" level=info msg="Read disk 2.1 GiB/3.5 GiB (60%)\n"
Jun 06 02:13:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:51.380123    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:13:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:51.380980    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:13:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:51.380997    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:13:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:13:51.381003    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:13:51 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:51Z" level=info msg="Read disk 2.1 GiB/3.5 GiB (61%)\n"
Jun 06 02:13:52 sno131.outbound.vz.bos2.lab report-progress.sh[15436]: E0606 02:13:52.200758   15436 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:52 sno131.outbound.vz.bos2.lab report-progress.sh[15436]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:52 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:52Z" level=info msg="Read disk 2.1 GiB/3.5 GiB (62%)\n"
Jun 06 02:13:53 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:53Z" level=info msg="Read disk 2.2 GiB/3.5 GiB (62%)\n"
Jun 06 02:13:54 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:13:54 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:54Z" level=info msg="Read disk 2.2 GiB/3.5 GiB (63%)\n"
Jun 06 02:13:55 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:55Z" level=info msg="Read disk 2.2 GiB/3.5 GiB (64%)\n"
Jun 06 02:13:56 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:56Z" level=info msg="Read disk 2.2 GiB/3.5 GiB (64%)\n"
Jun 06 02:13:57 sno131.outbound.vz.bos2.lab report-progress.sh[15477]: E0606 02:13:57.246526   15477 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:57 sno131.outbound.vz.bos2.lab report-progress.sh[15477]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:13:57 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:57Z" level=info msg="Read disk 2.3 GiB/3.5 GiB (65%)\n"
Jun 06 02:13:57 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:57Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=c3d1833a-5f55-4477-b268-2e55955173f7
Jun 06 02:13:57 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:13:57Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 65%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=c3d1833a-5f55-4477-b268-2e55955173f7
Jun 06 02:13:58 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:58Z" level=info msg="Read disk 2.3 GiB/3.5 GiB (66%)\n"
Jun 06 02:13:59 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:13:59 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:13:59Z" level=info msg="Read disk 2.3 GiB/3.5 GiB (67%)\n"
Jun 06 02:14:00 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:00Z" level=info msg="Read disk 2.4 GiB/3.5 GiB (68%)\n"
Jun 06 02:14:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:01.119795    7266 kubelet.go:1409] "Image garbage collection succeeded"
Jun 06 02:14:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:01.122203    7266 kubelet_getters.go:182] "Pod status updated" pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:14:01 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:14:01.125953362Z" level=info msg="Checking image status: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4964f9b316ef38d1755f1a51287f9cbe290d3762525e003ac872a4506545186f" id=a85e492e-039c-46bd-8d20-97528470fb48 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:14:01 sno131.outbound.vz.bos2.lab crio[7089]: time="2023-06-06 02:14:01.126344833Z" level=info msg="Image status: &ImageStatusResponse{Image:&Image{Id:0bca04c68bcda14d0d8bf772b9c3aefd496371e4d9803fcda942dc3967325222,RepoTags:[],RepoDigests:[quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4964f9b316ef38d1755f1a51287f9cbe290d3762525e003ac872a4506545186f],Size_:365389135,Uid:nil,Username:,Spec:&ImageSpec{Image:,Annotations:map[string]string{},},Pinned:false,},Info:map[string]string{},}" id=a85e492e-039c-46bd-8d20-97528470fb48 name=/runtime.v1.ImageService/ImageStatus
Jun 06 02:14:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:01.386491    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:14:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:01.387203    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:14:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:01.387219    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:14:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:01.387226    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:14:01 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:01Z" level=info msg="Read disk 2.5 GiB/3.5 GiB (71%)\n"
Jun 06 02:14:01 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:14:01Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=159d2b83-eaca-4f68-b0de-6bfb102da5d7
Jun 06 02:14:01 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:14:01Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 71%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=159d2b83-eaca-4f68-b0de-6bfb102da5d7
Jun 06 02:14:02 sno131.outbound.vz.bos2.lab report-progress.sh[15520]: E0606 02:14:02.292189   15520 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:02 sno131.outbound.vz.bos2.lab report-progress.sh[15520]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:02 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:02Z" level=info msg="Read disk 2.5 GiB/3.5 GiB (72%)\n"
Jun 06 02:14:03 sno131.outbound.vz.bos2.lab sshd[15534]: main: sshd: ssh-rsa algorithm is disabled
Jun 06 02:14:03 sno131.outbound.vz.bos2.lab sshd[15534]: Accepted publickey for core from 192.168.58.15 port 44752 ssh2: RSA SHA256:ltZ47o/fDXlJWgy139p4iY4V9dEJkhH4Iqtjrso8YTQ
Jun 06 02:14:03 sno131.outbound.vz.bos2.lab systemd-logind[2202]: New session 9 of user core.
Jun 06 02:14:03 sno131.outbound.vz.bos2.lab systemd[1]: Started Session 9 of User core.
Jun 06 02:14:03 sno131.outbound.vz.bos2.lab sshd[15534]: pam_unix(sshd:session): session opened for user core(uid=1000) by (uid=0)
Jun 06 02:14:03 sno131.outbound.vz.bos2.lab sshd[15534]: pam_unix(sshd:session): session closed for user core
Jun 06 02:14:03 sno131.outbound.vz.bos2.lab systemd[1]: session-9.scope: Deactivated successfully.
Jun 06 02:14:03 sno131.outbound.vz.bos2.lab systemd-logind[2202]: Session 9 logged out. Waiting for processes to exit.
Jun 06 02:14:03 sno131.outbound.vz.bos2.lab systemd-logind[2202]: Removed session 9.
Jun 06 02:14:03 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:03Z" level=info msg="Read disk 2.5 GiB/3.5 GiB (73%)\n"
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:04Z" level=info msg="Read disk 2.6 GiB/3.5 GiB (76%)\n"
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:14:04Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=003d2e61-fea7-4dad-8c3e-5e287b861f70
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:14:04Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 76%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=003d2e61-fea7-4dad-8c3e-5e287b861f70
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017644.9050] device (eno1): state change: ip-config -> failed (reason 'ip-config-unavailable', sys-iface-state: 'managed')
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <warn>  [1686017644.9054] device (eno1): Activation: failed for connection 'Wired connection 1'
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017644.9054] device (eno1): state change: failed -> disconnected (reason 'none', sys-iface-state: 'managed')
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017644.9067] dhcp4 (eno1): canceled DHCP transaction
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017644.9068] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017644.9068] dhcp4 (eno1): state changed no lease
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017644.9074] policy: auto-activating connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017644.9076] device (eno1): Activation: starting connection 'Wired connection 1' (db36373c-3489-3dfa-b38f-a1ff7113c9bf)
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017644.9077] device (eno1): state change: disconnected -> prepare (reason 'none', sys-iface-state: 'managed')
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017644.9078] device (eno1): state change: prepare -> config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017644.9084] device (eno1): state change: config -> ip-config (reason 'none', sys-iface-state: 'managed')
Jun 06 02:14:04 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017644.9091] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:14:05 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:05Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (76%)\n"
Jun 06 02:14:06 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:06Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (76%)\n"
Jun 06 02:14:07 sno131.outbound.vz.bos2.lab report-progress.sh[15582]: E0606 02:14:07.336937   15582 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:07 sno131.outbound.vz.bos2.lab report-progress.sh[15582]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:07 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:07Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (77%)\n"
Jun 06 02:14:08 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:08Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (77%)\n"
Jun 06 02:14:09 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:14:09 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:09Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (77%)\n"
Jun 06 02:14:10 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:10Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (78%)\n"
Jun 06 02:14:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:11.392468    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:14:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:11.393705    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:14:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:11.393723    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:14:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:11.393730    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:14:11 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:11Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (78%)\n"
Jun 06 02:14:12 sno131.outbound.vz.bos2.lab report-progress.sh[15624]: E0606 02:14:12.381324   15624 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:12 sno131.outbound.vz.bos2.lab report-progress.sh[15624]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:12 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:12Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (78%)\n"
Jun 06 02:14:13 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:13Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (78%)\n"
Jun 06 02:14:14 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:14:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:15Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (78%)\n"
Jun 06 02:14:16 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:16Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (78%)\n"
Jun 06 02:14:17 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:17Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (78%)\n"
Jun 06 02:14:17 sno131.outbound.vz.bos2.lab report-progress.sh[15667]: E0606 02:14:17.425838   15667 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:17 sno131.outbound.vz.bos2.lab report-progress.sh[15667]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:18 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:18Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (78%)\n"
Jun 06 02:14:19 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:14:19 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:19Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (79%)\n"
Jun 06 02:14:20 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:20Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (79%)\n"
Jun 06 02:14:21 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:21Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (79%)\n"
Jun 06 02:14:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:21.398909    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:14:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:21.399719    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:14:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:21.399736    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:14:21 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:21.399742    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:14:22 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:22Z" level=info msg="Read disk 2.7 GiB/3.5 GiB (79%)\n"
Jun 06 02:14:22 sno131.outbound.vz.bos2.lab report-progress.sh[15710]: E0606 02:14:22.475130   15710 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:22 sno131.outbound.vz.bos2.lab report-progress.sh[15710]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:23 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:23Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (79%)\n"
Jun 06 02:14:24 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:14:24 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:24Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (79%)\n"
Jun 06 02:14:25 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:25Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (79%)\n"
Jun 06 02:14:26 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:26Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (79%)\n"
Jun 06 02:14:27 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:27Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (80%)\n"
Jun 06 02:14:27 sno131.outbound.vz.bos2.lab report-progress.sh[15751]: E0606 02:14:27.520803   15751 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:27 sno131.outbound.vz.bos2.lab report-progress.sh[15751]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:28 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:28Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (80%)\n"
Jun 06 02:14:29 sno131.outbound.vz.bos2.lab sshd[15769]: main: sshd: ssh-rsa algorithm is disabled
Jun 06 02:14:29 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:14:29 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:29Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (80%)\n"
Jun 06 02:14:29 sno131.outbound.vz.bos2.lab sshd[15769]: Accepted publickey for core from 192.168.58.15 port 44778 ssh2: RSA SHA256:ltZ47o/fDXlJWgy139p4iY4V9dEJkhH4Iqtjrso8YTQ
Jun 06 02:14:29 sno131.outbound.vz.bos2.lab systemd-logind[2202]: New session 10 of user core.
Jun 06 02:14:29 sno131.outbound.vz.bos2.lab systemd[1]: Started Session 10 of User core.
Jun 06 02:14:29 sno131.outbound.vz.bos2.lab sshd[15769]: pam_unix(sshd:session): session opened for user core(uid=1000) by (uid=0)
Jun 06 02:14:29 sno131.outbound.vz.bos2.lab sshd[15782]: Received disconnect from 192.168.58.15 port 44778:11: disconnected by user
Jun 06 02:14:29 sno131.outbound.vz.bos2.lab sshd[15782]: Disconnected from user core 192.168.58.15 port 44778
Jun 06 02:14:29 sno131.outbound.vz.bos2.lab sshd[15769]: pam_unix(sshd:session): session closed for user core
Jun 06 02:14:29 sno131.outbound.vz.bos2.lab systemd[1]: session-10.scope: Deactivated successfully.
Jun 06 02:14:29 sno131.outbound.vz.bos2.lab systemd-logind[2202]: Session 10 logged out. Waiting for processes to exit.
Jun 06 02:14:29 sno131.outbound.vz.bos2.lab systemd-logind[2202]: Removed session 10.
Jun 06 02:14:30 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:30.225239    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:14:30 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:30.226209    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:14:30 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:30.226226    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:14:30 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:30.226233    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:14:30 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:30Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (80%)\n"
Jun 06 02:14:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:31.404943    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:14:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:31.405680    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:14:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:31.405695    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:14:31 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:31.405700    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:14:31 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:31Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (80%)\n"
Jun 06 02:14:32 sno131.outbound.vz.bos2.lab report-progress.sh[15812]: E0606 02:14:32.565389   15812 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:32 sno131.outbound.vz.bos2.lab report-progress.sh[15812]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:32 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:32Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (80%)\n"
Jun 06 02:14:33 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:33Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (81%)\n"
Jun 06 02:14:33 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:14:33Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=b3e1a980-7d18-4422-aa95-b50171f2a18f
Jun 06 02:14:33 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:14:33Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 81%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=b3e1a980-7d18-4422-aa95-b50171f2a18f
Jun 06 02:14:34 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:14:34 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:34Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (81%)\n"
Jun 06 02:14:35 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:35Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (81%)\n"
Jun 06 02:14:36 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:36Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (81%)\n"
Jun 06 02:14:37 sno131.outbound.vz.bos2.lab report-progress.sh[15855]: E0606 02:14:37.608961   15855 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:37 sno131.outbound.vz.bos2.lab report-progress.sh[15855]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:37 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:37Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (81%)\n"
Jun 06 02:14:38 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:38Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (81%)\n"
Jun 06 02:14:39 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:14:39 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:39Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (81%)\n"
Jun 06 02:14:40 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:40Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (82%)\n"
Jun 06 02:14:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:41.410726    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:14:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:41.411713    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:14:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:41.411730    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:14:41 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:41.411736    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:14:41 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:41Z" level=info msg="Read disk 2.8 GiB/3.5 GiB (82%)\n"
Jun 06 02:14:42 sno131.outbound.vz.bos2.lab report-progress.sh[15897]: E0606 02:14:42.652797   15897 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:42 sno131.outbound.vz.bos2.lab report-progress.sh[15897]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:42 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:42Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (82%)\n"
Jun 06 02:14:43 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:43Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (82%)\n"
Jun 06 02:14:44 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:14:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:14:44" level=warning msg="Certificate verification is turned off. This is not recommended in production environments" file="inventory_session.go:126"
Jun 06 02:14:44 sno131.outbound.vz.bos2.lab next_step_runne[4389]: time="06-06-2023 02:14:44" level=info msg="Query for next steps" file="step_processor.go:233" request_id=041f8ea3-f775-4762-b8b6-371e656a7589
Jun 06 02:14:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:14:44Z" level=info msg="GetNextSteps infra_env: <5f396111-46ed-4173-9648-bc0a9a818139>, host: <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>, host status: <installing-in-progress>" func="github.com/openshift/assisted-service/internal/host/hostcommands.(*InstructionManager).GetNextSteps" file="/src/internal/host/hostcommands/instruction_manager.go:160" go-id=2120 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=041f8ea3-f775-4762-b8b6-371e656a7589
Jun 06 02:14:44 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:14:44Z" level=info msg="No steps required for infraEnv <5f396111-46ed-4173-9648-bc0a9a818139> host <1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f>" func=github.com/openshift/assisted-service/internal/host/hostcommands.logSteps file="/src/internal/host/hostcommands/instruction_manager.go:284" go-id=2120 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=instructions request_id=041f8ea3-f775-4762-b8b6-371e656a7589
Jun 06 02:14:44 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:44Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (82%)\n"
Jun 06 02:14:45 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:45Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (82%)\n"
Jun 06 02:14:46 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:46Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (83%)\n"
Jun 06 02:14:47 sno131.outbound.vz.bos2.lab report-progress.sh[15937]: E0606 02:14:47.696652   15937 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:47 sno131.outbound.vz.bos2.lab report-progress.sh[15937]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:48 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:48Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (83%)\n"
Jun 06 02:14:49 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:49Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (83%)\n"
Jun 06 02:14:49 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:14:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017689.9160] device (eno1): state change: ip-config -> failed (reason 'ip-config-unavailable', sys-iface-state: 'managed')
Jun 06 02:14:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <warn>  [1686017689.9162] device (eno1): Activation: failed for connection 'Wired connection 1'
Jun 06 02:14:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017689.9163] device (eno1): state change: failed -> disconnected (reason 'none', sys-iface-state: 'managed')
Jun 06 02:14:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017689.9183] dhcp4 (eno1): canceled DHCP transaction
Jun 06 02:14:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017689.9183] dhcp4 (eno1): activation: beginning transaction (timeout in 45 seconds)
Jun 06 02:14:49 sno131.outbound.vz.bos2.lab NetworkManager[2186]: <info>  [1686017689.9183] dhcp4 (eno1): state changed no lease
Jun 06 02:14:50 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:50Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (83%)\n"
Jun 06 02:14:51 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:51Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (83%)\n"
Jun 06 02:14:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:51.416362    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:14:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:51.417187    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:14:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:51.417205    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:14:51 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:14:51.417212    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:14:52 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:52Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (84%)\n"
Jun 06 02:14:52 sno131.outbound.vz.bos2.lab report-progress.sh[15979]: E0606 02:14:52.741186   15979 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:52 sno131.outbound.vz.bos2.lab report-progress.sh[15979]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:53 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:53Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (84%)\n"
Jun 06 02:14:54 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:54Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (84%)\n"
Jun 06 02:14:54 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:14:55 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:55Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (84%)\n"
Jun 06 02:14:56 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:56Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (84%)\n"
Jun 06 02:14:57 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:57Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (84%)\n"
Jun 06 02:14:57 sno131.outbound.vz.bos2.lab report-progress.sh[16020]: E0606 02:14:57.786650   16020 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:57 sno131.outbound.vz.bos2.lab report-progress.sh[16020]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:14:58 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:58Z" level=info msg="Read disk 2.9 GiB/3.5 GiB (85%)\n"
Jun 06 02:14:59 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:14:59Z" level=info msg="Read disk 3.0 GiB/3.5 GiB (85%)\n"
Jun 06 02:14:59 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:15:00 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:00Z" level=info msg="Read disk 3.0 GiB/3.5 GiB (85%)\n"
Jun 06 02:15:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:15:01.122585    7266 kubelet_getters.go:182] "Pod status updated" pod="default/bootstrap-machine-config-operator-sno131.outbound.vz.bos2.lab" status=Running
Jun 06 02:15:01 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:01Z" level=info msg="Read disk 3.0 GiB/3.5 GiB (85%)\n"
Jun 06 02:15:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:15:01.422038    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:15:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:15:01.423541    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:15:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:15:01.423557    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:15:01 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:15:01.423563    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:15:02 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:02Z" level=info msg="Read disk 3.0 GiB/3.5 GiB (85%)\n"
Jun 06 02:15:02 sno131.outbound.vz.bos2.lab report-progress.sh[16064]: E0606 02:15:02.829104   16064 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:15:02 sno131.outbound.vz.bos2.lab report-progress.sh[16064]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:15:03 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:03Z" level=info msg="Read disk 3.0 GiB/3.5 GiB (86%)\n"
Jun 06 02:15:03 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:03Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=3ee4a7ab-021c-4ca3-afac-d9885db5934d
Jun 06 02:15:03 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:03Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 86%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=3ee4a7ab-021c-4ca3-afac-d9885db5934d
Jun 06 02:15:04 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:04Z" level=info msg="Read disk 3.0 GiB/3.5 GiB (86%)\n"
Jun 06 02:15:04 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:15:05 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:05Z" level=info msg="Read disk 3.0 GiB/3.5 GiB (86%)\n"
Jun 06 02:15:06 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:06Z" level=info msg="Read disk 3.0 GiB/3.5 GiB (86%)\n"
Jun 06 02:15:07 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:07Z" level=info msg="Read disk 3.0 GiB/3.5 GiB (88%)\n"
Jun 06 02:15:07 sno131.outbound.vz.bos2.lab report-progress.sh[16106]: E0606 02:15:07.874597   16106 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:15:07 sno131.outbound.vz.bos2.lab report-progress.sh[16106]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:15:08 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:08Z" level=info msg="Read disk 3.1 GiB/3.5 GiB (88%)\n"
Jun 06 02:15:09 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:09Z" level=info msg="Read disk 3.1 GiB/3.5 GiB (89%)\n"
Jun 06 02:15:09 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:15:10 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:10Z" level=info msg="Read disk 3.1 GiB/3.5 GiB (90%)\n"
Jun 06 02:15:11 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:11Z" level=info msg="Read disk 3.2 GiB/3.5 GiB (91%)\n"
Jun 06 02:15:11 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:11Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=7eb806c3-4f4b-4b55-9aea-ce674be1465e
Jun 06 02:15:11 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:11Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 91%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=7eb806c3-4f4b-4b55-9aea-ce674be1465e
Jun 06 02:15:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:15:11.428709    7266 kubelet_node_status.go:376] "Setting node annotation to enable volume controller attach/detach"
Jun 06 02:15:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:15:11.429654    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientMemory"
Jun 06 02:15:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:15:11.429670    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasNoDiskPressure"
Jun 06 02:15:11 sno131.outbound.vz.bos2.lab kubelet.sh[7266]: I0606 02:15:11.429677    7266 kubelet_node_status.go:696] "Recording event message for node" node="sno131.outbound.vz.bos2.lab" event="NodeHasSufficientPID"
Jun 06 02:15:12 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:12Z" level=info msg="Read disk 3.2 GiB/3.5 GiB (92%)\n"
Jun 06 02:15:12 sno131.outbound.vz.bos2.lab report-progress.sh[16147]: E0606 02:15:12.917961   16147 memcache.go:238] couldn't get current server API group list: Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:15:12 sno131.outbound.vz.bos2.lab report-progress.sh[16147]: error: unable to recognize "STDIN": Get "https://api-int.sno131.outbound.vz.bos2.lab:6443/api?timeout=32s": dial tcp 192.168.14.27:6443: connect: connection refused
Jun 06 02:15:13 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:13Z" level=info msg="Read disk 3.3 GiB/3.5 GiB (96%)\n"
Jun 06 02:15:13 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:13Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=c75c89b8-04d1-42bd-9add-ace84729c97c
Jun 06 02:15:13 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:13Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 96%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=c75c89b8-04d1-42bd-9add-ace84729c97c
Jun 06 02:15:14 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:14Z" level=info msg="Read disk 3.5 GiB/3.5 GiB (100%)\n"
Jun 06 02:15:14 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:14Z" level=info msg="Update host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f install progress" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5334" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=8fd6da14-9581-42be-ba1b-14116a34bd0d
Jun 06 02:15:14 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:14Z" level=info msg="Host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f in cluster 348785c6-46bc-472b-80be-59bd077b9966: reached installation stage Writing image to disk: 100%" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostInstallProgressInternal" file="/src/internal/bminventory/inventory.go:5361" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=8fd6da14-9581-42be-ba1b-14116a34bd0d
Jun 06 02:15:14 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:14Z" level=info msg="Read disk 3.5 GiB/3.5 GiB (100%)\n"
Jun 06 02:15:14 sno131.outbound.vz.bos2.lab start-cluster-installation.sh[4520]: Cluster status: installing
Jun 06 02:15:14 sno131.outbound.vz.bos2.lab kernel: GPT:Primary header thinks Alt. header is not at the end of the disk.
Jun 06 02:15:14 sno131.outbound.vz.bos2.lab kernel: GPT:7256063 != 3750748847
Jun 06 02:15:14 sno131.outbound.vz.bos2.lab kernel: GPT:Alternate GPT header not at the end of the disk.
Jun 06 02:15:14 sno131.outbound.vz.bos2.lab kernel: GPT:7256063 != 3750748847
Jun 06 02:15:14 sno131.outbound.vz.bos2.lab kernel: GPT: Use GNU Parted to correct GPT errors.
Jun 06 02:15:14 sno131.outbound.vz.bos2.lab kernel:  nvme0n1: p1 p2 p3 p4
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="Writing Ignition config\n"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab kernel: EXT4-fs (nvme0n1p3): mounted filesystem with ordered data mode. Quota mode: none.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="Copying networking configuration from /etc/NetworkManager/system-connections/\n"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="Copying /etc/NetworkManager/system-connections/ens1f0.nmconnection to installed system\n"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab systemd[1]: tmp-coreos\x2dinstaller\x2d1U3SdX.mount: Deactivated successfully.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab kernel: EXT4-fs (nvme0n1p3): unmounting filesystem.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab kernel: GPT:Primary header thinks Alt. header is not at the end of the disk.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab kernel: GPT:7256063 != 3750748847
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab kernel: GPT:Alternate GPT header not at the end of the disk.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab kernel: GPT:7256063 != 3750748847
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab kernel: GPT: Use GNU Parted to correct GPT errors.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab kernel:  nvme0n1: p1 p2 p3 p4
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab systemd-udevd[16174]: nvme0n1p4: Process '/bin/sh -c '/bin/umount -fl /dev/nvme0n1p4 && /usr/bin/logger -p daemon.warn -s WARNING: hot-removed /dev/nvme0n1p4 that was still mounted, data may have been corrupted'' failed with exit code 32.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab systemd-udevd[16175]: nvme0n1p2: Process '/bin/sh -c '/bin/umount -fl /dev/nvme0n1p2 && /usr/bin/logger -p daemon.warn -s WARNING: hot-removed /dev/nvme0n1p2 that was still mounted, data may have been corrupted'' failed with exit code 32.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab systemd-udevd[16176]: nvme0n1p1: Process '/bin/sh -c '/bin/umount -fl /dev/nvme0n1p1 && /usr/bin/logger -p daemon.warn -s WARNING: hot-removed /dev/nvme0n1p1 that was still mounted, data may have been corrupted'' failed with exit code 32.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab systemd-udevd[16172]: nvme0n1p3: Process '/bin/sh -c '/bin/umount -fl /dev/nvme0n1p3 && /usr/bin/logger -p daemon.warn -s WARNING: hot-removed /dev/nvme0n1p3 that was still mounted, data may have been corrupted'' failed with exit code 32.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="Install complete.\n"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="Done writing image to disk"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="SetBootOrder, runtime.GOARCH: amd64, device: /dev/nvme0n1"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab kernel: GPT:Primary header thinks Alt. header is not at the end of the disk.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab kernel: GPT:7256063 != 3750748847
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab kernel: GPT:Alternate GPT header not at the end of the disk.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab kernel: GPT:7256063 != 3750748847
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab kernel: GPT: Use GNU Parted to correct GPT errors.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab kernel:  nvme0n1: p1 p2 p3 p4
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab systemd-udevd[16176]: nvme0n1p1: Process '/bin/sh -c '/bin/umount -fl /dev/nvme0n1p1 && /usr/bin/logger -p daemon.warn -s WARNING: hot-removed /dev/nvme0n1p1 that was still mounted, data may have been corrupted'' failed with exit code 32.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab systemd-udevd[16175]: nvme0n1p2: Process '/bin/sh -c '/bin/umount -fl /dev/nvme0n1p2 && /usr/bin/logger -p daemon.warn -s WARNING: hot-removed /dev/nvme0n1p2 that was still mounted, data may have been corrupted'' failed with exit code 32.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab systemd-udevd[16172]: nvme0n1p3: Process '/bin/sh -c '/bin/umount -fl /dev/nvme0n1p3 && /usr/bin/logger -p daemon.warn -s WARNING: hot-removed /dev/nvme0n1p3 that was still mounted, data may have been corrupted'' failed with exit code 32.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab systemd-udevd[16174]: nvme0n1p4: Process '/bin/sh -c '/bin/umount -fl /dev/nvme0n1p4 && /usr/bin/logger -p daemon.warn -s WARNING: hot-removed /dev/nvme0n1p4 that was still mounted, data may have been corrupted'' failed with exit code 32.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="Setting efibootmgr to boot from disk"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="Using EFI file 'shimx64.efi' for GOARCH 'amd64'"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="efibootmgr: ** Warning ** : Boot001F has same label Red Hat Enterprise Linux\n"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="BootCurrent: 001D\nTimeout: 0 seconds\nBootOrder: 001E,001F,000E,0013,0014,0011,0012,0017,0018,0015,0016,001B,001C,0019,001A,0009,000A,000B,000C,000D,0000,0001,0002,0005,0006,0007,0008,0003,0004,000F,0010,001D\nBoot0000* System Utilities\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(1fd631e5-44e0-2f91-10ab-f88f3568ef30)\nBoot0001  Non bootable Hotkey\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(4affaab0-1376-44b4-9c6e-e92388751bc6)\nBoot0002  Intelligent Provisioning\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(4a433501-ddaa-490b-96b2-04f42d8669b8)\nBoot0003  Embedded UEFI Shell\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(c57ad6b7-0515-40a8-9d21-551652854e37)\nBoot0004  Embedded iPXE\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(e22ad661-333a-4452-a101-64cc1898b837)\nBoot0005  Diagnose Error\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(0849279d-40d5-53ea-e764-2496766f9844)\nBoot0006  Boot Menu\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(d3fd6286-43c5-bb8d-0793-07b70aa9de36)\nBoot0007  Network Boot\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(0334f316-c276-49f6-9879-aaf1ecffa5d5)\nBoot0008  View Integrated Management Log\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(93c92423-d1c6-4286-be67-b76b6671047e)\nBoot0009  View GUI mode Integrated Management Log\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(f77778ab-a777-7777-9c58-60b5f0cba9d4)\nBoot000A  View BIOS Event Log\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(c20a40f3-4f7f-b41f-f614-628093c6b567)\nBoot000B  HTTP Boot\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(3f770860-3d63-4803-9ea3-df37144ab546)\nBoot000C  PXE Boot\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(ee8b26b0-37e9-11e1-b86c-0800200c9a66)\nBoot000D  Embedded Diagnostics\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(b57fe6f1-4f49-d46e-4bba-0a8add34d2f3)\nBoot000E* Generic USB Boot\tUsbClass(ffff,ffff,255,255)\nBoot000F* Embedded NVMe M.2 Drive 1 : NVM Express Controller - S436NA0R757305-SAMSUNG MZ1LB1T9HALS-00007-0\tPciRoot(0x5)/Pci(0x3,0x0)/Pci(0x0,0x0)/NVMe(0x1,00-00-00-00-00-00-00-00)N.....YM....R,Y.\nBoot0010* Embedded NVMe M.2 Drive 2 : NVM Express Controller - S436NA0R757289-SAMSUNG MZ1LB1T9HALS-00007-0\tPciRoot(0x5)/Pci(0x4,0x0)/Pci(0x0,0x0)/NVMe(0x1,00-00-00-00-00-00-00-00)N.....YM....R,Y.\nBoot0011* Embedded LOM 1 Port 1 : Intel(R) I210 Gigabit  Backplane Connection (HTTP(S) IPv6)\tPciRoot(0x0)/Pci(0x1c,0x5)/Pci(0x0,0x0)/MAC(5cba2c1f6ce5,1)/IPv6([::]:<->[::]:,0,0)/Uri()N.....YM....R,Y.\nBoot0012* Embedded LOM 1 Port 1 : Intel(R) I210 Gigabit  Backplane Connection (PXE IPv6)\tPciRoot(0x0)/Pci(0x1c,0x5)/Pci(0x0,0x0)/MAC(5cba2c1f6ce5,1)/IPv6([::]:<->[::]:,0,0)N.....YM....R,Y.\nBoot0013* Embedded LOM 1 Port 1 : Intel(R) I210 Gigabit  Backplane Connection (HTTP(S) IPv4)\tPciRoot(0x0)/Pci(0x1c,0x5)/Pci(0x0,0x0)/MAC(5cba2c1f6ce5,1)/IPv4(0.0.0.00.0.0.0,0,0)/Uri()N.....YM....R,Y.\nBoot0014* Embedded LOM 1 Port 1 : Intel(R) I210 Gigabit  Backplane Connection (PXE IPv4)\tPciRoot(0x0)/Pci(0x1c,0x5)/Pci(0x0,0x0)/MAC(5cba2c1f6ce5,1)/IPv4(0.0.0.00.0.0.0,0,0)N.....YM....R,Y.\nBoot0015* Slot 2 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (HTTP(S) IPv6)\tPciRoot(0x1)/Pci(0x4,0x0)/Pci(0x0,0x0)/MAC(b49691da5ac4,1)/IPv6([::]:<->[::]:,0,0)/Uri()N.....YM....R,Y.\n"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="Boot0016* Slot 2 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (PXE IPv6)\tPciRoot(0x1)/Pci(0x4,0x0)/Pci(0x0,0x0)/MAC(b49691da5ac4,1)/IPv6([::]:<->[::]:,0,0)N.....YM....R,Y.\nBoot0017* Slot 2 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (HTTP(S) IPv4)\tPciRoot(0x1)/Pci(0x4,0x0)/Pci(0x0,0x0)/MAC(b49691da5ac4,1)/IPv4(0.0.0.00.0.0.0,0,0)/Uri()N.....YM....R,Y.\nBoot0018* Slot 2 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (PXE IPv4)\tPciRoot(0x1)/Pci(0x4,0x0)/Pci(0x0,0x0)/MAC(b49691da5ac4,1)/IPv4(0.0.0.00.0.0.0,0,0)N.....YM....R,Y.\nBoot0019* Slot 1 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (PXE IPv6)\tPciRoot(0x1)/Pci(0x2,0x0)/Pci(0x0,0x0)/MAC(b49691d9a464,1)/IPv6([::]:<->[::]:,0,0)N.....YM....R,Y.\nBoot001A* Slot 1 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (HTTP(S) IPv6)\tPciRoot(0x1)/Pci(0x2,0x0)/Pci(0x0,0x0)/MAC(b49691d9a464,1)/IPv6([::]:<->[::]:,0,0)/Uri()N.....YM....R,Y.\nBoot001B* Slot 1 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (HTTP(S) IPv4)\tPciRoot(0x1)/Pci(0x2,0x0)/Pci(0x0,0x0)/MAC(b49691d9a464,1)/IPv4(0.0.0.00.0.0.0,0,0)/Uri()N.....YM....R,Y.\nBoot001C* Slot 1 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (PXE IPv4)\tPciRoot(0x1)/Pci(0x2,0x0)/Pci(0x0,0x0)/MAC(b49691d9a464,1)/IPv4(0.0.0.00.0.0.0,0,0)N.....YM....R,Y.\nBoot001D* iLO Virtual USB 3 : iLO Virtual CD-ROM\tPciRoot(0x0)/Pci(0x1c,0x4)/Pci(0x0,0x4)/USB(1,0)N.....YM....R,Y.\nBoot001F* Red Hat Enterprise Linux\tHD(2,GPT,ca6858b5-957f-4a65-8830-6d730b9668b5,0x1000,0x3f800)/File(\\EFI\\redhat\\shimx64.efi)\nBoot001E* Red Hat Enterprise Linux\tHD(2,GPT,ca6858b5-957f-4a65-8830-6d730b9668b5,0x1000,0x3f800)/File(\\EFI\\redhat\\shimx64.efi)\n"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="Found duplicate value in boot manager: efibootmgr: ** Warning ** : Boot001F has same label Red Hat Enterprise Linux"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="Removing boot entry number 001F"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="Using EFI file 'shimx64.efi' for GOARCH 'amd64'"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="BootCurrent: 001D\nTimeout: 0 seconds\nBootOrder: 001E,000E,0013,0014,0011,0012,0017,0018,0015,0016,001B,001C,0019,001A,0009,000A,000B,000C,000D,0000,0001,0002,0005,0006,0007,0008,0003,0004,000F,0010,001D\nBoot0000* System Utilities\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(1fd631e5-44e0-2f91-10ab-f88f3568ef30)\nBoot0001  Non bootable Hotkey\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(4affaab0-1376-44b4-9c6e-e92388751bc6)\nBoot0002  Intelligent Provisioning\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(4a433501-ddaa-490b-96b2-04f42d8669b8)\nBoot0003  Embedded UEFI Shell\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(c57ad6b7-0515-40a8-9d21-551652854e37)\nBoot0004  Embedded iPXE\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(e22ad661-333a-4452-a101-64cc1898b837)\nBoot0005  Diagnose Error\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(0849279d-40d5-53ea-e764-2496766f9844)\nBoot0006  Boot Menu\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(d3fd6286-43c5-bb8d-0793-07b70aa9de36)\nBoot0007  Network Boot\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(0334f316-c276-49f6-9879-aaf1ecffa5d5)\nBoot0008  View Integrated Management Log\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(93c92423-d1c6-4286-be67-b76b6671047e)\nBoot0009  View GUI mode Integrated Management Log\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(f77778ab-a777-7777-9c58-60b5f0cba9d4)\nBoot000A  View BIOS Event Log\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(c20a40f3-4f7f-b41f-f614-628093c6b567)\nBoot000B  HTTP Boot\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(3f770860-3d63-4803-9ea3-df37144ab546)\nBoot000C  PXE Boot\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(ee8b26b0-37e9-11e1-b86c-0800200c9a66)\nBoot000D  Embedded Diagnostics\tFvVol(cdbb7b35-6833-4ed6-9ab2-57d2acddf6f0)/FvFile(b57fe6f1-4f49-d46e-4bba-0a8add34d2f3)\nBoot000E* Generic USB Boot\tUsbClass(ffff,ffff,255,255)\nBoot000F* Embedded NVMe M.2 Drive 1 : NVM Express Controller - S436NA0R757305-SAMSUNG MZ1LB1T9HALS-00007-0\tPciRoot(0x5)/Pci(0x3,0x0)/Pci(0x0,0x0)/NVMe(0x1,00-00-00-00-00-00-00-00)N.....YM....R,Y.\nBoot0010* Embedded NVMe M.2 Drive 2 : NVM Express Controller - S436NA0R757289-SAMSUNG MZ1LB1T9HALS-00007-0\tPciRoot(0x5)/Pci(0x4,0x0)/Pci(0x0,0x0)/NVMe(0x1,00-00-00-00-00-00-00-00)N.....YM....R,Y.\nBoot0011* Embedded LOM 1 Port 1 : Intel(R) I210 Gigabit  Backplane Connection (HTTP(S) IPv6)\tPciRoot(0x0)/Pci(0x1c,0x5)/Pci(0x0,0x0)/MAC(5cba2c1f6ce5,1)/IPv6([::]:<->[::]:,0,0)/Uri()N.....YM....R,Y.\nBoot0012* Embedded LOM 1 Port 1 : Intel(R) I210 Gigabit  Backplane Connection (PXE IPv6)\tPciRoot(0x0)/Pci(0x1c,0x5)/Pci(0x0,0x0)/MAC(5cba2c1f6ce5,1)/IPv6([::]:<->[::]:,0,0)N.....YM....R,Y.\nBoot0013* Embedded LOM 1 Port 1 : Intel(R) I210 Gigabit  Backplane Connection (HTTP(S) IPv4)\tPciRoot(0x0)/Pci(0x1c,0x5)/Pci(0x0,0x0)/MAC(5cba2c1f6ce5,1)/IPv4(0.0.0.00.0.0.0,0,0)/Uri()N.....YM....R,Y.\n"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="Boot0014* Embedded LOM 1 Port 1 : Intel(R) I210 Gigabit  Backplane Connection (PXE IPv4)\tPciRoot(0x0)/Pci(0x1c,0x5)/Pci(0x0,0x0)/MAC(5cba2c1f6ce5,1)/IPv4(0.0.0.00.0.0.0,0,0)N.....YM....R,Y.\nBoot0015* Slot 2 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (HTTP(S) IPv6)\tPciRoot(0x1)/Pci(0x4,0x0)/Pci(0x0,0x0)/MAC(b49691da5ac4,1)/IPv6([::]:<->[::]:,0,0)/Uri()N.....YM....R,Y.\nBoot0016* Slot 2 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (PXE IPv6)\tPciRoot(0x1)/Pci(0x4,0x0)/Pci(0x0,0x0)/MAC(b49691da5ac4,1)/IPv6([::]:<->[::]:,0,0)N.....YM....R,Y.\nBoot0017* Slot 2 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (HTTP(S) IPv4)\tPciRoot(0x1)/Pci(0x4,0x0)/Pci(0x0,0x0)/MAC(b49691da5ac4,1)/IPv4(0.0.0.00.0.0.0,0,0)/Uri()N.....YM....R,Y.\nBoot0018* Slot 2 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (PXE IPv4)\tPciRoot(0x1)/Pci(0x4,0x0)/Pci(0x0,0x0)/MAC(b49691da5ac4,1)/IPv4(0.0.0.00.0.0.0,0,0)N.....YM....R,Y.\nBoot0019* Slot 1 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (PXE IPv6)\tPciRoot(0x1)/Pci(0x2,0x0)/Pci(0x0,0x0)/MAC(b49691d9a464,1)/IPv6([::]:<->[::]:,0,0)N.....YM....R,Y.\nBoot001A* Slot 1 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (HTTP(S) IPv6)\tPciRoot(0x1)/Pci(0x2,0x0)/Pci(0x0,0x0)/MAC(b49691d9a464,1)/IPv6([::]:<->[::]:,0,0)/Uri()N.....YM....R,Y.\nBoot001B* Slot 1 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (HTTP(S) IPv4)\tPciRoot(0x1)/Pci(0x2,0x0)/Pci(0x0,0x0)/MAC(b49691d9a464,1)/IPv4(0.0.0.00.0.0.0,0,0)/Uri()N.....YM....R,Y.\nBoot001C* Slot 1 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (PXE IPv4)\tPciRoot(0x1)/Pci(0x2,0x0)/Pci(0x0,0x0)/MAC(b49691d9a464,1)/IPv4(0.0.0.00.0.0.0,0,0)N.....YM....R,Y.\nBoot001D* iLO Virtual USB 3 : iLO Virtual CD-ROM\tPciRoot(0x0)/Pci(0x1c,0x4)/Pci(0x0,0x4)/USB(1,0)N.....YM....R,Y.\nBoot001E* Red Hat Enterprise Linux\tHD(2,GPT,ca6858b5-957f-4a65-8830-6d730b9668b5,0x1000,0x3f800)/File(\\EFI\\redhat\\shimx64.efi)\n"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="Using EFI file 'shimx64.efi' for GOARCH 'amd64'"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="BootCurrent: 001D\nTimeout: 0 seconds\nBootOrder: 001E,000E,0013,0014,0011,0012,0017,0018,0015,0016,001B,001C,0019,001A,0009,000A,000B,000C,000D,0000,0001,0002,0005,0006,0007,0008,0003,0004,000F,0010,001D\nBoot0000* System Utilities\nBoot0001  Non bootable Hotkey\nBoot0002  Intelligent Provisioning\nBoot0003  Embedded UEFI Shell\nBoot0004  Embedded iPXE\nBoot0005  Diagnose Error\nBoot0006  Boot Menu\nBoot0007  Network Boot\nBoot0008  View Integrated Management Log\nBoot0009  View GUI mode Integrated Management Log\nBoot000A  View BIOS Event Log\nBoot000B  HTTP Boot\nBoot000C  PXE Boot\nBoot000D  Embedded Diagnostics\nBoot000E* Generic USB Boot\nBoot000F* Embedded NVMe M.2 Drive 1 : NVM Express Controller - S436NA0R757305-SAMSUNG MZ1LB1T9HALS-00007-0\nBoot0010* Embedded NVMe M.2 Drive 2 : NVM Express Controller - S436NA0R757289-SAMSUNG MZ1LB1T9HALS-00007-0\nBoot0011* Embedded LOM 1 Port 1 : Intel(R) I210 Gigabit  Backplane Connection (HTTP(S) IPv6)\nBoot0012* Embedded LOM 1 Port 1 : Intel(R) I210 Gigabit  Backplane Connection (PXE IPv6)\nBoot0013* Embedded LOM 1 Port 1 : Intel(R) I210 Gigabit  Backplane Connection (HTTP(S) IPv4)\nBoot0014* Embedded LOM 1 Port 1 : Intel(R) I210 Gigabit  Backplane Connection (PXE IPv4)\nBoot0015* Slot 2 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (HTTP(S) IPv6)\nBoot0016* Slot 2 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (PXE IPv6)\nBoot0017* Slot 2 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (HTTP(S) IPv4)\nBoot0018* Slot 2 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (PXE IPv4)\nBoot0019* Slot 1 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (PXE IPv6)\nBoot001A* Slot 1 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (HTTP(S) IPv6)\nBoot001B* Slot 1 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (HTTP(S) IPv4)\nBoot001C* Slot 1 Port 1 : Intel(R) Ethernet Network Adapter E810-XXV-4 (PXE IPv4)\nBoot001D* iLO Virtual USB 3 : iLO Virtual CD-ROM\nBoot001E* Red Hat Enterprise Linux\n"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="Uploading logs and reporting status before rebooting the node 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f for cluster 348785c6-46bc-472b-80be-59bd077b9966"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:15Z" level=info msg="update log progress on host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra-env 5f396111-46ed-4173-9648-bc0a9a818139 to requested" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostLogsProgress" file="/src/internal/bminventory/inventory.go:5750" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=78537c1e-cec3-479a-b115-6a8447c81317
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:15Z" level=info msg="host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f has been updated with the following log progress [logs_info requested logs_started_at 2023-06-06T02:15:15.646Z]" func=github.com/openshift/assisted-service/internal/host/hostutil.UpdateLogsProgress file="/src/internal/host/hostutil/update_host.go:49" go-id=1802 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=host-state request_id=78537c1e-cec3-479a-b115-6a8447c81317
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab systemd[1]: Started libpod-conmon-8dec1e193a7c70bda8831ffb84f6d50b51f8359404143a950a0be7c2e5bc7a86.scope.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab systemd[1]: Started libcontainer container 8dec1e193a7c70bda8831ffb84f6d50b51f8359404143a950a0be7c2e5bc7a86.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=warning msg="Certificate verification is turned off. This is not recommended in production environments" file="inventory_session.go:126"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:15Z" level=info msg="update log progress on host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra-env 5f396111-46ed-4173-9648-bc0a9a818139 to requested" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostLogsProgress" file="/src/internal/bminventory/inventory.go:5750" go-id=2210 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=800fc70a-74b7-40d5-998b-3af46b6d44ea
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Start gathering journalctl logs with tags [agent installer], services [bootkube] and installer-gather" file="send_logs.go:356"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:15Z" level=info msg="host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f has been updated with the following log progress [logs_info requested logs_started_at 2023-06-06T02:15:15.802Z]" func=github.com/openshift/assisted-service/internal/host/hostutil.UpdateLogsProgress file="/src/internal/host/hostutil/update_host.go:49" go-id=2210 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=host-state request_id=800fc70a-74b7-40d5-998b-3af46b6d44ea
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="List block devices" file="execute.go:49"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- /usr/bin/lsblk -o NAME,MAJ:MIN,SIZE,TYPE,FSTYPE,KNAME,MODEL,UUID,WWN,HCTL,VENDOR,STATE,TRAN,PKNAME]" file="execute.go:39"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="List mounts" file="execute.go:49"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- /usr/bin/findmnt --df]" file="execute.go:39"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Disk mapping by id" file="execute.go:49"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- /bin/ls -l /dev/disk/by-id]" file="execute.go:39"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Disk mapping by path" file="execute.go:49"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- /bin/ls -l /dev/disk/by-path]" file="execute.go:39"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Running pvdisplay" file="execute.go:49"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- /usr/sbin/pvdisplay -v]" file="execute.go:39"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Running vgdisplay" file="execute.go:49"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- /usr/sbin/vgdisplay -v]" file="execute.go:39"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Running lvdisplay" file="execute.go:49"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Executing nsenter [--target 1 --cgroup --mount --ipc --net -- /usr/sbin/lvdisplay -v]" file="execute.go:39"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Running journalctl [TAG=agent]" file="send_logs.go:310"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Running journalctl [TAG=installer]" file="send_logs.go:310"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Running journalctl [-u bootkube]" file="send_logs.go:310"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:15Z" level=info msg="update log progress on host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra-env 5f396111-46ed-4173-9648-bc0a9a818139 to collecting" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostLogsProgress" file="/src/internal/bminventory/inventory.go:5750" go-id=2210 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=800fc70a-74b7-40d5-998b-3af46b6d44ea
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:15Z" level=info msg="host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f has been updated with the following log progress [logs_info collecting]" func=github.com/openshift/assisted-service/internal/host/hostutil.UpdateLogsProgress file="/src/internal/host/hostutil/update_host.go:49" go-id=2210 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=host-state request_id=800fc70a-74b7-40d5-998b-3af46b6d44ea
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Archiving /var/log/logs_host_1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f and creating /var/log/logs.tar.gz" file="send_logs.go:331"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab logs_sender[16258]: time="06-06-2023 02:15:15" level=info msg="Executing tar [-czvf /var/log/logs.tar.gz -C /var/log logs_host_1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f]" file="execute.go:39"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:15Z" level=info msg="Uploading logs from cluster 348785c6-46bc-472b-80be-59bd077b9966" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).v2uploadLogs" file="/src/internal/bminventory/inventory_v2_handlers.go:459" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=2210 pkg=Inventory request_id=800fc70a-74b7-40d5-998b-3af46b6d44ea
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:15Z" level=info msg="Successfully uploaded file 348785c6-46bc-472b-80be-59bd077b9966/logs/1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f/logs.tar.gz" func="github.com/openshift/assisted-service/pkg/s3wrapper.(*FSClient).UploadStream" file="/src/pkg/s3wrapper/filesystem.go:134" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=2210 request_id=800fc70a-74b7-40d5-998b-3af46b6d44ea
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:15Z" level=info msg="host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f has been updated with the following log progress [logs_info collecting]" func=github.com/openshift/assisted-service/internal/host/hostutil.UpdateLogsProgress file="/src/internal/host/hostutil/update_host.go:49" cluster_id=348785c6-46bc-472b-80be-59bd077b9966 go-id=2210 pkg=host-state request_id=800fc70a-74b7-40d5-998b-3af46b6d44ea
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:15Z" level=info msg="update log progress on host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra-env 5f396111-46ed-4173-9648-bc0a9a818139 to completed" func="github.com/openshift/assisted-service/internal/bminventory.(*bareMetalInventory).V2UpdateHostLogsProgress" file="/src/internal/bminventory/inventory.go:5750" go-id=2210 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=Inventory request_id=800fc70a-74b7-40d5-998b-3af46b6d44ea
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab service[3916]: time="2023-06-06T02:15:15Z" level=info msg="host 1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f has been updated with the following log progress [logs_info completed]" func=github.com/openshift/assisted-service/internal/host/hostutil.UpdateLogsProgress file="/src/internal/host/hostutil/update_host.go:49" go-id=2210 host_id=1f3ce9a8-afcb-f4a5-790f-5d1961a70a1f infra_env_id=5f396111-46ed-4173-9648-bc0a9a818139 pkg=host-state request_id=800fc70a-74b7-40d5-998b-3af46b6d44ea
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab installer[6411]: time="2023-06-06T02:15:15Z" level=info msg="Logs were sent\n2 errors occurred:\n\t* /usr/sbin/vgdisplay failed: 0   No volume groups found.\n\n\n\t* /usr/sbin/lvdisplay failed: 0   No volume groups found.\n\n\n\n\n"
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab systemd[1]: libpod-8dec1e193a7c70bda8831ffb84f6d50b51f8359404143a950a0be7c2e5bc7a86.scope: Deactivated successfully.
Jun 06 02:15:15 sno131.outbound.vz.bos2.lab systemd[1]: libpod-conmon-8dec1e193a7c70bda8831ffb84f6d50b51f8359404143a950a0be7c2e5bc7a86.scope: Deactivated successfully.

Broadcast message from root@localhost (Tue 2023-06-06 02:15:16 UTC):

The system will reboot now!

Connection to 192.168.14.27 closed by remote host.
Connection to 192.168.14.27 closed.
[root@hub-helper ~]# 